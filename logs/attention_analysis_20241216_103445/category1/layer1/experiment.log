WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-12-16 10:39:03.358440: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-16 10:39:03.454505: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2024-12-16 10:39:03.454894: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x417c860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-16 10:39:03.454908: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-16 10:39:03.458062: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-16 10:39:03.595090: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x41797e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-16 10:39:03.595109: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-12-16 10:39:03.595637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:2f:00.0
2024-12-16 10:39:03.596853: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:39:03.597951: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:39:03.599014: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:39:03.600060: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:39:03.601103: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:39:03.602166: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:39:03.603241: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:39:03.603253: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-12-16 10:39:03.603270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-16 10:39:03.603275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-16 10:39:03.603278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:61: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:87: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:15: sigmoid_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.sigmoid_cross_entropy instead. Note that the order of the predictions and labels arguments has been changed.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:322: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:82: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.


Verifying paths:
tc_path: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs exists
weight_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists
image_path: /scratch/hy2611/CNN_attention/Data/VGG16/images exists
save_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists

Initializing model...
('c11', [1, 224, 224, 64])
('c12', [1, 224, 224, 64])
('c21', [1, 112, 112, 128])
('c22', [1, 112, 112, 128])
('c31', [1, 56, 56, 256])
('c32', [1, 56, 56, 256])
('c33', [1, 56, 56, 256])
('c41', [1, 28, 28, 512])
('c42', [1, 28, 28, 512])
('c43', [1, 28, 28, 512])
('c51', [1, 14, 14, 512])
('c52', [1, 14, 14, 512])
('c53', [1, 14, 14, 512])
(0, 'conv1_1_W', (3, 3, 3, 64))
(1, 'conv1_1_b', (64,))
(2, 'conv1_2_W', (3, 3, 64, 64))
(3, 'conv1_2_b', (64,))
(4, 'conv2_1_W', (3, 3, 64, 128))
(5, 'conv2_1_b', (128,))
(6, 'conv2_2_W', (3, 3, 128, 128))
(7, 'conv2_2_b', (128,))
(8, 'conv3_1_W', (3, 3, 128, 256))
(9, 'conv3_1_b', (256,))
(10, 'conv3_2_W', (3, 3, 256, 256))
(11, 'conv3_2_b', (256,))
(12, 'conv3_3_W', (3, 3, 256, 256))
(13, 'conv3_3_b', (256,))
(14, 'conv4_1_W', (3, 3, 256, 512))
(15, 'conv4_1_b', (512,))
(16, 'conv4_2_W', (3, 3, 512, 512))
(17, 'conv4_2_b', (512,))
(18, 'conv4_3_W', (3, 3, 512, 512))
(19, 'conv4_3_b', (512,))
(20, 'conv5_1_W', (3, 3, 512, 512))
(21, 'conv5_1_b', (512,))
(22, 'conv5_2_W', (3, 3, 512, 512))
(23, 'conv5_2_b', (512,))
(24, 'conv5_3_W', (3, 3, 512, 512))
(25, 'conv5_3_b', (512,))
(26, 'fc6_W', (25088, 4096))
(27, 'fc6_b', (4096,))
(28, 'fc7_W', (4096, 4096))
(29, 'fc7_b', (4096,))
Checking checkpoint files:
Data file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_1.ckpt.data-00000-of-00001 - Found
Index file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_1.ckpt.index - Found
Loading checkpoint from: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_1.ckpt
Checkpoint loaded successfully

Initializing components...
Found tuning curves file: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs/featvecs20_train35_c.txt

Loading category 1 data...
Original positive images shape: (2, 224, 224, 3)

Processing data...

Processing attention strength 0.0
Attention vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

Processing batch 1/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.08070, std=0.07069
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.08070, std: 0.07069
Attention - min: 0.00000, max: 1.00000, mean: 0.43693, std: 0.13061

Metrics for layer 0:
  pearson_correlation: -0.0033
  kl_divergence: -5396.0615
  ssim: 0.0537
  iou: 0.1423
Layer 0 metrics:
  pearson_correlation: -0.0033
  kl_divergence: -5396.0615
  ssim: 0.0537
  iou: 0.1423

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.08070, std: 0.07069
Attention - min: 0.00000, max: 1.00000, mean: 0.42841, std: 0.12131

Metrics for layer 1:
  pearson_correlation: -0.0044
  kl_divergence: -5338.7183
  ssim: 0.0624
  iou: 0.1400
Layer 1 metrics:
  pearson_correlation: -0.0044
  kl_divergence: -5338.7183
  ssim: 0.0624
  iou: 0.1400

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11663, std: 0.08958
Attention - min: 0.00000, max: 1.00000, mean: 0.39363, std: 0.11000

Metrics for layer 2:
  pearson_correlation: -0.0064
  kl_divergence: -1350.2247
  ssim: 0.0907
  iou: 0.1404
Layer 2 metrics:
  pearson_correlation: -0.0064
  kl_divergence: -1350.2247
  ssim: 0.0907
  iou: 0.1404

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11663, std: 0.08958
Attention - min: 0.00000, max: 1.00000, mean: 0.44022, std: 0.13103

Metrics for layer 3:
  pearson_correlation: -0.0107
  kl_divergence: -1496.9230
  ssim: 0.0672
  iou: 0.1360
Layer 3 metrics:
  pearson_correlation: -0.0107
  kl_divergence: -1496.9230
  ssim: 0.0672
  iou: 0.1360

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12090, std: 0.09242
Attention - min: 0.00000, max: 1.00000, mean: 0.41972, std: 0.12644

Metrics for layer 4:
  pearson_correlation: -0.0215
  kl_divergence: -352.3780
  ssim: 0.0709
  iou: 0.1354
Layer 4 metrics:
  pearson_correlation: -0.0215
  kl_divergence: -352.3780
  ssim: 0.0709
  iou: 0.1354

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12090, std: 0.09242
Attention - min: 0.00000, max: 1.00000, mean: 0.45999, std: 0.13581

Metrics for layer 5:
  pearson_correlation: 0.0044
  kl_divergence: -391.7101
  ssim: 0.0641
  iou: 0.1429
Layer 5 metrics:
  pearson_correlation: 0.0044
  kl_divergence: -391.7101
  ssim: 0.0641
  iou: 0.1429

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12090, std: 0.09242
Attention - min: 0.00000, max: 1.00000, mean: 0.51432, std: 0.14658

Metrics for layer 6:
  pearson_correlation: -0.0143
  kl_divergence: -428.9968
  ssim: 0.0495
  iou: 0.1329
Layer 6 metrics:
  pearson_correlation: -0.0143
  kl_divergence: -428.9968
  ssim: 0.0495
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.22487, std: 0.17192
Attention - min: 0.00000, max: 1.00000, mean: 0.51193, std: 0.18057

Metrics for layer 7:
  pearson_correlation: -0.0315
  kl_divergence: -78.8603
  ssim: 0.0065
  iou: 0.1529
Layer 7 metrics:
  pearson_correlation: -0.0315
  kl_divergence: -78.8603
  ssim: 0.0065
  iou: 0.1529

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.22487, std: 0.17192
Attention - min: 0.00000, max: 1.00000, mean: 0.51835, std: 0.16945

Metrics for layer 8:
  pearson_correlation: -0.0196
  kl_divergence: -87.0046
  ssim: 0.0128
  iou: 0.1168
Layer 8 metrics:
  pearson_correlation: -0.0196
  kl_divergence: -87.0046
  ssim: 0.0128
  iou: 0.1168

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.22487, std: 0.17192
Attention - min: 0.00000, max: 1.00000, mean: 0.48058, std: 0.16373

Metrics for layer 9:
  pearson_correlation: -0.0046
  kl_divergence: -66.4483
  ssim: 0.0333
  iou: 0.1496
Layer 9 metrics:
  pearson_correlation: -0.0046
  kl_divergence: -66.4483
  ssim: 0.0333
  iou: 0.1496

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17662, std: 0.15432
Attention - min: 0.00000, max: 1.00000, mean: 0.38063, std: 0.14587

Metrics for layer 10:
  pearson_correlation: 0.0818
  kl_divergence: -13.1132
  ssim: 0.1353
  iou: 0.1667
Layer 10 metrics:
  pearson_correlation: 0.0818
  kl_divergence: -13.1132
  ssim: 0.1353
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17662, std: 0.15432
Attention - min: 0.00000, max: 1.00000, mean: 0.43024, std: 0.18058

Metrics for layer 11:
  pearson_correlation: -0.1100
  kl_divergence: -9.1525
  ssim: -0.0475
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: -0.1100
  kl_divergence: -9.1525
  ssim: -0.0475
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17662, std: 0.15432
Attention - min: 0.00000, max: 1.00000, mean: 0.43701, std: 0.21303

Metrics for layer 12:
  pearson_correlation: -0.0455
  kl_divergence: -12.9610
  ssim: -0.0466
  iou: 0.0889
Layer 12 metrics:
  pearson_correlation: -0.0455
  kl_divergence: -12.9610
  ssim: -0.0466
  iou: 0.0889
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.08070, std=0.07069
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat1_layer1/batch_0_strength_0.0_results.npy

Processing batch 2/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06196, std=0.06672
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06196, std: 0.06672
Attention - min: 0.00000, max: 1.00000, mean: 0.45350, std: 0.11678

Metrics for layer 0:
  pearson_correlation: 0.0041
  kl_divergence: -4715.6812
  ssim: 0.0488
  iou: 0.1436
Layer 0 metrics:
  pearson_correlation: 0.0041
  kl_divergence: -4715.6812
  ssim: 0.0488
  iou: 0.1436

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06196, std: 0.06672
Attention - min: 0.00000, max: 1.00000, mean: 0.41551, std: 0.12003

Metrics for layer 1:
  pearson_correlation: 0.0096
  kl_divergence: -4417.9595
  ssim: 0.0506
  iou: 0.1458
Layer 1 metrics:
  pearson_correlation: 0.0096
  kl_divergence: -4417.9595
  ssim: 0.0506
  iou: 0.1458

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.08710, std: 0.08256
Attention - min: 0.00000, max: 1.00000, mean: 0.50883, std: 0.12113

Metrics for layer 2:
  pearson_correlation: 0.0084
  kl_divergence: -1493.2904
  ssim: 0.0590
  iou: 0.1454
Layer 2 metrics:
  pearson_correlation: 0.0084
  kl_divergence: -1493.2904
  ssim: 0.0590
  iou: 0.1454

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.08710, std: 0.08256
Attention - min: 0.00000, max: 1.00000, mean: 0.48661, std: 0.12651

Metrics for layer 3:
  pearson_correlation: 0.0006
  kl_divergence: -1432.0737
  ssim: 0.0555
  iou: 0.1377
Layer 3 metrics:
  pearson_correlation: 0.0006
  kl_divergence: -1432.0737
  ssim: 0.0555
  iou: 0.1377

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12277, std: 0.11698
Attention - min: 0.00000, max: 1.00000, mean: 0.44045, std: 0.14148

Metrics for layer 4:
  pearson_correlation: -0.0152
  kl_divergence: -320.5254
  ssim: 0.0713
  iou: 0.1281
Layer 4 metrics:
  pearson_correlation: -0.0152
  kl_divergence: -320.5254
  ssim: 0.0713
  iou: 0.1281

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12277, std: 0.11698
Attention - min: 0.00000, max: 1.00000, mean: 0.45325, std: 0.14258

Metrics for layer 5:
  pearson_correlation: -0.0074
  kl_divergence: -333.0970
  ssim: 0.0545
  iou: 0.1470
Layer 5 metrics:
  pearson_correlation: -0.0074
  kl_divergence: -333.0970
  ssim: 0.0545
  iou: 0.1470

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12277, std: 0.11698
Attention - min: 0.00000, max: 1.00000, mean: 0.48784, std: 0.12926

Metrics for layer 6:
  pearson_correlation: -0.0305
  kl_divergence: -366.8416
  ssim: 0.0572
  iou: 0.1329
Layer 6 metrics:
  pearson_correlation: -0.0305
  kl_divergence: -366.8416
  ssim: 0.0572
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.10849, std: 0.10530
Attention - min: 0.00000, max: 1.00000, mean: 0.45733, std: 0.15370

Metrics for layer 7:
  pearson_correlation: 0.0474
  kl_divergence: -84.6651
  ssim: 0.0677
  iou: 0.1598
Layer 7 metrics:
  pearson_correlation: 0.0474
  kl_divergence: -84.6651
  ssim: 0.0677
  iou: 0.1598

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.10849, std: 0.10530
Attention - min: 0.00000, max: 1.00000, mean: 0.48148, std: 0.17102

Metrics for layer 8:
  pearson_correlation: 0.0613
  kl_divergence: -87.6035
  ssim: 0.0601
  iou: 0.1529
Layer 8 metrics:
  pearson_correlation: 0.0613
  kl_divergence: -87.6035
  ssim: 0.0601
  iou: 0.1529

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.10849, std: 0.10530
Attention - min: 0.00000, max: 1.00000, mean: 0.49857, std: 0.16668

Metrics for layer 9:
  pearson_correlation: 0.0342
  kl_divergence: -90.4031
  ssim: 0.0614
  iou: 0.1496
Layer 9 metrics:
  pearson_correlation: 0.0342
  kl_divergence: -90.4031
  ssim: 0.0614
  iou: 0.1496

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13446, std: 0.14771
Attention - min: 0.00000, max: 1.00000, mean: 0.42464, std: 0.16404

Metrics for layer 10:
  pearson_correlation: 0.0506
  kl_divergence: -15.2485
  ssim: 0.0678
  iou: 0.1395
Layer 10 metrics:
  pearson_correlation: 0.0506
  kl_divergence: -15.2485
  ssim: 0.0678
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13446, std: 0.14771
Attention - min: 0.00000, max: 1.00000, mean: 0.41924, std: 0.15949

Metrics for layer 11:
  pearson_correlation: -0.0198
  kl_divergence: -14.8367
  ssim: -0.0092
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: -0.0198
  kl_divergence: -14.8367
  ssim: -0.0092
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13446, std: 0.14771
Attention - min: 0.00000, max: 1.00000, mean: 0.48806, std: 0.16646

Metrics for layer 12:
  pearson_correlation: 0.0555
  kl_divergence: -20.7075
  ssim: 0.0581
  iou: 0.1264
Layer 12 metrics:
  pearson_correlation: 0.0555
  kl_divergence: -20.7075
  ssim: 0.0581
  iou: 0.1264
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06196, std=0.06672
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat1_layer1/batch_1_strength_0.0_results.npy

Processing attention strength 0.2
Attention vector: [0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.08070, std=0.07069
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.08070, std: 0.07069
Attention - min: 0.00000, max: 1.00000, mean: 0.41921, std: 0.10997

Metrics for layer 0:
  pearson_correlation: 0.0070
  kl_divergence: -5290.8340
  ssim: 0.0729
  iou: 0.1463
Layer 0 metrics:
  pearson_correlation: 0.0070
  kl_divergence: -5290.8340
  ssim: 0.0729
  iou: 0.1463

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.08070, std: 0.07069
Attention - min: 0.00000, max: 1.00000, mean: 0.50604, std: 0.11742

Metrics for layer 1:
  pearson_correlation: 0.0016
  kl_divergence: -6078.3462
  ssim: 0.0551
  iou: 0.1445
Layer 1 metrics:
  pearson_correlation: 0.0016
  kl_divergence: -6078.3462
  ssim: 0.0551
  iou: 0.1445

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11663, std: 0.08958
Attention - min: 0.00000, max: 1.00000, mean: 0.47221, std: 0.11872

Metrics for layer 2:
  pearson_correlation: 0.0063
  kl_divergence: -1631.2819
  ssim: 0.0759
  iou: 0.1443
Layer 2 metrics:
  pearson_correlation: 0.0063
  kl_divergence: -1631.2819
  ssim: 0.0759
  iou: 0.1443

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11663, std: 0.08958
Attention - min: 0.00000, max: 1.00000, mean: 0.43176, std: 0.12406

Metrics for layer 3:
  pearson_correlation: 0.0018
  kl_divergence: -1480.2531
  ssim: 0.0779
  iou: 0.1424
Layer 3 metrics:
  pearson_correlation: 0.0018
  kl_divergence: -1480.2531
  ssim: 0.0779
  iou: 0.1424

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12090, std: 0.09242
Attention - min: 0.00000, max: 1.00000, mean: 0.54206, std: 0.14521

Metrics for layer 4:
  pearson_correlation: 0.0149
  kl_divergence: -458.5574
  ssim: 0.0629
  iou: 0.1521
Layer 4 metrics:
  pearson_correlation: 0.0149
  kl_divergence: -458.5574
  ssim: 0.0629
  iou: 0.1521

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12090, std: 0.09242
Attention - min: 0.00000, max: 1.00000, mean: 0.45984, std: 0.13614

Metrics for layer 5:
  pearson_correlation: -0.0103
  kl_divergence: -388.9478
  ssim: 0.0673
  iou: 0.1371
Layer 5 metrics:
  pearson_correlation: -0.0103
  kl_divergence: -388.9478
  ssim: 0.0673
  iou: 0.1371

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12090, std: 0.09242
Attention - min: 0.00000, max: 1.00000, mean: 0.45247, std: 0.14345

Metrics for layer 6:
  pearson_correlation: 0.0035
  kl_divergence: -375.7807
  ssim: 0.0669
  iou: 0.1572
Layer 6 metrics:
  pearson_correlation: 0.0035
  kl_divergence: -375.7807
  ssim: 0.0669
  iou: 0.1572

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.22487, std: 0.17192
Attention - min: 0.00000, max: 1.00000, mean: 0.45059, std: 0.15230

Metrics for layer 7:
  pearson_correlation: 0.0437
  kl_divergence: -62.2931
  ssim: 0.0971
  iou: 0.1667
Layer 7 metrics:
  pearson_correlation: 0.0437
  kl_divergence: -62.2931
  ssim: 0.0971
  iou: 0.1667

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.22487, std: 0.17192
Attention - min: 0.00000, max: 1.00000, mean: 0.55389, std: 0.14983

Metrics for layer 8:
  pearson_correlation: -0.0104
  kl_divergence: -104.6125
  ssim: 0.0557
  iou: 0.1264
Layer 8 metrics:
  pearson_correlation: -0.0104
  kl_divergence: -104.6125
  ssim: 0.0557
  iou: 0.1264

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.22487, std: 0.17192
Attention - min: 0.00000, max: 1.00000, mean: 0.41725, std: 0.15976

Metrics for layer 9:
  pearson_correlation: 0.0123
  kl_divergence: -41.6811
  ssim: 0.0755
  iou: 0.1632
Layer 9 metrics:
  pearson_correlation: 0.0123
  kl_divergence: -41.6811
  ssim: 0.0755
  iou: 0.1632

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17662, std: 0.15432
Attention - min: 0.00000, max: 1.00000, mean: 0.45967, std: 0.18153

Metrics for layer 10:
  pearson_correlation: 0.0487
  kl_divergence: -17.0317
  ssim: 0.0661
  iou: 0.1264
Layer 10 metrics:
  pearson_correlation: 0.0487
  kl_divergence: -17.0317
  ssim: 0.0661
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17662, std: 0.15432
Attention - min: 0.00000, max: 1.00000, mean: 0.45978, std: 0.16384

Metrics for layer 11:
  pearson_correlation: -0.0522
  kl_divergence: -10.2784
  ssim: 0.0673
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: -0.0522
  kl_divergence