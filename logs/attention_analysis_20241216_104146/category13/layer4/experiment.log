WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-12-16 11:30:09.143748: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-16 11:30:09.163501: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2024-12-16 11:30:09.163945: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56959f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:30:09.163955: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-16 11:30:09.166606: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-16 11:30:09.298089: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x568cbb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:30:09.298108: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-12-16 11:30:09.298640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:2f:00.0
2024-12-16 11:30:09.299725: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:30:09.300708: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:30:09.301659: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:30:09.302802: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:30:09.303755: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:30:09.304693: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:30:09.305635: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:30:09.305647: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-12-16 11:30:09.305665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-16 11:30:09.305670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-16 11:30:09.305673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:61: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:87: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:15: sigmoid_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.sigmoid_cross_entropy instead. Note that the order of the predictions and labels arguments has been changed.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:322: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:82: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.


Verifying paths:
tc_path: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs exists
weight_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists
image_path: /scratch/hy2611/CNN_attention/Data/VGG16/images exists
save_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists

Initializing model...
('c11', [1, 224, 224, 64])
('c12', [1, 224, 224, 64])
('c21', [1, 112, 112, 128])
('c22', [1, 112, 112, 128])
('c31', [1, 56, 56, 256])
('c32', [1, 56, 56, 256])
('c33', [1, 56, 56, 256])
('c41', [1, 28, 28, 512])
('c42', [1, 28, 28, 512])
('c43', [1, 28, 28, 512])
('c51', [1, 14, 14, 512])
('c52', [1, 14, 14, 512])
('c53', [1, 14, 14, 512])
(0, 'conv1_1_W', (3, 3, 3, 64))
(1, 'conv1_1_b', (64,))
(2, 'conv1_2_W', (3, 3, 64, 64))
(3, 'conv1_2_b', (64,))
(4, 'conv2_1_W', (3, 3, 64, 128))
(5, 'conv2_1_b', (128,))
(6, 'conv2_2_W', (3, 3, 128, 128))
(7, 'conv2_2_b', (128,))
(8, 'conv3_1_W', (3, 3, 128, 256))
(9, 'conv3_1_b', (256,))
(10, 'conv3_2_W', (3, 3, 256, 256))
(11, 'conv3_2_b', (256,))
(12, 'conv3_3_W', (3, 3, 256, 256))
(13, 'conv3_3_b', (256,))
(14, 'conv4_1_W', (3, 3, 256, 512))
(15, 'conv4_1_b', (512,))
(16, 'conv4_2_W', (3, 3, 512, 512))
(17, 'conv4_2_b', (512,))
(18, 'conv4_3_W', (3, 3, 512, 512))
(19, 'conv4_3_b', (512,))
(20, 'conv5_1_W', (3, 3, 512, 512))
(21, 'conv5_1_b', (512,))
(22, 'conv5_2_W', (3, 3, 512, 512))
(23, 'conv5_2_b', (512,))
(24, 'conv5_3_W', (3, 3, 512, 512))
(25, 'conv5_3_b', (512,))
(26, 'fc6_W', (25088, 4096))
(27, 'fc6_b', (4096,))
(28, 'fc7_W', (4096, 4096))
(29, 'fc7_b', (4096,))
Checking checkpoint files:
Data file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_13.ckpt.data-00000-of-00001 - Found
Index file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_13.ckpt.index - Found
Loading checkpoint from: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_13.ckpt
Checkpoint loaded successfully

Initializing components...
Found tuning curves file: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs/featvecs20_train35_c.txt

Loading category 13 data...
Original positive images shape: (2, 224, 224, 3)

Processing data...

Processing attention strength 0.0
Attention vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

Processing batch 1/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.43759, std: 0.12044

Metrics for layer 0:
  pearson_correlation: 0.0035
  kl_divergence: -4807.5127
  ssim: 0.0510
  iou: 0.1456
Layer 0 metrics:
  pearson_correlation: 0.0035
  kl_divergence: -4807.5127
  ssim: 0.0510
  iou: 0.1456

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.40860, std: 0.12071

Metrics for layer 1:
  pearson_correlation: 0.0006
  kl_divergence: -4558.8066
  ssim: 0.0523
  iou: 0.1421
Layer 1 metrics:
  pearson_correlation: 0.0006
  kl_divergence: -4558.8066
  ssim: 0.0523
  iou: 0.1421

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.46684, std: 0.14048

Metrics for layer 2:
  pearson_correlation: 0.0025
  kl_divergence: -1508.2336
  ssim: 0.0512
  iou: 0.1433
Layer 2 metrics:
  pearson_correlation: 0.0025
  kl_divergence: -1508.2336
  ssim: 0.0512
  iou: 0.1433

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.47078, std: 0.12694

Metrics for layer 3:
  pearson_correlation: 0.0089
  kl_divergence: -1534.1853
  ssim: 0.0674
  iou: 0.1443
Layer 3 metrics:
  pearson_correlation: 0.0089
  kl_divergence: -1534.1853
  ssim: 0.0674
  iou: 0.1443

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.49918, std: 0.15286

Metrics for layer 4:
  pearson_correlation: 0.0158
  kl_divergence: -409.8537
  ssim: 0.0621
  iou: 0.1538
Layer 4 metrics:
  pearson_correlation: 0.0158
  kl_divergence: -409.8537
  ssim: 0.0621
  iou: 0.1538

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.45198, std: 0.13624

Metrics for layer 5:
  pearson_correlation: 0.0250
  kl_divergence: -373.9251
  ssim: 0.0640
  iou: 0.1496
Layer 5 metrics:
  pearson_correlation: 0.0250
  kl_divergence: -373.9251
  ssim: 0.0640
  iou: 0.1496

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.47509, std: 0.14396

Metrics for layer 6:
  pearson_correlation: -0.0143
  kl_divergence: -383.2456
  ssim: 0.0436
  iou: 0.1487
Layer 6 metrics:
  pearson_correlation: -0.0143
  kl_divergence: -383.2456
  ssim: 0.0436
  iou: 0.1487

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.50413, std: 0.18565

Metrics for layer 7:
  pearson_correlation: 0.0164
  kl_divergence: -95.8327
  ssim: 0.0605
  iou: 0.1362
Layer 7 metrics:
  pearson_correlation: 0.0164
  kl_divergence: -95.8327
  ssim: 0.0605
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.54060, std: 0.14651

Metrics for layer 8:
  pearson_correlation: -0.0091
  kl_divergence: -108.7196
  ssim: 0.0612
  iou: 0.1462
Layer 8 metrics:
  pearson_correlation: -0.0091
  kl_divergence: -108.7196
  ssim: 0.0612
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.47376, std: 0.17704

Metrics for layer 9:
  pearson_correlation: 0.0713
  kl_divergence: -92.5144
  ssim: 0.0629
  iou: 0.1772
Layer 9 metrics:
  pearson_correlation: 0.0713
  kl_divergence: -92.5144
  ssim: 0.0629
  iou: 0.1772

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.49760, std: 0.19779

Metrics for layer 10:
  pearson_correlation: 0.0056
  kl_divergence: -19.7462
  ssim: 0.0600
  iou: 0.1264
Layer 10 metrics:
  pearson_correlation: 0.0056
  kl_divergence: -19.7462
  ssim: 0.0600
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.56584, std: 0.15418

Metrics for layer 11:
  pearson_correlation: 0.0233
  kl_divergence: -25.5451
  ssim: 0.0446
  iou: 0.1807
Layer 11 metrics:
  pearson_correlation: 0.0233
  kl_divergence: -25.5451
  ssim: 0.0446
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.51499, std: 0.18241

Metrics for layer 12:
  pearson_correlation: 0.0773
  kl_divergence: -19.5117
  ssim: 0.0453
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: 0.0773
  kl_divergence: -19.5117
  ssim: 0.0453
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer4/batch_0_strength_0.0_results.npy

Processing batch 2/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.43006, std: 0.11843

Metrics for layer 0:
  pearson_correlation: -0.0102
  kl_divergence: -5436.2930
  ssim: 0.0630
  iou: 0.1407
Layer 0 metrics:
  pearson_correlation: -0.0102
  kl_divergence: -5436.2930
  ssim: 0.0630
  iou: 0.1407

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.46958, std: 0.12197

Metrics for layer 1:
  pearson_correlation: 0.0073
  kl_divergence: -5893.5859
  ssim: 0.0609
  iou: 0.1419
Layer 1 metrics:
  pearson_correlation: 0.0073
  kl_divergence: -5893.5859
  ssim: 0.0609
  iou: 0.1419

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.47222, std: 0.14055

Metrics for layer 2:
  pearson_correlation: -0.0058
  kl_divergence: -1637.8217
  ssim: 0.0623
  iou: 0.1379
Layer 2 metrics:
  pearson_correlation: -0.0058
  kl_divergence: -1637.8217
  ssim: 0.0623
  iou: 0.1379

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.44762, std: 0.11887

Metrics for layer 3:
  pearson_correlation: 0.0081
  kl_divergence: -1573.4048
  ssim: 0.0831
  iou: 0.1466
Layer 3 metrics:
  pearson_correlation: 0.0081
  kl_divergence: -1573.4048
  ssim: 0.0831
  iou: 0.1466

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.48309, std: 0.13738

Metrics for layer 4:
  pearson_correlation: -0.0307
  kl_divergence: -414.6959
  ssim: 0.0569
  iou: 0.1387
Layer 4 metrics:
  pearson_correlation: -0.0307
  kl_divergence: -414.6959
  ssim: 0.0569
  iou: 0.1387

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.46830, std: 0.14593

Metrics for layer 5:
  pearson_correlation: -0.0337
  kl_divergence: -382.4159
  ssim: 0.0497
  iou: 0.1354
Layer 5 metrics:
  pearson_correlation: -0.0337
  kl_divergence: -382.4159
  ssim: 0.0497
  iou: 0.1354

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.42442, std: 0.14388

Metrics for layer 6:
  pearson_correlation: -0.0007
  kl_divergence: -350.1523
  ssim: 0.0666
  iou: 0.1354
Layer 6 metrics:
  pearson_correlation: -0.0007
  kl_divergence: -350.1523
  ssim: 0.0666
  iou: 0.1354

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.45517, std: 0.16024

Metrics for layer 7:
  pearson_correlation: 0.0033
  kl_divergence: -82.1730
  ssim: 0.0318
  iou: 0.1297
Layer 7 metrics:
  pearson_correlation: 0.0033
  kl_divergence: -82.1730
  ssim: 0.0318
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.47320, std: 0.16681

Metrics for layer 8:
  pearson_correlation: 0.0286
  kl_divergence: -86.2546
  ssim: 0.0604
  iou: 0.1395
Layer 8 metrics:
  pearson_correlation: 0.0286
  kl_divergence: -86.2546
  ssim: 0.0604
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.41262, std: 0.16145

Metrics for layer 9:
  pearson_correlation: 0.0256
  kl_divergence: -61.4374
  ssim: 0.0525
  iou: 0.1701
Layer 9 metrics:
  pearson_correlation: 0.0256
  kl_divergence: -61.4374
  ssim: 0.0525
  iou: 0.1701

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.54384, std: 0.17980

Metrics for layer 10:
  pearson_correlation: -0.0914
  kl_divergence: -26.3083
  ssim: -0.0589
  iou: 0.1264
Layer 10 metrics:
  pearson_correlation: -0.0914
  kl_divergence: -26.3083
  ssim: -0.0589
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.49220, std: 0.16836

Metrics for layer 11:
  pearson_correlation: -0.1080
  kl_divergence: -19.4859
  ssim: 0.0606
  iou: 0.1011
Layer 11 metrics:
  pearson_correlation: -0.1080
  kl_divergence: -19.4859
  ssim: 0.0606
  iou: 0.1011

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.41446, std: 0.19341

Metrics for layer 12:
  pearson_correlation: -0.0909
  kl_divergence: -11.5618
  ssim: -0.0225
  iou: 0.0889
Layer 12 metrics:
  pearson_correlation: -0.0909
  kl_divergence: -11.5618
  ssim: -0.0225
  iou: 0.0889
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer4/batch_1_strength_0.0_results.npy

Processing attention strength 0.4
Attention vector: [0.  0.  0.  0.  0.4 0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.39082, std: 0.10663

Metrics for layer 0:
  pearson_correlation: -0.0027
  kl_divergence: -4446.1733
  ssim: 0.0640
  iou: 0.1397
Layer 0 metrics:
  pearson_correlation: -0.0027
  kl_divergence: -4446.1733
  ssim: 0.0640
  iou: 0.1397

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.43546, std: 0.12065

Metrics for layer 1:
  pearson_correlation: 0.0007
  kl_divergence: -4785.4995
  ssim: 0.0504
  iou: 0.1480
Layer 1 metrics:
  pearson_correlation: 0.0007
  kl_divergence: -4785.4995
  ssim: 0.0504
  iou: 0.1480

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.50402, std: 0.11965

Metrics for layer 2:
  pearson_correlation: 0.0095
  kl_divergence: -1632.4519
  ssim: 0.0671
  iou: 0.1420
Layer 2 metrics:
  pearson_correlation: 0.0095
  kl_divergence: -1632.4519
  ssim: 0.0671
  iou: 0.1420

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.45617, std: 0.12554

Metrics for layer 3:
  pearson_correlation: 0.0077
  kl_divergence: -1494.8970
  ssim: 0.0652
  iou: 0.1445
Layer 3 metrics:
  pearson_correlation: 0.0077
  kl_divergence: -1494.8970
  ssim: 0.0652
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.46834, std: 0.13647

Metrics for layer 4:
  pearson_correlation: -0.0141
  kl_divergence: -386.4591
  ssim: 0.0636
  iou: 0.1395
Layer 4 metrics:
  pearson_correlation: -0.0141
  kl_divergence: -386.4591
  ssim: 0.0636
  iou: 0.1395

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.47771, std: 0.15208

Metrics for layer 5:
  pearson_correlation: -0.0068
  kl_divergence: -389.3727
  ssim: 0.0603
  iou: 0.1470
Layer 5 metrics:
  pearson_correlation: -0.0068
  kl_divergence: -389.3727
  ssim: 0.0603
  iou: 0.1470

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.50731, std: 0.13649

Metrics for layer 6:
  pearson_correlation: 0.0104
  kl_divergence: -419.4141
  ssim: 0.0595
  iou: 0.1487
Layer 6 metrics:
  pearson_correlation: 0.0104
  kl_divergence: -419.4141
  ssim: 0.0595
  iou: 0.1487

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.45904, std: 0.15243

Metrics for layer 7:
  pearson_correlation: -0.0246
  kl_divergence: -80.7924
  ssim: 0.0424
  iou: 0.1429
Layer 7 metrics:
  pearson_correlation: -0.0246
  kl_divergence: -80.7924
  ssim: 0.0424
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.42920, std: 0.15086

Metrics for layer 8:
  pearson_correlation: -0.0478
  kl_divergence: -80.1861
  ssim: 0.0521
  iou: 0.1073
Layer 8 metrics:
  pearson_correlation: -0.0478
  kl_divergence: -80.1861
  ssim: 0.0521
  iou: 0.1073

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.49133, std: 0.16492

Metrics for layer 9:
  pearson_correlation: -0.0366
  kl_divergence: -96.4593
  ssim: 0.0290
  iou: 0.1264
Layer 9 metrics:
  pearson_correlation: -0.0366
  kl_divergence: -96.4593
  ssim: 0.0290
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.45299, std: 0.17822

Metrics for layer 10:
  pearson_correlation: 0.1401
  kl_divergence: -16.8627
  ssim: 0.2063
  iou: 0.1807
Layer 10 metrics:
  pearson_correlation: 0.1401
  kl_divergence: -16.8627
  ssim: 0.2063
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.47918, std: 0.19279

Metrics for layer 11:
  pearson_correlation: -0.0113
  kl_divergence: -19.6123
  ssim: -0.0185
  iou: 0.1807
Layer 11 metrics:
  pearson_correlation: -0.0113
  kl_divergence: -19.6123
  ssim: -0.0185
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.55907, std: 0.18137

Metrics for layer 12:
  pearson_correlation: 0.0087
  kl_divergence: -20.8710
  ssim: 0.0606
  iou: 0.1264
Layer 12 metrics:
  pearson_correlation: 0.0087
  kl_divergence: -20.8710
  ssim: 0.0606
  iou: 0.1264
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer4/batch_0_strength_0.4_results.npy

Processing batch 2/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.44867, std: 0.12551

Metrics for layer 0:
  pearson_correlation: -0.0047
  kl_divergence: -5634.2407
  ssim: 0.0583
  iou: 0.1428
Layer 0 metrics:
  pearson_correlation: -0.0047
  kl_divergence: -5634.2407
  ssim: 0.0583
  iou: 0.1428

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.40139, std: 0.11870

Metrics for layer 1:
  pearson_correlation: -0.0018
  kl_divergence: -5083.8867
  ssim: 0.0693
  iou: 0.1421
Layer 1 metrics:
  pearson_correlation: -0.0018
  kl_divergence: -5083.8867
  ssim: 0.0693
  iou: 0.1421

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.50158, std: 0.13588

Metrics for layer 2:
  pearson_correlation: 0.0032
  kl_divergence: -1753.5363
  ssim: 0.0592
  iou: 0.1408
Layer 2 metrics:
  pearson_correlation: 0.0032
  kl_divergence: -1753.5363
  ssim: 0.0592
  iou: 0.1408

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.43583, std: 0.13351

Metrics for layer 3:
  pearson_correlation: 0.0030
  kl_divergence: -1503.7587
  ssim: 0.0707
  iou: 0.1431
Layer 3 metrics:
  pearson_correlation: 0.0030
  kl_divergence: -1503.7587
  ssim: 0.0707
  iou: 0.1431

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.48256, std: 0.13923

Metrics for layer 4:
  pearson_correlation: 0.0065
  kl_divergence: -414.5038
  ssim: 0.0755
  iou: 0.1305
Layer 4 metrics:
  pearson_correlation: 0.0065
  kl_divergence: -414.5038
  ssim: 0.0755
  iou: 0.1305

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.50116, std: 0.14044

Metrics for layer 5:
  pearson_correlation: 0.0101
  kl_divergence: -436.0259
  ssim: 0.0629
  iou: 0.1479
Layer 5 metrics:
  pearson_correlation: 0.0101
  kl_divergence: -436.0259
  ssim: 0.0629
  iou: 0.1479

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.43311, std: 0.14449

Metrics for layer 6:
  pearson_correlation: 0.0052
  kl_divergence: -365.3983
  ssim: 0.0649
  iou: 0.1379
Layer 6 metrics:
  pearson_correlation: 0.0052
  kl_divergence: -365.3983
  ssim: 0.0649
  iou: 0.1379

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.44851, std: 0.15071

Metrics for layer 7:
  pearson_correlation: -0.0144
  kl_divergence: -77.2731
  ssim: 0.0483
  iou: 0.1667
Layer 7 metrics:
  pearson_correlation: -0.0144
  kl_divergence: -77.2731
  ssim: 0.0483
  iou: 0.1667

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.46204, std: 0.18535

Metrics for layer 8:
  pearson_correlation: -0.0055
  kl_divergence: -75.4862
  ssim: 0.0493
  iou: 0.1563
Layer 8 metrics:
  pearson_correlation: -0.0055
  kl_divergence: -75.4862
  ssim: 0.0493
  iou: 0.1563

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.49705, std: 0.15427

Metrics for layer 9:
  pearson_correlation: -0.0094
  kl_divergence: -94.6529
  ssim: 0.0573
  iou: 0.1168
Layer 9 metrics:
  pearson_correlation: -0.0094
  kl_divergence: -94.6529
  ssim: 0.0573
  iou: 0.1168

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.42950, std: 0.19788

Metrics for layer 10:
  pearson_correlation: -0.1519
  kl_divergence: -15.3541
  ssim: -0.1106
  iou: 0.0769
Layer 10 metrics:
  pearson_correlation: -0.1519
  kl_divergence: -15.3541
  ssim: -0.1106
  iou: 0.0769

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.47431, std: 0.19019

Metrics for layer 11:
  pearson_correlation: 0.0166
  kl_divergence: -18.6624
  ssim: 0.0654
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: 0.0166
  kl_divergence: -18.6624
  ssim: 0.0654
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.46721, std: 0.20475

Metrics for layer 12:
  pearson_correlation: 0.1319
  kl_divergence: -20.4979
  ssim: 0.0979
  iou: 0.1951
Layer 12 metrics:
  pearson_correlation: 0.1319
  kl_divergence: -20.4979
  ssim: 0.0979
  iou: 0.1951
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer4/batch_1_strength_0.4_results.npy

Processing attention strength 0.8
Attention vector: [0.  0.  0.  0.  0.8 0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.42792, std: 0.12312

Metrics for layer 0:
  pearson_correlation: -0.0007
  kl_divergence: -4716.5210
  ssim: 0.0491
  iou: 0.1449
Layer 0 metrics:
  pearson_correlation: -0.0007
  kl_divergence: -4716.5210
  ssim: 0.0491
  iou: 0.1449

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.39980, std: 0.11151

Metrics for layer 1:
  pearson_correlation: -0.0012
  kl_divergence: -4507.9062
  ssim: 0.0608
  iou: 0.1439
Layer 1 metrics:
  pearson_correlation: -0.0012
  kl_divergence: -4507.9062
  ssim: 0.0608
  iou: 0.1439

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.42046, std: 0.12889

Metrics for layer 2:
  pearson_correlation: -0.0095
  kl_divergence: -1371.5049
  ssim: 0.0640
  iou: 0.1362
Layer 2 metrics:
  pearson_correlation: -0.0095
  kl_divergence: -1371.5049
  ssim: 0.0640
  iou: 0.1362

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.44354, std: 0.12486

Metrics for layer 3:
  pearson_correlation: 0.0079
  kl_divergence: -1456.3293
  ssim: 0.0722
  iou: 0.1458
Layer 3 metrics:
  pearson_correlation: 0.0079
  kl_divergence: -1456.3293
  ssim: 0.0722
  iou: 0.1458

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.48562, std: 0.14058

Metrics for layer 4:
  pearson_correlation: 0.0058
  kl_divergence: -400.5345
  ssim: 0.0656
  iou: 0.1529
Layer 4 metrics:
  pearson_correlation: 0.0058
  kl_divergence: -400.5345
  ssim: 0.0656
  iou: 0.1529

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.47931, std: 0.13326

Metrics for layer 5:
  pearson_correlation: 0.0161
  kl_divergence: -398.3146
  ssim: 0.0661
  iou: 0.1371
Layer 5 metrics:
  pearson_correlation: 0.0161
  kl_divergence: -398.3146
  ssim: 0.0661
  iou: 0.1371

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.44917, std: 0.14886

Metrics for layer 6:
  pearson_correlation: 0.0142
  kl_divergence: -365.1243
  ssim: 0.0652
  iou: 0.1504
Layer 6 metrics:
  pearson_correlation: 0.0142
  kl_divergence: -365.1243
  ssim: 0.0652
  iou: 0.1504

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.51818, std: 0.15677

Metrics for layer 7:
  pearson_correlation: 0.0230
  kl_divergence: -100.4005
  ssim: 0.0723
  iou: 0.1429
Layer 7 metrics:
  pearson_correlation: 0.0230
  kl_divergence: -100.4005
  ssim: 0.0723
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.44225, std: 0.15035

Metrics for layer 8:
  pearson_correlation: 0.0684
  kl_divergence: -87.2191
  ssim: 0.0795
  iou: 0.1772
Layer 8 metrics:
  pearson_correlation: 0.0684
  kl_divergence: -87.2191
  ssim: 0.0795
  iou: 0.1772

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.46146, std: 0.16735

Metrics for layer 9:
  pearson_correlation: 0.0307
  kl_divergence: -83.3892
  ssim: 0.0830
  iou: 0.1772
Layer 9 metrics:
  pearson_correlation: 0.0307
  kl_divergence: -83.3892
  ssim: 0.0830
  iou: 0.1772

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.45237, std: 0.17369

Metrics for layer 10:
  pearson_correlation: 0.0714
  kl_divergence: -19.6930
  ssim: 0.0408
  iou: 0.1136
Layer 10 metrics:
  pearson_correlation: 0.0714
  kl_divergence: -19.6930
  ssim: 0.0408
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.52642, std: 0.22144

Metrics for layer 11:
  pearson_correlation: 0.0036
  kl_divergence: -22.2250
  ssim: 0.0237
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: 0.0036
  kl_divergence: -22.2250
  ssim: 0.0237
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.56083, std: 0.19614

Metrics for layer 12:
  pearson_correlation: -0.0098
  kl_divergence: -22.2070
  ssim: 0.0166
  iou: 0.0769
Layer 12 metrics:
  pearson_correlation: -0.0098
  kl_divergence: -22.2070
  ssim: 0.0166
  iou: 0.0769
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer4/batch_0_strength_0.8_results.npy

Processing batch 2/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.45223, std: 0.12809

Metrics for layer 0:
  pearson_correlation: 0.0033
  kl_divergence: -5677.9087
  ssim: 0.0586
  iou: 0.1434
Layer 0 metrics:
  pearson_correlation: 0.0033
  kl_divergence: -5677.9087
  ssim: 0.0586
  iou: 0.1434

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.41926, std: 0.12405

Metrics for layer 1:
  pearson_correlation: 0.0057
  kl_divergence: -5300.3306
  ssim: 0.0659
  iou: 0.1419
Layer 1 metrics:
  pearson_correlation: 0.0057
  kl_divergence: -5300.3306
  ssim: 0.0659
  iou: 0.1419

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.46931, std: 0.12032

Metrics for layer 2:
  pearson_correlation: 0.0172
  kl_divergence: -1655.5421
  ssim: 0.0830
  iou: 0.1572
Layer 2 metrics:
  pearson_correlation: 0.0172
  kl_divergence: -1655.5421
  ssim: 0.0830
  iou: 0.1572

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.43199, std: 0.12743

Metrics for layer 3:
  pearson_correlation: 0.0108
  kl_divergence: -1500.3616
  ssim: 0.0769
  iou: 0.1460
Layer 3 metrics:
  pearson_correlation: 0.0108
  kl_divergence: -1500.3616
  ssim: 0.0769
  iou: 0.1460

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.51529, std: 0.14617

Metrics for layer 4:
  pearson_correlation: 0.0152
  kl_divergence: -451.6787
  ssim: 0.0630
  iou: 0.1420
Layer 4 metrics:
  pearson_correlation: 0.0152
  kl_divergence: -451.6787
  ssim: 0.0630
  iou: 0.1420

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.48740, std: 0.15376

Metrics for layer 5:
  pearson_correlation: 0.0012
  kl_divergence: -418.7875
  ssim: 0.0572
  iou: 0.1354
Layer 5 metrics:
  pearson_correlation: 0.0012
  kl_divergence: -418.7875
  ssim: 0.0572
  iou: 0.1354

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.48398, std: 0.15142

Metrics for layer 6:
  pearson_correlation: 0.0314
  kl_divergence: -418.0497
  ssim: 0.0574
  iou: 0.1598
Layer 6 metrics:
  pearson_correlation: 0.0314
  kl_divergence: -418.0497
  ssim: 0.0574
  iou: 0.1598

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.49838, std: 0.16619

Metrics for layer 7:
  pearson_correlation: -0.0999
  kl_divergence: -71.8889
  ssim: -0.0219
  iou: 0.1232
Layer 7 metrics:
  pearson_correlation: -0.0999
  kl_divergence: -71.8889
  ssim: -0.0219
  iou: 0.1232

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.51420, std: 0.15308

Metrics for layer 8:
  pearson_correlation: 0.0131
  kl_divergence: -102.8165
  ssim: 0.0619
  iou: 0.1598
Layer 8 metrics:
  pearson_correlation: 0.0131
  kl_divergence: -102.8165
  ssim: 0.0619
  iou: 0.1598

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.52582, std: 0.16713

Metrics for layer 9:
  pearson_correlation: 0.0268
  kl_divergence: -104.7743
  ssim: 0.0503
  iou: 0.1362
Layer 9 metrics:
  pearson_correlation: 0.0268
  kl_divergence: -104.7743
  ssim: 0.0503
  iou: 0.1362

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.54331, std: 0.20160

Metrics for layer 10:
  pearson_correlation: -0.0035
  kl_divergence: -25.6080
  ssim: 0.0446
  iou: 0.1264
Layer 10 metrics:
  pearson_correlation: -0.0035
  kl_divergence: -25.6080
  ssim: 0.0446
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.52306, std: 0.18491

Metrics for layer 11:
  pearson_correlation: 0.0491
  kl_divergence: -23.6517
  ssim: 0.0943
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: 0.0491
  kl_divergence: -23.6517
  ssim: 0.0943
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.50240, std: 0.19838

Metrics for layer 12:
  pearson_correlation: -0.0436
  kl_divergence: -21.5210
  ssim: 0.0260
  iou: 0.1264
Layer 12 metrics:
  pearson_correlation: -0.0436
  kl_divergence: -21.5210
  ssim: 0.0260
  iou: 0.1264
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer4/batch_1_strength_0.8_results.npy

Processing attention strength 1.2
Attention vector: [0.  0.  0.  0.  1.2 0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.43410, std: 0.12507

Metrics for layer 0:
  pearson_correlation: -0.0015
  kl_divergence: -4760.8931
  ssim: 0.0476
  iou: 0.1445
Layer 0 metrics:
  pearson_correlation: -0.0015
  kl_divergence: -4760.8931
  ssim: 0.0476
  iou: 0.1445

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.41160, std: 0.12719

Metrics for layer 1:
  pearson_correlation: -0.0007
  kl_divergence: -4565.7979
  ssim: 0.0482
  iou: 0.1412
Layer 1 metrics:
  pearson_correlation: -0.0007
  kl_divergence: -4565.7979
  ssim: 0.0482
  iou: 0.1412

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.44256, std: 0.13721

Metrics for layer 2:
  pearson_correlation: 0.0000
  kl_divergence: -1436.6377
  ssim: 0.0572
  iou: 0.1452
Layer 2 metrics:
  pearson_correlation: 0.0000
  kl_divergence: -1436.6377
  ssim: 0.0572
  iou: 0.1452

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.43613, std: 0.11928

Metrics for layer 3:
  pearson_correlation: -0.0037
  kl_divergence: -1434.6399
  ssim: 0.0699
  iou: 0.1418
Layer 3 metrics:
  pearson_correlation: -0.0037
  kl_divergence: -1434.6399
  ssim: 0.0699
  iou: 0.1418

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.49324, std: 0.13726

Metrics for layer 4:
  pearson_correlation: 0.0127
  kl_divergence: -405.4705
  ssim: 0.0643
  iou: 0.1445
Layer 4 metrics:
  pearson_correlation: 0.0127
  kl_divergence: -405.4705
  ssim: 0.0643
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.47190, std: 0.14440

Metrics for layer 5:
  pearson_correlation: -0.0027
  kl_divergence: -388.9505
  ssim: 0.0503
  iou: 0.1371
Layer 5 metrics:
  pearson_correlation: -0.0027
  kl_divergence: -388.9505
  ssim: 0.0503
  iou: 0.1371

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.50179, std: 0.15742

Metrics for layer 6:
  pearson_correlation: -0.0054
  kl_divergence: -409.8710
  ssim: 0.0505
  iou: 0.1454
Layer 6 metrics:
  pearson_correlation: -0.0054
  kl_divergence: -409.8710
  ssim: 0.0505
  iou: 0.1454

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.45618, std: 0.17137

Metrics for layer 7:
  pearson_correlation: -0.0350
  kl_divergence: -84.4499
  ssim: 0.0331
  iou: 0.1701
Layer 7 metrics:
  pearson_correlation: -0.0350
  kl_divergence: -84.4499
  ssim: 0.0331
  iou: 0.1701

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.47466, std: 0.18088

Metrics for layer 8:
  pearson_correlation: 0.0153
  kl_divergence: -90.8887
  ssim: 0.0699
  iou: 0.1496
Layer 8 metrics:
  pearson_correlation: 0.0153
  kl_divergence: -90.8887
  ssim: 0.0699
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.55367, std: 0.14384

Metrics for layer 9:
  pearson_correlation: 0.0185
  kl_divergence: -111.0460
  ssim: 0.0711
  iou: 0.1879
Layer 9 metrics:
  pearson_correlation: 0.0185
  kl_divergence: -111.0460
  ssim: 0.0711
  iou: 0.1879

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.53059, std: 0.20224

Metrics for layer 10:
  pearson_correlation: 0.0988
  kl_divergence: -23.1300
  ssim: 0.1114
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: 0.0988
  kl_divergence: -23.1300
  ssim: 0.1114
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.58235, std: 0.17464

Metrics for layer 11:
  pearson_correlation: 0.0010
  kl_divergence: -25.7727
  ssim: 0.0661
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: 0.0010
  kl_divergence: -25.7727
  ssim: 0.0661
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.42564, std: 0.18810

Metrics for layer 12:
  pearson_correlation: 0.1013
  kl_divergence: -17.5860
  ssim: 0.1994
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: 0.1013
  kl_divergence: -17.5860
  ssim: 0.1994
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer4/batch_0_strength_1.2_results.npy

Processing batch 2/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.43155, std: 0.12696

Metrics for layer 0:
  pearson_correlation: -0.0068
  kl_divergence: -5421.5107
  ssim: 0.0589
  iou: 0.1408
Layer 0 metrics:
  pearson_correlation: -0.0068
  kl_divergence: -5421.5107
  ssim: 0.0589
  iou: 0.1408

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.38851, std: 0.11730

Metrics for layer 1:
  pearson_correlation: 0.0029
  kl_divergence: -4920.3691
  ssim: 0.0736
  iou: 0.1452
Layer 1 metrics:
  pearson_correlation: 0.0029
  kl_divergence: -4920.3691
  ssim: 0.0736
  iou: 0.1452

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.43953, std: 0.12473

Metrics for layer 2:
  pearson_correlation: -0.0171
  kl_divergence: -1526.7786
  ssim: 0.0723
  iou: 0.1412
Layer 2 metrics:
  pearson_correlation: -0.0171
  kl_divergence: -1526.7786
  ssim: 0.0723
  iou: 0.1412

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.47027, std: 0.12280

Metrics for layer 3:
  pearson_correlation: -0.0070
  kl_divergence: -1650.2551
  ssim: 0.0683
  iou: 0.1346
Layer 3 metrics:
  pearson_correlation: -0.0070
  kl_divergence: -1650.2551
  ssim: 0.0683
  iou: 0.1346

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.48659, std: 0.13769

Metrics for layer 4:
  pearson_correlation: -0.0100
  kl_divergence: -421.8042
  ssim: 0.0583
  iou: 0.1555
Layer 4 metrics:
  pearson_correlation: -0.0100
  kl_divergence: -421.8042
  ssim: 0.0583
  iou: 0.1555

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.46456, std: 0.14879

Metrics for layer 5:
  pearson_correlation: -0.0194
  kl_divergence: -395.0495
  ssim: 0.0490
  iou: 0.1429
Layer 5 metrics:
  pearson_correlation: -0.0194
  kl_divergence: -395.0495
  ssim: 0.0490
  iou: 0.1429

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.51468, std: 0.14511

Metrics for layer 6:
  pearson_correlation: 0.0198
  kl_divergence: -450.6721
  ssim: 0.0637
  iou: 0.1454
Layer 6 metrics:
  pearson_correlation: 0.0198
  kl_divergence: -450.6721
  ssim: 0.0637
  iou: 0.1454

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.52622, std: 0.17903

Metrics for layer 7:
  pearson_correlation: 0.0510
  kl_divergence: -99.4507
  ssim: 0.0814
  iou: 0.1772
Layer 7 metrics:
  pearson_correlation: 0.0510
  kl_divergence: -99.4507
  ssim: 0.0814
  iou: 0.1772

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.54527, std: 0.16747

Metrics for layer 8:
  pearson_correlation: -0.0305
  kl_divergence: -107.2304
  ssim: 0.0369
  iou: 0.1329
Layer 8 metrics:
  pearson_correlation: -0.0305
  kl_divergence: -107.2304
  ssim: 0.0369
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.49792, std: 0.16979

Metrics for layer 9:
  pearson_correlation: -0.0188
  kl_divergence: -93.9890
  ssim: 0.0320
  iou: 0.1264
Layer 9 metrics:
  pearson_correlation: -0.0188
  kl_divergence: -93.9890
  ssim: 0.0320
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.45710, std: 0.19223

Metrics for layer 10:
  pearson_correlation: -0.0445
  kl_divergence: -18.8116
  ssim: -0.0067
  iou: 0.1011
Layer 10 metrics:
  pearson_correlation: -0.0445
  kl_divergence: -18.8116
  ssim: -0.0067
  iou: 0.1011

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.52537, std: 0.19178

Metrics for layer 11:
  pearson_correlation: 0.0729
  kl_divergence: -25.2779
  ssim: 0.0737
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: 0.0729
  kl_divergence: -25.2779
  ssim: 0.0737
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.34379, std: 0.14114

Metrics for layer 12:
  pearson_correlation: -0.0403
  kl_divergence: -7.0606
  ssim: 0.0670
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: -0.0403
  kl_divergence: -7.0606
  ssim: 0.0670
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer4/batch_1_strength_1.2_results.npy

Analysis complete! Results saved to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer4
