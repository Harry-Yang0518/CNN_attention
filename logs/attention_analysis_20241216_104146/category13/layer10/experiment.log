WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-12-16 11:47:16.643970: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-16 11:47:16.651044: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2024-12-16 11:47:16.651388: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x49ef000 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:47:16.651400: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-16 11:47:16.654104: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-16 11:47:16.782473: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x49edfa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:47:16.782494: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-12-16 11:47:16.782972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:2f:00.0
2024-12-16 11:47:16.784160: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:47:16.785234: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:47:16.786279: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:47:16.787346: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:47:16.788372: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:47:16.789411: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:47:16.790432: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:47:16.790443: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-12-16 11:47:16.790462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-16 11:47:16.790467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-16 11:47:16.790471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:61: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:87: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:15: sigmoid_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.sigmoid_cross_entropy instead. Note that the order of the predictions and labels arguments has been changed.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:322: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:82: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.


Verifying paths:
tc_path: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs exists
weight_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists
image_path: /scratch/hy2611/CNN_attention/Data/VGG16/images exists
save_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists

Initializing model...
('c11', [1, 224, 224, 64])
('c12', [1, 224, 224, 64])
('c21', [1, 112, 112, 128])
('c22', [1, 112, 112, 128])
('c31', [1, 56, 56, 256])
('c32', [1, 56, 56, 256])
('c33', [1, 56, 56, 256])
('c41', [1, 28, 28, 512])
('c42', [1, 28, 28, 512])
('c43', [1, 28, 28, 512])
('c51', [1, 14, 14, 512])
('c52', [1, 14, 14, 512])
('c53', [1, 14, 14, 512])
(0, 'conv1_1_W', (3, 3, 3, 64))
(1, 'conv1_1_b', (64,))
(2, 'conv1_2_W', (3, 3, 64, 64))
(3, 'conv1_2_b', (64,))
(4, 'conv2_1_W', (3, 3, 64, 128))
(5, 'conv2_1_b', (128,))
(6, 'conv2_2_W', (3, 3, 128, 128))
(7, 'conv2_2_b', (128,))
(8, 'conv3_1_W', (3, 3, 128, 256))
(9, 'conv3_1_b', (256,))
(10, 'conv3_2_W', (3, 3, 256, 256))
(11, 'conv3_2_b', (256,))
(12, 'conv3_3_W', (3, 3, 256, 256))
(13, 'conv3_3_b', (256,))
(14, 'conv4_1_W', (3, 3, 256, 512))
(15, 'conv4_1_b', (512,))
(16, 'conv4_2_W', (3, 3, 512, 512))
(17, 'conv4_2_b', (512,))
(18, 'conv4_3_W', (3, 3, 512, 512))
(19, 'conv4_3_b', (512,))
(20, 'conv5_1_W', (3, 3, 512, 512))
(21, 'conv5_1_b', (512,))
(22, 'conv5_2_W', (3, 3, 512, 512))
(23, 'conv5_2_b', (512,))
(24, 'conv5_3_W', (3, 3, 512, 512))
(25, 'conv5_3_b', (512,))
(26, 'fc6_W', (25088, 4096))
(27, 'fc6_b', (4096,))
(28, 'fc7_W', (4096, 4096))
(29, 'fc7_b', (4096,))
Checking checkpoint files:
Data file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_13.ckpt.data-00000-of-00001 - Found
Index file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_13.ckpt.index - Found
Loading checkpoint from: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_13.ckpt
Checkpoint loaded successfully

Initializing components...
Found tuning curves file: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs/featvecs20_train35_c.txt

Loading category 13 data...
Original positive images shape: (2, 224, 224, 3)

Processing data...

Processing attention strength 0.0
Attention vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

Processing batch 1/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.42850, std: 0.11635

Metrics for layer 0:
  pearson_correlation: 0.0006
  kl_divergence: -4741.1318
  ssim: 0.0538
  iou: 0.1448
Layer 0 metrics:
  pearson_correlation: 0.0006
  kl_divergence: -4741.1318
  ssim: 0.0538
  iou: 0.1448

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.39871, std: 0.11143

Metrics for layer 1:
  pearson_correlation: -0.0076
  kl_divergence: -4495.9873
  ssim: 0.0594
  iou: 0.1387
Layer 1 metrics:
  pearson_correlation: -0.0076
  kl_divergence: -4495.9873
  ssim: 0.0594
  iou: 0.1387

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.45721, std: 0.13797

Metrics for layer 2:
  pearson_correlation: -0.0027
  kl_divergence: -1479.8730
  ssim: 0.0574
  iou: 0.1414
Layer 2 metrics:
  pearson_correlation: -0.0027
  kl_divergence: -1479.8730
  ssim: 0.0574
  iou: 0.1414

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.46803, std: 0.13199

Metrics for layer 3:
  pearson_correlation: -0.0044
  kl_divergence: -1518.6178
  ssim: 0.0618
  iou: 0.1431
Layer 3 metrics:
  pearson_correlation: -0.0044
  kl_divergence: -1518.6178
  ssim: 0.0618
  iou: 0.1431

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.44764, std: 0.14709

Metrics for layer 4:
  pearson_correlation: 0.0006
  kl_divergence: -365.5330
  ssim: 0.0572
  iou: 0.1346
Layer 4 metrics:
  pearson_correlation: 0.0006
  kl_divergence: -365.5330
  ssim: 0.0572
  iou: 0.1346

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.49029, std: 0.13983

Metrics for layer 5:
  pearson_correlation: -0.0197
  kl_divergence: -405.1943
  ssim: 0.0445
  iou: 0.1305
Layer 5 metrics:
  pearson_correlation: -0.0197
  kl_divergence: -405.1943
  ssim: 0.0445
  iou: 0.1305

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.40019, std: 0.13768

Metrics for layer 6:
  pearson_correlation: -0.0097
  kl_divergence: -316.0486
  ssim: 0.0638
  iou: 0.1454
Layer 6 metrics:
  pearson_correlation: -0.0097
  kl_divergence: -316.0486
  ssim: 0.0638
  iou: 0.1454

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.55232, std: 0.16245

Metrics for layer 7:
  pearson_correlation: 0.0660
  kl_divergence: -108.1838
  ssim: 0.0717
  iou: 0.1395
Layer 7 metrics:
  pearson_correlation: 0.0660
  kl_divergence: -108.1838
  ssim: 0.0717
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.44534, std: 0.17966

Metrics for layer 8:
  pearson_correlation: 0.0154
  kl_divergence: -82.0292
  ssim: 0.0709
  iou: 0.1362
Layer 8 metrics:
  pearson_correlation: 0.0154
  kl_divergence: -82.0292
  ssim: 0.0709
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.49248, std: 0.17941

Metrics for layer 9:
  pearson_correlation: -0.0161
  kl_divergence: -94.5168
  ssim: 0.0193
  iou: 0.1329
Layer 9 metrics:
  pearson_correlation: -0.0161
  kl_divergence: -94.5168
  ssim: 0.0193
  iou: 0.1329

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.46662, std: 0.17587

Metrics for layer 10:
  pearson_correlation: 0.0854
  kl_divergence: -20.4632
  ssim: 0.1046
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: 0.0854
  kl_divergence: -20.4632
  ssim: 0.1046
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.56241, std: 0.19658

Metrics for layer 11:
  pearson_correlation: 0.0010
  kl_divergence: -11.2808
  ssim: 0.0388
  iou: 0.2250
Layer 11 metrics:
  pearson_correlation: 0.0010
  kl_divergence: -11.2808
  ssim: 0.0388
  iou: 0.2250

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.50753, std: 0.17703

Metrics for layer 12:
  pearson_correlation: -0.0366
  kl_divergence: -19.5300
  ssim: -0.0188
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: -0.0366
  kl_divergence: -19.5300
  ssim: -0.0188
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer10/batch_0_strength_0.0_results.npy

Processing batch 2/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.41178, std: 0.12058

Metrics for layer 0:
  pearson_correlation: -0.0010
  kl_divergence: -5211.3354
  ssim: 0.0671
  iou: 0.1412
Layer 0 metrics:
  pearson_correlation: -0.0010
  kl_divergence: -5211.3354
  ssim: 0.0671
  iou: 0.1412

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.43099, std: 0.12503

Metrics for layer 1:
  pearson_correlation: -0.0027
  kl_divergence: -5431.2109
  ssim: 0.0621
  iou: 0.1368
Layer 1 metrics:
  pearson_correlation: -0.0027
  kl_divergence: -5431.2109
  ssim: 0.0621
  iou: 0.1368

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.46623, std: 0.11913

Metrics for layer 2:
  pearson_correlation: -0.0140
  kl_divergence: -1638.4066
  ssim: 0.0731
  iou: 0.1385
Layer 2 metrics:
  pearson_correlation: -0.0140
  kl_divergence: -1638.4066
  ssim: 0.0731
  iou: 0.1385

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.47163, std: 0.12285

Metrics for layer 3:
  pearson_correlation: -0.0024
  kl_divergence: -1658.7483
  ssim: 0.0761
  iou: 0.1462
Layer 3 metrics:
  pearson_correlation: -0.0024
  kl_divergence: -1658.7483
  ssim: 0.0761
  iou: 0.1462

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.47173, std: 0.16558

Metrics for layer 4:
  pearson_correlation: -0.0285
  kl_divergence: -389.6877
  ssim: 0.0412
  iou: 0.1404
Layer 4 metrics:
  pearson_correlation: -0.0285
  kl_divergence: -389.6877
  ssim: 0.0412
  iou: 0.1404

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.47071, std: 0.14048

Metrics for layer 5:
  pearson_correlation: 0.0181
  kl_divergence: -407.1491
  ssim: 0.0750
  iou: 0.1496
Layer 5 metrics:
  pearson_correlation: 0.0181
  kl_divergence: -407.1491
  ssim: 0.0750
  iou: 0.1496

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.52138, std: 0.13699

Metrics for layer 6:
  pearson_correlation: 0.0042
  kl_divergence: -458.5949
  ssim: 0.0589
  iou: 0.1512
Layer 6 metrics:
  pearson_correlation: 0.0042
  kl_divergence: -458.5949
  ssim: 0.0589
  iou: 0.1512

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.51842, std: 0.16578

Metrics for layer 7:
  pearson_correlation: -0.0339
  kl_divergence: -99.7080
  ssim: 0.0404
  iou: 0.1563
Layer 7 metrics:
  pearson_correlation: -0.0339
  kl_divergence: -99.7080
  ssim: 0.0404
  iou: 0.1563

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.52648, std: 0.15484

Metrics for layer 8:
  pearson_correlation: -0.0170
  kl_divergence: -100.5814
  ssim: 0.0518
  iou: 0.1496
Layer 8 metrics:
  pearson_correlation: -0.0170
  kl_divergence: -100.5814
  ssim: 0.0518
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.46093, std: 0.14535

Metrics for layer 9:
  pearson_correlation: -0.0145
  kl_divergence: -83.7150
  ssim: 0.0641
  iou: 0.1362
Layer 9 metrics:
  pearson_correlation: -0.0145
  kl_divergence: -83.7150
  ssim: 0.0641
  iou: 0.1362

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.46532, std: 0.19546

Metrics for layer 10:
  pearson_correlation: -0.0678
  kl_divergence: -16.9827
  ssim: 0.0350
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: -0.0678
  kl_divergence: -16.9827
  ssim: 0.0350
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.41286, std: 0.18766

Metrics for layer 11:
  pearson_correlation: -0.0355
  kl_divergence: -13.4129
  ssim: 0.0215
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: -0.0355
  kl_divergence: -13.4129
  ssim: 0.0215
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.57147, std: 0.17086

Metrics for layer 12:
  pearson_correlation: 0.0776
  kl_divergence: -23.7379
  ssim: 0.0392
  iou: 0.1951
Layer 12 metrics:
  pearson_correlation: 0.0776
  kl_divergence: -23.7379
  ssim: 0.0392
  iou: 0.1951
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer10/batch_1_strength_0.0_results.npy

Processing attention strength 0.4
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.4 0.  0. ]

Processing batch 1/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.43730, std: 0.12469

Metrics for layer 0:
  pearson_correlation: -0.0016
  kl_divergence: -4790.5112
  ssim: 0.0472
  iou: 0.1445
Layer 0 metrics:
  pearson_correlation: -0.0016
  kl_divergence: -4790.5112
  ssim: 0.0472
  iou: 0.1445

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.44070, std: 0.12555

Metrics for layer 1:
  pearson_correlation: -0.0051
  kl_divergence: -4810.1309
  ssim: 0.0447
  iou: 0.1444
Layer 1 metrics:
  pearson_correlation: -0.0051
  kl_divergence: -4810.1309
  ssim: 0.0447
  iou: 0.1444

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.45215, std: 0.13122

Metrics for layer 2:
  pearson_correlation: -0.0003
  kl_divergence: -1473.2947
  ssim: 0.0616
  iou: 0.1381
Layer 2 metrics:
  pearson_correlation: -0.0003
  kl_divergence: -1473.2947
  ssim: 0.0616
  iou: 0.1381

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.47796, std: 0.13483

Metrics for layer 3:
  pearson_correlation: 0.0149
  kl_divergence: -1549.4260
  ssim: 0.0592
  iou: 0.1458
Layer 3 metrics:
  pearson_correlation: 0.0149
  kl_divergence: -1549.4260
  ssim: 0.0592
  iou: 0.1458

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.45452, std: 0.15224

Metrics for layer 4:
  pearson_correlation: 0.0218
  kl_divergence: -372.0878
  ssim: 0.0654
  iou: 0.1504
Layer 4 metrics:
  pearson_correlation: 0.0218
  kl_divergence: -372.0878
  ssim: 0.0654
  iou: 0.1504

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.48360, std: 0.15509

Metrics for layer 5:
  pearson_correlation: -0.0052
  kl_divergence: -393.1036
  ssim: 0.0524
  iou: 0.1412
Layer 5 metrics:
  pearson_correlation: -0.0052
  kl_divergence: -393.1036
  ssim: 0.0524
  iou: 0.1412

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.47600, std: 0.13832

Metrics for layer 6:
  pearson_correlation: -0.0018
  kl_divergence: -394.1038
  ssim: 0.0561
  iou: 0.1487
Layer 6 metrics:
  pearson_correlation: -0.0018
  kl_divergence: -394.1038
  ssim: 0.0561
  iou: 0.1487

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.43560, std: 0.16577

Metrics for layer 7:
  pearson_correlation: -0.0174
  kl_divergence: -80.5433
  ssim: 0.0454
  iou: 0.1264
Layer 7 metrics:
  pearson_correlation: -0.0174
  kl_divergence: -80.5433
  ssim: 0.0454
  iou: 0.1264

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.47119, std: 0.15975

Metrics for layer 8:
  pearson_correlation: -0.0174
  kl_divergence: -91.5768
  ssim: 0.0461
  iou: 0.1395
Layer 8 metrics:
  pearson_correlation: -0.0174
  kl_divergence: -91.5768
  ssim: 0.0461
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.50802, std: 0.16887

Metrics for layer 9:
  pearson_correlation: -0.0005
  kl_divergence: -94.6740
  ssim: 0.0457
  iou: 0.1563
Layer 9 metrics:
  pearson_correlation: -0.0005
  kl_divergence: -94.6740
  ssim: 0.0457
  iou: 0.1563

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.50274, std: 0.15156

Metrics for layer 10:
  pearson_correlation: 0.0603
  kl_divergence: -20.7962
  ssim: 0.1191
  iou: 0.1395
Layer 10 metrics:
  pearson_correlation: 0.0603
  kl_divergence: -20.7962
  ssim: 0.1191
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.40979, std: 0.16245

Metrics for layer 11:
  pearson_correlation: -0.1380
  kl_divergence: -6.6555
  ssim: 0.0184
  iou: 0.1011
Layer 11 metrics:
  pearson_correlation: -0.1380
  kl_divergence: -6.6555
  ssim: 0.0184
  iou: 0.1011

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.51900, std: 0.18084

Metrics for layer 12:
  pearson_correlation: 0.0132
  kl_divergence: -21.8792
  ssim: 0.0700
  iou: 0.1136
Layer 12 metrics:
  pearson_correlation: 0.0132
  kl_divergence: -21.8792
  ssim: 0.0700
  iou: 0.1136
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer10/batch_0_strength_0.4_results.npy

Processing batch 2/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.46206, std: 0.12512

Metrics for layer 0:
  pearson_correlation: -0.0010
  kl_divergence: -5794.3740
  ssim: 0.0576
  iou: 0.1424
Layer 0 metrics:
  pearson_correlation: -0.0010
  kl_divergence: -5794.3740
  ssim: 0.0576
  iou: 0.1424

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.45858, std: 0.12995

Metrics for layer 1:
  pearson_correlation: -0.0006
  kl_divergence: -5736.1587
  ssim: 0.0557
  iou: 0.1437
Layer 1 metrics:
  pearson_correlation: -0.0006
  kl_divergence: -5736.1587
  ssim: 0.0557
  iou: 0.1437

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.47548, std: 0.11990

Metrics for layer 2:
  pearson_correlation: -0.0057
  kl_divergence: -1672.5961
  ssim: 0.0804
  iou: 0.1395
Layer 2 metrics:
  pearson_correlation: -0.0057
  kl_divergence: -1672.5961
  ssim: 0.0804
  iou: 0.1395

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.47522, std: 0.12688

Metrics for layer 3:
  pearson_correlation: -0.0034
  kl_divergence: -1666.4523
  ssim: 0.0725
  iou: 0.1458
Layer 3 metrics:
  pearson_correlation: -0.0034
  kl_divergence: -1666.4523
  ssim: 0.0725
  iou: 0.1458

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.49904, std: 0.14165

Metrics for layer 4:
  pearson_correlation: -0.0016
  kl_divergence: -433.5633
  ssim: 0.0645
  iou: 0.1264
Layer 4 metrics:
  pearson_correlation: -0.0016
  kl_divergence: -433.5633
  ssim: 0.0645
  iou: 0.1264

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.50094, std: 0.14526

Metrics for layer 5:
  pearson_correlation: 0.0193
  kl_divergence: -438.3831
  ssim: 0.0600
  iou: 0.1529
Layer 5 metrics:
  pearson_correlation: 0.0193
  kl_divergence: -438.3831
  ssim: 0.0600
  iou: 0.1529

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.54538, std: 0.12197

Metrics for layer 6:
  pearson_correlation: -0.0191
  kl_divergence: -479.2814
  ssim: 0.0534
  iou: 0.1281
Layer 6 metrics:
  pearson_correlation: -0.0191
  kl_divergence: -479.2814
  ssim: 0.0534
  iou: 0.1281

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.49013, std: 0.14938

Metrics for layer 7:
  pearson_correlation: 0.0057
  kl_divergence: -95.0993
  ssim: 0.0596
  iou: 0.1429
Layer 7 metrics:
  pearson_correlation: 0.0057
  kl_divergence: -95.0993
  ssim: 0.0596
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.44683, std: 0.16317

Metrics for layer 8:
  pearson_correlation: -0.0410
  kl_divergence: -74.6780
  ssim: -0.0009
  iou: 0.1297
Layer 8 metrics:
  pearson_correlation: -0.0410
  kl_divergence: -74.6780
  ssim: -0.0009
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.46586, std: 0.14336

Metrics for layer 9:
  pearson_correlation: 0.0452
  kl_divergence: -86.6916
  ssim: 0.0713
  iou: 0.1563
Layer 9 metrics:
  pearson_correlation: 0.0452
  kl_divergence: -86.6916
  ssim: 0.0713
  iou: 0.1563

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.49892, std: 0.17224

Metrics for layer 10:
  pearson_correlation: -0.0271
  kl_divergence: -20.1059
  ssim: 0.0722
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: -0.0271
  kl_divergence: -20.1059
  ssim: 0.0722
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.52027, std: 0.22429

Metrics for layer 11:
  pearson_correlation: 0.0471
  kl_divergence: -21.8776
  ssim: 0.0463
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: 0.0471
  kl_divergence: -21.8776
  ssim: 0.0463
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.43216, std: 0.16105

Metrics for layer 12:
  pearson_correlation: 0.0985
  kl_divergence: -19.1532
  ssim: 0.1176
  iou: 0.1807
Layer 12 metrics:
  pearson_correlation: 0.0985
  kl_divergence: -19.1532
  ssim: 0.1176
  iou: 0.1807
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer10/batch_1_strength_0.4_results.npy

Processing attention strength 0.8
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.8 0.  0. ]

Processing batch 1/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.41611, std: 0.12174

Metrics for layer 0:
  pearson_correlation: 0.0052
  kl_divergence: -4627.1196
  ssim: 0.0514
  iou: 0.1432
Layer 0 metrics:
  pearson_correlation: 0.0052
  kl_divergence: -4627.1196
  ssim: 0.0514
  iou: 0.1432

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.42959, std: 0.11709

Metrics for layer 1:
  pearson_correlation: -0.0038
  kl_divergence: -4745.0093
  ssim: 0.0508
  iou: 0.1375
Layer 1 metrics:
  pearson_correlation: -0.0038
  kl_divergence: -4745.0093
  ssim: 0.0508
  iou: 0.1375

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.48739, std: 0.12947

Metrics for layer 2:
  pearson_correlation: 0.0043
  kl_divergence: -1576.6577
  ssim: 0.0627
  iou: 0.1412
Layer 2 metrics:
  pearson_correlation: 0.0043
  kl_divergence: -1576.6577
  ssim: 0.0627
  iou: 0.1412

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.47201, std: 0.12652

Metrics for layer 3:
  pearson_correlation: 0.0026
  kl_divergence: -1535.6902
  ssim: 0.0614
  iou: 0.1443
Layer 3 metrics:
  pearson_correlation: 0.0026
  kl_divergence: -1535.6902
  ssim: 0.0614
  iou: 0.1443

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.46900, std: 0.13438

Metrics for layer 4:
  pearson_correlation: 0.0038
  kl_divergence: -389.4149
  ssim: 0.0665
  iou: 0.1445
Layer 4 metrics:
  pearson_correlation: 0.0038
  kl_divergence: -389.4149
  ssim: 0.0665
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.46790, std: 0.15509

Metrics for layer 5:
  pearson_correlation: -0.0016
  kl_divergence: -381.6557
  ssim: 0.0573
  iou: 0.1420
Layer 5 metrics:
  pearson_correlation: -0.0016
  kl_divergence: -381.6557
  ssim: 0.0573
  iou: 0.1420

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.45568, std: 0.15093

Metrics for layer 6:
  pearson_correlation: -0.0095
  kl_divergence: -369.2377
  ssim: 0.0528
  iou: 0.1496
Layer 6 metrics:
  pearson_correlation: -0.0095
  kl_divergence: -369.2377
  ssim: 0.0528
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.40755, std: 0.13897

Metrics for layer 7:
  pearson_correlation: -0.0673
  kl_divergence: -65.3567
  ssim: 0.0459
  iou: 0.1200
Layer 7 metrics:
  pearson_correlation: -0.0673
  kl_divergence: -65.3567
  ssim: 0.0459
  iou: 0.1200

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.36293, std: 0.13419

Metrics for layer 8:
  pearson_correlation: 0.0198
  kl_divergence: -65.8924
  ssim: 0.0934
  iou: 0.1563
Layer 8 metrics:
  pearson_correlation: 0.0198
  kl_divergence: -65.8924
  ssim: 0.0934
  iou: 0.1563

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.49379, std: 0.15416

Metrics for layer 9:
  pearson_correlation: 0.0204
  kl_divergence: -99.1927
  ssim: 0.0639
  iou: 0.1462
Layer 9 metrics:
  pearson_correlation: 0.0204
  kl_divergence: -99.1927
  ssim: 0.0639
  iou: 0.1462

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.58234, std: 0.17097

Metrics for layer 10:
  pearson_correlation: 0.0205
  kl_divergence: -26.9071
  ssim: -0.0026
  iou: 0.1395
Layer 10 metrics:
  pearson_correlation: 0.0205
  kl_divergence: -26.9071
  ssim: -0.0026
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.46936, std: 0.21186

Metrics for layer 11:
  pearson_correlation: 0.0138
  kl_divergence: -16.9075
  ssim: -0.0170
  iou: 0.2099
Layer 11 metrics:
  pearson_correlation: 0.0138
  kl_divergence: -16.9075
  ssim: -0.0170
  iou: 0.2099

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.57808, std: 0.17243

Metrics for layer 12:
  pearson_correlation: 0.0705
  kl_divergence: -22.0924
  ssim: 0.0596
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: 0.0705
  kl_divergence: -22.0924
  ssim: 0.0596
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer10/batch_0_strength_0.8_results.npy

Processing batch 2/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.43044, std: 0.12159

Metrics for layer 0:
  pearson_correlation: -0.0057
  kl_divergence: -5434.1421
  ssim: 0.0624
  iou: 0.1428
Layer 0 metrics:
  pearson_correlation: -0.0057
  kl_divergence: -5434.1421
  ssim: 0.0624
  iou: 0.1428

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.44862, std: 0.13243

Metrics for layer 1:
  pearson_correlation: 0.0000
  kl_divergence: -5614.9092
  ssim: 0.0570
  iou: 0.1455
Layer 1 metrics:
  pearson_correlation: 0.0000
  kl_divergence: -5614.9092
  ssim: 0.0570
  iou: 0.1455

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.47044, std: 0.13502

Metrics for layer 2:
  pearson_correlation: -0.0181
  kl_divergence: -1631.3770
  ssim: 0.0635
  iou: 0.1332
Layer 2 metrics:
  pearson_correlation: -0.0181
  kl_divergence: -1631.3770
  ssim: 0.0635
  iou: 0.1332

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.42802, std: 0.12238

Metrics for layer 3:
  pearson_correlation: 0.0023
  kl_divergence: -1486.8923
  ssim: 0.0834
  iou: 0.1418
Layer 3 metrics:
  pearson_correlation: 0.0023
  kl_divergence: -1486.8923
  ssim: 0.0834
  iou: 0.1418

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.52123, std: 0.14863

Metrics for layer 4:
  pearson_correlation: -0.0047
  kl_divergence: -449.3055
  ssim: 0.0558
  iou: 0.1321
Layer 4 metrics:
  pearson_correlation: -0.0047
  kl_divergence: -449.3055
  ssim: 0.0558
  iou: 0.1321

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.40646, std: 0.12726

Metrics for layer 5:
  pearson_correlation: 0.0017
  kl_divergence: -338.0437
  ssim: 0.0793
  iou: 0.1429
Layer 5 metrics:
  pearson_correlation: 0.0017
  kl_divergence: -338.0437
  ssim: 0.0793
  iou: 0.1429

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.46531, std: 0.16286

Metrics for layer 6:
  pearson_correlation: 0.0176
  kl_divergence: -393.4349
  ssim: 0.0585
  iou: 0.1313
Layer 6 metrics:
  pearson_correlation: 0.0176
  kl_divergence: -393.4349
  ssim: 0.0585
  iou: 0.1313

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.46555, std: 0.15268

Metrics for layer 7:
  pearson_correlation: -0.0280
  kl_divergence: -70.6145
  ssim: 0.0525
  iou: 0.1598
Layer 7 metrics:
  pearson_correlation: -0.0280
  kl_divergence: -70.6145
  ssim: 0.0525
  iou: 0.1598

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.48501, std: 0.15478

Metrics for layer 8:
  pearson_correlation: -0.0173
  kl_divergence: -92.5053
  ssim: 0.0466
  iou: 0.1200
Layer 8 metrics:
  pearson_correlation: -0.0173
  kl_divergence: -92.5053
  ssim: 0.0466
  iou: 0.1200

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.51269, std: 0.15435

Metrics for layer 9:
  pearson_correlation: 0.0100
  kl_divergence: -99.0721
  ssim: 0.0556
  iou: 0.1200
Layer 9 metrics:
  pearson_correlation: 0.0100
  kl_divergence: -99.0721
  ssim: 0.0556
  iou: 0.1200

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.51366, std: 0.19211

Metrics for layer 10:
  pearson_correlation: 0.0133
  kl_divergence: -22.2408
  ssim: 0.0620
  iou: 0.1395
Layer 10 metrics:
  pearson_correlation: 0.0133
  kl_divergence: -22.2408
  ssim: 0.0620
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.50692, std: 0.20342

Metrics for layer 11:
  pearson_correlation: 0.0838
  kl_divergence: -21.9796
  ssim: 0.1272
  iou: 0.2099
Layer 11 metrics:
  pearson_correlation: 0.0838
  kl_divergence: -21.9796
  ssim: 0.1272
  iou: 0.2099

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.37897, std: 0.16225

Metrics for layer 12:
  pearson_correlation: -0.0854
  kl_divergence: -10.9000
  ssim: 0.0475
  iou: 0.1011
Layer 12 metrics:
  pearson_correlation: -0.0854
  kl_divergence: -10.9000
  ssim: 0.0475
  iou: 0.1011
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer10/batch_1_strength_0.8_results.npy

Processing attention strength 1.2
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.2 0.  0. ]

Processing batch 1/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.43107, std: 0.12470

Metrics for layer 0:
  pearson_correlation: -0.0021
  kl_divergence: -4739.2993
  ssim: 0.0479
  iou: 0.1406
Layer 0 metrics:
  pearson_correlation: -0.0021
  kl_divergence: -4739.2993
  ssim: 0.0479
  iou: 0.1406

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.43426, std: 0.12454

Metrics for layer 1:
  pearson_correlation: -0.0020
  kl_divergence: -4765.7964
  ssim: 0.0493
  iou: 0.1405
Layer 1 metrics:
  pearson_correlation: -0.0020
  kl_divergence: -4765.7964
  ssim: 0.0493
  iou: 0.1405

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.45027, std: 0.14082

Metrics for layer 2:
  pearson_correlation: 0.0011
  kl_divergence: -1454.4330
  ssim: 0.0540
  iou: 0.1377
Layer 2 metrics:
  pearson_correlation: 0.0011
  kl_divergence: -1454.4330
  ssim: 0.0540
  iou: 0.1377

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.43205, std: 0.12541

Metrics for layer 3:
  pearson_correlation: 0.0143
  kl_divergence: -1421.9528
  ssim: 0.0729
  iou: 0.1462
Layer 3 metrics:
  pearson_correlation: 0.0143
  kl_divergence: -1421.9528
  ssim: 0.0729
  iou: 0.1462

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.50076, std: 0.13818

Metrics for layer 4:
  pearson_correlation: -0.0137
  kl_divergence: -409.9963
  ssim: 0.0526
  iou: 0.1329
Layer 4 metrics:
  pearson_correlation: -0.0137
  kl_divergence: -409.9963
  ssim: 0.0526
  iou: 0.1329

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.43692, std: 0.14716

Metrics for layer 5:
  pearson_correlation: -0.0068
  kl_divergence: -354.3342
  ssim: 0.0562
  iou: 0.1272
Layer 5 metrics:
  pearson_correlation: -0.0068
  kl_divergence: -354.3342
  ssim: 0.0562
  iou: 0.1272

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.48707, std: 0.12246

Metrics for layer 6:
  pearson_correlation: -0.0256
  kl_divergence: -402.0546
  ssim: 0.0610
  iou: 0.1404
Layer 6 metrics:
  pearson_correlation: -0.0256
  kl_divergence: -402.0546
  ssim: 0.0610
  iou: 0.1404

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.44015, std: 0.15966

Metrics for layer 7:
  pearson_correlation: 0.0136
  kl_divergence: -80.7252
  ssim: 0.0364
  iou: 0.1429
Layer 7 metrics:
  pearson_correlation: 0.0136
  kl_divergence: -80.7252
  ssim: 0.0364
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.53972, std: 0.14721

Metrics for layer 8:
  pearson_correlation: -0.0563
  kl_divergence: -96.7609
  ssim: 0.0244
  iou: 0.1429
Layer 8 metrics:
  pearson_correlation: -0.0563
  kl_divergence: -96.7609
  ssim: 0.0244
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.53743, std: 0.17108

Metrics for layer 9:
  pearson_correlation: 0.0240
  kl_divergence: -107.0033
  ssim: 0.0538
  iou: 0.1232
Layer 9 metrics:
  pearson_correlation: 0.0240
  kl_divergence: -107.0033
  ssim: 0.0538
  iou: 0.1232

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.44130, std: 0.20207

Metrics for layer 10:
  pearson_correlation: 0.1643
  kl_divergence: -17.8119
  ssim: 0.1773
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: 0.1643
  kl_divergence: -17.8119
  ssim: 0.1773
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.44759, std: 0.16396

Metrics for layer 11:
  pearson_correlation: 0.0036
  kl_divergence: -11.9904
  ssim: 0.0647
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: 0.0036
  kl_divergence: -11.9904
  ssim: 0.0647
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.47048, std: 0.20399

Metrics for layer 12:
  pearson_correlation: -0.1239
  kl_divergence: -16.8960
  ssim: -0.1185
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: -0.1239
  kl_divergence: -16.8960
  ssim: -0.1185
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer10/batch_0_strength_1.2_results.npy

Processing batch 2/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.44843, std: 0.12045

Metrics for layer 0:
  pearson_correlation: 0.0028
  kl_divergence: -5657.1270
  ssim: 0.0629
  iou: 0.1435
Layer 0 metrics:
  pearson_correlation: 0.0028
  kl_divergence: -5657.1270
  ssim: 0.0629
  iou: 0.1435

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.42045, std: 0.11570

Metrics for layer 1:
  pearson_correlation: 0.0032
  kl_divergence: -5339.7148
  ssim: 0.0697
  iou: 0.1456
Layer 1 metrics:
  pearson_correlation: 0.0032
  kl_divergence: -5339.7148
  ssim: 0.0697
  iou: 0.1456

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.49362, std: 0.13452

Metrics for layer 2:
  pearson_correlation: 0.0083
  kl_divergence: -1727.0856
  ssim: 0.0662
  iou: 0.1479
Layer 2 metrics:
  pearson_correlation: 0.0083
  kl_divergence: -1727.0856
  ssim: 0.0662
  iou: 0.1479

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.44193, std: 0.12680

Metrics for layer 3:
  pearson_correlation: 0.0025
  kl_divergence: -1542.9847
  ssim: 0.0759
  iou: 0.1418
Layer 3 metrics:
  pearson_correlation: 0.0025
  kl_divergence: -1542.9847
  ssim: 0.0759
  iou: 0.1418

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.45880, std: 0.15424

Metrics for layer 4:
  pearson_correlation: 0.0153
  kl_divergence: -382.3708
  ssim: 0.0630
  iou: 0.1572
Layer 4 metrics:
  pearson_correlation: 0.0153
  kl_divergence: -382.3708
  ssim: 0.0630
  iou: 0.1572

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.48014, std: 0.13579

Metrics for layer 5:
  pearson_correlation: -0.0149
  kl_divergence: -418.8085
  ssim: 0.0702
  iou: 0.1272
Layer 5 metrics:
  pearson_correlation: -0.0149
  kl_divergence: -418.8085
  ssim: 0.0702
  iou: 0.1272

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.48274, std: 0.14828

Metrics for layer 6:
  pearson_correlation: -0.0177
  kl_divergence: -415.0668
  ssim: 0.0561
  iou: 0.1512
Layer 6 metrics:
  pearson_correlation: -0.0177
  kl_divergence: -415.0668
  ssim: 0.0561
  iou: 0.1512

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.46413, std: 0.14767

Metrics for layer 7:
  pearson_correlation: 0.0717
  kl_divergence: -91.4353
  ssim: 0.0883
  iou: 0.1632
Layer 7 metrics:
  pearson_correlation: 0.0717
  kl_divergence: -91.4353
  ssim: 0.0883
  iou: 0.1632

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.56736, std: 0.14641

Metrics for layer 8:
  pearson_correlation: -0.0465
  kl_divergence: -100.6090
  ssim: 0.0416
  iou: 0.1462
Layer 8 metrics:
  pearson_correlation: -0.0465
  kl_divergence: -100.6090
  ssim: 0.0416
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.45272, std: 0.16719

Metrics for layer 9:
  pearson_correlation: -0.0143
  kl_divergence: -75.5494
  ssim: 0.0290
  iou: 0.1232
Layer 9 metrics:
  pearson_correlation: -0.0143
  kl_divergence: -75.5494
  ssim: 0.0290
  iou: 0.1232

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.43799, std: 0.20138

Metrics for layer 10:
  pearson_correlation: 0.0158
  kl_divergence: -17.8164
  ssim: 0.0257
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: 0.0158
  kl_divergence: -17.8164
  ssim: 0.0257
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.45715, std: 0.20243

Metrics for layer 11:
  pearson_correlation: 0.1296
  kl_divergence: -20.7558
  ssim: 0.1128
  iou: 0.2099
Layer 11 metrics:
  pearson_correlation: 0.1296
  kl_divergence: -20.7558
  ssim: 0.1128
  iou: 0.2099

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.52926, std: 0.18344

Metrics for layer 12:
  pearson_correlation: -0.0539
  kl_divergence: -24.2151
  ssim: 0.0653
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: -0.0539
  kl_divergence: -24.2151
  ssim: 0.0653
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer10/batch_1_strength_1.2_results.npy

Analysis complete! Results saved to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer10
