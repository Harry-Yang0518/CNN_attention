WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-12-16 11:38:44.403241: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-16 11:38:44.422541: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2024-12-16 11:38:44.423060: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4eb0e00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:38:44.423077: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-16 11:38:44.425733: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-16 11:38:44.581444: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4ea27f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:38:44.581461: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-12-16 11:38:44.581953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:2f:00.0
2024-12-16 11:38:44.583030: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:38:44.584000: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:38:44.584938: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:38:44.585880: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:38:44.586809: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:38:44.587736: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:38:44.588666: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:38:44.588678: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-12-16 11:38:44.588697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-16 11:38:44.588701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-16 11:38:44.588704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:61: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:87: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:15: sigmoid_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.sigmoid_cross_entropy instead. Note that the order of the predictions and labels arguments has been changed.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:322: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:82: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.


Verifying paths:
tc_path: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs exists
weight_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists
image_path: /scratch/hy2611/CNN_attention/Data/VGG16/images exists
save_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists

Initializing model...
('c11', [1, 224, 224, 64])
('c12', [1, 224, 224, 64])
('c21', [1, 112, 112, 128])
('c22', [1, 112, 112, 128])
('c31', [1, 56, 56, 256])
('c32', [1, 56, 56, 256])
('c33', [1, 56, 56, 256])
('c41', [1, 28, 28, 512])
('c42', [1, 28, 28, 512])
('c43', [1, 28, 28, 512])
('c51', [1, 14, 14, 512])
('c52', [1, 14, 14, 512])
('c53', [1, 14, 14, 512])
(0, 'conv1_1_W', (3, 3, 3, 64))
(1, 'conv1_1_b', (64,))
(2, 'conv1_2_W', (3, 3, 64, 64))
(3, 'conv1_2_b', (64,))
(4, 'conv2_1_W', (3, 3, 64, 128))
(5, 'conv2_1_b', (128,))
(6, 'conv2_2_W', (3, 3, 128, 128))
(7, 'conv2_2_b', (128,))
(8, 'conv3_1_W', (3, 3, 128, 256))
(9, 'conv3_1_b', (256,))
(10, 'conv3_2_W', (3, 3, 256, 256))
(11, 'conv3_2_b', (256,))
(12, 'conv3_3_W', (3, 3, 256, 256))
(13, 'conv3_3_b', (256,))
(14, 'conv4_1_W', (3, 3, 256, 512))
(15, 'conv4_1_b', (512,))
(16, 'conv4_2_W', (3, 3, 512, 512))
(17, 'conv4_2_b', (512,))
(18, 'conv4_3_W', (3, 3, 512, 512))
(19, 'conv4_3_b', (512,))
(20, 'conv5_1_W', (3, 3, 512, 512))
(21, 'conv5_1_b', (512,))
(22, 'conv5_2_W', (3, 3, 512, 512))
(23, 'conv5_2_b', (512,))
(24, 'conv5_3_W', (3, 3, 512, 512))
(25, 'conv5_3_b', (512,))
(26, 'fc6_W', (25088, 4096))
(27, 'fc6_b', (4096,))
(28, 'fc7_W', (4096, 4096))
(29, 'fc7_b', (4096,))
Checking checkpoint files:
Data file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_13.ckpt.data-00000-of-00001 - Found
Index file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_13.ckpt.index - Found
Loading checkpoint from: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_13.ckpt
Checkpoint loaded successfully

Initializing components...
Found tuning curves file: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs/featvecs20_train35_c.txt

Loading category 13 data...
Original positive images shape: (2, 224, 224, 3)

Processing data...

Processing attention strength 0.0
Attention vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

Processing batch 1/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.39234, std: 0.11357

Metrics for layer 0:
  pearson_correlation: -0.0040
  kl_divergence: -4436.2627
  ssim: 0.0594
  iou: 0.1423
Layer 0 metrics:
  pearson_correlation: -0.0040
  kl_divergence: -4436.2627
  ssim: 0.0594
  iou: 0.1423

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.43246, std: 0.12686

Metrics for layer 1:
  pearson_correlation: 0.0026
  kl_divergence: -4747.3154
  ssim: 0.0488
  iou: 0.1436
Layer 1 metrics:
  pearson_correlation: 0.0026
  kl_divergence: -4747.3154
  ssim: 0.0488
  iou: 0.1436

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.43911, std: 0.12460

Metrics for layer 2:
  pearson_correlation: 0.0032
  kl_divergence: -1441.2842
  ssim: 0.0677
  iou: 0.1479
Layer 2 metrics:
  pearson_correlation: 0.0032
  kl_divergence: -1441.2842
  ssim: 0.0677
  iou: 0.1479

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.45659, std: 0.13039

Metrics for layer 3:
  pearson_correlation: 0.0013
  kl_divergence: -1488.8351
  ssim: 0.0618
  iou: 0.1406
Layer 3 metrics:
  pearson_correlation: 0.0013
  kl_divergence: -1488.8351
  ssim: 0.0618
  iou: 0.1406

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.50254, std: 0.13811

Metrics for layer 4:
  pearson_correlation: 0.0203
  kl_divergence: -417.8859
  ssim: 0.0614
  iou: 0.1462
Layer 4 metrics:
  pearson_correlation: 0.0203
  kl_divergence: -417.8859
  ssim: 0.0614
  iou: 0.1462

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.48620, std: 0.15418

Metrics for layer 5:
  pearson_correlation: -0.0109
  kl_divergence: -394.8734
  ssim: 0.0494
  iou: 0.1563
Layer 5 metrics:
  pearson_correlation: -0.0109
  kl_divergence: -394.8734
  ssim: 0.0494
  iou: 0.1563

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.44540, std: 0.12318

Metrics for layer 6:
  pearson_correlation: 0.0443
  kl_divergence: -372.6177
  ssim: 0.0927
  iou: 0.1487
Layer 6 metrics:
  pearson_correlation: 0.0443
  kl_divergence: -372.6177
  ssim: 0.0927
  iou: 0.1487

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.48844, std: 0.15806

Metrics for layer 7:
  pearson_correlation: -0.0455
  kl_divergence: -96.4651
  ssim: 0.0300
  iou: 0.1297
Layer 7 metrics:
  pearson_correlation: -0.0455
  kl_divergence: -96.4651
  ssim: 0.0300
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.47878, std: 0.17340

Metrics for layer 8:
  pearson_correlation: 0.0277
  kl_divergence: -92.5688
  ssim: 0.0506
  iou: 0.1772
Layer 8 metrics:
  pearson_correlation: 0.0277
  kl_divergence: -92.5688
  ssim: 0.0506
  iou: 0.1772

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.50354, std: 0.18247

Metrics for layer 9:
  pearson_correlation: -0.0206
  kl_divergence: -94.8802
  ssim: 0.0254
  iou: 0.1329
Layer 9 metrics:
  pearson_correlation: -0.0206
  kl_divergence: -94.8802
  ssim: 0.0254
  iou: 0.1329

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.43184, std: 0.16531

Metrics for layer 10:
  pearson_correlation: 0.0422
  kl_divergence: -17.1275
  ssim: 0.0521
  iou: 0.1667
Layer 10 metrics:
  pearson_correlation: 0.0422
  kl_divergence: -17.1275
  ssim: 0.0521
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.58376, std: 0.18238

Metrics for layer 11:
  pearson_correlation: 0.2348
  kl_divergence: -25.8120
  ssim: 0.1854
  iou: 0.2099
Layer 11 metrics:
  pearson_correlation: 0.2348
  kl_divergence: -25.8120
  ssim: 0.1854
  iou: 0.2099

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.49548, std: 0.18864

Metrics for layer 12:
  pearson_correlation: -0.0799
  kl_divergence: -12.2287
  ssim: -0.0104
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: -0.0799
  kl_divergence: -12.2287
  ssim: -0.0104
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer7/batch_0_strength_0.0_results.npy

Processing batch 2/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.44431, std: 0.12372

Metrics for layer 0:
  pearson_correlation: -0.0011
  kl_divergence: -5593.2207
  ssim: 0.0605
  iou: 0.1434
Layer 0 metrics:
  pearson_correlation: -0.0011
  kl_divergence: -5593.2207
  ssim: 0.0605
  iou: 0.1434

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.42775, std: 0.12447

Metrics for layer 1:
  pearson_correlation: 0.0009
  kl_divergence: -5397.4897
  ssim: 0.0625
  iou: 0.1424
Layer 1 metrics:
  pearson_correlation: 0.0009
  kl_divergence: -5397.4897
  ssim: 0.0625
  iou: 0.1424

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.47261, std: 0.12828

Metrics for layer 2:
  pearson_correlation: -0.0087
  kl_divergence: -1653.1882
  ssim: 0.0690
  iou: 0.1373
Layer 2 metrics:
  pearson_correlation: -0.0087
  kl_divergence: -1653.1882
  ssim: 0.0690
  iou: 0.1373

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.47174, std: 0.13066

Metrics for layer 3:
  pearson_correlation: 0.0015
  kl_divergence: -1651.4463
  ssim: 0.0712
  iou: 0.1379
Layer 3 metrics:
  pearson_correlation: 0.0015
  kl_divergence: -1651.4463
  ssim: 0.0712
  iou: 0.1379

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.49439, std: 0.14477

Metrics for layer 4:
  pearson_correlation: 0.0173
  kl_divergence: -431.3388
  ssim: 0.0678
  iou: 0.1420
Layer 4 metrics:
  pearson_correlation: 0.0173
  kl_divergence: -431.3388
  ssim: 0.0678
  iou: 0.1420

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.45815, std: 0.14573

Metrics for layer 5:
  pearson_correlation: -0.0070
  kl_divergence: -389.7463
  ssim: 0.0593
  iou: 0.1420
Layer 5 metrics:
  pearson_correlation: -0.0070
  kl_divergence: -389.7463
  ssim: 0.0593
  iou: 0.1420

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.48422, std: 0.13659

Metrics for layer 6:
  pearson_correlation: -0.0036
  kl_divergence: -423.2323
  ssim: 0.0575
  iou: 0.1404
Layer 6 metrics:
  pearson_correlation: -0.0036
  kl_divergence: -423.2323
  ssim: 0.0575
  iou: 0.1404

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.49396, std: 0.16837

Metrics for layer 7:
  pearson_correlation: -0.0454
  kl_divergence: -84.7066
  ssim: 0.0211
  iou: 0.1264
Layer 7 metrics:
  pearson_correlation: -0.0454
  kl_divergence: -84.7066
  ssim: 0.0211
  iou: 0.1264

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.54038, std: 0.14387

Metrics for layer 8:
  pearson_correlation: 0.0347
  kl_divergence: -106.5925
  ssim: 0.0565
  iou: 0.1395
Layer 8 metrics:
  pearson_correlation: 0.0347
  kl_divergence: -106.5925
  ssim: 0.0565
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.45622, std: 0.12794

Metrics for layer 9:
  pearson_correlation: 0.0443
  kl_divergence: -86.3736
  ssim: 0.0883
  iou: 0.1529
Layer 9 metrics:
  pearson_correlation: 0.0443
  kl_divergence: -86.3736
  ssim: 0.0883
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.46255, std: 0.17459

Metrics for layer 10:
  pearson_correlation: -0.1032
  kl_divergence: -16.7893
  ssim: -0.0273
  iou: 0.1264
Layer 10 metrics:
  pearson_correlation: -0.1032
  kl_divergence: -16.7893
  ssim: -0.0273
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.50674, std: 0.19619

Metrics for layer 11:
  pearson_correlation: 0.0659
  kl_divergence: -22.2994
  ssim: 0.0239
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: 0.0659
  kl_divergence: -22.2994
  ssim: 0.0239
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.60159, std: 0.17368

Metrics for layer 12:
  pearson_correlation: 0.0342
  kl_divergence: -30.3048
  ssim: 0.0650
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: 0.0342
  kl_divergence: -30.3048
  ssim: 0.0650
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer7/batch_1_strength_0.0_results.npy

Processing attention strength 0.4
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.4 0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.39316, std: 0.11522

Metrics for layer 0:
  pearson_correlation: -0.0041
  kl_divergence: -4439.3999
  ssim: 0.0582
  iou: 0.1412
Layer 0 metrics:
  pearson_correlation: -0.0041
  kl_divergence: -4439.3999
  ssim: 0.0582
  iou: 0.1412

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.44788, std: 0.12014

Metrics for layer 1:
  pearson_correlation: 0.0046
  kl_divergence: -4891.0444
  ssim: 0.0500
  iou: 0.1444
Layer 1 metrics:
  pearson_correlation: 0.0046
  kl_divergence: -4891.0444
  ssim: 0.0500
  iou: 0.1444

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.45857, std: 0.12625

Metrics for layer 2:
  pearson_correlation: 0.0030
  kl_divergence: -1495.9427
  ssim: 0.0651
  iou: 0.1487
Layer 2 metrics:
  pearson_correlation: 0.0030
  kl_divergence: -1495.9427
  ssim: 0.0651
  iou: 0.1487

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.44597, std: 0.11481

Metrics for layer 3:
  pearson_correlation: 0.0038
  kl_divergence: -1471.7461
  ssim: 0.0744
  iou: 0.1424
Layer 3 metrics:
  pearson_correlation: 0.0038
  kl_divergence: -1471.7461
  ssim: 0.0744
  iou: 0.1424

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.52850, std: 0.14560

Metrics for layer 4:
  pearson_correlation: -0.0191
  kl_divergence: -431.3058
  ssim: 0.0431
  iou: 0.1387
Layer 4 metrics:
  pearson_correlation: -0.0191
  kl_divergence: -431.3058
  ssim: 0.0431
  iou: 0.1387

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.52380, std: 0.15043

Metrics for layer 5:
  pearson_correlation: -0.0066
  kl_divergence: -427.1127
  ssim: 0.0474
  iou: 0.1321
Layer 5 metrics:
  pearson_correlation: -0.0066
  kl_divergence: -427.1127
  ssim: 0.0474
  iou: 0.1321

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.47851, std: 0.12975

Metrics for layer 6:
  pearson_correlation: 0.0100
  kl_divergence: -398.8520
  ssim: 0.0693
  iou: 0.1395
Layer 6 metrics:
  pearson_correlation: 0.0100
  kl_divergence: -398.8520
  ssim: 0.0693
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.52530, std: 0.17692

Metrics for layer 7:
  pearson_correlation: 0.0472
  kl_divergence: -102.6742
  ssim: 0.0447
  iou: 0.1632
Layer 7 metrics:
  pearson_correlation: 0.0472
  kl_divergence: -102.6742
  ssim: 0.0447
  iou: 0.1632

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.51661, std: 0.16415

Metrics for layer 8:
  pearson_correlation: 0.0511
  kl_divergence: -104.7634
  ssim: 0.0584
  iou: 0.1462
Layer 8 metrics:
  pearson_correlation: 0.0511
  kl_divergence: -104.7634
  ssim: 0.0584
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.44129, std: 0.14321

Metrics for layer 9:
  pearson_correlation: -0.0125
  kl_divergence: -84.7907
  ssim: 0.0716
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: -0.0125
  kl_divergence: -84.7907
  ssim: 0.0716
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.55012, std: 0.17734

Metrics for layer 10:
  pearson_correlation: 0.0468
  kl_divergence: -23.0660
  ssim: 0.1183
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: 0.0468
  kl_divergence: -23.0660
  ssim: 0.1183
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.55098, std: 0.17783

Metrics for layer 11:
  pearson_correlation: -0.0357
  kl_divergence: -24.6491
  ssim: 0.0048
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: -0.0357
  kl_divergence: -24.6491
  ssim: 0.0048
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.50642, std: 0.19771

Metrics for layer 12:
  pearson_correlation: 0.2008
  kl_divergence: -19.3364
  ssim: 0.0919
  iou: 0.1951
Layer 12 metrics:
  pearson_correlation: 0.2008
  kl_divergence: -19.3364
  ssim: 0.0919
  iou: 0.1951
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer7/batch_0_strength_0.4_results.npy

Processing batch 2/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.40659, std: 0.11455

Metrics for layer 0:
  pearson_correlation: -0.0023
  kl_divergence: -5166.7432
  ssim: 0.0721
  iou: 0.1433
Layer 0 metrics:
  pearson_correlation: -0.0023
  kl_divergence: -5166.7432
  ssim: 0.0721
  iou: 0.1433

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.43127, std: 0.12567

Metrics for layer 1:
  pearson_correlation: 0.0002
  kl_divergence: -5432.3218
  ssim: 0.0636
  iou: 0.1414
Layer 1 metrics:
  pearson_correlation: 0.0002
  kl_divergence: -5432.3218
  ssim: 0.0636
  iou: 0.1414

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.48528, std: 0.13807

Metrics for layer 2:
  pearson_correlation: 0.0062
  kl_divergence: -1693.5177
  ssim: 0.0624
  iou: 0.1468
Layer 2 metrics:
  pearson_correlation: 0.0062
  kl_divergence: -1693.5177
  ssim: 0.0624
  iou: 0.1468

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.45672, std: 0.13554

Metrics for layer 3:
  pearson_correlation: -0.0107
  kl_divergence: -1581.4199
  ssim: 0.0636
  iou: 0.1414
Layer 3 metrics:
  pearson_correlation: -0.0107
  kl_divergence: -1581.4199
  ssim: 0.0636
  iou: 0.1414

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.41126, std: 0.12725

Metrics for layer 4:
  pearson_correlation: -0.0279
  kl_divergence: -343.6005
  ssim: 0.0699
  iou: 0.1248
Layer 4 metrics:
  pearson_correlation: -0.0279
  kl_divergence: -343.6005
  ssim: 0.0699
  iou: 0.1248

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.47093, std: 0.15248

Metrics for layer 5:
  pearson_correlation: 0.0045
  kl_divergence: -400.4831
  ssim: 0.0593
  iou: 0.1437
Layer 5 metrics:
  pearson_correlation: 0.0045
  kl_divergence: -400.4831
  ssim: 0.0593
  iou: 0.1437

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.51168, std: 0.14104

Metrics for layer 6:
  pearson_correlation: -0.0137
  kl_divergence: -443.3337
  ssim: 0.0523
  iou: 0.1371
Layer 6 metrics:
  pearson_correlation: -0.0137
  kl_divergence: -443.3337
  ssim: 0.0523
  iou: 0.1371

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.53441, std: 0.16531

Metrics for layer 7:
  pearson_correlation: 0.0199
  kl_divergence: -106.7027
  ssim: 0.0385
  iou: 0.1598
Layer 7 metrics:
  pearson_correlation: 0.0199
  kl_divergence: -106.7027
  ssim: 0.0385
  iou: 0.1598

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.45749, std: 0.15601

Metrics for layer 8:
  pearson_correlation: 0.0190
  kl_divergence: -82.5993
  ssim: 0.0810
  iou: 0.1563
Layer 8 metrics:
  pearson_correlation: 0.0190
  kl_divergence: -82.5993
  ssim: 0.0810
  iou: 0.1563

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.51426, std: 0.15812

Metrics for layer 9:
  pearson_correlation: -0.0249
  kl_divergence: -96.5587
  ssim: 0.0485
  iou: 0.1429
Layer 9 metrics:
  pearson_correlation: -0.0249
  kl_divergence: -96.5587
  ssim: 0.0485
  iou: 0.1429

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.45899, std: 0.19757

Metrics for layer 10:
  pearson_correlation: 0.0099
  kl_divergence: -20.0520
  ssim: 0.0742
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: 0.0099
  kl_divergence: -20.0520
  ssim: 0.0742
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.52367, std: 0.16394

Metrics for layer 11:
  pearson_correlation: 0.1220
  kl_divergence: -26.8783
  ssim: 0.1215
  iou: 0.1667
Layer 11 metrics:
  pearson_correlation: 0.1220
  kl_divergence: -26.8783
  ssim: 0.1215
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.44590, std: 0.17177

Metrics for layer 12:
  pearson_correlation: -0.0277
  kl_divergence: -19.6766
  ssim: -0.0205
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: -0.0277
  kl_divergence: -19.6766
  ssim: -0.0205
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer7/batch_1_strength_0.4_results.npy

Processing attention strength 0.8
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.8 0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.42513, std: 0.11798

Metrics for layer 0:
  pearson_correlation: -0.0030
  kl_divergence: -4704.0059
  ssim: 0.0524
  iou: 0.1422
Layer 0 metrics:
  pearson_correlation: -0.0030
  kl_divergence: -4704.0059
  ssim: 0.0524
  iou: 0.1422

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.39600, std: 0.11582

Metrics for layer 1:
  pearson_correlation: 0.0004
  kl_divergence: -4467.3501
  ssim: 0.0568
  iou: 0.1416
Layer 1 metrics:
  pearson_correlation: 0.0004
  kl_divergence: -4467.3501
  ssim: 0.0568
  iou: 0.1416

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.43693, std: 0.12336

Metrics for layer 2:
  pearson_correlation: 0.0165
  kl_divergence: -1439.1062
  ssim: 0.0737
  iou: 0.1506
Layer 2 metrics:
  pearson_correlation: 0.0165
  kl_divergence: -1439.1062
  ssim: 0.0737
  iou: 0.1506

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.48393, std: 0.14192

Metrics for layer 3:
  pearson_correlation: -0.0042
  kl_divergence: -1555.2544
  ssim: 0.0480
  iou: 0.1420
Layer 3 metrics:
  pearson_correlation: -0.0042
  kl_divergence: -1555.2544
  ssim: 0.0480
  iou: 0.1420

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.47484, std: 0.15372

Metrics for layer 4:
  pearson_correlation: -0.0431
  kl_divergence: -381.6947
  ssim: 0.0429
  iou: 0.1354
Layer 4 metrics:
  pearson_correlation: -0.0431
  kl_divergence: -381.6947
  ssim: 0.0429
  iou: 0.1354

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.49377, std: 0.14237

Metrics for layer 5:
  pearson_correlation: -0.0104
  kl_divergence: -398.2497
  ssim: 0.0585
  iou: 0.1437
Layer 5 metrics:
  pearson_correlation: -0.0104
  kl_divergence: -398.2497
  ssim: 0.0585
  iou: 0.1437

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.48216, std: 0.13369

Metrics for layer 6:
  pearson_correlation: -0.0001
  kl_divergence: -398.7612
  ssim: 0.0636
  iou: 0.1470
Layer 6 metrics:
  pearson_correlation: -0.0001
  kl_divergence: -398.7612
  ssim: 0.0636
  iou: 0.1470

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.50400, std: 0.18157

Metrics for layer 7:
  pearson_correlation: 0.0022
  kl_divergence: -93.7595
  ssim: 0.0593
  iou: 0.1462
Layer 7 metrics:
  pearson_correlation: 0.0022
  kl_divergence: -93.7595
  ssim: 0.0593
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.46341, std: 0.15477

Metrics for layer 8:
  pearson_correlation: -0.0018
  kl_divergence: -87.8861
  ssim: 0.0554
  iou: 0.1462
Layer 8 metrics:
  pearson_correlation: -0.0018
  kl_divergence: -87.8861
  ssim: 0.0554
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.53831, std: 0.14840

Metrics for layer 9:
  pearson_correlation: 0.0319
  kl_divergence: -108.6234
  ssim: 0.0510
  iou: 0.1632
Layer 9 metrics:
  pearson_correlation: 0.0319
  kl_divergence: -108.6234
  ssim: 0.0510
  iou: 0.1632

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.53520, std: 0.18126

Metrics for layer 10:
  pearson_correlation: -0.0640
  kl_divergence: -22.4261
  ssim: -0.0492
  iou: 0.1264
Layer 10 metrics:
  pearson_correlation: -0.0640
  kl_divergence: -22.4261
  ssim: -0.0492
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.49196, std: 0.18405

Metrics for layer 11:
  pearson_correlation: 0.0848
  kl_divergence: -18.5990
  ssim: 0.1075
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: 0.0848
  kl_divergence: -18.5990
  ssim: 0.1075
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.43982, std: 0.18314

Metrics for layer 12:
  pearson_correlation: -0.0525
  kl_divergence: -13.9596
  ssim: 0.0024
  iou: 0.1136
Layer 12 metrics:
  pearson_correlation: -0.0525
  kl_divergence: -13.9596
  ssim: 0.0024
  iou: 0.1136
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer7/batch_0_strength_0.8_results.npy

Processing batch 2/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.44238, std: 0.11914

Metrics for layer 0:
  pearson_correlation: -0.0033
  kl_divergence: -5586.8735
  ssim: 0.0636
  iou: 0.1436
Layer 0 metrics:
  pearson_correlation: -0.0033
  kl_divergence: -5586.8735
  ssim: 0.0636
  iou: 0.1436

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.42932, std: 0.11712

Metrics for layer 1:
  pearson_correlation: 0.0034
  kl_divergence: -5447.6963
  ssim: 0.0696
  iou: 0.1426
Layer 1 metrics:
  pearson_correlation: 0.0034
  kl_divergence: -5447.6963
  ssim: 0.0696
  iou: 0.1426

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.39394, std: 0.11903

Metrics for layer 2:
  pearson_correlation: 0.0136
  kl_divergence: -1350.4808
  ssim: 0.0959
  iou: 0.1426
Layer 2 metrics:
  pearson_correlation: 0.0136
  kl_divergence: -1350.4808
  ssim: 0.0959
  iou: 0.1426

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.43797, std: 0.13023

Metrics for layer 3:
  pearson_correlation: -0.0008
  kl_divergence: -1513.2844
  ssim: 0.0763
  iou: 0.1477
Layer 3 metrics:
  pearson_correlation: -0.0008
  kl_divergence: -1513.2844
  ssim: 0.0763
  iou: 0.1477

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.49083, std: 0.15088

Metrics for layer 4:
  pearson_correlation: -0.0134
  kl_divergence: -419.6827
  ssim: 0.0552
  iou: 0.1362
Layer 4 metrics:
  pearson_correlation: -0.0134
  kl_divergence: -419.6827
  ssim: 0.0552
  iou: 0.1362

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.48485, std: 0.14585

Metrics for layer 5:
  pearson_correlation: -0.0093
  kl_divergence: -413.4705
  ssim: 0.0551
  iou: 0.1496
Layer 5 metrics:
  pearson_correlation: -0.0093
  kl_divergence: -413.4705
  ssim: 0.0551
  iou: 0.1496

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.47172, std: 0.12484

Metrics for layer 6:
  pearson_correlation: 0.0182
  kl_divergence: -414.6407
  ssim: 0.0862
  iou: 0.1454
Layer 6 metrics:
  pearson_correlation: 0.0182
  kl_divergence: -414.6407
  ssim: 0.0862
  iou: 0.1454

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.51483, std: 0.15129

Metrics for layer 7:
  pearson_correlation: 0.0200
  kl_divergence: -100.7702
  ssim: 0.0597
  iou: 0.1462
Layer 7 metrics:
  pearson_correlation: 0.0200
  kl_divergence: -100.7702
  ssim: 0.0597
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.39408, std: 0.15664

Metrics for layer 8:
  pearson_correlation: 0.0114
  kl_divergence: -59.0914
  ssim: 0.0786
  iou: 0.1168
Layer 8 metrics:
  pearson_correlation: 0.0114
  kl_divergence: -59.0914
  ssim: 0.0786
  iou: 0.1168

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.47340, std: 0.14439

Metrics for layer 9:
  pearson_correlation: 0.0179
  kl_divergence: -89.6641
  ssim: 0.0757
  iou: 0.1632
Layer 9 metrics:
  pearson_correlation: 0.0179
  kl_divergence: -89.6641
  ssim: 0.0757
  iou: 0.1632

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.51075, std: 0.19615

Metrics for layer 10:
  pearson_correlation: -0.1132
  kl_divergence: -19.8691
  ssim: 0.0385
  iou: 0.1136
Layer 10 metrics:
  pearson_correlation: -0.1132
  kl_divergence: -19.8691
  ssim: 0.0385
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.39384, std: 0.16685

Metrics for layer 11:
  pearson_correlation: -0.0644
  kl_divergence: -13.2501
  ssim: 0.0105
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: -0.0644
  kl_divergence: -13.2501
  ssim: 0.0105
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.51304, std: 0.19372

Metrics for layer 12:
  pearson_correlation: 0.0414
  kl_divergence: -24.8127
  ssim: 0.0894
  iou: 0.1951
Layer 12 metrics:
  pearson_correlation: 0.0414
  kl_divergence: -24.8127
  ssim: 0.0894
  iou: 0.1951
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer7/batch_1_strength_0.8_results.npy

Processing attention strength 1.2
Attention vector: [0.  0.  0.  0.  0.  0.  0.  1.2 0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.36402, std: 0.10509

Metrics for layer 0:
  pearson_correlation: 0.0081
  kl_divergence: -4209.3350
  ssim: 0.0702
  iou: 0.1455
Layer 0 metrics:
  pearson_correlation: 0.0081
  kl_divergence: -4209.3350
  ssim: 0.0702
  iou: 0.1455

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.37583, std: 0.11095

Metrics for layer 1:
  pearson_correlation: -0.0028
  kl_divergence: -4292.8447
  ssim: 0.0646
  iou: 0.1421
Layer 1 metrics:
  pearson_correlation: -0.0028
  kl_divergence: -4292.8447
  ssim: 0.0646
  iou: 0.1421

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.46065, std: 0.13276

Metrics for layer 2:
  pearson_correlation: 0.0038
  kl_divergence: -1499.2192
  ssim: 0.0609
  iou: 0.1464
Layer 2 metrics:
  pearson_correlation: 0.0038
  kl_divergence: -1499.2192
  ssim: 0.0609
  iou: 0.1464

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.46266, std: 0.12723

Metrics for layer 3:
  pearson_correlation: 0.0172
  kl_divergence: -1513.1055
  ssim: 0.0674
  iou: 0.1439
Layer 3 metrics:
  pearson_correlation: 0.0172
  kl_divergence: -1513.1055
  ssim: 0.0674
  iou: 0.1439

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.47982, std: 0.14367

Metrics for layer 4:
  pearson_correlation: -0.0266
  kl_divergence: -392.6957
  ssim: 0.0440
  iou: 0.1379
Layer 4 metrics:
  pearson_correlation: -0.0266
  kl_divergence: -392.6957
  ssim: 0.0440
  iou: 0.1379

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.46592, std: 0.15260

Metrics for layer 5:
  pearson_correlation: -0.0024
  kl_divergence: -379.3218
  ssim: 0.0530
  iou: 0.1387
Layer 5 metrics:
  pearson_correlation: -0.0024
  kl_divergence: -379.3218
  ssim: 0.0530
  iou: 0.1387

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.47316, std: 0.13527

Metrics for layer 6:
  pearson_correlation: 0.0176
  kl_divergence: -391.2782
  ssim: 0.0676
  iou: 0.1454
Layer 6 metrics:
  pearson_correlation: 0.0176
  kl_divergence: -391.2782
  ssim: 0.0676
  iou: 0.1454

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.51214, std: 0.17837

Metrics for layer 7:
  pearson_correlation: 0.0455
  kl_divergence: -101.8851
  ssim: 0.0590
  iou: 0.1772
Layer 7 metrics:
  pearson_correlation: 0.0455
  kl_divergence: -101.8851
  ssim: 0.0590
  iou: 0.1772

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.43441, std: 0.14699

Metrics for layer 8:
  pearson_correlation: -0.0774
  kl_divergence: -82.0814
  ssim: 0.0411
  iou: 0.1232
Layer 8 metrics:
  pearson_correlation: -0.0774
  kl_divergence: -82.0814
  ssim: 0.0411
  iou: 0.1232

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.48053, std: 0.15424

Metrics for layer 9:
  pearson_correlation: 0.0397
  kl_divergence: -95.3281
  ssim: 0.0888
  iou: 0.1232
Layer 9 metrics:
  pearson_correlation: 0.0397
  kl_divergence: -95.3281
  ssim: 0.0888
  iou: 0.1232

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.55922, std: 0.17786

Metrics for layer 10:
  pearson_correlation: 0.0551
  kl_divergence: -26.1981
  ssim: 0.0798
  iou: 0.1136
Layer 10 metrics:
  pearson_correlation: 0.0551
  kl_divergence: -26.1981
  ssim: 0.0798
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.52886, std: 0.18492

Metrics for layer 11:
  pearson_correlation: 0.0761
  kl_divergence: -24.8662
  ssim: 0.0402
  iou: 0.1807
Layer 11 metrics:
  pearson_correlation: 0.0761
  kl_divergence: -24.8662
  ssim: 0.0402
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.41717, std: 0.15829

Metrics for layer 12:
  pearson_correlation: 0.1236
  kl_divergence: -16.6388
  ssim: 0.1383
  iou: 0.2099
Layer 12 metrics:
  pearson_correlation: 0.1236
  kl_divergence: -16.6388
  ssim: 0.1383
  iou: 0.2099
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer7/batch_0_strength_1.2_results.npy

Processing batch 2/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.42303, std: 0.13171

Metrics for layer 0:
  pearson_correlation: 0.0025
  kl_divergence: -5305.6489
  ssim: 0.0606
  iou: 0.1459
Layer 0 metrics:
  pearson_correlation: 0.0025
  kl_divergence: -5305.6489
  ssim: 0.0606
  iou: 0.1459

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.45000, std: 0.12616

Metrics for layer 1:
  pearson_correlation: -0.0023
  kl_divergence: -5652.1221
  ssim: 0.0579
  iou: 0.1423
Layer 1 metrics:
  pearson_correlation: -0.0023
  kl_divergence: -5652.1221
  ssim: 0.0579
  iou: 0.1423

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.43789, std: 0.11746

Metrics for layer 2:
  pearson_correlation: 0.0013
  kl_divergence: -1535.2322
  ssim: 0.0829
  iou: 0.1422
Layer 2 metrics:
  pearson_correlation: 0.0013
  kl_divergence: -1535.2322
  ssim: 0.0829
  iou: 0.1422

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.47687, std: 0.13448

Metrics for layer 3:
  pearson_correlation: 0.0057
  kl_divergence: -1664.7003
  ssim: 0.0654
  iou: 0.1410
Layer 3 metrics:
  pearson_correlation: 0.0057
  kl_divergence: -1664.7003
  ssim: 0.0654
  iou: 0.1410

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.49125, std: 0.14788

Metrics for layer 4:
  pearson_correlation: 0.0116
  kl_divergence: -425.8957
  ssim: 0.0505
  iou: 0.1429
Layer 4 metrics:
  pearson_correlation: 0.0116
  kl_divergence: -425.8957
  ssim: 0.0505
  iou: 0.1429

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.48778, std: 0.14004

Metrics for layer 5:
  pearson_correlation: -0.0043
  kl_divergence: -422.2355
  ssim: 0.0601
  iou: 0.1504
Layer 5 metrics:
  pearson_correlation: -0.0043
  kl_divergence: -422.2355
  ssim: 0.0601
  iou: 0.1504

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.49910, std: 0.15111

Metrics for layer 6:
  pearson_correlation: 0.0195
  kl_divergence: -431.5711
  ssim: 0.0667
  iou: 0.1379
Layer 6 metrics:
  pearson_correlation: 0.0195
  kl_divergence: -431.5711
  ssim: 0.0667
  iou: 0.1379

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.47003, std: 0.15783

Metrics for layer 7:
  pearson_correlation: -0.0296
  kl_divergence: -85.7296
  ssim: 0.0195
  iou: 0.1011
Layer 7 metrics:
  pearson_correlation: -0.0296
  kl_divergence: -85.7296
  ssim: 0.0195
  iou: 0.1011

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.49239, std: 0.16823

Metrics for layer 8:
  pearson_correlation: -0.0023
  kl_divergence: -88.4217
  ssim: 0.0611
  iou: 0.1329
Layer 8 metrics:
  pearson_correlation: -0.0023
  kl_divergence: -88.4217
  ssim: 0.0611
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.50867, std: 0.15786

Metrics for layer 9:
  pearson_correlation: -0.0449
  kl_divergence: -91.8646
  ssim: 0.0406
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: -0.0449
  kl_divergence: -91.8646
  ssim: 0.0406
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.46250, std: 0.18530

Metrics for layer 10:
  pearson_correlation: 0.0273
  kl_divergence: -14.6503
  ssim: 0.0498
  iou: 0.1951
Layer 10 metrics:
  pearson_correlation: 0.0273
  kl_divergence: -14.6503
  ssim: 0.0498
  iou: 0.1951

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.46612, std: 0.19384

Metrics for layer 11:
  pearson_correlation: -0.0839
  kl_divergence: -15.2740
  ssim: -0.0157
  iou: 0.0889
Layer 11 metrics:
  pearson_correlation: -0.0839
  kl_divergence: -15.2740
  ssim: -0.0157
  iou: 0.0889

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.49155, std: 0.15480

Metrics for layer 12:
  pearson_correlation: -0.0051
  kl_divergence: -22.6424
  ssim: 0.0234
  iou: 0.1264
Layer 12 metrics:
  pearson_correlation: -0.0051
  kl_divergence: -22.6424
  ssim: 0.0234
  iou: 0.1264
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer7/batch_1_strength_1.2_results.npy

Analysis complete! Results saved to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer7
