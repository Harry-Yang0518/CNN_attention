Starting experiments for category 5
Running experiment for category 5, layer 0
===================================================
Starting experiment:
Category: 5
Layer: 0
Logs will be saved to: /scratch/hy2611/CNN_attention/logs/attention_analysis_20241216_104146/category5/layer0
===================================================
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-12-16 10:41:54.404802: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-16 10:41:54.423522: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2024-12-16 10:41:54.423951: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4078dc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-16 10:41:54.423970: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-16 10:41:54.426658: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-16 10:41:54.556194: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4070290 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-16 10:41:54.556213: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-12-16 10:41:54.556684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:2f:00.0
2024-12-16 10:41:54.557886: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:41:54.558944: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:41:54.559977: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:41:54.560992: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:41:54.562004: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:41:54.563034: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:41:54.564080: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:41:54.564092: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-12-16 10:41:54.564110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-16 10:41:54.564115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-16 10:41:54.564118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:61: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:87: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:15: sigmoid_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.sigmoid_cross_entropy instead. Note that the order of the predictions and labels arguments has been changed.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:322: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:82: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.


Verifying paths:
tc_path: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs exists
weight_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists
image_path: /scratch/hy2611/CNN_attention/Data/VGG16/images exists
save_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists

Initializing model...
('c11', [1, 224, 224, 64])
('c12', [1, 224, 224, 64])
('c21', [1, 112, 112, 128])
('c22', [1, 112, 112, 128])
('c31', [1, 56, 56, 256])
('c32', [1, 56, 56, 256])
('c33', [1, 56, 56, 256])
('c41', [1, 28, 28, 512])
('c42', [1, 28, 28, 512])
('c43', [1, 28, 28, 512])
('c51', [1, 14, 14, 512])
('c52', [1, 14, 14, 512])
('c53', [1, 14, 14, 512])
(0, 'conv1_1_W', (3, 3, 3, 64))
(1, 'conv1_1_b', (64,))
(2, 'conv1_2_W', (3, 3, 64, 64))
(3, 'conv1_2_b', (64,))
(4, 'conv2_1_W', (3, 3, 64, 128))
(5, 'conv2_1_b', (128,))
(6, 'conv2_2_W', (3, 3, 128, 128))
(7, 'conv2_2_b', (128,))
(8, 'conv3_1_W', (3, 3, 128, 256))
(9, 'conv3_1_b', (256,))
(10, 'conv3_2_W', (3, 3, 256, 256))
(11, 'conv3_2_b', (256,))
(12, 'conv3_3_W', (3, 3, 256, 256))
(13, 'conv3_3_b', (256,))
(14, 'conv4_1_W', (3, 3, 256, 512))
(15, 'conv4_1_b', (512,))
(16, 'conv4_2_W', (3, 3, 512, 512))
(17, 'conv4_2_b', (512,))
(18, 'conv4_3_W', (3, 3, 512, 512))
(19, 'conv4_3_b', (512,))
(20, 'conv5_1_W', (3, 3, 512, 512))
(21, 'conv5_1_b', (512,))
(22, 'conv5_2_W', (3, 3, 512, 512))
(23, 'conv5_2_b', (512,))
(24, 'conv5_3_W', (3, 3, 512, 512))
(25, 'conv5_3_b', (512,))
(26, 'fc6_W', (25088, 4096))
(27, 'fc6_b', (4096,))
(28, 'fc7_W', (4096, 4096))
(29, 'fc7_b', (4096,))
Checking checkpoint files:
Data file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.data-00000-of-00001 - Found
Index file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.index - Found
Loading checkpoint from: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt
Checkpoint loaded successfully

Initializing components...
Found tuning curves file: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs/featvecs20_train35_c.txt

Loading category 5 data...
Original positive images shape: (2, 224, 224, 3)

Processing data...

Processing attention strength 0.0
Attention vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

Processing batch 1/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.39658, std: 0.11233

Metrics for layer 0:
  pearson_correlation: 0.0023
  kl_divergence: -4356.3066
  ssim: 0.0578
  iou: 0.1431
Layer 0 metrics:
  pearson_correlation: 0.0023
  kl_divergence: -4356.3066
  ssim: 0.0578
  iou: 0.1431

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.41495, std: 0.11968

Metrics for layer 1:
  pearson_correlation: 0.0007
  kl_divergence: -4484.8804
  ssim: 0.0518
  iou: 0.1411
Layer 1 metrics:
  pearson_correlation: 0.0007
  kl_divergence: -4484.8804
  ssim: 0.0518
  iou: 0.1411

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.46754, std: 0.12959

Metrics for layer 2:
  pearson_correlation: -0.0012
  kl_divergence: -1415.9977
  ssim: 0.0518
  iou: 0.1449
Layer 2 metrics:
  pearson_correlation: -0.0012
  kl_divergence: -1415.9977
  ssim: 0.0518
  iou: 0.1449

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.46304, std: 0.14024

Metrics for layer 3:
  pearson_correlation: 0.0078
  kl_divergence: -1398.4260
  ssim: 0.0499
  iou: 0.1437
Layer 3 metrics:
  pearson_correlation: 0.0078
  kl_divergence: -1398.4260
  ssim: 0.0499
  iou: 0.1437

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46585, std: 0.13839

Metrics for layer 4:
  pearson_correlation: 0.0032
  kl_divergence: -365.8076
  ssim: 0.0640
  iou: 0.1521
Layer 4 metrics:
  pearson_correlation: 0.0032
  kl_divergence: -365.8076
  ssim: 0.0640
  iou: 0.1521

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46125, std: 0.15165

Metrics for layer 5:
  pearson_correlation: 0.0105
  kl_divergence: -356.9698
  ssim: 0.0534
  iou: 0.1581
Layer 5 metrics:
  pearson_correlation: 0.0105
  kl_divergence: -356.9698
  ssim: 0.0534
  iou: 0.1581

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.49115, std: 0.14487

Metrics for layer 6:
  pearson_correlation: -0.0343
  kl_divergence: -373.8137
  ssim: 0.0437
  iou: 0.1362
Layer 6 metrics:
  pearson_correlation: -0.0343
  kl_divergence: -373.8137
  ssim: 0.0437
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.50844, std: 0.17288

Metrics for layer 7:
  pearson_correlation: -0.0147
  kl_divergence: -95.3945
  ssim: 0.0366
  iou: 0.1329
Layer 7 metrics:
  pearson_correlation: -0.0147
  kl_divergence: -95.3945
  ssim: 0.0366
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.45104, std: 0.16098

Metrics for layer 8:
  pearson_correlation: -0.0523
  kl_divergence: -78.7661
  ssim: 0.0280
  iou: 0.1563
Layer 8 metrics:
  pearson_correlation: -0.0523
  kl_divergence: -78.7661
  ssim: 0.0280
  iou: 0.1563

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.50952, std: 0.15667

Metrics for layer 9:
  pearson_correlation: -0.0360
  kl_divergence: -95.7065
  ssim: 0.0463
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: -0.0360
  kl_divergence: -95.7065
  ssim: 0.0463
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.51631, std: 0.20867

Metrics for layer 10:
  pearson_correlation: 0.0139
  kl_divergence: -23.0499
  ssim: 0.0578
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: 0.0139
  kl_divergence: -23.0499
  ssim: 0.0578
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.45175, std: 0.19500

Metrics for layer 11:
  pearson_correlation: 0.0043
  kl_divergence: -13.3118
  ssim: -0.0286
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: 0.0043
  kl_divergence: -13.3118
  ssim: -0.0286
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.41806, std: 0.19040

Metrics for layer 12:
  pearson_correlation: 0.0969
  kl_divergence: -17.0518
  ssim: 0.0930
  iou: 0.1011
Layer 12 metrics:
  pearson_correlation: 0.0969
  kl_divergence: -17.0518
  ssim: 0.0930
  iou: 0.1011
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer0/batch_0_strength_0.0_results.npy

Processing batch 2/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.44779, std: 0.12647

Metrics for layer 0:
  pearson_correlation: 0.0055
  kl_divergence: -3871.4653
  ssim: 0.0305
  iou: 0.1446
Layer 0 metrics:
  pearson_correlation: 0.0055
  kl_divergence: -3871.4653
  ssim: 0.0305
  iou: 0.1446

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.42335, std: 0.12421

Metrics for layer 1:
  pearson_correlation: 0.0023
  kl_divergence: -3756.8896
  ssim: 0.0327
  iou: 0.1443
Layer 1 metrics:
  pearson_correlation: 0.0023
  kl_divergence: -3756.8896
  ssim: 0.0327
  iou: 0.1443

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.46721, std: 0.13962

Metrics for layer 2:
  pearson_correlation: 0.0071
  kl_divergence: -1382.3275
  ssim: 0.0437
  iou: 0.1468
Layer 2 metrics:
  pearson_correlation: 0.0071
  kl_divergence: -1382.3275
  ssim: 0.0437
  iou: 0.1468

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.47115, std: 0.12295

Metrics for layer 3:
  pearson_correlation: 0.0090
  kl_divergence: -1401.9724
  ssim: 0.0543
  iou: 0.1441
Layer 3 metrics:
  pearson_correlation: 0.0090
  kl_divergence: -1401.9724
  ssim: 0.0543
  iou: 0.1441

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.51348, std: 0.13395

Metrics for layer 4:
  pearson_correlation: -0.0207
  kl_divergence: -411.9026
  ssim: 0.0549
  iou: 0.1445
Layer 4 metrics:
  pearson_correlation: -0.0207
  kl_divergence: -411.9026
  ssim: 0.0549
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.49799, std: 0.14924

Metrics for layer 5:
  pearson_correlation: -0.0014
  kl_divergence: -401.2802
  ssim: 0.0482
  iou: 0.1445
Layer 5 metrics:
  pearson_correlation: -0.0014
  kl_divergence: -401.2802
  ssim: 0.0482
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48273, std: 0.13694

Metrics for layer 6:
  pearson_correlation: 0.0258
  kl_divergence: -393.6738
  ssim: 0.0667
  iou: 0.1649
Layer 6 metrics:
  pearson_correlation: 0.0258
  kl_divergence: -393.6738
  ssim: 0.0667
  iou: 0.1649

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.43246, std: 0.15643

Metrics for layer 7:
  pearson_correlation: -0.0060
  kl_divergence: -80.2594
  ssim: 0.0331
  iou: 0.1168
Layer 7 metrics:
  pearson_correlation: -0.0060
  kl_divergence: -80.2594
  ssim: 0.0331
  iou: 0.1168

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.49523, std: 0.14396

Metrics for layer 8:
  pearson_correlation: 0.0233
  kl_divergence: -90.0194
  ssim: 0.0442
  iou: 0.1496
Layer 8 metrics:
  pearson_correlation: 0.0233
  kl_divergence: -90.0194
  ssim: 0.0442
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.51018, std: 0.16787

Metrics for layer 9:
  pearson_correlation: 0.0098
  kl_divergence: -90.2207
  ssim: 0.0198
  iou: 0.1772
Layer 9 metrics:
  pearson_correlation: 0.0098
  kl_divergence: -90.2207
  ssim: 0.0198
  iou: 0.1772

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.53824, std: 0.17156

Metrics for layer 10:
  pearson_correlation: 0.0569
  kl_divergence: -21.3979
  ssim: 0.0590
  iou: 0.2250
Layer 10 metrics:
  pearson_correlation: 0.0569
  kl_divergence: -21.3979
  ssim: 0.0590
  iou: 0.2250

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.41958, std: 0.18601

Metrics for layer 11:
  pearson_correlation: -0.1320
  kl_divergence: -6.5692
  ssim: 0.0221
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: -0.1320
  kl_divergence: -6.5692
  ssim: 0.0221
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.53564, std: 0.20219

Metrics for layer 12:
  pearson_correlation: -0.0254
  kl_divergence: -22.1391
  ssim: 0.0089
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: -0.0254
  kl_divergence: -22.1391
  ssim: 0.0089
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer0/batch_1_strength_0.0_results.npy

Processing attention strength 0.4
Attention vector: [0.4 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.52395, std: 0.11905

Metrics for layer 0:
  pearson_correlation: -0.0053
  kl_divergence: -5249.3496
  ssim: 0.0405
  iou: 0.1405
Layer 0 metrics:
  pearson_correlation: -0.0053
  kl_divergence: -5249.3496
  ssim: 0.0405
  iou: 0.1405

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.43365, std: 0.12170

Metrics for layer 1:
  pearson_correlation: 0.0053
  kl_divergence: -4635.8804
  ssim: 0.0493
  iou: 0.1434
Layer 1 metrics:
  pearson_correlation: 0.0053
  kl_divergence: -4635.8804
  ssim: 0.0493
  iou: 0.1434

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.47221, std: 0.13079

Metrics for layer 2:
  pearson_correlation: 0.0036
  kl_divergence: -1426.1653
  ssim: 0.0496
  iou: 0.1468
Layer 2 metrics:
  pearson_correlation: 0.0036
  kl_divergence: -1426.1653
  ssim: 0.0496
  iou: 0.1468

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.49595, std: 0.12676

Metrics for layer 3:
  pearson_correlation: 0.0009
  kl_divergence: -1482.9893
  ssim: 0.0553
  iou: 0.1350
Layer 3 metrics:
  pearson_correlation: 0.0009
  kl_divergence: -1482.9893
  ssim: 0.0553
  iou: 0.1350

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.43378, std: 0.12769

Metrics for layer 4:
  pearson_correlation: 0.0192
  kl_divergence: -342.8031
  ssim: 0.0827
  iou: 0.1379
Layer 4 metrics:
  pearson_correlation: 0.0192
  kl_divergence: -342.8031
  ssim: 0.0827
  iou: 0.1379

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50611, std: 0.16602

Metrics for layer 5:
  pearson_correlation: 0.0008
  kl_divergence: -385.9115
  ssim: 0.0502
  iou: 0.1420
Layer 5 metrics:
  pearson_correlation: 0.0008
  kl_divergence: -385.9115
  ssim: 0.0502
  iou: 0.1420

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.49229, std: 0.14932

Metrics for layer 6:
  pearson_correlation: -0.0056
  kl_divergence: -381.6968
  ssim: 0.0570
  iou: 0.1420
Layer 6 metrics:
  pearson_correlation: -0.0056
  kl_divergence: -381.6968
  ssim: 0.0570
  iou: 0.1420

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.43330, std: 0.16793

Metrics for layer 7:
  pearson_correlation: -0.0061
  kl_divergence: -75.0692
  ssim: 0.0355
  iou: 0.1563
Layer 7 metrics:
  pearson_correlation: -0.0061
  kl_divergence: -75.0692
  ssim: 0.0355
  iou: 0.1563

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.51276, std: 0.15286

Metrics for layer 8:
  pearson_correlation: -0.0195
  kl_divergence: -95.9858
  ssim: 0.0307
  iou: 0.1395
Layer 8 metrics:
  pearson_correlation: -0.0195
  kl_divergence: -95.9858
  ssim: 0.0307
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.45224, std: 0.16466

Metrics for layer 9:
  pearson_correlation: -0.0626
  kl_divergence: -79.6538
  ssim: 0.0235
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: -0.0626
  kl_divergence: -79.6538
  ssim: 0.0235
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.45798, std: 0.18524

Metrics for layer 10:
  pearson_correlation: -0.0539
  kl_divergence: -6.6585
  ssim: -0.0330
  iou: 0.1264
Layer 10 metrics:
  pearson_correlation: -0.0539
  kl_divergence: -6.6585
  ssim: -0.0330
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.56191, std: 0.16773

Metrics for layer 11:
  pearson_correlation: 0.0328
  kl_divergence: -26.6955
  ssim: 0.0402
  iou: 0.2099
Layer 11 metrics:
  pearson_correlation: 0.0328
  kl_divergence: -26.6955
  ssim: 0.0402
  iou: 0.2099

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.47783, std: 0.17950

Metrics for layer 12:
  pearson_correlation: 0.1650
  kl_divergence: -22.0112
  ssim: 0.1835
  iou: 0.1136
Layer 12 metrics:
  pearson_correlation: 0.1650
  kl_divergence: -22.0112
  ssim: 0.1835
  iou: 0.1136
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer0/batch_0_strength_0.4_results.npy

Processing batch 2/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.49904, std: 0.11918

Metrics for layer 0:
  pearson_correlation: 0.0036
  kl_divergence: -4094.7229
  ssim: 0.0297
  iou: 0.1447
Layer 0 metrics:
  pearson_correlation: 0.0036
  kl_divergence: -4094.7229
  ssim: 0.0297
  iou: 0.1447

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.41189, std: 0.11296

Metrics for layer 1:
  pearson_correlation: 0.0023
  kl_divergence: -3720.6411
  ssim: 0.0383
  iou: 0.1423
Layer 1 metrics:
  pearson_correlation: 0.0023
  kl_divergence: -3720.6411
  ssim: 0.0383
  iou: 0.1423

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.45292, std: 0.13348

Metrics for layer 2:
  pearson_correlation: 0.0120
  kl_divergence: -1355.9376
  ssim: 0.0468
  iou: 0.1487
Layer 2 metrics:
  pearson_correlation: 0.0120
  kl_divergence: -1355.9376
  ssim: 0.0468
  iou: 0.1487

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.45864, std: 0.12761

Metrics for layer 3:
  pearson_correlation: -0.0040
  kl_divergence: -1369.3923
  ssim: 0.0497
  iou: 0.1452
Layer 3 metrics:
  pearson_correlation: -0.0040
  kl_divergence: -1369.3923
  ssim: 0.0497
  iou: 0.1452

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.50480, std: 0.15223

Metrics for layer 4:
  pearson_correlation: 0.0102
  kl_divergence: -403.4090
  ssim: 0.0494
  iou: 0.1546
Layer 4 metrics:
  pearson_correlation: 0.0102
  kl_divergence: -403.4090
  ssim: 0.0494
  iou: 0.1546

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.38642, std: 0.13443

Metrics for layer 5:
  pearson_correlation: -0.0611
  kl_divergence: -295.0052
  ssim: 0.0498
  iou: 0.1305
Layer 5 metrics:
  pearson_correlation: -0.0611
  kl_divergence: -295.0052
  ssim: 0.0498
  iou: 0.1305

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.45599, std: 0.14494

Metrics for layer 6:
  pearson_correlation: 0.0062
  kl_divergence: -364.7340
  ssim: 0.0544
  iou: 0.1412
Layer 6 metrics:
  pearson_correlation: 0.0062
  kl_divergence: -364.7340
  ssim: 0.0544
  iou: 0.1412

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.48854, std: 0.16365

Metrics for layer 7:
  pearson_correlation: -0.0077
  kl_divergence: -87.3911
  ssim: 0.0249
  iou: 0.1429
Layer 7 metrics:
  pearson_correlation: -0.0077
  kl_divergence: -87.3911
  ssim: 0.0249
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.53108, std: 0.16126

Metrics for layer 8:
  pearson_correlation: -0.0008
  kl_divergence: -93.6781
  ssim: 0.0420
  iou: 0.1429
Layer 8 metrics:
  pearson_correlation: -0.0008
  kl_divergence: -93.6781
  ssim: 0.0420
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.48628, std: 0.15065

Metrics for layer 9:
  pearson_correlation: -0.0342
  kl_divergence: -87.5290
  ssim: 0.0326
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: -0.0342
  kl_divergence: -87.5290
  ssim: 0.0326
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.48469, std: 0.18496

Metrics for layer 10:
  pearson_correlation: 0.0439
  kl_divergence: -15.8025
  ssim: 0.0281
  iou: 0.1667
Layer 10 metrics:
  pearson_correlation: 0.0439
  kl_divergence: -15.8025
  ssim: 0.0281
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.54807, std: 0.18128

Metrics for layer 11:
  pearson_correlation: -0.0489
  kl_divergence: -12.7790
  ssim: 0.0082
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: -0.0489
  kl_divergence: -12.7790
  ssim: 0.0082
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.43901, std: 0.15619

Metrics for layer 12:
  pearson_correlation: -0.0982
  kl_divergence: -12.8026
  ssim: -0.0409
  iou: 0.1011
Layer 12 metrics:
  pearson_correlation: -0.0982
  kl_divergence: -12.8026
  ssim: -0.0409
  iou: 0.1011
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer0/batch_1_strength_0.4_results.npy

Processing attention strength 0.8
Attention vector: [0.8 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.51735, std: 0.10988

Metrics for layer 0:
  pearson_correlation: 0.0049
  kl_divergence: -5231.2666
  ssim: 0.0473
  iou: 0.1455
Layer 0 metrics:
  pearson_correlation: 0.0049
  kl_divergence: -5231.2666
  ssim: 0.0473
  iou: 0.1455

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.45654, std: 0.11797

Metrics for layer 1:
  pearson_correlation: -0.0004
  kl_divergence: -4808.3853
  ssim: 0.0468
  iou: 0.1453
Layer 1 metrics:
  pearson_correlation: -0.0004
  kl_divergence: -4808.3853
  ssim: 0.0468
  iou: 0.1453

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.46319, std: 0.12723

Metrics for layer 2:
  pearson_correlation: -0.0087
  kl_divergence: -1404.7703
  ssim: 0.0542
  iou: 0.1366
Layer 2 metrics:
  pearson_correlation: -0.0087
  kl_divergence: -1404.7703
  ssim: 0.0542
  iou: 0.1366

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.47248, std: 0.13176

Metrics for layer 3:
  pearson_correlation: -0.0022
  kl_divergence: -1425.6234
  ssim: 0.0541
  iou: 0.1387
Layer 3 metrics:
  pearson_correlation: -0.0022
  kl_divergence: -1425.6234
  ssim: 0.0541
  iou: 0.1387

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.43237, std: 0.14951

Metrics for layer 4:
  pearson_correlation: -0.0158
  kl_divergence: -328.6906
  ssim: 0.0610
  iou: 0.1387
Layer 4 metrics:
  pearson_correlation: -0.0158
  kl_divergence: -328.6906
  ssim: 0.0610
  iou: 0.1387

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46019, std: 0.15209

Metrics for layer 5:
  pearson_correlation: -0.0006
  kl_divergence: -351.5083
  ssim: 0.0516
  iou: 0.1470
Layer 5 metrics:
  pearson_correlation: -0.0006
  kl_divergence: -351.5083
  ssim: 0.0516
  iou: 0.1470

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.51605, std: 0.15351

Metrics for layer 6:
  pearson_correlation: 0.0125
  kl_divergence: -399.3014
  ssim: 0.0461
  iou: 0.1470
Layer 6 metrics:
  pearson_correlation: 0.0125
  kl_divergence: -399.3014
  ssim: 0.0461
  iou: 0.1470

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.51375, std: 0.18242

Metrics for layer 7:
  pearson_correlation: 0.0195
  kl_divergence: -96.3281
  ssim: 0.0571
  iou: 0.1362
Layer 7 metrics:
  pearson_correlation: 0.0195
  kl_divergence: -96.3281
  ssim: 0.0571
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.51512, std: 0.16298

Metrics for layer 8:
  pearson_correlation: -0.0028
  kl_divergence: -98.5538
  ssim: 0.0503
  iou: 0.1329
Layer 8 metrics:
  pearson_correlation: -0.0028
  kl_divergence: -98.5538
  ssim: 0.0503
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.52114, std: 0.15995

Metrics for layer 9:
  pearson_correlation: 0.0008
  kl_divergence: -99.9690
  ssim: 0.0352
  iou: 0.1362
Layer 9 metrics:
  pearson_correlation: 0.0008
  kl_divergence: -99.9690
  ssim: 0.0352
  iou: 0.1362

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.54228, std: 0.16419

Metrics for layer 10:
  pearson_correlation: -0.1800
  kl_divergence: -11.9405
  ssim: -0.1338
  iou: 0.0652
Layer 10 metrics:
  pearson_correlation: -0.1800
  kl_divergence: -11.9405
  ssim: -0.1338
  iou: 0.0652

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49600, std: 0.18182

Metrics for layer 11:
  pearson_correlation: -0.0481
  kl_divergence: -21.4458
  ssim: 0.0232
  iou: 0.0769
Layer 11 metrics:
  pearson_correlation: -0.0481
  kl_divergence: -21.4458
  ssim: 0.0232
  iou: 0.0769

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.52573, std: 0.18298

Metrics for layer 12:
  pearson_correlation: -0.0702
  kl_divergence: -24.4642
  ssim: 0.0103
  iou: 0.0769
Layer 12 metrics:
  pearson_correlation: -0.0702
  kl_divergence: -24.4642
  ssim: 0.0103
  iou: 0.0769
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer0/batch_0_strength_0.8_results.npy

Processing batch 2/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.50529, std: 0.11513

Metrics for layer 0:
  pearson_correlation: 0.0102
  kl_divergence: -4125.5361
  ssim: 0.0309
  iou: 0.1457
Layer 0 metrics:
  pearson_correlation: 0.0102
  kl_divergence: -4125.5361
  ssim: 0.0309
  iou: 0.1457

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43751, std: 0.12912

Metrics for layer 1:
  pearson_correlation: -0.0098
  kl_divergence: -3808.9680
  ssim: 0.0292
  iou: 0.1401
Layer 1 metrics:
  pearson_correlation: -0.0098
  kl_divergence: -3808.9680
  ssim: 0.0292
  iou: 0.1401

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.42878, std: 0.12886

Metrics for layer 2:
  pearson_correlation: 0.0094
  kl_divergence: -1304.5083
  ssim: 0.0555
  iou: 0.1456
Layer 2 metrics:
  pearson_correlation: 0.0094
  kl_divergence: -1304.5083
  ssim: 0.0555
  iou: 0.1456

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.46321, std: 0.12929

Metrics for layer 3:
  pearson_correlation: 0.0029
  kl_divergence: -1380.5278
  ssim: 0.0482
  iou: 0.1408
Layer 3 metrics:
  pearson_correlation: 0.0029
  kl_divergence: -1380.5278
  ssim: 0.0482
  iou: 0.1408

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48656, std: 0.15107

Metrics for layer 4:
  pearson_correlation: -0.0011
  kl_divergence: -392.1363
  ssim: 0.0561
  iou: 0.1454
Layer 4 metrics:
  pearson_correlation: -0.0011
  kl_divergence: -392.1363
  ssim: 0.0561
  iou: 0.1454

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.46544, std: 0.14702

Metrics for layer 5:
  pearson_correlation: -0.0224
  kl_divergence: -372.4256
  ssim: 0.0387
  iou: 0.1354
Layer 5 metrics:
  pearson_correlation: -0.0224
  kl_divergence: -372.4256
  ssim: 0.0387
  iou: 0.1354

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.44868, std: 0.14956

Metrics for layer 6:
  pearson_correlation: -0.0258
  kl_divergence: -347.7662
  ssim: 0.0424
  iou: 0.1362
Layer 6 metrics:
  pearson_correlation: -0.0258
  kl_divergence: -347.7662
  ssim: 0.0424
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.44437, std: 0.16879

Metrics for layer 7:
  pearson_correlation: 0.0058
  kl_divergence: -80.4262
  ssim: 0.0315
  iou: 0.1429
Layer 7 metrics:
  pearson_correlation: 0.0058
  kl_divergence: -80.4262
  ssim: 0.0315
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.44910, std: 0.15109

Metrics for layer 8:
  pearson_correlation: -0.0670
  kl_divergence: -80.7997
  ssim: 0.0163
  iou: 0.1264
Layer 8 metrics:
  pearson_correlation: -0.0670
  kl_divergence: -80.7997
  ssim: 0.0163
  iou: 0.1264

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.52938, std: 0.15847

Metrics for layer 9:
  pearson_correlation: -0.0243
  kl_divergence: -90.5745
  ssim: 0.0299
  iou: 0.1329
Layer 9 metrics:
  pearson_correlation: -0.0243
  kl_divergence: -90.5745
  ssim: 0.0299
  iou: 0.1329

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.41861, std: 0.18076

Metrics for layer 10:
  pearson_correlation: 0.1041
  kl_divergence: -13.2832
  ssim: 0.1651
  iou: 0.1807
Layer 10 metrics:
  pearson_correlation: 0.1041
  kl_divergence: -13.2832
  ssim: 0.1651
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.55493, std: 0.19447

Metrics for layer 11:
  pearson_correlation: -0.0775
  kl_divergence: -22.3194
  ssim: 0.0345
  iou: 0.0889
Layer 11 metrics:
  pearson_correlation: -0.0775
  kl_divergence: -22.3194
  ssim: 0.0345
  iou: 0.0889

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.38850, std: 0.16026

Metrics for layer 12:
  pearson_correlation: 0.0824
  kl_divergence: -7.9717
  ssim: 0.1408
  iou: 0.2099
Layer 12 metrics:
  pearson_correlation: 0.0824
  kl_divergence: -7.9717
  ssim: 0.1408
  iou: 0.2099
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer0/batch_1_strength_0.8_results.npy

Processing attention strength 1.2
Attention vector: [1.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.48380, std: 0.12092

Metrics for layer 0:
  pearson_correlation: -0.0041
  kl_divergence: -4986.5767
  ssim: 0.0422
  iou: 0.1434
Layer 0 metrics:
  pearson_correlation: -0.0041
  kl_divergence: -4986.5767
  ssim: 0.0422
  iou: 0.1434

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.39835, std: 0.12371

Metrics for layer 1:
  pearson_correlation: 0.0049
  kl_divergence: -4341.8892
  ssim: 0.0518
  iou: 0.1436
Layer 1 metrics:
  pearson_correlation: 0.0049
  kl_divergence: -4341.8892
  ssim: 0.0518
  iou: 0.1436

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.48323, std: 0.12469

Metrics for layer 2:
  pearson_correlation: 0.0050
  kl_divergence: -1455.2832
  ssim: 0.0546
  iou: 0.1475
Layer 2 metrics:
  pearson_correlation: 0.0050
  kl_divergence: -1455.2832
  ssim: 0.0546
  iou: 0.1475

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.49027, std: 0.12473

Metrics for layer 3:
  pearson_correlation: -0.0016
  kl_divergence: -1471.3071
  ssim: 0.0580
  iou: 0.1366
Layer 3 metrics:
  pearson_correlation: -0.0016
  kl_divergence: -1471.3071
  ssim: 0.0580
  iou: 0.1366

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46110, std: 0.13999

Metrics for layer 4:
  pearson_correlation: -0.0043
  kl_divergence: -359.8649
  ssim: 0.0546
  iou: 0.1496
Layer 4 metrics:
  pearson_correlation: -0.0043
  kl_divergence: -359.8649
  ssim: 0.0546
  iou: 0.1496

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.45819, std: 0.14305

Metrics for layer 5:
  pearson_correlation: -0.0070
  kl_divergence: -357.6678
  ssim: 0.0498
  iou: 0.1346
Layer 5 metrics:
  pearson_correlation: -0.0070
  kl_divergence: -357.6678
  ssim: 0.0498
  iou: 0.1346

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.44858, std: 0.15022

Metrics for layer 6:
  pearson_correlation: 0.0499
  kl_divergence: -345.4122
  ssim: 0.0633
  iou: 0.1598
Layer 6 metrics:
  pearson_correlation: 0.0499
  kl_divergence: -345.4122
  ssim: 0.0633
  iou: 0.1598

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.50641, std: 0.17115

Metrics for layer 7:
  pearson_correlation: 0.0079
  kl_divergence: -88.1313
  ssim: 0.0605
  iou: 0.1737
Layer 7 metrics:
  pearson_correlation: 0.0079
  kl_divergence: -88.1313
  ssim: 0.0605
  iou: 0.1737

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.50465, std: 0.14955

Metrics for layer 8:
  pearson_correlation: 0.0377
  kl_divergence: -93.0857
  ssim: 0.0701
  iou: 0.1701
Layer 8 metrics:
  pearson_correlation: 0.0377
  kl_divergence: -93.0857
  ssim: 0.0701
  iou: 0.1701

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.52321, std: 0.15870

Metrics for layer 9:
  pearson_correlation: -0.0686
  kl_divergence: -98.1588
  ssim: 0.0126
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: -0.0686
  kl_divergence: -98.1588
  ssim: 0.0126
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.58498, std: 0.15810

Metrics for layer 10:
  pearson_correlation: 0.0396
  kl_divergence: -24.3368
  ssim: 0.0704
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: 0.0396
  kl_divergence: -24.3368
  ssim: 0.0704
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.35413, std: 0.16008

Metrics for layer 11:
  pearson_correlation: -0.0036
  kl_divergence: -5.2516
  ssim: 0.0471
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: -0.0036
  kl_divergence: -5.2516
  ssim: 0.0471
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.57583, std: 0.16373

Metrics for layer 12:
  pearson_correlation: 0.0190
  kl_divergence: -23.4003
  ssim: 0.0661
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: 0.0190
  kl_divergence: -23.4003
  ssim: 0.0661
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer0/batch_0_strength_1.2_results.npy

Processing batch 2/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.50348, std: 0.12089

Metrics for layer 0:
  pearson_correlation: 0.0085
  kl_divergence: -4111.2407
  ssim: 0.0292
  iou: 0.1445
Layer 0 metrics:
  pearson_correlation: 0.0085
  kl_divergence: -4111.2407
  ssim: 0.0292
  iou: 0.1445

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.41993, std: 0.11587

Metrics for layer 1:
  pearson_correlation: -0.0070
  kl_divergence: -3749.9216
  ssim: 0.0362
  iou: 0.1400
Layer 1 metrics:
  pearson_correlation: -0.0070
  kl_divergence: -3749.9216
  ssim: 0.0362
  iou: 0.1400

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.47372, std: 0.13258

Metrics for layer 2:
  pearson_correlation: -0.0084
  kl_divergence: -1393.4402
  ssim: 0.0428
  iou: 0.1441
Layer 2 metrics:
  pearson_correlation: -0.0084
  kl_divergence: -1393.4402
  ssim: 0.0428
  iou: 0.1441

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.42434, std: 0.13705

Metrics for layer 3:
  pearson_correlation: 0.0051
  kl_divergence: -1287.0330
  ssim: 0.0527
  iou: 0.1431
Layer 3 metrics:
  pearson_correlation: 0.0051
  kl_divergence: -1287.0330
  ssim: 0.0527
  iou: 0.1431

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.46756, std: 0.10955

Metrics for layer 4:
  pearson_correlation: -0.0206
  kl_divergence: -385.5840
  ssim: 0.0658
  iou: 0.1338
Layer 4 metrics:
  pearson_correlation: -0.0206
  kl_divergence: -385.5840
  ssim: 0.0658
  iou: 0.1338

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.45647, std: 0.12972

Metrics for layer 5:
  pearson_correlation: -0.0123
  kl_divergence: -371.5886
  ssim: 0.0685
  iou: 0.1379
Layer 5 metrics:
  pearson_correlation: -0.0123
  kl_divergence: -371.5886
  ssim: 0.0685
  iou: 0.1379

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48507, std: 0.13527

Metrics for layer 6:
  pearson_correlation: 0.0021
  kl_divergence: -391.5260
  ssim: 0.0612
  iou: 0.1379
Layer 6 metrics:
  pearson_correlation: 0.0021
  kl_divergence: -391.5260
  ssim: 0.0612
  iou: 0.1379

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.50095, std: 0.15663

Metrics for layer 7:
  pearson_correlation: 0.0253
  kl_divergence: -87.2313
  ssim: 0.0427
  iou: 0.1395
Layer 7 metrics:
  pearson_correlation: 0.0253
  kl_divergence: -87.2313
  ssim: 0.0427
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.44622, std: 0.17103

Metrics for layer 8:
  pearson_correlation: -0.0534
  kl_divergence: -77.8167
  ssim: 0.0208
  iou: 0.1105
Layer 8 metrics:
  pearson_correlation: -0.0534
  kl_divergence: -77.8167
  ssim: 0.0208
  iou: 0.1105

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.46855, std: 0.16723

Metrics for layer 9:
  pearson_correlation: 0.0250
  kl_divergence: -84.3542
  ssim: 0.0461
  iou: 0.1496
Layer 9 metrics:
  pearson_correlation: 0.0250
  kl_divergence: -84.3542
  ssim: 0.0461
  iou: 0.1496

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.52089, std: 0.19417

Metrics for layer 10:
  pearson_correlation: 0.0702
  kl_divergence: -19.7176
  ssim: 0.1106
  iou: 0.2099
Layer 10 metrics:
  pearson_correlation: 0.0702
  kl_divergence: -19.7176
  ssim: 0.1106
  iou: 0.2099

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.51532, std: 0.21214

Metrics for layer 11:
  pearson_correlation: 0.0397
  kl_divergence: -19.8900
  ssim: 0.1020
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: 0.0397
  kl_divergence: -19.8900
  ssim: 0.1020
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.47083, std: 0.19597

Metrics for layer 12:
  pearson_correlation: 0.1391
  kl_divergence: -19.8885
  ssim: 0.0955
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: 0.1391
  kl_divergence: -19.8885
  ssim: 0.0955
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer0/batch_1_strength_1.2_results.npy

Analysis complete! Results saved to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer0
Completed experiment for category 5, layer 0
----------------------------------------
Running experiment for category 5, layer 1
===================================================
Starting experiment:
Category: 5
Layer: 1
Logs will be saved to: /scratch/hy2611/CNN_attention/logs/attention_analysis_20241216_104146/category5/layer1
===================================================
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-12-16 10:44:35.690893: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-16 10:44:35.698362: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2024-12-16 10:44:35.698668: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x50ef710 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-16 10:44:35.698678: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-16 10:44:35.701349: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-16 10:44:35.840880: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x50e76e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-16 10:44:35.840898: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-12-16 10:44:35.841455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:2f:00.0
2024-12-16 10:44:35.842534: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:44:35.843496: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:44:35.844447: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:44:35.845513: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:44:35.846441: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:44:35.847351: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:44:35.848268: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:44:35.848279: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-12-16 10:44:35.848296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-16 10:44:35.848301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-16 10:44:35.848304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:61: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:87: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:15: sigmoid_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.sigmoid_cross_entropy instead. Note that the order of the predictions and labels arguments has been changed.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:322: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:82: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.


Verifying paths:
tc_path: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs exists
weight_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists
image_path: /scratch/hy2611/CNN_attention/Data/VGG16/images exists
save_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists

Initializing model...
('c11', [1, 224, 224, 64])
('c12', [1, 224, 224, 64])
('c21', [1, 112, 112, 128])
('c22', [1, 112, 112, 128])
('c31', [1, 56, 56, 256])
('c32', [1, 56, 56, 256])
('c33', [1, 56, 56, 256])
('c41', [1, 28, 28, 512])
('c42', [1, 28, 28, 512])
('c43', [1, 28, 28, 512])
('c51', [1, 14, 14, 512])
('c52', [1, 14, 14, 512])
('c53', [1, 14, 14, 512])
(0, 'conv1_1_W', (3, 3, 3, 64))
(1, 'conv1_1_b', (64,))
(2, 'conv1_2_W', (3, 3, 64, 64))
(3, 'conv1_2_b', (64,))
(4, 'conv2_1_W', (3, 3, 64, 128))
(5, 'conv2_1_b', (128,))
(6, 'conv2_2_W', (3, 3, 128, 128))
(7, 'conv2_2_b', (128,))
(8, 'conv3_1_W', (3, 3, 128, 256))
(9, 'conv3_1_b', (256,))
(10, 'conv3_2_W', (3, 3, 256, 256))
(11, 'conv3_2_b', (256,))
(12, 'conv3_3_W', (3, 3, 256, 256))
(13, 'conv3_3_b', (256,))
(14, 'conv4_1_W', (3, 3, 256, 512))
(15, 'conv4_1_b', (512,))
(16, 'conv4_2_W', (3, 3, 512, 512))
(17, 'conv4_2_b', (512,))
(18, 'conv4_3_W', (3, 3, 512, 512))
(19, 'conv4_3_b', (512,))
(20, 'conv5_1_W', (3, 3, 512, 512))
(21, 'conv5_1_b', (512,))
(22, 'conv5_2_W', (3, 3, 512, 512))
(23, 'conv5_2_b', (512,))
(24, 'conv5_3_W', (3, 3, 512, 512))
(25, 'conv5_3_b', (512,))
(26, 'fc6_W', (25088, 4096))
(27, 'fc6_b', (4096,))
(28, 'fc7_W', (4096, 4096))
(29, 'fc7_b', (4096,))
Checking checkpoint files:
Data file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.data-00000-of-00001 - Found
Index file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.index - Found
Loading checkpoint from: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt
Checkpoint loaded successfully

Initializing components...
Found tuning curves file: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs/featvecs20_train35_c.txt

Loading category 5 data...
Original positive images shape: (2, 224, 224, 3)

Processing data...

Processing attention strength 0.0
Attention vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

Processing batch 1/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.44372, std: 0.12503

Metrics for layer 0:
  pearson_correlation: 0.0009
  kl_divergence: -4698.9736
  ssim: 0.0454
  iou: 0.1415
Layer 0 metrics:
  pearson_correlation: 0.0009
  kl_divergence: -4698.9736
  ssim: 0.0454
  iou: 0.1415

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.40185, std: 0.12029

Metrics for layer 1:
  pearson_correlation: -0.0006
  kl_divergence: -4375.1567
  ssim: 0.0511
  iou: 0.1426
Layer 1 metrics:
  pearson_correlation: -0.0006
  kl_divergence: -4375.1567
  ssim: 0.0511
  iou: 0.1426

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.42090, std: 0.12677

Metrics for layer 2:
  pearson_correlation: -0.0125
  kl_divergence: -1297.1346
  ssim: 0.0561
  iou: 0.1393
Layer 2 metrics:
  pearson_correlation: -0.0125
  kl_divergence: -1297.1346
  ssim: 0.0561
  iou: 0.1393

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.44003, std: 0.13255

Metrics for layer 3:
  pearson_correlation: 0.0053
  kl_divergence: -1347.8384
  ssim: 0.0556
  iou: 0.1404
Layer 3 metrics:
  pearson_correlation: 0.0053
  kl_divergence: -1347.8384
  ssim: 0.0556
  iou: 0.1404

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46055, std: 0.13668

Metrics for layer 4:
  pearson_correlation: -0.0070
  kl_divergence: -362.3446
  ssim: 0.0595
  iou: 0.1264
Layer 4 metrics:
  pearson_correlation: -0.0070
  kl_divergence: -362.3446
  ssim: 0.0595
  iou: 0.1264

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50377, std: 0.14644

Metrics for layer 5:
  pearson_correlation: -0.0085
  kl_divergence: -390.5598
  ssim: 0.0446
  iou: 0.1420
Layer 5 metrics:
  pearson_correlation: -0.0085
  kl_divergence: -390.5598
  ssim: 0.0446
  iou: 0.1420

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50699, std: 0.15060

Metrics for layer 6:
  pearson_correlation: -0.0145
  kl_divergence: -391.5804
  ssim: 0.0530
  iou: 0.1437
Layer 6 metrics:
  pearson_correlation: -0.0145
  kl_divergence: -391.5804
  ssim: 0.0530
  iou: 0.1437

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.44368, std: 0.16577

Metrics for layer 7:
  pearson_correlation: 0.0696
  kl_divergence: -82.8287
  ssim: 0.0830
  iou: 0.1737
Layer 7 metrics:
  pearson_correlation: 0.0696
  kl_divergence: -82.8287
  ssim: 0.0830
  iou: 0.1737

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.48769, std: 0.15351

Metrics for layer 8:
  pearson_correlation: -0.0073
  kl_divergence: -92.3872
  ssim: 0.0462
  iou: 0.1429
Layer 8 metrics:
  pearson_correlation: -0.0073
  kl_divergence: -92.3872
  ssim: 0.0462
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.54397, std: 0.15906

Metrics for layer 9:
  pearson_correlation: -0.0843
  kl_divergence: -98.0822
  ssim: -0.0005
  iou: 0.1232
Layer 9 metrics:
  pearson_correlation: -0.0843
  kl_divergence: -98.0822
  ssim: -0.0005
  iou: 0.1232

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.43943, std: 0.17577

Metrics for layer 10:
  pearson_correlation: -0.0012
  kl_divergence: -17.5698
  ssim: 0.0346
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: -0.0012
  kl_divergence: -17.5698
  ssim: 0.0346
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.48424, std: 0.20428

Metrics for layer 11:
  pearson_correlation: -0.0097
  kl_divergence: -19.1959
  ssim: 0.0284
  iou: 0.1011
Layer 11 metrics:
  pearson_correlation: -0.0097
  kl_divergence: -19.1959
  ssim: 0.0284
  iou: 0.1011

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.41528, std: 0.17867

Metrics for layer 12:
  pearson_correlation: 0.0096
  kl_divergence: -14.1534
  ssim: 0.0491
  iou: 0.1264
Layer 12 metrics:
  pearson_correlation: 0.0096
  kl_divergence: -14.1534
  ssim: 0.0491
  iou: 0.1264
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer1/batch_0_strength_0.0_results.npy

Processing batch 2/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.42483, std: 0.12865

Metrics for layer 0:
  pearson_correlation: -0.0035
  kl_divergence: -3753.6528
  ssim: 0.0304
  iou: 0.1419
Layer 0 metrics:
  pearson_correlation: -0.0035
  kl_divergence: -3753.6528
  ssim: 0.0304
  iou: 0.1419

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43015, std: 0.11891

Metrics for layer 1:
  pearson_correlation: -0.0110
  kl_divergence: -3789.7854
  ssim: 0.0336
  iou: 0.1412
Layer 1 metrics:
  pearson_correlation: -0.0110
  kl_divergence: -3789.7854
  ssim: 0.0336
  iou: 0.1412

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.39616, std: 0.11476

Metrics for layer 2:
  pearson_correlation: 0.0005
  kl_divergence: -1234.7073
  ssim: 0.0684
  iou: 0.1449
Layer 2 metrics:
  pearson_correlation: 0.0005
  kl_divergence: -1234.7073
  ssim: 0.0684
  iou: 0.1449

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.47740, std: 0.12750

Metrics for layer 3:
  pearson_correlation: -0.0062
  kl_divergence: -1407.1215
  ssim: 0.0480
  iou: 0.1393
Layer 3 metrics:
  pearson_correlation: -0.0062
  kl_divergence: -1407.1215
  ssim: 0.0480
  iou: 0.1393

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.51182, std: 0.12782

Metrics for layer 4:
  pearson_correlation: -0.0105
  kl_divergence: -416.4832
  ssim: 0.0515
  iou: 0.1371
Layer 4 metrics:
  pearson_correlation: -0.0105
  kl_divergence: -416.4832
  ssim: 0.0515
  iou: 0.1371

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.41682, std: 0.13975

Metrics for layer 5:
  pearson_correlation: -0.0001
  kl_divergence: -326.9590
  ssim: 0.0627
  iou: 0.1454
Layer 5 metrics:
  pearson_correlation: -0.0001
  kl_divergence: -326.9590
  ssim: 0.0627
  iou: 0.1454

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.50623, std: 0.14436

Metrics for layer 6:
  pearson_correlation: 0.0326
  kl_divergence: -411.0579
  ssim: 0.0632
  iou: 0.1496
Layer 6 metrics:
  pearson_correlation: 0.0326
  kl_divergence: -411.0579
  ssim: 0.0632
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.40266, std: 0.14864

Metrics for layer 7:
  pearson_correlation: -0.0178
  kl_divergence: -72.0599
  ssim: 0.0358
  iou: 0.1496
Layer 7 metrics:
  pearson_correlation: -0.0178
  kl_divergence: -72.0599
  ssim: 0.0358
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.56029, std: 0.14856

Metrics for layer 8:
  pearson_correlation: 0.0066
  kl_divergence: -96.3391
  ssim: 0.0271
  iou: 0.1632
Layer 8 metrics:
  pearson_correlation: 0.0066
  kl_divergence: -96.3391
  ssim: 0.0271
  iou: 0.1632

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.47888, std: 0.14097

Metrics for layer 9:
  pearson_correlation: -0.0049
  kl_divergence: -87.4797
  ssim: 0.0500
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: -0.0049
  kl_divergence: -87.4797
  ssim: 0.0500
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.45788, std: 0.19410

Metrics for layer 10:
  pearson_correlation: 0.0067
  kl_divergence: -8.1384
  ssim: 0.0373
  iou: 0.1395
Layer 10 metrics:
  pearson_correlation: 0.0067
  kl_divergence: -8.1384
  ssim: 0.0373
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.53245, std: 0.19626

Metrics for layer 11:
  pearson_correlation: 0.0218
  kl_divergence: -17.6240
  ssim: 0.0479
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: 0.0218
  kl_divergence: -17.6240
  ssim: 0.0479
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.51917, std: 0.18491

Metrics for layer 12:
  pearson_correlation: 0.0329
  kl_divergence: -20.1833
  ssim: 0.0562
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: 0.0329
  kl_divergence: -20.1833
  ssim: 0.0562
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer1/batch_1_strength_0.0_results.npy

Processing attention strength 0.4
Attention vector: [0.  0.4 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.45440, std: 0.11404

Metrics for layer 0:
  pearson_correlation: 0.0037
  kl_divergence: -4805.3774
  ssim: 0.0510
  iou: 0.1430
Layer 0 metrics:
  pearson_correlation: 0.0037
  kl_divergence: -4805.3774
  ssim: 0.0510
  iou: 0.1430

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.48530, std: 0.11319

Metrics for layer 1:
  pearson_correlation: 0.0037
  kl_divergence: -5017.2178
  ssim: 0.0481
  iou: 0.1428
Layer 1 metrics:
  pearson_correlation: 0.0037
  kl_divergence: -5017.2178
  ssim: 0.0481
  iou: 0.1428

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.44966, std: 0.13956

Metrics for layer 2:
  pearson_correlation: -0.0128
  kl_divergence: -1360.0225
  ssim: 0.0488
  iou: 0.1329
Layer 2 metrics:
  pearson_correlation: -0.0128
  kl_divergence: -1360.0225
  ssim: 0.0488
  iou: 0.1329

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.53119, std: 0.12676

Metrics for layer 3:
  pearson_correlation: -0.0026
  kl_divergence: -1554.1204
  ssim: 0.0483
  iou: 0.1362
Layer 3 metrics:
  pearson_correlation: -0.0026
  kl_divergence: -1554.1204
  ssim: 0.0483
  iou: 0.1362

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.45894, std: 0.15507

Metrics for layer 4:
  pearson_correlation: 0.0260
  kl_divergence: -351.7322
  ssim: 0.0560
  iou: 0.1598
Layer 4 metrics:
  pearson_correlation: 0.0260
  kl_divergence: -351.7322
  ssim: 0.0560
  iou: 0.1598

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.48284, std: 0.15063

Metrics for layer 5:
  pearson_correlation: -0.0189
  kl_divergence: -368.5446
  ssim: 0.0505
  iou: 0.1429
Layer 5 metrics:
  pearson_correlation: -0.0189
  kl_divergence: -368.5446
  ssim: 0.0505
  iou: 0.1429

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47071, std: 0.14866

Metrics for layer 6:
  pearson_correlation: 0.0164
  kl_divergence: -368.1803
  ssim: 0.0623
  iou: 0.1504
Layer 6 metrics:
  pearson_correlation: 0.0164
  kl_divergence: -368.1803
  ssim: 0.0623
  iou: 0.1504

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.49722, std: 0.18094

Metrics for layer 7:
  pearson_correlation: 0.0035
  kl_divergence: -90.6250
  ssim: 0.0284
  iou: 0.1297
Layer 7 metrics:
  pearson_correlation: 0.0035
  kl_divergence: -90.6250
  ssim: 0.0284
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.49876, std: 0.15552

Metrics for layer 8:
  pearson_correlation: 0.0310
  kl_divergence: -91.7314
  ssim: 0.0620
  iou: 0.1598
Layer 8 metrics:
  pearson_correlation: 0.0310
  kl_divergence: -91.7314
  ssim: 0.0620
  iou: 0.1598

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.46949, std: 0.16550

Metrics for layer 9:
  pearson_correlation: 0.0004
  kl_divergence: -83.7949
  ssim: 0.0619
  iou: 0.1632
Layer 9 metrics:
  pearson_correlation: 0.0004
  kl_divergence: -83.7949
  ssim: 0.0619
  iou: 0.1632

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.47215, std: 0.18284

Metrics for layer 10:
  pearson_correlation: 0.0110
  kl_divergence: -21.3328
  ssim: 0.0830
  iou: 0.1667
Layer 10 metrics:
  pearson_correlation: 0.0110
  kl_divergence: -21.3328
  ssim: 0.0830
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.40930, std: 0.18115

Metrics for layer 11:
  pearson_correlation: -0.0440
  kl_divergence: -14.0807
  ssim: 0.0773
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: -0.0440
  kl_divergence: -14.0807
  ssim: 0.0773
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49618, std: 0.18778

Metrics for layer 12:
  pearson_correlation: 0.0531
  kl_divergence: -17.4987
  ssim: 0.1277
  iou: 0.1011
Layer 12 metrics:
  pearson_correlation: 0.0531
  kl_divergence: -17.4987
  ssim: 0.1277
  iou: 0.1011
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer1/batch_0_strength_0.4_results.npy

Processing batch 2/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.44105, std: 0.11896

Metrics for layer 0:
  pearson_correlation: -0.0015
  kl_divergence: -3846.7524
  ssim: 0.0333
  iou: 0.1407
Layer 0 metrics:
  pearson_correlation: -0.0015
  kl_divergence: -3846.7524
  ssim: 0.0333
  iou: 0.1407

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.50221, std: 0.11614

Metrics for layer 1:
  pearson_correlation: -0.0014
  kl_divergence: -4107.1572
  ssim: 0.0301
  iou: 0.1442
Layer 1 metrics:
  pearson_correlation: -0.0014
  kl_divergence: -4107.1572
  ssim: 0.0301
  iou: 0.1442

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.46619, std: 0.11466

Metrics for layer 2:
  pearson_correlation: -0.0045
  kl_divergence: -1392.0814
  ssim: 0.0585
  iou: 0.1402
Layer 2 metrics:
  pearson_correlation: -0.0045
  kl_divergence: -1392.0814
  ssim: 0.0585
  iou: 0.1402

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.46609, std: 0.13253

Metrics for layer 3:
  pearson_correlation: -0.0062
  kl_divergence: -1381.4126
  ssim: 0.0452
  iou: 0.1364
Layer 3 metrics:
  pearson_correlation: -0.0062
  kl_divergence: -1381.4126
  ssim: 0.0452
  iou: 0.1364

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.46090, std: 0.14520

Metrics for layer 4:
  pearson_correlation: -0.0019
  kl_divergence: -370.8408
  ssim: 0.0520
  iou: 0.1496
Layer 4 metrics:
  pearson_correlation: -0.0019
  kl_divergence: -370.8408
  ssim: 0.0520
  iou: 0.1496

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48357, std: 0.14077

Metrics for layer 5:
  pearson_correlation: 0.0035
  kl_divergence: -391.2833
  ssim: 0.0498
  iou: 0.1479
Layer 5 metrics:
  pearson_correlation: 0.0035
  kl_divergence: -391.2833
  ssim: 0.0498
  iou: 0.1479

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.46273, std: 0.14030

Metrics for layer 6:
  pearson_correlation: 0.0268
  kl_divergence: -374.1224
  ssim: 0.0679
  iou: 0.1404
Layer 6 metrics:
  pearson_correlation: 0.0268
  kl_divergence: -374.1224
  ssim: 0.0679
  iou: 0.1404

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.44931, std: 0.16036

Metrics for layer 7:
  pearson_correlation: 0.0178
  kl_divergence: -82.9204
  ssim: 0.0453
  iou: 0.1329
Layer 7 metrics:
  pearson_correlation: 0.0178
  kl_divergence: -82.9204
  ssim: 0.0453
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.49256, std: 0.14784

Metrics for layer 8:
  pearson_correlation: -0.0058
  kl_divergence: -88.9478
  ssim: 0.0319
  iou: 0.1496
Layer 8 metrics:
  pearson_correlation: -0.0058
  kl_divergence: -88.9478
  ssim: 0.0319
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.47718, std: 0.13954

Metrics for layer 9:
  pearson_correlation: -0.0556
  kl_divergence: -66.1928
  ssim: 0.0275
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: -0.0556
  kl_divergence: -66.1928
  ssim: 0.0275
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.49401, std: 0.16744

Metrics for layer 10:
  pearson_correlation: -0.0640
  kl_divergence: -10.7964
  ssim: -0.0438
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: -0.0640
  kl_divergence: -10.7964
  ssim: -0.0438
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.47335, std: 0.23057

Metrics for layer 11:
  pearson_correlation: -0.0375
  kl_divergence: -9.6267
  ssim: 0.0235
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: -0.0375
  kl_divergence: -9.6267
  ssim: 0.0235
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.46981, std: 0.20554

Metrics for layer 12:
  pearson_correlation: -0.1204
  kl_divergence: -12.2890
  ssim: -0.0590
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: -0.1204
  kl_divergence: -12.2890
  ssim: -0.0590
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer1/batch_1_strength_0.4_results.npy

Processing attention strength 0.8
Attention vector: [0.  0.8 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.41655, std: 0.12762

Metrics for layer 0:
  pearson_correlation: 0.0034
  kl_divergence: -4484.2568
  ssim: 0.0463
  iou: 0.1449
Layer 0 metrics:
  pearson_correlation: 0.0034
  kl_divergence: -4484.2568
  ssim: 0.0463
  iou: 0.1449

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.47719, std: 0.12389

Metrics for layer 1:
  pearson_correlation: 0.0085
  kl_divergence: -4947.8604
  ssim: 0.0443
  iou: 0.1464
Layer 1 metrics:
  pearson_correlation: 0.0085
  kl_divergence: -4947.8604
  ssim: 0.0443
  iou: 0.1464

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.46267, std: 0.12705

Metrics for layer 2:
  pearson_correlation: -0.0021
  kl_divergence: -1404.7505
  ssim: 0.0539
  iou: 0.1500
Layer 2 metrics:
  pearson_correlation: -0.0021
  kl_divergence: -1404.7505
  ssim: 0.0539
  iou: 0.1500

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.43485, std: 0.13972

Metrics for layer 3:
  pearson_correlation: -0.0184
  kl_divergence: -1318.7800
  ssim: 0.0484
  iou: 0.1383
Layer 3 metrics:
  pearson_correlation: -0.0184
  kl_divergence: -1318.7800
  ssim: 0.0484
  iou: 0.1383

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50629, std: 0.13218

Metrics for layer 4:
  pearson_correlation: 0.0134
  kl_divergence: -401.2447
  ssim: 0.0530
  iou: 0.1387
Layer 4 metrics:
  pearson_correlation: 0.0134
  kl_divergence: -401.2447
  ssim: 0.0530
  iou: 0.1387

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.45705, std: 0.15214

Metrics for layer 5:
  pearson_correlation: 0.0139
  kl_divergence: -352.8663
  ssim: 0.0496
  iou: 0.1496
Layer 5 metrics:
  pearson_correlation: 0.0139
  kl_divergence: -352.8663
  ssim: 0.0496
  iou: 0.1496

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50891, std: 0.14310

Metrics for layer 6:
  pearson_correlation: 0.0222
  kl_divergence: -401.3020
  ssim: 0.0588
  iou: 0.1538
Layer 6 metrics:
  pearson_correlation: 0.0222
  kl_divergence: -401.3020
  ssim: 0.0588
  iou: 0.1538

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.53503, std: 0.13086

Metrics for layer 7:
  pearson_correlation: -0.0228
  kl_divergence: -104.0750
  ssim: 0.0327
  iou: 0.1496
Layer 7 metrics:
  pearson_correlation: -0.0228
  kl_divergence: -104.0750
  ssim: 0.0327
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.46143, std: 0.16104

Metrics for layer 8:
  pearson_correlation: -0.0172
  kl_divergence: -87.2471
  ssim: 0.0412
  iou: 0.1362
Layer 8 metrics:
  pearson_correlation: -0.0172
  kl_divergence: -87.2471
  ssim: 0.0412
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.52143, std: 0.17497

Metrics for layer 9:
  pearson_correlation: 0.0144
  kl_divergence: -95.7508
  ssim: 0.0395
  iou: 0.1598
Layer 9 metrics:
  pearson_correlation: 0.0144
  kl_divergence: -95.7508
  ssim: 0.0395
  iou: 0.1598

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.52029, std: 0.20688

Metrics for layer 10:
  pearson_correlation: -0.0850
  kl_divergence: -20.1963
  ssim: -0.0031
  iou: 0.0769
Layer 10 metrics:
  pearson_correlation: -0.0850
  kl_divergence: -20.1963
  ssim: -0.0031
  iou: 0.0769

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.53498, std: 0.20082

Metrics for layer 11:
  pearson_correlation: 0.0534
  kl_divergence: -25.6111
  ssim: 0.0329
  iou: 0.0889
Layer 11 metrics:
  pearson_correlation: 0.0534
  kl_divergence: -25.6111
  ssim: 0.0329
  iou: 0.0889

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.59616, std: 0.18912

Metrics for layer 12:
  pearson_correlation: -0.0994
  kl_divergence: -18.3877
  ssim: 0.0177
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: -0.0994
  kl_divergence: -18.3877
  ssim: 0.0177
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer1/batch_0_strength_0.8_results.npy

Processing batch 2/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.38479, std: 0.10979

Metrics for layer 0:
  pearson_correlation: -0.0050
  kl_divergence: -3581.8906
  ssim: 0.0425
  iou: 0.1402
Layer 0 metrics:
  pearson_correlation: -0.0050
  kl_divergence: -3581.8906
  ssim: 0.0425
  iou: 0.1402

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.48694, std: 0.11758

Metrics for layer 1:
  pearson_correlation: -0.0018
  kl_divergence: -4043.7834
  ssim: 0.0308
  iou: 0.1405
Layer 1 metrics:
  pearson_correlation: -0.0018
  kl_divergence: -4043.7834
  ssim: 0.0308
  iou: 0.1405

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.46346, std: 0.13949

Metrics for layer 2:
  pearson_correlation: -0.0012
  kl_divergence: -1371.2882
  ssim: 0.0439
  iou: 0.1416
Layer 2 metrics:
  pearson_correlation: -0.0012
  kl_divergence: -1371.2882
  ssim: 0.0439
  iou: 0.1416

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.45468, std: 0.12190

Metrics for layer 3:
  pearson_correlation: 0.0028
  kl_divergence: -1366.9307
  ssim: 0.0549
  iou: 0.1449
Layer 3 metrics:
  pearson_correlation: 0.0028
  kl_divergence: -1366.9307
  ssim: 0.0549
  iou: 0.1449

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.49058, std: 0.15557

Metrics for layer 4:
  pearson_correlation: 0.0090
  kl_divergence: -393.5437
  ssim: 0.0411
  iou: 0.1598
Layer 4 metrics:
  pearson_correlation: 0.0090
  kl_divergence: -393.5437
  ssim: 0.0411
  iou: 0.1598

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.43512, std: 0.13869

Metrics for layer 5:
  pearson_correlation: -0.0112
  kl_divergence: -349.6536
  ssim: 0.0487
  iou: 0.1272
Layer 5 metrics:
  pearson_correlation: -0.0112
  kl_divergence: -349.6536
  ssim: 0.0487
  iou: 0.1272

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.44048, std: 0.14299

Metrics for layer 6:
  pearson_correlation: -0.0087
  kl_divergence: -351.3231
  ssim: 0.0539
  iou: 0.1346
Layer 6 metrics:
  pearson_correlation: -0.0087
  kl_divergence: -351.3231
  ssim: 0.0539
  iou: 0.1346

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.58510, std: 0.15381

Metrics for layer 7:
  pearson_correlation: 0.0078
  kl_divergence: -99.5978
  ssim: 0.0392
  iou: 0.1297
Layer 7 metrics:
  pearson_correlation: 0.0078
  kl_divergence: -99.5978
  ssim: 0.0392
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.50436, std: 0.14923

Metrics for layer 8:
  pearson_correlation: -0.0101
  kl_divergence: -90.9795
  ssim: 0.0361
  iou: 0.1462
Layer 8 metrics:
  pearson_correlation: -0.0101
  kl_divergence: -90.9795
  ssim: 0.0361
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.48353, std: 0.15800

Metrics for layer 9:
  pearson_correlation: 0.0510
  kl_divergence: -87.6366
  ssim: 0.0406
  iou: 0.1915
Layer 9 metrics:
  pearson_correlation: 0.0510
  kl_divergence: -87.6366
  ssim: 0.0406
  iou: 0.1915

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.48764, std: 0.16032

Metrics for layer 10:
  pearson_correlation: -0.0274
  kl_divergence: -18.7071
  ssim: -0.0534
  iou: 0.1667
Layer 10 metrics:
  pearson_correlation: -0.0274
  kl_divergence: -18.7071
  ssim: -0.0534
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.48114, std: 0.14626

Metrics for layer 11:
  pearson_correlation: -0.0489
  kl_divergence: -18.7789
  ssim: 0.0074
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: -0.0489
  kl_divergence: -18.7789
  ssim: 0.0074
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.55168, std: 0.15921

Metrics for layer 12:
  pearson_correlation: -0.0237
  kl_divergence: -23.4752
  ssim: -0.0286
  iou: 0.1136
Layer 12 metrics:
  pearson_correlation: -0.0237
  kl_divergence: -23.4752
  ssim: -0.0286
  iou: 0.1136
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer1/batch_1_strength_0.8_results.npy

Processing attention strength 1.2
Attention vector: [0.  1.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.46262, std: 0.11541

Metrics for layer 0:
  pearson_correlation: 0.0042
  kl_divergence: -4862.3364
  ssim: 0.0486
  iou: 0.1416
Layer 0 metrics:
  pearson_correlation: 0.0042
  kl_divergence: -4862.3364
  ssim: 0.0486
  iou: 0.1416

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.51957, std: 0.10764

Metrics for layer 1:
  pearson_correlation: 0.0047
  kl_divergence: -5246.7949
  ssim: 0.0484
  iou: 0.1432
Layer 1 metrics:
  pearson_correlation: 0.0047
  kl_divergence: -5246.7949
  ssim: 0.0484
  iou: 0.1432

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.44730, std: 0.13090

Metrics for layer 2:
  pearson_correlation: -0.0135
  kl_divergence: -1363.1714
  ssim: 0.0520
  iou: 0.1433
Layer 2 metrics:
  pearson_correlation: -0.0135
  kl_divergence: -1363.1714
  ssim: 0.0520
  iou: 0.1433

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.44030, std: 0.12199

Metrics for layer 3:
  pearson_correlation: 0.0011
  kl_divergence: -1356.2675
  ssim: 0.0618
  iou: 0.1410
Layer 3 metrics:
  pearson_correlation: 0.0011
  kl_divergence: -1356.2675
  ssim: 0.0618
  iou: 0.1410

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47911, std: 0.13435

Metrics for layer 4:
  pearson_correlation: -0.0361
  kl_divergence: -374.0480
  ssim: 0.0529
  iou: 0.1240
Layer 4 metrics:
  pearson_correlation: -0.0361
  kl_divergence: -374.0480
  ssim: 0.0529
  iou: 0.1240

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47207, std: 0.13752

Metrics for layer 5:
  pearson_correlation: 0.0001
  kl_divergence: -365.0025
  ssim: 0.0604
  iou: 0.1487
Layer 5 metrics:
  pearson_correlation: 0.0001
  kl_divergence: -365.0025
  ssim: 0.0604
  iou: 0.1487

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50961, std: 0.14109

Metrics for layer 6:
  pearson_correlation: 0.0273
  kl_divergence: -398.4733
  ssim: 0.0605
  iou: 0.1563
Layer 6 metrics:
  pearson_correlation: 0.0273
  kl_divergence: -398.4733
  ssim: 0.0605
  iou: 0.1563

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.49918, std: 0.15189

Metrics for layer 7:
  pearson_correlation: -0.0086
  kl_divergence: -95.8311
  ssim: 0.0408
  iou: 0.1329
Layer 7 metrics:
  pearson_correlation: -0.0086
  kl_divergence: -95.8311
  ssim: 0.0408
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.44343, std: 0.14926

Metrics for layer 8:
  pearson_correlation: -0.0009
  kl_divergence: -82.8260
  ssim: 0.0491
  iou: 0.1297
Layer 8 metrics:
  pearson_correlation: -0.0009
  kl_divergence: -82.8260
  ssim: 0.0491
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.44927, std: 0.18618

Metrics for layer 9:
  pearson_correlation: 0.0400
  kl_divergence: -81.3837
  ssim: 0.0561
  iou: 0.1772
Layer 9 metrics:
  pearson_correlation: 0.0400
  kl_divergence: -81.3837
  ssim: 0.0561
  iou: 0.1772

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.55249, std: 0.15006

Metrics for layer 10:
  pearson_correlation: -0.1047
  kl_divergence: -23.8013
  ssim: 0.0007
  iou: 0.1136
Layer 10 metrics:
  pearson_correlation: -0.1047
  kl_divergence: -23.8013
  ssim: 0.0007
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.41112, std: 0.15793

Metrics for layer 11:
  pearson_correlation: 0.0225
  kl_divergence: -13.0076
  ssim: 0.0542
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: 0.0225
  kl_divergence: -13.0076
  ssim: 0.0542
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.54915, std: 0.18929

Metrics for layer 12:
  pearson_correlation: 0.1502
  kl_divergence: -24.1426
  ssim: 0.1357
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: 0.1502
  kl_divergence: -24.1426
  ssim: 0.1357
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer1/batch_0_strength_1.2_results.npy

Processing batch 2/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.40348, std: 0.11429

Metrics for layer 0:
  pearson_correlation: -0.0006
  kl_divergence: -3673.9814
  ssim: 0.0385
  iou: 0.1442
Layer 0 metrics:
  pearson_correlation: -0.0006
  kl_divergence: -3673.9814
  ssim: 0.0385
  iou: 0.1442

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.52526, std: 0.11711

Metrics for layer 1:
  pearson_correlation: -0.0066
  kl_divergence: -4193.1572
  ssim: 0.0282
  iou: 0.1409
Layer 1 metrics:
  pearson_correlation: -0.0066
  kl_divergence: -4193.1572
  ssim: 0.0282
  iou: 0.1409

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.46944, std: 0.12749

Metrics for layer 2:
  pearson_correlation: -0.0198
  kl_divergence: -1389.5391
  ssim: 0.0473
  iou: 0.1329
Layer 2 metrics:
  pearson_correlation: -0.0198
  kl_divergence: -1389.5391
  ssim: 0.0473
  iou: 0.1329

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.46864, std: 0.13725

Metrics for layer 3:
  pearson_correlation: -0.0113
  kl_divergence: -1381.2782
  ssim: 0.0407
  iou: 0.1426
Layer 3 metrics:
  pearson_correlation: -0.0113
  kl_divergence: -1381.2782
  ssim: 0.0407
  iou: 0.1426

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47020, std: 0.14161

Metrics for layer 4:
  pearson_correlation: -0.0168
  kl_divergence: -378.0021
  ssim: 0.0549
  iou: 0.1362
Layer 4 metrics:
  pearson_correlation: -0.0168
  kl_divergence: -378.0021
  ssim: 0.0549
  iou: 0.1362

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48452, std: 0.14072

Metrics for layer 5:
  pearson_correlation: 0.0074
  kl_divergence: -391.8931
  ssim: 0.0617
  iou: 0.1546
Layer 5 metrics:
  pearson_correlation: 0.0074
  kl_divergence: -391.8931
  ssim: 0.0617
  iou: 0.1546

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.46975, std: 0.13815

Metrics for layer 6:
  pearson_correlation: 0.0011
  kl_divergence: -379.6352
  ssim: 0.0626
  iou: 0.1512
Layer 6 metrics:
  pearson_correlation: 0.0011
  kl_divergence: -379.6352
  ssim: 0.0626
  iou: 0.1512

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.49698, std: 0.15303

Metrics for layer 7:
  pearson_correlation: -0.0245
  kl_divergence: -87.7195
  ssim: 0.0271
  iou: 0.1264
Layer 7 metrics:
  pearson_correlation: -0.0245
  kl_divergence: -87.7195
  ssim: 0.0271
  iou: 0.1264

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.46652, std: 0.17475

Metrics for layer 8:
  pearson_correlation: -0.0064
  kl_divergence: -81.9351
  ssim: 0.0257
  iou: 0.1598
Layer 8 metrics:
  pearson_correlation: -0.0064
  kl_divergence: -81.9351
  ssim: 0.0257
  iou: 0.1598

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.48627, std: 0.17652

Metrics for layer 9:
  pearson_correlation: -0.0614
  kl_divergence: -84.9459
  ssim: 0.0185
  iou: 0.1200
Layer 9 metrics:
  pearson_correlation: -0.0614
  kl_divergence: -84.9459
  ssim: 0.0185
  iou: 0.1200

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.47602, std: 0.17502

Metrics for layer 10:
  pearson_correlation: -0.1374
  kl_divergence: -12.3859
  ssim: -0.0570
  iou: 0.1136
Layer 10 metrics:
  pearson_correlation: -0.1374
  kl_divergence: -12.3859
  ssim: -0.0570
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.56313, std: 0.16444

Metrics for layer 11:
  pearson_correlation: 0.0663
  kl_divergence: -25.3282
  ssim: 0.0178
  iou: 0.1807
Layer 11 metrics:
  pearson_correlation: 0.0663
  kl_divergence: -25.3282
  ssim: 0.0178
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.54379, std: 0.16839

Metrics for layer 12:
  pearson_correlation: 0.0029
  kl_divergence: -23.3123
  ssim: 0.0418
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: 0.0029
  kl_divergence: -23.3123
  ssim: 0.0418
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer1/batch_1_strength_1.2_results.npy

Analysis complete! Results saved to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer1
Completed experiment for category 5, layer 1
----------------------------------------
Running experiment for category 5, layer 2
===================================================
Starting experiment:
Category: 5
Layer: 2
Logs will be saved to: /scratch/hy2611/CNN_attention/logs/attention_analysis_20241216_104146/category5/layer2
===================================================
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-12-16 10:47:22.003616: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-16 10:47:22.022513: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2024-12-16 10:47:22.022955: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3dfb7b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-16 10:47:22.022972: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-16 10:47:22.025829: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-16 10:47:22.170847: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3dd5f70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-16 10:47:22.170866: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-12-16 10:47:22.171411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:2f:00.0
2024-12-16 10:47:22.172641: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:47:22.173717: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:47:22.174753: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:47:22.175920: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:47:22.176985: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:47:22.177982: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:47:22.178991: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:47:22.179003: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-12-16 10:47:22.179022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-16 10:47:22.179027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-16 10:47:22.179030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:61: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:87: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:15: sigmoid_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.sigmoid_cross_entropy instead. Note that the order of the predictions and labels arguments has been changed.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:322: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:82: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.


Verifying paths:
tc_path: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs exists
weight_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists
image_path: /scratch/hy2611/CNN_attention/Data/VGG16/images exists
save_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists

Initializing model...
('c11', [1, 224, 224, 64])
('c12', [1, 224, 224, 64])
('c21', [1, 112, 112, 128])
('c22', [1, 112, 112, 128])
('c31', [1, 56, 56, 256])
('c32', [1, 56, 56, 256])
('c33', [1, 56, 56, 256])
('c41', [1, 28, 28, 512])
('c42', [1, 28, 28, 512])
('c43', [1, 28, 28, 512])
('c51', [1, 14, 14, 512])
('c52', [1, 14, 14, 512])
('c53', [1, 14, 14, 512])
(0, 'conv1_1_W', (3, 3, 3, 64))
(1, 'conv1_1_b', (64,))
(2, 'conv1_2_W', (3, 3, 64, 64))
(3, 'conv1_2_b', (64,))
(4, 'conv2_1_W', (3, 3, 64, 128))
(5, 'conv2_1_b', (128,))
(6, 'conv2_2_W', (3, 3, 128, 128))
(7, 'conv2_2_b', (128,))
(8, 'conv3_1_W', (3, 3, 128, 256))
(9, 'conv3_1_b', (256,))
(10, 'conv3_2_W', (3, 3, 256, 256))
(11, 'conv3_2_b', (256,))
(12, 'conv3_3_W', (3, 3, 256, 256))
(13, 'conv3_3_b', (256,))
(14, 'conv4_1_W', (3, 3, 256, 512))
(15, 'conv4_1_b', (512,))
(16, 'conv4_2_W', (3, 3, 512, 512))
(17, 'conv4_2_b', (512,))
(18, 'conv4_3_W', (3, 3, 512, 512))
(19, 'conv4_3_b', (512,))
(20, 'conv5_1_W', (3, 3, 512, 512))
(21, 'conv5_1_b', (512,))
(22, 'conv5_2_W', (3, 3, 512, 512))
(23, 'conv5_2_b', (512,))
(24, 'conv5_3_W', (3, 3, 512, 512))
(25, 'conv5_3_b', (512,))
(26, 'fc6_W', (25088, 4096))
(27, 'fc6_b', (4096,))
(28, 'fc7_W', (4096, 4096))
(29, 'fc7_b', (4096,))
Checking checkpoint files:
Data file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.data-00000-of-00001 - Found
Index file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.index - Found
Loading checkpoint from: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt
Checkpoint loaded successfully

Initializing components...
Found tuning curves file: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs/featvecs20_train35_c.txt

Loading category 5 data...
Original positive images shape: (2, 224, 224, 3)

Processing data...

Processing attention strength 0.0
Attention vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

Processing batch 1/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.40431, std: 0.11780

Metrics for layer 0:
  pearson_correlation: 0.0018
  kl_divergence: -4404.2583
  ssim: 0.0532
  iou: 0.1465
Layer 0 metrics:
  pearson_correlation: 0.0018
  kl_divergence: -4404.2583
  ssim: 0.0532
  iou: 0.1465

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.38371, std: 0.10999

Metrics for layer 1:
  pearson_correlation: -0.0008
  kl_divergence: -4250.0933
  ssim: 0.0614
  iou: 0.1438
Layer 1 metrics:
  pearson_correlation: -0.0008
  kl_divergence: -4250.0933
  ssim: 0.0614
  iou: 0.1438

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.38380, std: 0.12187

Metrics for layer 2:
  pearson_correlation: 0.0238
  kl_divergence: -1209.4312
  ssim: 0.0747
  iou: 0.1468
Layer 2 metrics:
  pearson_correlation: 0.0238
  kl_divergence: -1209.4312
  ssim: 0.0747
  iou: 0.1468

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.43247, std: 0.12863

Metrics for layer 3:
  pearson_correlation: -0.0147
  kl_divergence: -1325.9395
  ssim: 0.0566
  iou: 0.1340
Layer 3 metrics:
  pearson_correlation: -0.0147
  kl_divergence: -1325.9395
  ssim: 0.0566
  iou: 0.1340

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.41193, std: 0.12697

Metrics for layer 4:
  pearson_correlation: -0.0332
  kl_divergence: -318.3831
  ssim: 0.0672
  iou: 0.1329
Layer 4 metrics:
  pearson_correlation: -0.0332
  kl_divergence: -318.3831
  ssim: 0.0672
  iou: 0.1329

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.45066, std: 0.12900

Metrics for layer 5:
  pearson_correlation: 0.0142
  kl_divergence: -356.2542
  ssim: 0.0841
  iou: 0.1563
Layer 5 metrics:
  pearson_correlation: 0.0142
  kl_divergence: -356.2542
  ssim: 0.0841
  iou: 0.1563

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.45350, std: 0.14525

Metrics for layer 6:
  pearson_correlation: -0.0330
  kl_divergence: -350.2531
  ssim: 0.0443
  iou: 0.1379
Layer 6 metrics:
  pearson_correlation: -0.0330
  kl_divergence: -350.2531
  ssim: 0.0443
  iou: 0.1379

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.45020, std: 0.16279

Metrics for layer 7:
  pearson_correlation: -0.0132
  kl_divergence: -79.3327
  ssim: 0.0284
  iou: 0.1529
Layer 7 metrics:
  pearson_correlation: -0.0132
  kl_divergence: -79.3327
  ssim: 0.0284
  iou: 0.1529

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.48409, std: 0.16969

Metrics for layer 8:
  pearson_correlation: -0.0045
  kl_divergence: -88.5294
  ssim: 0.0700
  iou: 0.1462
Layer 8 metrics:
  pearson_correlation: -0.0045
  kl_divergence: -88.5294
  ssim: 0.0700
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.45375, std: 0.14177

Metrics for layer 9:
  pearson_correlation: 0.0075
  kl_divergence: -84.7872
  ssim: 0.0518
  iou: 0.1200
Layer 9 metrics:
  pearson_correlation: 0.0075
  kl_divergence: -84.7872
  ssim: 0.0518
  iou: 0.1200

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.48154, std: 0.19841

Metrics for layer 10:
  pearson_correlation: 0.0423
  kl_divergence: -20.3739
  ssim: 0.0449
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: 0.0423
  kl_divergence: -20.3739
  ssim: 0.0449
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.45121, std: 0.19133

Metrics for layer 11:
  pearson_correlation: -0.0207
  kl_divergence: -10.8705
  ssim: 0.0568
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: -0.0207
  kl_divergence: -10.8705
  ssim: 0.0568
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.48889, std: 0.20613

Metrics for layer 12:
  pearson_correlation: 0.0687
  kl_divergence: -16.0148
  ssim: 0.0985
  iou: 0.2099
Layer 12 metrics:
  pearson_correlation: 0.0687
  kl_divergence: -16.0148
  ssim: 0.0985
  iou: 0.2099
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer2/batch_0_strength_0.0_results.npy

Processing batch 2/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43857, std: 0.12392

Metrics for layer 0:
  pearson_correlation: -0.0026
  kl_divergence: -3828.7766
  ssim: 0.0315
  iou: 0.1435
Layer 0 metrics:
  pearson_correlation: -0.0026
  kl_divergence: -3828.7766
  ssim: 0.0315
  iou: 0.1435

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.44774, std: 0.11817

Metrics for layer 1:
  pearson_correlation: -0.0004
  kl_divergence: -3880.3760
  ssim: 0.0336
  iou: 0.1411
Layer 1 metrics:
  pearson_correlation: -0.0004
  kl_divergence: -3880.3760
  ssim: 0.0336
  iou: 0.1411

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.44512, std: 0.12693

Metrics for layer 2:
  pearson_correlation: 0.0008
  kl_divergence: -1339.9357
  ssim: 0.0524
  iou: 0.1441
Layer 2 metrics:
  pearson_correlation: 0.0008
  kl_divergence: -1339.9357
  ssim: 0.0524
  iou: 0.1441

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.43305, std: 0.12607

Metrics for layer 3:
  pearson_correlation: -0.0149
  kl_divergence: -1312.2218
  ssim: 0.0538
  iou: 0.1327
Layer 3 metrics:
  pearson_correlation: -0.0149
  kl_divergence: -1312.2218
  ssim: 0.0538
  iou: 0.1327

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.45404, std: 0.15711

Metrics for layer 4:
  pearson_correlation: 0.0218
  kl_divergence: -361.2858
  ssim: 0.0597
  iou: 0.1445
Layer 4 metrics:
  pearson_correlation: 0.0218
  kl_divergence: -361.2858
  ssim: 0.0597
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.54032, std: 0.13115

Metrics for layer 5:
  pearson_correlation: -0.0167
  kl_divergence: -436.5047
  ssim: 0.0451
  iou: 0.1404
Layer 5 metrics:
  pearson_correlation: -0.0167
  kl_divergence: -436.5047
  ssim: 0.0451
  iou: 0.1404

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47014, std: 0.14825

Metrics for layer 6:
  pearson_correlation: -0.0080
  kl_divergence: -377.6370
  ssim: 0.0412
  iou: 0.1454
Layer 6 metrics:
  pearson_correlation: -0.0080
  kl_divergence: -377.6370
  ssim: 0.0412
  iou: 0.1454

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.47900, std: 0.16897

Metrics for layer 7:
  pearson_correlation: -0.0177
  kl_divergence: -85.7907
  ssim: 0.0129
  iou: 0.1297
Layer 7 metrics:
  pearson_correlation: -0.0177
  kl_divergence: -85.7907
  ssim: 0.0129
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.48007, std: 0.17749

Metrics for layer 8:
  pearson_correlation: -0.0424
  kl_divergence: -83.8589
  ssim: 0.0209
  iou: 0.1264
Layer 8 metrics:
  pearson_correlation: -0.0424
  kl_divergence: -83.8589
  ssim: 0.0209
  iou: 0.1264

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.44543, std: 0.15708

Metrics for layer 9:
  pearson_correlation: -0.0108
  kl_divergence: -81.5606
  ssim: 0.0438
  iou: 0.1462
Layer 9 metrics:
  pearson_correlation: -0.0108
  kl_divergence: -81.5606
  ssim: 0.0438
  iou: 0.1462

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.47769, std: 0.17611

Metrics for layer 10:
  pearson_correlation: 0.0357
  kl_divergence: -18.1556
  ssim: 0.0635
  iou: 0.1951
Layer 10 metrics:
  pearson_correlation: 0.0357
  kl_divergence: -18.1556
  ssim: 0.0635
  iou: 0.1951

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.48527, std: 0.18647

Metrics for layer 11:
  pearson_correlation: -0.0055
  kl_divergence: -3.6109
  ssim: 0.0479
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: -0.0055
  kl_divergence: -3.6109
  ssim: 0.0479
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.51877, std: 0.19304

Metrics for layer 12:
  pearson_correlation: 0.1249
  kl_divergence: -14.5980
  ssim: 0.2292
  iou: 0.1951
Layer 12 metrics:
  pearson_correlation: 0.1249
  kl_divergence: -14.5980
  ssim: 0.2292
  iou: 0.1951
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer2/batch_1_strength_0.0_results.npy

Processing attention strength 0.4
Attention vector: [0.  0.  0.4 0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.45473, std: 0.12610

Metrics for layer 0:
  pearson_correlation: -0.0044
  kl_divergence: -4775.2979
  ssim: 0.0431
  iou: 0.1435
Layer 0 metrics:
  pearson_correlation: -0.0044
  kl_divergence: -4775.2979
  ssim: 0.0431
  iou: 0.1435

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.45377, std: 0.11953

Metrics for layer 1:
  pearson_correlation: -0.0050
  kl_divergence: -4782.5103
  ssim: 0.0461
  iou: 0.1421
Layer 1 metrics:
  pearson_correlation: -0.0050
  kl_divergence: -4782.5103
  ssim: 0.0461
  iou: 0.1421

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.47425, std: 0.12761

Metrics for layer 2:
  pearson_correlation: -0.0015
  kl_divergence: -1431.3462
  ssim: 0.0546
  iou: 0.1487
Layer 2 metrics:
  pearson_correlation: -0.0015
  kl_divergence: -1431.3462
  ssim: 0.0546
  iou: 0.1487

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.46089, std: 0.11026

Metrics for layer 3:
  pearson_correlation: -0.0225
  kl_divergence: -1409.2209
  ssim: 0.0628
  iou: 0.1334
Layer 3 metrics:
  pearson_correlation: -0.0225
  kl_divergence: -1409.2209
  ssim: 0.0628
  iou: 0.1334

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.44792, std: 0.13616

Metrics for layer 4:
  pearson_correlation: 0.0038
  kl_divergence: -348.9477
  ssim: 0.0662
  iou: 0.1395
Layer 4 metrics:
  pearson_correlation: 0.0038
  kl_divergence: -348.9477
  ssim: 0.0662
  iou: 0.1395

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46238, std: 0.14265

Metrics for layer 5:
  pearson_correlation: 0.0006
  kl_divergence: -359.7770
  ssim: 0.0619
  iou: 0.1387
Layer 5 metrics:
  pearson_correlation: 0.0006
  kl_divergence: -359.7770
  ssim: 0.0619
  iou: 0.1387

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.51288, std: 0.12940

Metrics for layer 6:
  pearson_correlation: 0.0097
  kl_divergence: -405.1793
  ssim: 0.0666
  iou: 0.1572
Layer 6 metrics:
  pearson_correlation: 0.0097
  kl_divergence: -405.1793
  ssim: 0.0666
  iou: 0.1572

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.54142, std: 0.14842

Metrics for layer 7:
  pearson_correlation: -0.0366
  kl_divergence: -104.1392
  ssim: 0.0364
  iou: 0.1168
Layer 7 metrics:
  pearson_correlation: -0.0366
  kl_divergence: -104.1392
  ssim: 0.0364
  iou: 0.1168

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.51477, std: 0.14420

Metrics for layer 8:
  pearson_correlation: 0.0158
  kl_divergence: -95.1350
  ssim: 0.0561
  iou: 0.1329
Layer 8 metrics:
  pearson_correlation: 0.0158
  kl_divergence: -95.1350
  ssim: 0.0561
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.41032, std: 0.14952

Metrics for layer 9:
  pearson_correlation: -0.0246
  kl_divergence: -72.4459
  ssim: 0.0711
  iou: 0.1136
Layer 9 metrics:
  pearson_correlation: -0.0246
  kl_divergence: -72.4459
  ssim: 0.0711
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.48575, std: 0.20743

Metrics for layer 10:
  pearson_correlation: 0.1005
  kl_divergence: -22.5108
  ssim: 0.0386
  iou: 0.1264
Layer 10 metrics:
  pearson_correlation: 0.1005
  kl_divergence: -22.5108
  ssim: 0.0386
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.47304, std: 0.23867

Metrics for layer 11:
  pearson_correlation: 0.0490
  kl_divergence: -17.5432
  ssim: 0.0924
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: 0.0490
  kl_divergence: -17.5432
  ssim: 0.0924
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.54743, std: 0.19299

Metrics for layer 12:
  pearson_correlation: -0.0430
  kl_divergence: -24.9286
  ssim: 0.0955
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: -0.0430
  kl_divergence: -24.9286
  ssim: 0.0955
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer2/batch_0_strength_0.4_results.npy

Processing batch 2/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43967, std: 0.12671

Metrics for layer 0:
  pearson_correlation: 0.0001
  kl_divergence: -3828.8416
  ssim: 0.0303
  iou: 0.1415
Layer 0 metrics:
  pearson_correlation: 0.0001
  kl_divergence: -3828.8416
  ssim: 0.0303
  iou: 0.1415

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.46034, std: 0.12786

Metrics for layer 1:
  pearson_correlation: 0.0051
  kl_divergence: -3925.4802
  ssim: 0.0285
  iou: 0.1439
Layer 1 metrics:
  pearson_correlation: 0.0051
  kl_divergence: -3925.4802
  ssim: 0.0285
  iou: 0.1439

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.49450, std: 0.12473

Metrics for layer 2:
  pearson_correlation: -0.0150
  kl_divergence: -1440.5804
  ssim: 0.0468
  iou: 0.1406
Layer 2 metrics:
  pearson_correlation: -0.0150
  kl_divergence: -1440.5804
  ssim: 0.0468
  iou: 0.1406

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.42631, std: 0.11904

Metrics for layer 3:
  pearson_correlation: 0.0000
  kl_divergence: -1305.7454
  ssim: 0.0591
  iou: 0.1364
Layer 3 metrics:
  pearson_correlation: 0.0000
  kl_divergence: -1305.7454
  ssim: 0.0591
  iou: 0.1364

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.39882, std: 0.13207

Metrics for layer 4:
  pearson_correlation: 0.0035
  kl_divergence: -312.5421
  ssim: 0.0693
  iou: 0.1546
Layer 4 metrics:
  pearson_correlation: 0.0035
  kl_divergence: -312.5421
  ssim: 0.0693
  iou: 0.1546

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.46356, std: 0.14875

Metrics for layer 5:
  pearson_correlation: -0.0196
  kl_divergence: -368.4181
  ssim: 0.0427
  iou: 0.1563
Layer 5 metrics:
  pearson_correlation: -0.0196
  kl_divergence: -368.4181
  ssim: 0.0427
  iou: 0.1563

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47323, std: 0.14718

Metrics for layer 6:
  pearson_correlation: 0.0223
  kl_divergence: -383.2991
  ssim: 0.0582
  iou: 0.1479
Layer 6 metrics:
  pearson_correlation: 0.0223
  kl_divergence: -383.2991
  ssim: 0.0582
  iou: 0.1479

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.41388, std: 0.15292

Metrics for layer 7:
  pearson_correlation: 0.0553
  kl_divergence: -77.6475
  ssim: 0.0610
  iou: 0.1598
Layer 7 metrics:
  pearson_correlation: 0.0553
  kl_divergence: -77.6475
  ssim: 0.0610
  iou: 0.1598

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.50502, std: 0.14211

Metrics for layer 8:
  pearson_correlation: -0.0286
  kl_divergence: -90.8462
  ssim: 0.0306
  iou: 0.1462
Layer 8 metrics:
  pearson_correlation: -0.0286
  kl_divergence: -90.8462
  ssim: 0.0306
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.51996, std: 0.16068

Metrics for layer 9:
  pearson_correlation: 0.0185
  kl_divergence: -87.1879
  ssim: 0.0458
  iou: 0.1362
Layer 9 metrics:
  pearson_correlation: 0.0185
  kl_divergence: -87.1879
  ssim: 0.0458
  iou: 0.1362

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.52962, std: 0.20460

Metrics for layer 10:
  pearson_correlation: -0.0163
  kl_divergence: -11.8444
  ssim: 0.0116
  iou: 0.1395
Layer 10 metrics:
  pearson_correlation: -0.0163
  kl_divergence: -11.8444
  ssim: 0.0116
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.43995, std: 0.15800

Metrics for layer 11:
  pearson_correlation: 0.1223
  kl_divergence: -15.1506
  ssim: 0.0501
  iou: 0.2895
Layer 11 metrics:
  pearson_correlation: 0.1223
  kl_divergence: -15.1506
  ssim: 0.0501
  iou: 0.2895

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.48336, std: 0.20598

Metrics for layer 12:
  pearson_correlation: -0.1141
  kl_divergence: -10.3803
  ssim: -0.1025
  iou: 0.1136
Layer 12 metrics:
  pearson_correlation: -0.1141
  kl_divergence: -10.3803
  ssim: -0.1025
  iou: 0.1136
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer2/batch_1_strength_0.4_results.npy

Processing attention strength 0.8
Attention vector: [0.  0.  0.8 0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.43341, std: 0.11417

Metrics for layer 0:
  pearson_correlation: -0.0132
  kl_divergence: -4635.7397
  ssim: 0.0501
  iou: 0.1417
Layer 0 metrics:
  pearson_correlation: -0.0132
  kl_divergence: -4635.7397
  ssim: 0.0501
  iou: 0.1417

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42037, std: 0.11305

Metrics for layer 1:
  pearson_correlation: -0.0003
  kl_divergence: -4541.7090
  ssim: 0.0534
  iou: 0.1449
Layer 1 metrics:
  pearson_correlation: -0.0003
  kl_divergence: -4541.7090
  ssim: 0.0534
  iou: 0.1449

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.49759, std: 0.12985

Metrics for layer 2:
  pearson_correlation: 0.0087
  kl_divergence: -1485.5208
  ssim: 0.0557
  iou: 0.1437
Layer 2 metrics:
  pearson_correlation: 0.0087
  kl_divergence: -1485.5208
  ssim: 0.0557
  iou: 0.1437

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.49361, std: 0.12530

Metrics for layer 3:
  pearson_correlation: 0.0079
  kl_divergence: -1479.2108
  ssim: 0.0524
  iou: 0.1468
Layer 3 metrics:
  pearson_correlation: 0.0079
  kl_divergence: -1479.2108
  ssim: 0.0524
  iou: 0.1468

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50834, std: 0.14531

Metrics for layer 4:
  pearson_correlation: -0.0016
  kl_divergence: -398.5020
  ssim: 0.0513
  iou: 0.1289
Layer 4 metrics:
  pearson_correlation: -0.0016
  kl_divergence: -398.5020
  ssim: 0.0513
  iou: 0.1289

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46627, std: 0.14449

Metrics for layer 5:
  pearson_correlation: -0.0119
  kl_divergence: -361.7308
  ssim: 0.0539
  iou: 0.1354
Layer 5 metrics:
  pearson_correlation: -0.0119
  kl_divergence: -361.7308
  ssim: 0.0539
  iou: 0.1354

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47282, std: 0.14823

Metrics for layer 6:
  pearson_correlation: 0.0359
  kl_divergence: -371.8611
  ssim: 0.0655
  iou: 0.1454
Layer 6 metrics:
  pearson_correlation: 0.0359
  kl_divergence: -371.8611
  ssim: 0.0655
  iou: 0.1454

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.43662, std: 0.14886

Metrics for layer 7:
  pearson_correlation: -0.0763
  kl_divergence: -79.2880
  ssim: 0.0292
  iou: 0.1232
Layer 7 metrics:
  pearson_correlation: -0.0763
  kl_divergence: -79.2880
  ssim: 0.0292
  iou: 0.1232

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.50968, std: 0.15908

Metrics for layer 8:
  pearson_correlation: 0.0020
  kl_divergence: -96.4228
  ssim: 0.0513
  iou: 0.1105
Layer 8 metrics:
  pearson_correlation: 0.0020
  kl_divergence: -96.4228
  ssim: 0.0513
  iou: 0.1105

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.43208, std: 0.16037

Metrics for layer 9:
  pearson_correlation: -0.0142
  kl_divergence: -76.3307
  ssim: 0.0764
  iou: 0.1264
Layer 9 metrics:
  pearson_correlation: -0.0142
  kl_divergence: -76.3307
  ssim: 0.0764
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.48965, std: 0.17782

Metrics for layer 10:
  pearson_correlation: -0.0417
  kl_divergence: -21.5485
  ssim: 0.0603
  iou: 0.1264
Layer 10 metrics:
  pearson_correlation: -0.0417
  kl_divergence: -21.5485
  ssim: 0.0603
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.40311, std: 0.17338

Metrics for layer 11:
  pearson_correlation: 0.0083
  kl_divergence: -14.8744
  ssim: 0.0724
  iou: 0.2099
Layer 11 metrics:
  pearson_correlation: 0.0083
  kl_divergence: -14.8744
  ssim: 0.0724
  iou: 0.2099

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.47391, std: 0.15470

Metrics for layer 12:
  pearson_correlation: 0.0553
  kl_divergence: -18.1442
  ssim: 0.0976
  iou: 0.1807
Layer 12 metrics:
  pearson_correlation: 0.0553
  kl_divergence: -18.1442
  ssim: 0.0976
  iou: 0.1807
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer2/batch_0_strength_0.8_results.npy

Processing batch 2/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.44039, std: 0.11510

Metrics for layer 0:
  pearson_correlation: 0.0071
  kl_divergence: -3854.1523
  ssim: 0.0354
  iou: 0.1415
Layer 0 metrics:
  pearson_correlation: 0.0071
  kl_divergence: -3854.1523
  ssim: 0.0354
  iou: 0.1415

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43091, std: 0.11854

Metrics for layer 1:
  pearson_correlation: -0.0001
  kl_divergence: -3801.7690
  ssim: 0.0335
  iou: 0.1445
Layer 1 metrics:
  pearson_correlation: -0.0001
  kl_divergence: -3801.7690
  ssim: 0.0335
  iou: 0.1445

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.46213, std: 0.12152

Metrics for layer 2:
  pearson_correlation: 0.0104
  kl_divergence: -1381.9536
  ssim: 0.0545
  iou: 0.1435
Layer 2 metrics:
  pearson_correlation: 0.0104
  kl_divergence: -1381.9536
  ssim: 0.0545
  iou: 0.1435

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.44633, std: 0.12852

Metrics for layer 3:
  pearson_correlation: -0.0089
  kl_divergence: -1340.4858
  ssim: 0.0500
  iou: 0.1412
Layer 3 metrics:
  pearson_correlation: -0.0089
  kl_divergence: -1340.4858
  ssim: 0.0500
  iou: 0.1412

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48308, std: 0.14721

Metrics for layer 4:
  pearson_correlation: 0.0013
  kl_divergence: -388.8607
  ssim: 0.0611
  iou: 0.1321
Layer 4 metrics:
  pearson_correlation: 0.0013
  kl_divergence: -388.8607
  ssim: 0.0611
  iou: 0.1321

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.53096, std: 0.15087

Metrics for layer 5:
  pearson_correlation: -0.0078
  kl_divergence: -422.1102
  ssim: 0.0406
  iou: 0.1354
Layer 5 metrics:
  pearson_correlation: -0.0078
  kl_divergence: -422.1102
  ssim: 0.0406
  iou: 0.1354

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.45521, std: 0.14274

Metrics for layer 6:
  pearson_correlation: 0.0180
  kl_divergence: -368.9247
  ssim: 0.0574
  iou: 0.1521
Layer 6 metrics:
  pearson_correlation: 0.0180
  kl_divergence: -368.9247
  ssim: 0.0574
  iou: 0.1521

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.44486, std: 0.17186

Metrics for layer 7:
  pearson_correlation: 0.0011
  kl_divergence: -79.5573
  ssim: 0.0368
  iou: 0.1529
Layer 7 metrics:
  pearson_correlation: 0.0011
  kl_divergence: -79.5573
  ssim: 0.0368
  iou: 0.1529

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.41897, std: 0.14809

Metrics for layer 8:
  pearson_correlation: -0.0669
  kl_divergence: -75.9076
  ssim: 0.0158
  iou: 0.1362
Layer 8 metrics:
  pearson_correlation: -0.0669
  kl_divergence: -75.9076
  ssim: 0.0158
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.39460, std: 0.15075

Metrics for layer 9:
  pearson_correlation: 0.0412
  kl_divergence: -74.9949
  ssim: 0.0606
  iou: 0.1667
Layer 9 metrics:
  pearson_correlation: 0.0412
  kl_divergence: -74.9949
  ssim: 0.0606
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.51035, std: 0.18125

Metrics for layer 10:
  pearson_correlation: -0.1020
  kl_divergence: 0.4096
  ssim: -0.1203
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: -0.1020
  kl_divergence: 0.4096
  ssim: -0.1203
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.48723, std: 0.19018

Metrics for layer 11:
  pearson_correlation: -0.0215
  kl_divergence: -16.4062
  ssim: 0.0435
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: -0.0215
  kl_divergence: -16.4062
  ssim: 0.0435
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.42092, std: 0.19077

Metrics for layer 12:
  pearson_correlation: 0.0799
  kl_divergence: -8.3290
  ssim: 0.1347
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: 0.0799
  kl_divergence: -8.3290
  ssim: 0.1347
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer2/batch_1_strength_0.8_results.npy

Processing attention strength 1.2
Attention vector: [0.  0.  1.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.45903, std: 0.12213

Metrics for layer 0:
  pearson_correlation: -0.0026
  kl_divergence: -4814.1685
  ssim: 0.0443
  iou: 0.1436
Layer 0 metrics:
  pearson_correlation: -0.0026
  kl_divergence: -4814.1685
  ssim: 0.0443
  iou: 0.1436

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.45264, std: 0.12543

Metrics for layer 1:
  pearson_correlation: 0.0083
  kl_divergence: -4773.4507
  ssim: 0.0453
  iou: 0.1450
Layer 1 metrics:
  pearson_correlation: 0.0083
  kl_divergence: -4773.4507
  ssim: 0.0453
  iou: 0.1450

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.49450, std: 0.13821

Metrics for layer 2:
  pearson_correlation: -0.0001
  kl_divergence: -1466.1978
  ssim: 0.0471
  iou: 0.1491
Layer 2 metrics:
  pearson_correlation: -0.0001
  kl_divergence: -1466.1978
  ssim: 0.0471
  iou: 0.1491

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.48092, std: 0.12658

Metrics for layer 3:
  pearson_correlation: -0.0083
  kl_divergence: -1445.9897
  ssim: 0.0508
  iou: 0.1439
Layer 3 metrics:
  pearson_correlation: -0.0083
  kl_divergence: -1445.9897
  ssim: 0.0508
  iou: 0.1439

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.49342, std: 0.13953

Metrics for layer 4:
  pearson_correlation: 0.0102
  kl_divergence: -387.6749
  ssim: 0.0603
  iou: 0.1429
Layer 4 metrics:
  pearson_correlation: 0.0102
  kl_divergence: -387.6749
  ssim: 0.0603
  iou: 0.1429

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.43623, std: 0.13378

Metrics for layer 5:
  pearson_correlation: -0.0179
  kl_divergence: -335.1386
  ssim: 0.0617
  iou: 0.1329
Layer 5 metrics:
  pearson_correlation: -0.0179
  kl_divergence: -335.1386
  ssim: 0.0617
  iou: 0.1329

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.48019, std: 0.14592

Metrics for layer 6:
  pearson_correlation: -0.0254
  kl_divergence: -372.5916
  ssim: 0.0525
  iou: 0.1354
Layer 6 metrics:
  pearson_correlation: -0.0254
  kl_divergence: -372.5916
  ssim: 0.0525
  iou: 0.1354

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.53355, std: 0.16621

Metrics for layer 7:
  pearson_correlation: -0.0071
  kl_divergence: -101.1587
  ssim: 0.0408
  iou: 0.1462
Layer 7 metrics:
  pearson_correlation: -0.0071
  kl_divergence: -101.1587
  ssim: 0.0408
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.47242, std: 0.17148

Metrics for layer 8:
  pearson_correlation: -0.0299
  kl_divergence: -87.3756
  ssim: 0.0258
  iou: 0.1200
Layer 8 metrics:
  pearson_correlation: -0.0299
  kl_divergence: -87.3756
  ssim: 0.0258
  iou: 0.1200

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.51047, std: 0.16922

Metrics for layer 9:
  pearson_correlation: -0.0560
  kl_divergence: -92.8833
  ssim: 0.0127
  iou: 0.1136
Layer 9 metrics:
  pearson_correlation: -0.0560
  kl_divergence: -92.8833
  ssim: 0.0127
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.48179, std: 0.17168

Metrics for layer 10:
  pearson_correlation: -0.0035
  kl_divergence: -8.8389
  ssim: -0.0229
  iou: 0.0889
Layer 10 metrics:
  pearson_correlation: -0.0035
  kl_divergence: -8.8389
  ssim: -0.0229
  iou: 0.0889

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.50727, std: 0.21539

Metrics for layer 11:
  pearson_correlation: -0.0727
  kl_divergence: -14.5812
  ssim: -0.0392
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: -0.0727
  kl_divergence: -14.5812
  ssim: -0.0392
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.41325, std: 0.18100

Metrics for layer 12:
  pearson_correlation: -0.0012
  kl_divergence: -11.1693
  ssim: 0.0456
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: -0.0012
  kl_divergence: -11.1693
  ssim: 0.0456
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer2/batch_0_strength_1.2_results.npy

Processing batch 2/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.39857, std: 0.11666

Metrics for layer 0:
  pearson_correlation: 0.0035
  kl_divergence: -3644.1555
  ssim: 0.0377
  iou: 0.1468
Layer 0 metrics:
  pearson_correlation: 0.0035
  kl_divergence: -3644.1555
  ssim: 0.0377
  iou: 0.1468

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.40815, std: 0.12067

Metrics for layer 1:
  pearson_correlation: -0.0030
  kl_divergence: -3683.8801
  ssim: 0.0348
  iou: 0.1465
Layer 1 metrics:
  pearson_correlation: -0.0030
  kl_divergence: -3683.8801
  ssim: 0.0348
  iou: 0.1465

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.51319, std: 0.13642

Metrics for layer 2:
  pearson_correlation: 0.0032
  kl_divergence: -1472.2012
  ssim: 0.0431
  iou: 0.1443
Layer 2 metrics:
  pearson_correlation: 0.0032
  kl_divergence: -1472.2012
  ssim: 0.0431
  iou: 0.1443

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.45625, std: 0.13190

Metrics for layer 3:
  pearson_correlation: 0.0005
  kl_divergence: -1362.0591
  ssim: 0.0476
  iou: 0.1523
Layer 3 metrics:
  pearson_correlation: 0.0005
  kl_divergence: -1362.0591
  ssim: 0.0476
  iou: 0.1523

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.44070, std: 0.13091

Metrics for layer 4:
  pearson_correlation: 0.0141
  kl_divergence: -360.1880
  ssim: 0.0660
  iou: 0.1521
Layer 4 metrics:
  pearson_correlation: 0.0141
  kl_divergence: -360.1880
  ssim: 0.0660
  iou: 0.1521

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.41901, std: 0.14945

Metrics for layer 5:
  pearson_correlation: 0.0225
  kl_divergence: -331.9963
  ssim: 0.0562
  iou: 0.1589
Layer 5 metrics:
  pearson_correlation: 0.0225
  kl_divergence: -331.9963
  ssim: 0.0562
  iou: 0.1589

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47362, std: 0.15281

Metrics for layer 6:
  pearson_correlation: 0.0016
  kl_divergence: -377.5775
  ssim: 0.0522
  iou: 0.1479
Layer 6 metrics:
  pearson_correlation: 0.0016
  kl_divergence: -377.5775
  ssim: 0.0522
  iou: 0.1479

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.52483, std: 0.14985

Metrics for layer 7:
  pearson_correlation: 0.0062
  kl_divergence: -92.1962
  ssim: 0.0311
  iou: 0.1632
Layer 7 metrics:
  pearson_correlation: 0.0062
  kl_divergence: -92.1962
  ssim: 0.0311
  iou: 0.1632

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.44584, std: 0.16954

Metrics for layer 8:
  pearson_correlation: 0.0119
  kl_divergence: -81.5453
  ssim: 0.0383
  iou: 0.1395
Layer 8 metrics:
  pearson_correlation: 0.0119
  kl_divergence: -81.5453
  ssim: 0.0383
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.51018, std: 0.15592

Metrics for layer 9:
  pearson_correlation: -0.0109
  kl_divergence: -90.5003
  ssim: 0.0356
  iou: 0.1462
Layer 9 metrics:
  pearson_correlation: -0.0109
  kl_divergence: -90.5003
  ssim: 0.0356
  iou: 0.1462

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.47968, std: 0.19817

Metrics for layer 10:
  pearson_correlation: 0.2221
  kl_divergence: -17.5056
  ssim: 0.2364
  iou: 0.2099
Layer 10 metrics:
  pearson_correlation: 0.2221
  kl_divergence: -17.5056
  ssim: 0.2364
  iou: 0.2099

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.45942, std: 0.18324

Metrics for layer 11:
  pearson_correlation: 0.0532
  kl_divergence: -16.7986
  ssim: 0.1471
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: 0.0532
  kl_divergence: -16.7986
  ssim: 0.1471
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.46566, std: 0.18661

Metrics for layer 12:
  pearson_correlation: -0.0511
  kl_divergence: -15.7937
  ssim: 0.0308
  iou: 0.1264
Layer 12 metrics:
  pearson_correlation: -0.0511
  kl_divergence: -15.7937
  ssim: 0.0308
  iou: 0.1264
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer2/batch_1_strength_1.2_results.npy

Analysis complete! Results saved to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer2
Completed experiment for category 5, layer 2
----------------------------------------
Running experiment for category 5, layer 3
===================================================
Starting experiment:
Category: 5
Layer: 3
Logs will be saved to: /scratch/hy2611/CNN_attention/logs/attention_analysis_20241216_104146/category5/layer3
===================================================
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-12-16 10:50:09.547247: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-16 10:50:09.609518: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2024-12-16 10:50:09.609923: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4bf59c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-16 10:50:09.609937: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-16 10:50:09.612824: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-16 10:50:09.751872: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4be4350 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-16 10:50:09.751890: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-12-16 10:50:09.752419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:2f:00.0
2024-12-16 10:50:09.753631: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:50:09.754732: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:50:09.755819: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:50:09.756911: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:50:09.757988: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:50:09.759042: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:50:09.760095: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:50:09.760106: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-12-16 10:50:09.760126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-16 10:50:09.760131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-16 10:50:09.760134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:61: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:87: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:15: sigmoid_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.sigmoid_cross_entropy instead. Note that the order of the predictions and labels arguments has been changed.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:322: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:82: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.


Verifying paths:
tc_path: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs exists
weight_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists
image_path: /scratch/hy2611/CNN_attention/Data/VGG16/images exists
save_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists

Initializing model...
('c11', [1, 224, 224, 64])
('c12', [1, 224, 224, 64])
('c21', [1, 112, 112, 128])
('c22', [1, 112, 112, 128])
('c31', [1, 56, 56, 256])
('c32', [1, 56, 56, 256])
('c33', [1, 56, 56, 256])
('c41', [1, 28, 28, 512])
('c42', [1, 28, 28, 512])
('c43', [1, 28, 28, 512])
('c51', [1, 14, 14, 512])
('c52', [1, 14, 14, 512])
('c53', [1, 14, 14, 512])
(0, 'conv1_1_W', (3, 3, 3, 64))
(1, 'conv1_1_b', (64,))
(2, 'conv1_2_W', (3, 3, 64, 64))
(3, 'conv1_2_b', (64,))
(4, 'conv2_1_W', (3, 3, 64, 128))
(5, 'conv2_1_b', (128,))
(6, 'conv2_2_W', (3, 3, 128, 128))
(7, 'conv2_2_b', (128,))
(8, 'conv3_1_W', (3, 3, 128, 256))
(9, 'conv3_1_b', (256,))
(10, 'conv3_2_W', (3, 3, 256, 256))
(11, 'conv3_2_b', (256,))
(12, 'conv3_3_W', (3, 3, 256, 256))
(13, 'conv3_3_b', (256,))
(14, 'conv4_1_W', (3, 3, 256, 512))
(15, 'conv4_1_b', (512,))
(16, 'conv4_2_W', (3, 3, 512, 512))
(17, 'conv4_2_b', (512,))
(18, 'conv4_3_W', (3, 3, 512, 512))
(19, 'conv4_3_b', (512,))
(20, 'conv5_1_W', (3, 3, 512, 512))
(21, 'conv5_1_b', (512,))
(22, 'conv5_2_W', (3, 3, 512, 512))
(23, 'conv5_2_b', (512,))
(24, 'conv5_3_W', (3, 3, 512, 512))
(25, 'conv5_3_b', (512,))
(26, 'fc6_W', (25088, 4096))
(27, 'fc6_b', (4096,))
(28, 'fc7_W', (4096, 4096))
(29, 'fc7_b', (4096,))
Checking checkpoint files:
Data file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.data-00000-of-00001 - Found
Index file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.index - Found
Loading checkpoint from: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt
Checkpoint loaded successfully

Initializing components...
Found tuning curves file: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs/featvecs20_train35_c.txt

Loading category 5 data...
Original positive images shape: (2, 224, 224, 3)

Processing data...

Processing attention strength 0.0
Attention vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

Processing batch 1/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.45233, std: 0.12559

Metrics for layer 0:
  pearson_correlation: -0.0043
  kl_divergence: -4760.2856
  ssim: 0.0428
  iou: 0.1404
Layer 0 metrics:
  pearson_correlation: -0.0043
  kl_divergence: -4760.2856
  ssim: 0.0428
  iou: 0.1404

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42460, std: 0.11675

Metrics for layer 1:
  pearson_correlation: 0.0015
  kl_divergence: -4571.3003
  ssim: 0.0532
  iou: 0.1420
Layer 1 metrics:
  pearson_correlation: 0.0015
  kl_divergence: -4571.3003
  ssim: 0.0532
  iou: 0.1420

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.49289, std: 0.12772

Metrics for layer 2:
  pearson_correlation: -0.0147
  kl_divergence: -1468.9125
  ssim: 0.0495
  iou: 0.1381
Layer 2 metrics:
  pearson_correlation: -0.0147
  kl_divergence: -1468.9125
  ssim: 0.0495
  iou: 0.1381

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.46971, std: 0.13519

Metrics for layer 3:
  pearson_correlation: -0.0040
  kl_divergence: -1416.3782
  ssim: 0.0498
  iou: 0.1433
Layer 3 metrics:
  pearson_correlation: -0.0040
  kl_divergence: -1416.3782
  ssim: 0.0498
  iou: 0.1433

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.45120, std: 0.14124

Metrics for layer 4:
  pearson_correlation: -0.0060
  kl_divergence: -347.4987
  ssim: 0.0532
  iou: 0.1404
Layer 4 metrics:
  pearson_correlation: -0.0060
  kl_divergence: -347.4987
  ssim: 0.0532
  iou: 0.1404

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50335, std: 0.14063

Metrics for layer 5:
  pearson_correlation: -0.0194
  kl_divergence: -388.3788
  ssim: 0.0526
  iou: 0.1248
Layer 5 metrics:
  pearson_correlation: -0.0194
  kl_divergence: -388.3788
  ssim: 0.0526
  iou: 0.1248

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47538, std: 0.14214

Metrics for layer 6:
  pearson_correlation: 0.0121
  kl_divergence: -374.4337
  ssim: 0.0700
  iou: 0.1598
Layer 6 metrics:
  pearson_correlation: 0.0121
  kl_divergence: -374.4337
  ssim: 0.0700
  iou: 0.1598

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.43002, std: 0.14676

Metrics for layer 7:
  pearson_correlation: 0.0077
  kl_divergence: -77.5297
  ssim: 0.0579
  iou: 0.1429
Layer 7 metrics:
  pearson_correlation: 0.0077
  kl_divergence: -77.5297
  ssim: 0.0579
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.46523, std: 0.16141

Metrics for layer 8:
  pearson_correlation: -0.0280
  kl_divergence: -83.1362
  ssim: 0.0581
  iou: 0.1297
Layer 8 metrics:
  pearson_correlation: -0.0280
  kl_divergence: -83.1362
  ssim: 0.0581
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.51094, std: 0.16177

Metrics for layer 9:
  pearson_correlation: -0.0278
  kl_divergence: -94.9022
  ssim: 0.0294
  iou: 0.1297
Layer 9 metrics:
  pearson_correlation: -0.0278
  kl_divergence: -94.9022
  ssim: 0.0294
  iou: 0.1297

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49066, std: 0.19062

Metrics for layer 10:
  pearson_correlation: 0.1717
  kl_divergence: -23.6652
  ssim: 0.1802
  iou: 0.1951
Layer 10 metrics:
  pearson_correlation: 0.1717
  kl_divergence: -23.6652
  ssim: 0.1802
  iou: 0.1951

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.51128, std: 0.19496

Metrics for layer 11:
  pearson_correlation: 0.0254
  kl_divergence: -23.0206
  ssim: -0.0041
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: 0.0254
  kl_divergence: -23.0206
  ssim: -0.0041
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.47793, std: 0.17153

Metrics for layer 12:
  pearson_correlation: 0.1426
  kl_divergence: -18.9583
  ssim: 0.1412
  iou: 0.1807
Layer 12 metrics:
  pearson_correlation: 0.1426
  kl_divergence: -18.9583
  ssim: 0.1412
  iou: 0.1807
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer3/batch_0_strength_0.0_results.npy

Processing batch 2/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.39924, std: 0.11495

Metrics for layer 0:
  pearson_correlation: 0.0034
  kl_divergence: -3652.7385
  ssim: 0.0393
  iou: 0.1477
Layer 0 metrics:
  pearson_correlation: 0.0034
  kl_divergence: -3652.7385
  ssim: 0.0393
  iou: 0.1477

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43133, std: 0.11647

Metrics for layer 1:
  pearson_correlation: -0.0003
  kl_divergence: -3805.5896
  ssim: 0.0357
  iou: 0.1409
Layer 1 metrics:
  pearson_correlation: -0.0003
  kl_divergence: -3805.5896
  ssim: 0.0357
  iou: 0.1409

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.42935, std: 0.12639

Metrics for layer 2:
  pearson_correlation: 0.0003
  kl_divergence: -1306.0195
  ssim: 0.0523
  iou: 0.1383
Layer 2 metrics:
  pearson_correlation: 0.0003
  kl_divergence: -1306.0195
  ssim: 0.0523
  iou: 0.1383

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.44801, std: 0.13909

Metrics for layer 3:
  pearson_correlation: -0.0066
  kl_divergence: -1335.1715
  ssim: 0.0434
  iou: 0.1389
Layer 3 metrics:
  pearson_correlation: -0.0066
  kl_divergence: -1335.1715
  ssim: 0.0434
  iou: 0.1389

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.45067, std: 0.13333

Metrics for layer 4:
  pearson_correlation: -0.0366
  kl_divergence: -360.3385
  ssim: 0.0538
  iou: 0.1313
Layer 4 metrics:
  pearson_correlation: -0.0366
  kl_divergence: -360.3385
  ssim: 0.0538
  iou: 0.1313

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47212, std: 0.14189

Metrics for layer 5:
  pearson_correlation: -0.0245
  kl_divergence: -379.0588
  ssim: 0.0555
  iou: 0.1297
Layer 5 metrics:
  pearson_correlation: -0.0245
  kl_divergence: -379.0588
  ssim: 0.0555
  iou: 0.1297

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47260, std: 0.15610

Metrics for layer 6:
  pearson_correlation: 0.0138
  kl_divergence: -378.3198
  ssim: 0.0475
  iou: 0.1623
Layer 6 metrics:
  pearson_correlation: 0.0138
  kl_divergence: -378.3198
  ssim: 0.0475
  iou: 0.1623

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.50273, std: 0.17489

Metrics for layer 7:
  pearson_correlation: -0.0309
  kl_divergence: -87.0755
  ssim: 0.0120
  iou: 0.1529
Layer 7 metrics:
  pearson_correlation: -0.0309
  kl_divergence: -87.0755
  ssim: 0.0120
  iou: 0.1529

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.42272, std: 0.15797

Metrics for layer 8:
  pearson_correlation: -0.0009
  kl_divergence: -78.1588
  ssim: 0.0406
  iou: 0.1462
Layer 8 metrics:
  pearson_correlation: -0.0009
  kl_divergence: -78.1588
  ssim: 0.0406
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.49109, std: 0.15884

Metrics for layer 9:
  pearson_correlation: -0.0228
  kl_divergence: -87.4740
  ssim: 0.0384
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: -0.0228
  kl_divergence: -87.4740
  ssim: 0.0384
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.49811, std: 0.16288

Metrics for layer 10:
  pearson_correlation: -0.1142
  kl_divergence: -15.9935
  ssim: -0.0921
  iou: 0.1667
Layer 10 metrics:
  pearson_correlation: -0.1142
  kl_divergence: -15.9935
  ssim: -0.0921
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.45953, std: 0.20225

Metrics for layer 11:
  pearson_correlation: -0.0728
  kl_divergence: -7.9688
  ssim: -0.0228
  iou: 0.1011
Layer 11 metrics:
  pearson_correlation: -0.0728
  kl_divergence: -7.9688
  ssim: -0.0228
  iou: 0.1011

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.55312, std: 0.18276

Metrics for layer 12:
  pearson_correlation: -0.0220
  kl_divergence: -24.0781
  ssim: 0.0470
  iou: 0.1136
Layer 12 metrics:
  pearson_correlation: -0.0220
  kl_divergence: -24.0781
  ssim: 0.0470
  iou: 0.1136
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer3/batch_1_strength_0.0_results.npy

Processing attention strength 0.4
Attention vector: [0.  0.  0.  0.4 0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.43665, std: 0.12709

Metrics for layer 0:
  pearson_correlation: -0.0019
  kl_divergence: -4639.0117
  ssim: 0.0440
  iou: 0.1437
Layer 0 metrics:
  pearson_correlation: -0.0019
  kl_divergence: -4639.0117
  ssim: 0.0440
  iou: 0.1437

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42419, std: 0.12178

Metrics for layer 1:
  pearson_correlation: -0.0044
  kl_divergence: -4548.9487
  ssim: 0.0475
  iou: 0.1425
Layer 1 metrics:
  pearson_correlation: -0.0044
  kl_divergence: -4548.9487
  ssim: 0.0475
  iou: 0.1425

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.46231, std: 0.13588

Metrics for layer 2:
  pearson_correlation: 0.0090
  kl_divergence: -1397.2031
  ssim: 0.0522
  iou: 0.1508
Layer 2 metrics:
  pearson_correlation: 0.0090
  kl_divergence: -1397.2031
  ssim: 0.0522
  iou: 0.1508

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.55296, std: 0.12327

Metrics for layer 3:
  pearson_correlation: 0.0003
  kl_divergence: -1598.9456
  ssim: 0.0515
  iou: 0.1393
Layer 3 metrics:
  pearson_correlation: 0.0003
  kl_divergence: -1598.9456
  ssim: 0.0515
  iou: 0.1393

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.42738, std: 0.13747

Metrics for layer 4:
  pearson_correlation: 0.0055
  kl_divergence: -329.0248
  ssim: 0.0624
  iou: 0.1429
Layer 4 metrics:
  pearson_correlation: 0.0055
  kl_divergence: -329.0248
  ssim: 0.0624
  iou: 0.1429

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.45842, std: 0.14089

Metrics for layer 5:
  pearson_correlation: -0.0030
  kl_divergence: -358.8674
  ssim: 0.0516
  iou: 0.1313
Layer 5 metrics:
  pearson_correlation: -0.0030
  kl_divergence: -358.8674
  ssim: 0.0516
  iou: 0.1313

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.43133, std: 0.15075

Metrics for layer 6:
  pearson_correlation: -0.0110
  kl_divergence: -331.5529
  ssim: 0.0547
  iou: 0.1281
Layer 6 metrics:
  pearson_correlation: -0.0110
  kl_divergence: -331.5529
  ssim: 0.0547
  iou: 0.1281

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.52073, std: 0.13663

Metrics for layer 7:
  pearson_correlation: -0.0178
  kl_divergence: -89.5013
  ssim: 0.0471
  iou: 0.1264
Layer 7 metrics:
  pearson_correlation: -0.0178
  kl_divergence: -89.5013
  ssim: 0.0471
  iou: 0.1264

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.46175, std: 0.16150

Metrics for layer 8:
  pearson_correlation: -0.0463
  kl_divergence: -79.3773
  ssim: 0.0532
  iou: 0.1329
Layer 8 metrics:
  pearson_correlation: -0.0463
  kl_divergence: -79.3773
  ssim: 0.0532
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.49692, std: 0.17366

Metrics for layer 9:
  pearson_correlation: -0.0151
  kl_divergence: -92.6061
  ssim: 0.0402
  iou: 0.1496
Layer 9 metrics:
  pearson_correlation: -0.0151
  kl_divergence: -92.6061
  ssim: 0.0402
  iou: 0.1496

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.47405, std: 0.18036

Metrics for layer 10:
  pearson_correlation: -0.0299
  kl_divergence: -17.6165
  ssim: -0.0110
  iou: 0.1264
Layer 10 metrics:
  pearson_correlation: -0.0299
  kl_divergence: -17.6165
  ssim: -0.0110
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49432, std: 0.19126

Metrics for layer 11:
  pearson_correlation: -0.0462
  kl_divergence: -19.1354
  ssim: 0.0045
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: -0.0462
  kl_divergence: -19.1354
  ssim: 0.0045
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.56477, std: 0.18982

Metrics for layer 12:
  pearson_correlation: -0.0781
  kl_divergence: -26.6891
  ssim: -0.0539
  iou: 0.1011
Layer 12 metrics:
  pearson_correlation: -0.0781
  kl_divergence: -26.6891
  ssim: -0.0539
  iou: 0.1011
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer3/batch_0_strength_0.4_results.npy

Processing batch 2/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43257, std: 0.11048

Metrics for layer 0:
  pearson_correlation: -0.0012
  kl_divergence: -3819.2207
  ssim: 0.0377
  iou: 0.1394
Layer 0 metrics:
  pearson_correlation: -0.0012
  kl_divergence: -3819.2207
  ssim: 0.0377
  iou: 0.1394

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.39015, std: 0.12069

Metrics for layer 1:
  pearson_correlation: -0.0083
  kl_divergence: -3587.9321
  ssim: 0.0358
  iou: 0.1375
Layer 1 metrics:
  pearson_correlation: -0.0083
  kl_divergence: -3587.9321
  ssim: 0.0358
  iou: 0.1375

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.44504, std: 0.13010

Metrics for layer 2:
  pearson_correlation: 0.0023
  kl_divergence: -1336.4153
  ssim: 0.0496
  iou: 0.1406
Layer 2 metrics:
  pearson_correlation: 0.0023
  kl_divergence: -1336.4153
  ssim: 0.0496
  iou: 0.1406

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.52914, std: 0.12125

Metrics for layer 3:
  pearson_correlation: -0.0037
  kl_divergence: -1509.6108
  ssim: 0.0468
  iou: 0.1371
Layer 3 metrics:
  pearson_correlation: -0.0037
  kl_divergence: -1509.6108
  ssim: 0.0468
  iou: 0.1371

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.44707, std: 0.15464

Metrics for layer 4:
  pearson_correlation: -0.0377
  kl_divergence: -351.2390
  ssim: 0.0423
  iou: 0.1412
Layer 4 metrics:
  pearson_correlation: -0.0377
  kl_divergence: -351.2390
  ssim: 0.0423
  iou: 0.1412

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47453, std: 0.13038

Metrics for layer 5:
  pearson_correlation: -0.0181
  kl_divergence: -385.7532
  ssim: 0.0593
  iou: 0.1248
Layer 5 metrics:
  pearson_correlation: -0.0181
  kl_divergence: -385.7532
  ssim: 0.0593
  iou: 0.1248

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.43863, std: 0.14986

Metrics for layer 6:
  pearson_correlation: 0.0027
  kl_divergence: -348.4506
  ssim: 0.0544
  iou: 0.1379
Layer 6 metrics:
  pearson_correlation: 0.0027
  kl_divergence: -348.4506
  ssim: 0.0544
  iou: 0.1379

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.53941, std: 0.16450

Metrics for layer 7:
  pearson_correlation: -0.0582
  kl_divergence: -92.4569
  ssim: 0.0168
  iou: 0.1329
Layer 7 metrics:
  pearson_correlation: -0.0582
  kl_divergence: -92.4569
  ssim: 0.0168
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.47764, std: 0.17517

Metrics for layer 8:
  pearson_correlation: 0.0225
  kl_divergence: -86.3752
  ssim: 0.0330
  iou: 0.1297
Layer 8 metrics:
  pearson_correlation: 0.0225
  kl_divergence: -86.3752
  ssim: 0.0330
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.45137, std: 0.17612

Metrics for layer 9:
  pearson_correlation: 0.0171
  kl_divergence: -78.8805
  ssim: 0.0452
  iou: 0.1667
Layer 9 metrics:
  pearson_correlation: 0.0171
  kl_divergence: -78.8805
  ssim: 0.0452
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.44369, std: 0.17782

Metrics for layer 10:
  pearson_correlation: -0.0168
  kl_divergence: -13.8433
  ssim: -0.0421
  iou: 0.1807
Layer 10 metrics:
  pearson_correlation: -0.0168
  kl_divergence: -13.8433
  ssim: -0.0421
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.48998, std: 0.17919

Metrics for layer 11:
  pearson_correlation: 0.0862
  kl_divergence: -20.0548
  ssim: 0.1907
  iou: 0.1807
Layer 11 metrics:
  pearson_correlation: 0.0862
  kl_divergence: -20.0548
  ssim: 0.1907
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.37469, std: 0.18717

Metrics for layer 12:
  pearson_correlation: -0.0881
  kl_divergence: 5.9081
  ssim: -0.0196
  iou: 0.1011
Layer 12 metrics:
  pearson_correlation: -0.0881
  kl_divergence: 5.9081
  ssim: -0.0196
  iou: 0.1011
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer3/batch_1_strength_0.4_results.npy

Processing attention strength 0.8
Attention vector: [0.  0.  0.  0.8 0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.44800, std: 0.12009

Metrics for layer 0:
  pearson_correlation: 0.0026
  kl_divergence: -4743.4116
  ssim: 0.0475
  iou: 0.1454
Layer 0 metrics:
  pearson_correlation: 0.0026
  kl_divergence: -4743.4116
  ssim: 0.0475
  iou: 0.1454

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.40664, std: 0.12064

Metrics for layer 1:
  pearson_correlation: -0.0027
  kl_divergence: -4413.5469
  ssim: 0.0503
  iou: 0.1415
Layer 1 metrics:
  pearson_correlation: -0.0027
  kl_divergence: -4413.5469
  ssim: 0.0503
  iou: 0.1415

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.45837, std: 0.13152

Metrics for layer 2:
  pearson_correlation: 0.0097
  kl_divergence: -1393.7780
  ssim: 0.0551
  iou: 0.1452
Layer 2 metrics:
  pearson_correlation: 0.0097
  kl_divergence: -1393.7780
  ssim: 0.0551
  iou: 0.1452

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.48018, std: 0.12526

Metrics for layer 3:
  pearson_correlation: 0.0050
  kl_divergence: -1443.7183
  ssim: 0.0577
  iou: 0.1431
Layer 3 metrics:
  pearson_correlation: 0.0050
  kl_divergence: -1443.7183
  ssim: 0.0577
  iou: 0.1431

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46189, std: 0.15181

Metrics for layer 4:
  pearson_correlation: 0.0248
  kl_divergence: -359.6756
  ssim: 0.0616
  iou: 0.1420
Layer 4 metrics:
  pearson_correlation: 0.0248
  kl_divergence: -359.6756
  ssim: 0.0616
  iou: 0.1420

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.49449, std: 0.14123

Metrics for layer 5:
  pearson_correlation: 0.0214
  kl_divergence: -386.4470
  ssim: 0.0643
  iou: 0.1521
Layer 5 metrics:
  pearson_correlation: 0.0214
  kl_divergence: -386.4470
  ssim: 0.0643
  iou: 0.1521

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50795, std: 0.13793

Metrics for layer 6:
  pearson_correlation: -0.0150
  kl_divergence: -396.1701
  ssim: 0.0644
  iou: 0.1346
Layer 6 metrics:
  pearson_correlation: -0.0150
  kl_divergence: -396.1701
  ssim: 0.0644
  iou: 0.1346

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.50343, std: 0.15456

Metrics for layer 7:
  pearson_correlation: 0.0035
  kl_divergence: -95.9517
  ssim: 0.0557
  iou: 0.1807
Layer 7 metrics:
  pearson_correlation: 0.0035
  kl_divergence: -95.9517
  ssim: 0.0557
  iou: 0.1807

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.45557, std: 0.16054

Metrics for layer 8:
  pearson_correlation: -0.0013
  kl_divergence: -81.4597
  ssim: 0.0454
  iou: 0.1329
Layer 8 metrics:
  pearson_correlation: -0.0013
  kl_divergence: -81.4597
  ssim: 0.0454
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.45374, std: 0.15846

Metrics for layer 9:
  pearson_correlation: 0.0912
  kl_divergence: -87.7654
  ssim: 0.0949
  iou: 0.1462
Layer 9 metrics:
  pearson_correlation: 0.0912
  kl_divergence: -87.7654
  ssim: 0.0949
  iou: 0.1462

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.47014, std: 0.17422

Metrics for layer 10:
  pearson_correlation: -0.0386
  kl_divergence: -5.8672
  ssim: -0.0523
  iou: 0.1136
Layer 10 metrics:
  pearson_correlation: -0.0386
  kl_divergence: -5.8672
  ssim: -0.0523
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.47740, std: 0.20232

Metrics for layer 11:
  pearson_correlation: 0.1078
  kl_divergence: -18.5630
  ssim: 0.2143
  iou: 0.1951
Layer 11 metrics:
  pearson_correlation: 0.1078
  kl_divergence: -18.5630
  ssim: 0.2143
  iou: 0.1951

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49859, std: 0.19664

Metrics for layer 12:
  pearson_correlation: -0.0953
  kl_divergence: -20.7992
  ssim: 0.0439
  iou: 0.1136
Layer 12 metrics:
  pearson_correlation: -0.0953
  kl_divergence: -20.7992
  ssim: 0.0439
  iou: 0.1136
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer3/batch_0_strength_0.8_results.npy

Processing batch 2/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.42871, std: 0.12604

Metrics for layer 0:
  pearson_correlation: 0.0008
  kl_divergence: -3779.0247
  ssim: 0.0316
  iou: 0.1419
Layer 0 metrics:
  pearson_correlation: 0.0008
  kl_divergence: -3779.0247
  ssim: 0.0316
  iou: 0.1419

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.41212, std: 0.11751

Metrics for layer 1:
  pearson_correlation: -0.0066
  kl_divergence: -3708.3252
  ssim: 0.0363
  iou: 0.1422
Layer 1 metrics:
  pearson_correlation: -0.0066
  kl_divergence: -3708.3252
  ssim: 0.0363
  iou: 0.1422

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.44640, std: 0.13664

Metrics for layer 2:
  pearson_correlation: -0.0025
  kl_divergence: -1335.5662
  ssim: 0.0446
  iou: 0.1402
Layer 2 metrics:
  pearson_correlation: -0.0025
  kl_divergence: -1335.5662
  ssim: 0.0446
  iou: 0.1402

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.49659, std: 0.13010

Metrics for layer 3:
  pearson_correlation: -0.0070
  kl_divergence: -1443.3911
  ssim: 0.0438
  iou: 0.1363
Layer 3 metrics:
  pearson_correlation: -0.0070
  kl_divergence: -1443.3911
  ssim: 0.0438
  iou: 0.1363

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.44779, std: 0.13190

Metrics for layer 4:
  pearson_correlation: -0.0054
  kl_divergence: -359.9367
  ssim: 0.0591
  iou: 0.1563
Layer 4 metrics:
  pearson_correlation: -0.0054
  kl_divergence: -359.9367
  ssim: 0.0591
  iou: 0.1563

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.43285, std: 0.13888

Metrics for layer 5:
  pearson_correlation: -0.0063
  kl_divergence: -345.9095
  ssim: 0.0601
  iou: 0.1297
Layer 5 metrics:
  pearson_correlation: -0.0063
  kl_divergence: -345.9095
  ssim: 0.0601
  iou: 0.1297

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48755, std: 0.14402

Metrics for layer 6:
  pearson_correlation: 0.0146
  kl_divergence: -394.4412
  ssim: 0.0534
  iou: 0.1496
Layer 6 metrics:
  pearson_correlation: 0.0146
  kl_divergence: -394.4412
  ssim: 0.0534
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.46818, std: 0.16257

Metrics for layer 7:
  pearson_correlation: 0.0061
  kl_divergence: -85.4384
  ssim: 0.0375
  iou: 0.1462
Layer 7 metrics:
  pearson_correlation: 0.0061
  kl_divergence: -85.4384
  ssim: 0.0375
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.48448, std: 0.18496

Metrics for layer 8:
  pearson_correlation: 0.0214
  kl_divergence: -85.0341
  ssim: 0.0317
  iou: 0.1701
Layer 8 metrics:
  pearson_correlation: 0.0214
  kl_divergence: -85.0341
  ssim: 0.0317
  iou: 0.1701

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.53553, std: 0.15879

Metrics for layer 9:
  pearson_correlation: 0.0162
  kl_divergence: -95.2290
  ssim: 0.0401
  iou: 0.1264
Layer 9 metrics:
  pearson_correlation: 0.0162
  kl_divergence: -95.2290
  ssim: 0.0401
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.50438, std: 0.16226

Metrics for layer 10:
  pearson_correlation: 0.0931
  kl_divergence: -21.7395
  ssim: 0.1597
  iou: 0.1667
Layer 10 metrics:
  pearson_correlation: 0.0931
  kl_divergence: -21.7395
  ssim: 0.1597
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.44298, std: 0.19538

Metrics for layer 11:
  pearson_correlation: -0.0686
  kl_divergence: -10.8874
  ssim: 0.0507
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: -0.0686
  kl_divergence: -10.8874
  ssim: 0.0507
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.40203, std: 0.17311

Metrics for layer 12:
  pearson_correlation: -0.0372
  kl_divergence: -11.5066
  ssim: 0.0326
  iou: 0.0889
Layer 12 metrics:
  pearson_correlation: -0.0372
  kl_divergence: -11.5066
  ssim: 0.0326
  iou: 0.0889
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer3/batch_1_strength_0.8_results.npy

Processing attention strength 1.2
Attention vector: [0.  0.  0.  1.2 0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.43109, std: 0.11570

Metrics for layer 0:
  pearson_correlation: -0.0022
  kl_divergence: -4621.9717
  ssim: 0.0504
  iou: 0.1444
Layer 0 metrics:
  pearson_correlation: -0.0022
  kl_divergence: -4621.9717
  ssim: 0.0504
  iou: 0.1444

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.39335, std: 0.11271

Metrics for layer 1:
  pearson_correlation: 0.0039
  kl_divergence: -4329.1763
  ssim: 0.0587
  iou: 0.1438
Layer 1 metrics:
  pearson_correlation: 0.0039
  kl_divergence: -4329.1763
  ssim: 0.0587
  iou: 0.1438

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.52200, std: 0.12699

Metrics for layer 2:
  pearson_correlation: -0.0014
  kl_divergence: -1536.6339
  ssim: 0.0491
  iou: 0.1410
Layer 2 metrics:
  pearson_correlation: -0.0014
  kl_divergence: -1536.6339
  ssim: 0.0491
  iou: 0.1410

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.49987, std: 0.13150

Metrics for layer 3:
  pearson_correlation: 0.0043
  kl_divergence: -1487.5059
  ssim: 0.0480
  iou: 0.1406
Layer 3 metrics:
  pearson_correlation: 0.0043
  kl_divergence: -1487.5059
  ssim: 0.0480
  iou: 0.1406

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46122, std: 0.14836

Metrics for layer 4:
  pearson_correlation: 0.0204
  kl_divergence: -357.6137
  ssim: 0.0508
  iou: 0.1504
Layer 4 metrics:
  pearson_correlation: 0.0204
  kl_divergence: -357.6137
  ssim: 0.0508
  iou: 0.1504

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50272, std: 0.13343

Metrics for layer 5:
  pearson_correlation: 0.0174
  kl_divergence: -396.0163
  ssim: 0.0571
  iou: 0.1512
Layer 5 metrics:
  pearson_correlation: 0.0174
  kl_divergence: -396.0163
  ssim: 0.0571
  iou: 0.1512

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.53132, std: 0.15010

Metrics for layer 6:
  pearson_correlation: -0.0164
  kl_divergence: -407.9266
  ssim: 0.0399
  iou: 0.1362
Layer 6 metrics:
  pearson_correlation: -0.0164
  kl_divergence: -407.9266
  ssim: 0.0399
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.47119, std: 0.16625

Metrics for layer 7:
  pearson_correlation: -0.0463
  kl_divergence: -86.3060
  ssim: 0.0407
  iou: 0.1105
Layer 7 metrics:
  pearson_correlation: -0.0463
  kl_divergence: -86.3060
  ssim: 0.0407
  iou: 0.1105

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.46884, std: 0.15270

Metrics for layer 8:
  pearson_correlation: -0.0606
  kl_divergence: -87.0719
  ssim: 0.0439
  iou: 0.1136
Layer 8 metrics:
  pearson_correlation: -0.0606
  kl_divergence: -87.0719
  ssim: 0.0439
  iou: 0.1136

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.46631, std: 0.15351

Metrics for layer 9:
  pearson_correlation: -0.0217
  kl_divergence: -87.0504
  ssim: 0.0281
  iou: 0.1362
Layer 9 metrics:
  pearson_correlation: -0.0217
  kl_divergence: -87.0504
  ssim: 0.0281
  iou: 0.1362

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.48586, std: 0.20374

Metrics for layer 10:
  pearson_correlation: 0.0623
  kl_divergence: -20.6976
  ssim: 0.1231
  iou: 0.1136
Layer 10 metrics:
  pearson_correlation: 0.0623
  kl_divergence: -20.6976
  ssim: 0.1231
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49916, std: 0.17671

Metrics for layer 11:
  pearson_correlation: 0.0377
  kl_divergence: -20.7903
  ssim: 0.0660
  iou: 0.1807
Layer 11 metrics:
  pearson_correlation: 0.0377
  kl_divergence: -20.7903
  ssim: 0.0660
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49182, std: 0.16855

Metrics for layer 12:
  pearson_correlation: -0.0540
  kl_divergence: -21.5735
  ssim: -0.0011
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: -0.0540
  kl_divergence: -21.5735
  ssim: -0.0011
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer3/batch_0_strength_1.2_results.npy

Processing batch 2/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.40379, std: 0.11256

Metrics for layer 0:
  pearson_correlation: 0.0042
  kl_divergence: -3681.1619
  ssim: 0.0398
  iou: 0.1401
Layer 0 metrics:
  pearson_correlation: 0.0042
  kl_divergence: -3681.1619
  ssim: 0.0398
  iou: 0.1401

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.44358, std: 0.11964

Metrics for layer 1:
  pearson_correlation: 0.0027
  kl_divergence: -3859.9280
  ssim: 0.0334
  iou: 0.1413
Layer 1 metrics:
  pearson_correlation: 0.0027
  kl_divergence: -3859.9280
  ssim: 0.0334
  iou: 0.1413

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.46222, std: 0.12412

Metrics for layer 2:
  pearson_correlation: -0.0047
  kl_divergence: -1380.7277
  ssim: 0.0497
  iou: 0.1385
Layer 2 metrics:
  pearson_correlation: -0.0047
  kl_divergence: -1380.7277
  ssim: 0.0497
  iou: 0.1385

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.49074, std: 0.12637

Metrics for layer 3:
  pearson_correlation: 0.0126
  kl_divergence: -1431.0948
  ssim: 0.0511
  iou: 0.1387
Layer 3 metrics:
  pearson_correlation: 0.0126
  kl_divergence: -1431.0948
  ssim: 0.0511
  iou: 0.1387

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.49157, std: 0.14815

Metrics for layer 4:
  pearson_correlation: -0.0034
  kl_divergence: -390.4441
  ssim: 0.0536
  iou: 0.1598
Layer 4 metrics:
  pearson_correlation: -0.0034
  kl_divergence: -390.4441
  ssim: 0.0536
  iou: 0.1598

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.45456, std: 0.14705

Metrics for layer 5:
  pearson_correlation: -0.0074
  kl_divergence: -363.1031
  ssim: 0.0526
  iou: 0.1546
Layer 5 metrics:
  pearson_correlation: -0.0074
  kl_divergence: -363.1031
  ssim: 0.0526
  iou: 0.1546

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48236, std: 0.14655

Metrics for layer 6:
  pearson_correlation: -0.0133
  kl_divergence: -387.6982
  ssim: 0.0436
  iou: 0.1387
Layer 6 metrics:
  pearson_correlation: -0.0133
  kl_divergence: -387.6982
  ssim: 0.0436
  iou: 0.1387

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.40295, std: 0.16093

Metrics for layer 7:
  pearson_correlation: 0.0269
  kl_divergence: -74.2430
  ssim: 0.0526
  iou: 0.1701
Layer 7 metrics:
  pearson_correlation: 0.0269
  kl_divergence: -74.2430
  ssim: 0.0526
  iou: 0.1701

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.46636, std: 0.18326

Metrics for layer 8:
  pearson_correlation: -0.0119
  kl_divergence: -83.1762
  ssim: 0.0224
  iou: 0.1329
Layer 8 metrics:
  pearson_correlation: -0.0119
  kl_divergence: -83.1762
  ssim: 0.0224
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.41781, std: 0.15253

Metrics for layer 9:
  pearson_correlation: -0.0324
  kl_divergence: -75.3669
  ssim: 0.0321
  iou: 0.1329
Layer 9 metrics:
  pearson_correlation: -0.0324
  kl_divergence: -75.3669
  ssim: 0.0321
  iou: 0.1329

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.48352, std: 0.16176

Metrics for layer 10:
  pearson_correlation: 0.1914
  kl_divergence: -21.2943
  ssim: 0.1470
  iou: 0.1951
Layer 10 metrics:
  pearson_correlation: 0.1914
  kl_divergence: -21.2943
  ssim: 0.1470
  iou: 0.1951

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.43510, std: 0.16703

Metrics for layer 11:
  pearson_correlation: -0.0179
  kl_divergence: -14.2847
  ssim: -0.0329
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: -0.0179
  kl_divergence: -14.2847
  ssim: -0.0329
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.55615, std: 0.16787

Metrics for layer 12:
  pearson_correlation: 0.1586
  kl_divergence: -25.9823
  ssim: 0.0970
  iou: 0.1807
Layer 12 metrics:
  pearson_correlation: 0.1586
  kl_divergence: -25.9823
  ssim: 0.0970
  iou: 0.1807
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer3/batch_1_strength_1.2_results.npy

Analysis complete! Results saved to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer3
Completed experiment for category 5, layer 3
----------------------------------------
Running experiment for category 5, layer 4
===================================================
Starting experiment:
Category: 5
Layer: 4
Logs will be saved to: /scratch/hy2611/CNN_attention/logs/attention_analysis_20241216_104146/category5/layer4
===================================================
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-12-16 10:52:51.438524: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-16 10:52:51.457511: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2024-12-16 10:52:51.457916: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55853c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-16 10:52:51.457928: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-16 10:52:51.460646: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-16 10:52:51.595988: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5582730 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-16 10:52:51.596007: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-12-16 10:52:51.596553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:2f:00.0
2024-12-16 10:52:51.597671: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:52:51.598648: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:52:51.599586: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:52:51.600530: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:52:51.601465: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:52:51.602393: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:52:51.603315: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:52:51.603327: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-12-16 10:52:51.603343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-16 10:52:51.603348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-16 10:52:51.603351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:61: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:87: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:15: sigmoid_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.sigmoid_cross_entropy instead. Note that the order of the predictions and labels arguments has been changed.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:322: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:82: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.


Verifying paths:
tc_path: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs exists
weight_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists
image_path: /scratch/hy2611/CNN_attention/Data/VGG16/images exists
save_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists

Initializing model...
('c11', [1, 224, 224, 64])
('c12', [1, 224, 224, 64])
('c21', [1, 112, 112, 128])
('c22', [1, 112, 112, 128])
('c31', [1, 56, 56, 256])
('c32', [1, 56, 56, 256])
('c33', [1, 56, 56, 256])
('c41', [1, 28, 28, 512])
('c42', [1, 28, 28, 512])
('c43', [1, 28, 28, 512])
('c51', [1, 14, 14, 512])
('c52', [1, 14, 14, 512])
('c53', [1, 14, 14, 512])
(0, 'conv1_1_W', (3, 3, 3, 64))
(1, 'conv1_1_b', (64,))
(2, 'conv1_2_W', (3, 3, 64, 64))
(3, 'conv1_2_b', (64,))
(4, 'conv2_1_W', (3, 3, 64, 128))
(5, 'conv2_1_b', (128,))
(6, 'conv2_2_W', (3, 3, 128, 128))
(7, 'conv2_2_b', (128,))
(8, 'conv3_1_W', (3, 3, 128, 256))
(9, 'conv3_1_b', (256,))
(10, 'conv3_2_W', (3, 3, 256, 256))
(11, 'conv3_2_b', (256,))
(12, 'conv3_3_W', (3, 3, 256, 256))
(13, 'conv3_3_b', (256,))
(14, 'conv4_1_W', (3, 3, 256, 512))
(15, 'conv4_1_b', (512,))
(16, 'conv4_2_W', (3, 3, 512, 512))
(17, 'conv4_2_b', (512,))
(18, 'conv4_3_W', (3, 3, 512, 512))
(19, 'conv4_3_b', (512,))
(20, 'conv5_1_W', (3, 3, 512, 512))
(21, 'conv5_1_b', (512,))
(22, 'conv5_2_W', (3, 3, 512, 512))
(23, 'conv5_2_b', (512,))
(24, 'conv5_3_W', (3, 3, 512, 512))
(25, 'conv5_3_b', (512,))
(26, 'fc6_W', (25088, 4096))
(27, 'fc6_b', (4096,))
(28, 'fc7_W', (4096, 4096))
(29, 'fc7_b', (4096,))
Checking checkpoint files:
Data file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.data-00000-of-00001 - Found
Index file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.index - Found
Loading checkpoint from: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt
Checkpoint loaded successfully

Initializing components...
Found tuning curves file: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs/featvecs20_train35_c.txt

Loading category 5 data...
Original positive images shape: (2, 224, 224, 3)

Processing data...

Processing attention strength 0.0
Attention vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

Processing batch 1/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.41686, std: 0.11234

Metrics for layer 0:
  pearson_correlation: 0.0007
  kl_divergence: -4517.5884
  ssim: 0.0560
  iou: 0.1426
Layer 0 metrics:
  pearson_correlation: 0.0007
  kl_divergence: -4517.5884
  ssim: 0.0560
  iou: 0.1426

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.45502, std: 0.11959

Metrics for layer 1:
  pearson_correlation: -0.0013
  kl_divergence: -4793.1729
  ssim: 0.0460
  iou: 0.1445
Layer 1 metrics:
  pearson_correlation: -0.0013
  kl_divergence: -4793.1729
  ssim: 0.0460
  iou: 0.1445

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.45490, std: 0.14089

Metrics for layer 2:
  pearson_correlation: -0.0098
  kl_divergence: -1372.5272
  ssim: 0.0470
  iou: 0.1420
Layer 2 metrics:
  pearson_correlation: -0.0098
  kl_divergence: -1372.5272
  ssim: 0.0470
  iou: 0.1420

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.50122, std: 0.12545

Metrics for layer 3:
  pearson_correlation: 0.0103
  kl_divergence: -1495.8376
  ssim: 0.0558
  iou: 0.1491
Layer 3 metrics:
  pearson_correlation: 0.0103
  kl_divergence: -1495.8376
  ssim: 0.0558
  iou: 0.1491

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.44972, std: 0.15062

Metrics for layer 4:
  pearson_correlation: -0.0094
  kl_divergence: -344.1094
  ssim: 0.0472
  iou: 0.1623
Layer 4 metrics:
  pearson_correlation: -0.0094
  kl_divergence: -344.1094
  ssim: 0.0472
  iou: 0.1623

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.38230, std: 0.12775

Metrics for layer 5:
  pearson_correlation: 0.0078
  kl_divergence: -290.9696
  ssim: 0.0855
  iou: 0.1420
Layer 5 metrics:
  pearson_correlation: 0.0078
  kl_divergence: -290.9696
  ssim: 0.0855
  iou: 0.1420

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.45376, std: 0.14743

Metrics for layer 6:
  pearson_correlation: -0.0092
  kl_divergence: -350.5372
  ssim: 0.0437
  iou: 0.1379
Layer 6 metrics:
  pearson_correlation: -0.0092
  kl_divergence: -350.5372
  ssim: 0.0437
  iou: 0.1379

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.46362, std: 0.16852

Metrics for layer 7:
  pearson_correlation: -0.0209
  kl_divergence: -82.2905
  ssim: 0.0291
  iou: 0.1297
Layer 7 metrics:
  pearson_correlation: -0.0209
  kl_divergence: -82.2905
  ssim: 0.0291
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.48125, std: 0.16912

Metrics for layer 8:
  pearson_correlation: -0.0207
  kl_divergence: -85.6529
  ssim: 0.0354
  iou: 0.1232
Layer 8 metrics:
  pearson_correlation: -0.0207
  kl_divergence: -85.6529
  ssim: 0.0354
  iou: 0.1232

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.49018, std: 0.16981

Metrics for layer 9:
  pearson_correlation: 0.0326
  kl_divergence: -90.1487
  ssim: 0.0531
  iou: 0.1563
Layer 9 metrics:
  pearson_correlation: 0.0326
  kl_divergence: -90.1487
  ssim: 0.0531
  iou: 0.1563

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.40767, std: 0.17285

Metrics for layer 10:
  pearson_correlation: 0.0518
  kl_divergence: -10.9090
  ssim: 0.2069
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: 0.0518
  kl_divergence: -10.9090
  ssim: 0.2069
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49736, std: 0.17944

Metrics for layer 11:
  pearson_correlation: -0.0083
  kl_divergence: -22.6082
  ssim: 0.0235
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: -0.0083
  kl_divergence: -22.6082
  ssim: 0.0235
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49826, std: 0.18511

Metrics for layer 12:
  pearson_correlation: 0.1283
  kl_divergence: -24.7340
  ssim: 0.0199
  iou: 0.1807
Layer 12 metrics:
  pearson_correlation: 0.1283
  kl_divergence: -24.7340
  ssim: 0.0199
  iou: 0.1807
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer4/batch_0_strength_0.0_results.npy

Processing batch 2/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43642, std: 0.11878

Metrics for layer 0:
  pearson_correlation: -0.0023
  kl_divergence: -3824.2415
  ssim: 0.0340
  iou: 0.1398
Layer 0 metrics:
  pearson_correlation: -0.0023
  kl_divergence: -3824.2415
  ssim: 0.0340
  iou: 0.1398

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43712, std: 0.12330

Metrics for layer 1:
  pearson_correlation: -0.0014
  kl_divergence: -3822.8096
  ssim: 0.0323
  iou: 0.1410
Layer 1 metrics:
  pearson_correlation: -0.0014
  kl_divergence: -3822.8096
  ssim: 0.0323
  iou: 0.1410

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.42281, std: 0.12633

Metrics for layer 2:
  pearson_correlation: 0.0136
  kl_divergence: -1293.7954
  ssim: 0.0536
  iou: 0.1506
Layer 2 metrics:
  pearson_correlation: 0.0136
  kl_divergence: -1293.7954
  ssim: 0.0536
  iou: 0.1506

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.47435, std: 0.12817

Metrics for layer 3:
  pearson_correlation: 0.0163
  kl_divergence: -1406.5320
  ssim: 0.0522
  iou: 0.1460
Layer 3 metrics:
  pearson_correlation: 0.0163
  kl_divergence: -1406.5320
  ssim: 0.0522
  iou: 0.1460

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.50208, std: 0.13748

Metrics for layer 4:
  pearson_correlation: 0.0287
  kl_divergence: -411.4992
  ssim: 0.0522
  iou: 0.1606
Layer 4 metrics:
  pearson_correlation: 0.0287
  kl_divergence: -411.4992
  ssim: 0.0522
  iou: 0.1606

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.49389, std: 0.16081

Metrics for layer 5:
  pearson_correlation: -0.0054
  kl_divergence: -388.9163
  ssim: 0.0468
  iou: 0.1487
Layer 5 metrics:
  pearson_correlation: -0.0054
  kl_divergence: -388.9163
  ssim: 0.0468
  iou: 0.1487

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48609, std: 0.14467

Metrics for layer 6:
  pearson_correlation: -0.0025
  kl_divergence: -393.4753
  ssim: 0.0556
  iou: 0.1404
Layer 6 metrics:
  pearson_correlation: -0.0025
  kl_divergence: -393.4753
  ssim: 0.0556
  iou: 0.1404

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.46912, std: 0.17044

Metrics for layer 7:
  pearson_correlation: 0.0492
  kl_divergence: -86.0167
  ssim: 0.0504
  iou: 0.1598
Layer 7 metrics:
  pearson_correlation: 0.0492
  kl_divergence: -86.0167
  ssim: 0.0504
  iou: 0.1598

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.52042, std: 0.14557

Metrics for layer 8:
  pearson_correlation: 0.0691
  kl_divergence: -93.9525
  ssim: 0.0560
  iou: 0.1879
Layer 8 metrics:
  pearson_correlation: 0.0691
  kl_divergence: -93.9525
  ssim: 0.0560
  iou: 0.1879

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.50828, std: 0.16884

Metrics for layer 9:
  pearson_correlation: 0.0239
  kl_divergence: -89.3325
  ssim: 0.0434
  iou: 0.1563
Layer 9 metrics:
  pearson_correlation: 0.0239
  kl_divergence: -89.3325
  ssim: 0.0434
  iou: 0.1563

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.52620, std: 0.17050

Metrics for layer 10:
  pearson_correlation: -0.0332
  kl_divergence: -20.4858
  ssim: 0.0381
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: -0.0332
  kl_divergence: -20.4858
  ssim: 0.0381
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.38948, std: 0.18267

Metrics for layer 11:
  pearson_correlation: 0.0082
  kl_divergence: -8.3071
  ssim: 0.0722
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: 0.0082
  kl_divergence: -8.3071
  ssim: 0.0722
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.52216, std: 0.21187

Metrics for layer 12:
  pearson_correlation: 0.0431
  kl_divergence: -10.6709
  ssim: 0.1498
  iou: 0.1951
Layer 12 metrics:
  pearson_correlation: 0.0431
  kl_divergence: -10.6709
  ssim: 0.1498
  iou: 0.1951
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer4/batch_1_strength_0.0_results.npy

Processing attention strength 0.4
Attention vector: [0.  0.  0.  0.  0.4 0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.44093, std: 0.12002

Metrics for layer 0:
  pearson_correlation: -0.0055
  kl_divergence: -4683.3652
  ssim: 0.0473
  iou: 0.1422
Layer 0 metrics:
  pearson_correlation: -0.0055
  kl_divergence: -4683.3652
  ssim: 0.0473
  iou: 0.1422

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.46455, std: 0.12303

Metrics for layer 1:
  pearson_correlation: -0.0047
  kl_divergence: -4850.8184
  ssim: 0.0431
  iou: 0.1420
Layer 1 metrics:
  pearson_correlation: -0.0047
  kl_divergence: -4850.8184
  ssim: 0.0431
  iou: 0.1420

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.45405, std: 0.12490

Metrics for layer 2:
  pearson_correlation: 0.0140
  kl_divergence: -1390.5037
  ssim: 0.0605
  iou: 0.1441
Layer 2 metrics:
  pearson_correlation: 0.0140
  kl_divergence: -1390.5037
  ssim: 0.0605
  iou: 0.1441

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.47024, std: 0.12812

Metrics for layer 3:
  pearson_correlation: -0.0003
  kl_divergence: -1424.3455
  ssim: 0.0550
  iou: 0.1452
Layer 3 metrics:
  pearson_correlation: -0.0003
  kl_divergence: -1424.3455
  ssim: 0.0550
  iou: 0.1452

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.52735, std: 0.13888

Metrics for layer 4:
  pearson_correlation: 0.0451
  kl_divergence: -417.0519
  ssim: 0.0648
  iou: 0.1667
Layer 4 metrics:
  pearson_correlation: 0.0451
  kl_divergence: -417.0519
  ssim: 0.0648
  iou: 0.1667

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.52829, std: 0.13319

Metrics for layer 5:
  pearson_correlation: -0.0088
  kl_divergence: -413.9525
  ssim: 0.0483
  iou: 0.1371
Layer 5 metrics:
  pearson_correlation: -0.0088
  kl_divergence: -413.9525
  ssim: 0.0483
  iou: 0.1371

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.43906, std: 0.14946

Metrics for layer 6:
  pearson_correlation: -0.0034
  kl_divergence: -337.2797
  ssim: 0.0571
  iou: 0.1329
Layer 6 metrics:
  pearson_correlation: -0.0034
  kl_divergence: -337.2797
  ssim: 0.0571
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.46106, std: 0.15865

Metrics for layer 7:
  pearson_correlation: -0.0491
  kl_divergence: -82.8581
  ssim: 0.0231
  iou: 0.1264
Layer 7 metrics:
  pearson_correlation: -0.0491
  kl_divergence: -82.8581
  ssim: 0.0231
  iou: 0.1264

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.47933, std: 0.17132

Metrics for layer 8:
  pearson_correlation: -0.0304
  kl_divergence: -88.7734
  ssim: 0.0333
  iou: 0.1563
Layer 8 metrics:
  pearson_correlation: -0.0304
  kl_divergence: -88.7734
  ssim: 0.0333
  iou: 0.1563

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.43441, std: 0.14586

Metrics for layer 9:
  pearson_correlation: -0.0340
  kl_divergence: -77.0852
  ssim: 0.0664
  iou: 0.1737
Layer 9 metrics:
  pearson_correlation: -0.0340
  kl_divergence: -77.0852
  ssim: 0.0664
  iou: 0.1737

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49347, std: 0.22175

Metrics for layer 10:
  pearson_correlation: 0.0363
  kl_divergence: -15.7119
  ssim: 0.0734
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: 0.0363
  kl_divergence: -15.7119
  ssim: 0.0734
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49389, std: 0.20310

Metrics for layer 11:
  pearson_correlation: 0.0617
  kl_divergence: -22.6268
  ssim: 0.0571
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: 0.0617
  kl_divergence: -22.6268
  ssim: 0.0571
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.47154, std: 0.17564

Metrics for layer 12:
  pearson_correlation: 0.0890
  kl_divergence: -20.6365
  ssim: 0.0572
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: 0.0890
  kl_divergence: -20.6365
  ssim: 0.0572
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer4/batch_0_strength_0.4_results.npy

Processing batch 2/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.41315, std: 0.11340

Metrics for layer 0:
  pearson_correlation: -0.0065
  kl_divergence: -3720.5457
  ssim: 0.0382
  iou: 0.1429
Layer 0 metrics:
  pearson_correlation: -0.0065
  kl_divergence: -3720.5457
  ssim: 0.0382
  iou: 0.1429

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.48964, std: 0.12542

Metrics for layer 1:
  pearson_correlation: -0.0051
  kl_divergence: -4046.8489
  ssim: 0.0277
  iou: 0.1415
Layer 1 metrics:
  pearson_correlation: -0.0051
  kl_divergence: -4046.8489
  ssim: 0.0277
  iou: 0.1415

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.44495, std: 0.12842

Metrics for layer 2:
  pearson_correlation: -0.0038
  kl_divergence: -1340.0184
  ssim: 0.0494
  iou: 0.1360
Layer 2 metrics:
  pearson_correlation: -0.0038
  kl_divergence: -1340.0184
  ssim: 0.0494
  iou: 0.1360

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.45358, std: 0.13283

Metrics for layer 3:
  pearson_correlation: -0.0150
  kl_divergence: -1350.3270
  ssim: 0.0460
  iou: 0.1391
Layer 3 metrics:
  pearson_correlation: -0.0150
  kl_divergence: -1350.3270
  ssim: 0.0460
  iou: 0.1391

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.46076, std: 0.14650

Metrics for layer 4:
  pearson_correlation: -0.0137
  kl_divergence: -366.5429
  ssim: 0.0539
  iou: 0.1371
Layer 4 metrics:
  pearson_correlation: -0.0137
  kl_divergence: -366.5429
  ssim: 0.0539
  iou: 0.1371

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47835, std: 0.13042

Metrics for layer 5:
  pearson_correlation: 0.0130
  kl_divergence: -390.1261
  ssim: 0.0638
  iou: 0.1470
Layer 5 metrics:
  pearson_correlation: 0.0130
  kl_divergence: -390.1261
  ssim: 0.0638
  iou: 0.1470

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.50889, std: 0.12837

Metrics for layer 6:
  pearson_correlation: 0.0055
  kl_divergence: -395.5451
  ssim: 0.0593
  iou: 0.1429
Layer 6 metrics:
  pearson_correlation: 0.0055
  kl_divergence: -395.5451
  ssim: 0.0593
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.48488, std: 0.16683

Metrics for layer 7:
  pearson_correlation: -0.0285
  kl_divergence: -85.8230
  ssim: 0.0206
  iou: 0.1200
Layer 7 metrics:
  pearson_correlation: -0.0285
  kl_divergence: -85.8230
  ssim: 0.0206
  iou: 0.1200

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.49589, std: 0.14605

Metrics for layer 8:
  pearson_correlation: -0.0162
  kl_divergence: -89.0302
  ssim: 0.0301
  iou: 0.1462
Layer 8 metrics:
  pearson_correlation: -0.0162
  kl_divergence: -89.0302
  ssim: 0.0301
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.45038, std: 0.14156

Metrics for layer 9:
  pearson_correlation: -0.0018
  kl_divergence: -81.6572
  ssim: 0.0497
  iou: 0.1429
Layer 9 metrics:
  pearson_correlation: -0.0018
  kl_divergence: -81.6572
  ssim: 0.0497
  iou: 0.1429

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.50311, std: 0.19072

Metrics for layer 10:
  pearson_correlation: 0.0749
  kl_divergence: -20.0528
  ssim: 0.1133
  iou: 0.2099
Layer 10 metrics:
  pearson_correlation: 0.0749
  kl_divergence: -20.0528
  ssim: 0.1133
  iou: 0.2099

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.53228, std: 0.20204

Metrics for layer 11:
  pearson_correlation: -0.0456
  kl_divergence: -19.9383
  ssim: 0.0264
  iou: 0.1011
Layer 11 metrics:
  pearson_correlation: -0.0456
  kl_divergence: -19.9383
  ssim: 0.0264
  iou: 0.1011

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.38646, std: 0.14708

Metrics for layer 12:
  pearson_correlation: -0.0241
  kl_divergence: -8.8354
  ssim: 0.0494
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: -0.0241
  kl_divergence: -8.8354
  ssim: 0.0494
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer4/batch_1_strength_0.4_results.npy

Processing attention strength 0.8
Attention vector: [0.  0.  0.  0.  0.8 0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.44008, std: 0.11683

Metrics for layer 0:
  pearson_correlation: -0.0058
  kl_divergence: -4685.9517
  ssim: 0.0495
  iou: 0.1428
Layer 0 metrics:
  pearson_correlation: -0.0058
  kl_divergence: -4685.9517
  ssim: 0.0495
  iou: 0.1428

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.39321, std: 0.11665

Metrics for layer 1:
  pearson_correlation: -0.0043
  kl_divergence: -4309.5356
  ssim: 0.0557
  iou: 0.1449
Layer 1 metrics:
  pearson_correlation: -0.0043
  kl_divergence: -4309.5356
  ssim: 0.0557
  iou: 0.1449

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.46092, std: 0.12741

Metrics for layer 2:
  pearson_correlation: -0.0065
  kl_divergence: -1398.9365
  ssim: 0.0539
  iou: 0.1443
Layer 2 metrics:
  pearson_correlation: -0.0065
  kl_divergence: -1398.9365
  ssim: 0.0539
  iou: 0.1443

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.42836, std: 0.12447

Metrics for layer 3:
  pearson_correlation: -0.0024
  kl_divergence: -1322.7227
  ssim: 0.0636
  iou: 0.1414
Layer 3 metrics:
  pearson_correlation: -0.0024
  kl_divergence: -1322.7227
  ssim: 0.0636
  iou: 0.1414

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47014, std: 0.14838

Metrics for layer 4:
  pearson_correlation: -0.0068
  kl_divergence: -364.9017
  ssim: 0.0608
  iou: 0.1289
Layer 4 metrics:
  pearson_correlation: -0.0068
  kl_divergence: -364.9017
  ssim: 0.0608
  iou: 0.1289

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46027, std: 0.14836

Metrics for layer 5:
  pearson_correlation: 0.0323
  kl_divergence: -359.8936
  ssim: 0.0575
  iou: 0.1479
Layer 5 metrics:
  pearson_correlation: 0.0323
  kl_divergence: -359.8936
  ssim: 0.0575
  iou: 0.1479

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47009, std: 0.14294

Metrics for layer 6:
  pearson_correlation: -0.0091
  kl_divergence: -365.5402
  ssim: 0.0517
  iou: 0.1512
Layer 6 metrics:
  pearson_correlation: -0.0091
  kl_divergence: -365.5402
  ssim: 0.0517
  iou: 0.1512

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.49321, std: 0.16057

Metrics for layer 7:
  pearson_correlation: -0.0106
  kl_divergence: -88.6372
  ssim: 0.0526
  iou: 0.1496
Layer 7 metrics:
  pearson_correlation: -0.0106
  kl_divergence: -88.6372
  ssim: 0.0526
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.50054, std: 0.16015

Metrics for layer 8:
  pearson_correlation: -0.0246
  kl_divergence: -92.8783
  ssim: 0.0462
  iou: 0.1362
Layer 8 metrics:
  pearson_correlation: -0.0246
  kl_divergence: -92.8783
  ssim: 0.0462
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.49848, std: 0.17914

Metrics for layer 9:
  pearson_correlation: 0.0581
  kl_divergence: -95.9867
  ssim: 0.0904
  iou: 0.1429
Layer 9 metrics:
  pearson_correlation: 0.0581
  kl_divergence: -95.9867
  ssim: 0.0904
  iou: 0.1429

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.45651, std: 0.19324

Metrics for layer 10:
  pearson_correlation: -0.0980
  kl_divergence: -15.5392
  ssim: -0.0784
  iou: 0.1136
Layer 10 metrics:
  pearson_correlation: -0.0980
  kl_divergence: -15.5392
  ssim: -0.0784
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49026, std: 0.17836

Metrics for layer 11:
  pearson_correlation: 0.1148
  kl_divergence: -21.8417
  ssim: 0.0673
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: 0.1148
  kl_divergence: -21.8417
  ssim: 0.0673
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49181, std: 0.18662

Metrics for layer 12:
  pearson_correlation: 0.1675
  kl_divergence: -23.0859
  ssim: 0.0971
  iou: 0.1951
Layer 12 metrics:
  pearson_correlation: 0.1675
  kl_divergence: -23.0859
  ssim: 0.0971
  iou: 0.1951
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer4/batch_0_strength_0.8_results.npy

Processing batch 2/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.46461, std: 0.11385

Metrics for layer 0:
  pearson_correlation: -0.0049
  kl_divergence: -3957.2527
  ssim: 0.0332
  iou: 0.1421
Layer 0 metrics:
  pearson_correlation: -0.0049
  kl_divergence: -3957.2527
  ssim: 0.0332
  iou: 0.1421

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.44606, std: 0.12640

Metrics for layer 1:
  pearson_correlation: 0.0032
  kl_divergence: -3861.9771
  ssim: 0.0302
  iou: 0.1438
Layer 1 metrics:
  pearson_correlation: 0.0032
  kl_divergence: -3861.9771
  ssim: 0.0302
  iou: 0.1438

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.49501, std: 0.12081

Metrics for layer 2:
  pearson_correlation: -0.0153
  kl_divergence: -1443.8374
  ssim: 0.0469
  iou: 0.1460
Layer 2 metrics:
  pearson_correlation: -0.0153
  kl_divergence: -1443.8374
  ssim: 0.0469
  iou: 0.1460

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.47976, std: 0.11531

Metrics for layer 3:
  pearson_correlation: -0.0121
  kl_divergence: -1418.5731
  ssim: 0.0555
  iou: 0.1422
Layer 3 metrics:
  pearson_correlation: -0.0121
  kl_divergence: -1418.5731
  ssim: 0.0555
  iou: 0.1422

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48627, std: 0.13434

Metrics for layer 4:
  pearson_correlation: 0.0321
  kl_divergence: -400.3745
  ssim: 0.0746
  iou: 0.1438
Layer 4 metrics:
  pearson_correlation: 0.0321
  kl_divergence: -400.3745
  ssim: 0.0746
  iou: 0.1438

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47242, std: 0.12866

Metrics for layer 5:
  pearson_correlation: 0.0075
  kl_divergence: -385.3716
  ssim: 0.0582
  iou: 0.1521
Layer 5 metrics:
  pearson_correlation: 0.0075
  kl_divergence: -385.3716
  ssim: 0.0582
  iou: 0.1521

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47904, std: 0.14344

Metrics for layer 6:
  pearson_correlation: -0.0123
  kl_divergence: -386.4458
  ssim: 0.0430
  iou: 0.1338
Layer 6 metrics:
  pearson_correlation: -0.0123
  kl_divergence: -386.4458
  ssim: 0.0430
  iou: 0.1338

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.48704, std: 0.18023

Metrics for layer 7:
  pearson_correlation: -0.0066
  kl_divergence: -86.9932
  ssim: 0.0273
  iou: 0.1496
Layer 7 metrics:
  pearson_correlation: -0.0066
  kl_divergence: -86.9932
  ssim: 0.0273
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.44675, std: 0.15232

Metrics for layer 8:
  pearson_correlation: 0.0367
  kl_divergence: -82.8889
  ssim: 0.0452
  iou: 0.1563
Layer 8 metrics:
  pearson_correlation: 0.0367
  kl_divergence: -82.8889
  ssim: 0.0452
  iou: 0.1563

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.48171, std: 0.16139

Metrics for layer 9:
  pearson_correlation: -0.0768
  kl_divergence: -85.8409
  ssim: 0.0166
  iou: 0.1168
Layer 9 metrics:
  pearson_correlation: -0.0768
  kl_divergence: -85.8409
  ssim: 0.0166
  iou: 0.1168

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.51774, std: 0.18762

Metrics for layer 10:
  pearson_correlation: 0.0651
  kl_divergence: -21.2491
  ssim: 0.0378
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: 0.0651
  kl_divergence: -21.2491
  ssim: 0.0378
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.42575, std: 0.19678

Metrics for layer 11:
  pearson_correlation: -0.0442
  kl_divergence: -9.6071
  ssim: -0.0724
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: -0.0442
  kl_divergence: -9.6071
  ssim: -0.0724
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.42923, std: 0.17749

Metrics for layer 12:
  pearson_correlation: 0.0878
  kl_divergence: -11.7204
  ssim: 0.0663
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: 0.0878
  kl_divergence: -11.7204
  ssim: 0.0663
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer4/batch_1_strength_0.8_results.npy

Processing attention strength 1.2
Attention vector: [0.  0.  0.  0.  1.2 0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.39962, std: 0.11807

Metrics for layer 0:
  pearson_correlation: 0.0056
  kl_divergence: -4372.5264
  ssim: 0.0543
  iou: 0.1415
Layer 0 metrics:
  pearson_correlation: 0.0056
  kl_divergence: -4372.5264
  ssim: 0.0543
  iou: 0.1415

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.39550, std: 0.12282

Metrics for layer 1:
  pearson_correlation: -0.0046
  kl_divergence: -4309.6978
  ssim: 0.0504
  iou: 0.1428
Layer 1 metrics:
  pearson_correlation: -0.0046
  kl_divergence: -4309.6978
  ssim: 0.0504
  iou: 0.1428

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.46299, std: 0.12909

Metrics for layer 2:
  pearson_correlation: -0.0078
  kl_divergence: -1397.6841
  ssim: 0.0486
  iou: 0.1420
Layer 2 metrics:
  pearson_correlation: -0.0078
  kl_divergence: -1397.6841
  ssim: 0.0486
  iou: 0.1420

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.45263, std: 0.13803

Metrics for layer 3:
  pearson_correlation: -0.0078
  kl_divergence: -1370.2350
  ssim: 0.0492
  iou: 0.1410
Layer 3 metrics:
  pearson_correlation: -0.0078
  kl_divergence: -1370.2350
  ssim: 0.0492
  iou: 0.1410

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.48519, std: 0.14093

Metrics for layer 4:
  pearson_correlation: -0.0119
  kl_divergence: -380.0247
  ssim: 0.0576
  iou: 0.1462
Layer 4 metrics:
  pearson_correlation: -0.0119
  kl_divergence: -380.0247
  ssim: 0.0576
  iou: 0.1462

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.49184, std: 0.14982

Metrics for layer 5:
  pearson_correlation: 0.0105
  kl_divergence: -384.2063
  ssim: 0.0603
  iou: 0.1329
Layer 5 metrics:
  pearson_correlation: 0.0105
  kl_divergence: -384.2063
  ssim: 0.0603
  iou: 0.1329

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47080, std: 0.14365

Metrics for layer 6:
  pearson_correlation: -0.0020
  kl_divergence: -367.2855
  ssim: 0.0549
  iou: 0.1445
Layer 6 metrics:
  pearson_correlation: -0.0020
  kl_divergence: -367.2855
  ssim: 0.0549
  iou: 0.1445

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.47299, std: 0.15913

Metrics for layer 7:
  pearson_correlation: -0.0211
  kl_divergence: -88.7746
  ssim: 0.0349
  iou: 0.1264
Layer 7 metrics:
  pearson_correlation: -0.0211
  kl_divergence: -88.7746
  ssim: 0.0349
  iou: 0.1264

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.43737, std: 0.17868

Metrics for layer 8:
  pearson_correlation: 0.0047
  kl_divergence: -72.0789
  ssim: 0.0540
  iou: 0.1297
Layer 8 metrics:
  pearson_correlation: 0.0047
  kl_divergence: -72.0789
  ssim: 0.0540
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.48068, std: 0.18209

Metrics for layer 9:
  pearson_correlation: -0.0141
  kl_divergence: -85.7981
  ssim: 0.0281
  iou: 0.1462
Layer 9 metrics:
  pearson_correlation: -0.0141
  kl_divergence: -85.7981
  ssim: 0.0281
  iou: 0.1462

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.42990, std: 0.19875

Metrics for layer 10:
  pearson_correlation: 0.0157
  kl_divergence: -13.1177
  ssim: 0.0438
  iou: 0.1395
Layer 10 metrics:
  pearson_correlation: 0.0157
  kl_divergence: -13.1177
  ssim: 0.0438
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.58857, std: 0.17545

Metrics for layer 11:
  pearson_correlation: 0.0668
  kl_divergence: -24.3667
  ssim: 0.0572
  iou: 0.1667
Layer 11 metrics:
  pearson_correlation: 0.0668
  kl_divergence: -24.3667
  ssim: 0.0572
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.48879, std: 0.16404

Metrics for layer 12:
  pearson_correlation: 0.0630
  kl_divergence: -16.7574
  ssim: 0.0765
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: 0.0630
  kl_divergence: -16.7574
  ssim: 0.0765
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer4/batch_0_strength_1.2_results.npy

Processing batch 2/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.42135, std: 0.12482

Metrics for layer 0:
  pearson_correlation: -0.0099
  kl_divergence: -3737.8853
  ssim: 0.0324
  iou: 0.1416
Layer 0 metrics:
  pearson_correlation: -0.0099
  kl_divergence: -3737.8853
  ssim: 0.0324
  iou: 0.1416

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.45439, std: 0.12011

Metrics for layer 1:
  pearson_correlation: -0.0032
  kl_divergence: -3904.9729
  ssim: 0.0316
  iou: 0.1400
Layer 1 metrics:
  pearson_correlation: -0.0032
  kl_divergence: -3904.9729
  ssim: 0.0316
  iou: 0.1400

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.44516, std: 0.12392

Metrics for layer 2:
  pearson_correlation: -0.0048
  kl_divergence: -1342.5632
  ssim: 0.0534
  iou: 0.1344
Layer 2 metrics:
  pearson_correlation: -0.0048
  kl_divergence: -1342.5632
  ssim: 0.0534
  iou: 0.1344

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.45354, std: 0.12163

Metrics for layer 3:
  pearson_correlation: 0.0015
  kl_divergence: -1363.0581
  ssim: 0.0578
  iou: 0.1360
Layer 3 metrics:
  pearson_correlation: 0.0015
  kl_divergence: -1363.0581
  ssim: 0.0578
  iou: 0.1360

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.56618, std: 0.13716

Metrics for layer 4:
  pearson_correlation: 0.0089
  kl_divergence: -454.9008
  ssim: 0.0517
  iou: 0.1445
Layer 4 metrics:
  pearson_correlation: 0.0089
  kl_divergence: -454.9008
  ssim: 0.0517
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.51141, std: 0.13894

Metrics for layer 5:
  pearson_correlation: -0.0064
  kl_divergence: -414.7867
  ssim: 0.0529
  iou: 0.1313
Layer 5 metrics:
  pearson_correlation: -0.0064
  kl_divergence: -414.7867
  ssim: 0.0529
  iou: 0.1313

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.50500, std: 0.13620

Metrics for layer 6:
  pearson_correlation: 0.0046
  kl_divergence: -411.2784
  ssim: 0.0521
  iou: 0.1387
Layer 6 metrics:
  pearson_correlation: 0.0046
  kl_divergence: -411.2784
  ssim: 0.0521
  iou: 0.1387

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.51871, std: 0.15610

Metrics for layer 7:
  pearson_correlation: 0.0228
  kl_divergence: -91.9633
  ssim: 0.0293
  iou: 0.1632
Layer 7 metrics:
  pearson_correlation: 0.0228
  kl_divergence: -91.9633
  ssim: 0.0293
  iou: 0.1632

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.51322, std: 0.16248

Metrics for layer 8:
  pearson_correlation: 0.0064
  kl_divergence: -90.1109
  ssim: 0.0325
  iou: 0.1496
Layer 8 metrics:
  pearson_correlation: 0.0064
  kl_divergence: -90.1109
  ssim: 0.0325
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.39954, std: 0.15527

Metrics for layer 9:
  pearson_correlation: -0.0308
  kl_divergence: -72.2306
  ssim: 0.0282
  iou: 0.1496
Layer 9 metrics:
  pearson_correlation: -0.0308
  kl_divergence: -72.2306
  ssim: 0.0282
  iou: 0.1496

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.43359, std: 0.14563

Metrics for layer 10:
  pearson_correlation: 0.0940
  kl_divergence: -17.0270
  ssim: 0.0806
  iou: 0.1807
Layer 10 metrics:
  pearson_correlation: 0.0940
  kl_divergence: -17.0270
  ssim: 0.0806
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.48373, std: 0.18381

Metrics for layer 11:
  pearson_correlation: -0.0450
  kl_divergence: -7.3020
  ssim: 0.0633
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: -0.0450
  kl_divergence: -7.3020
  ssim: 0.0633
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.50371, std: 0.18367

Metrics for layer 12:
  pearson_correlation: 0.0563
  kl_divergence: -17.0462
  ssim: 0.0817
  iou: 0.1807
Layer 12 metrics:
  pearson_correlation: 0.0563
  kl_divergence: -17.0462
  ssim: 0.0817
  iou: 0.1807
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer4/batch_1_strength_1.2_results.npy

Analysis complete! Results saved to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer4
Completed experiment for category 5, layer 4
----------------------------------------
Running experiment for category 5, layer 5
===================================================
Starting experiment:
Category: 5
Layer: 5
Logs will be saved to: /scratch/hy2611/CNN_attention/logs/attention_analysis_20241216_104146/category5/layer5
===================================================
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-12-16 10:55:29.506978: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-16 10:55:29.525500: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2024-12-16 10:55:29.525928: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4760640 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-16 10:55:29.525942: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-16 10:55:29.528576: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-16 10:55:29.667252: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x473f370 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-16 10:55:29.667270: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-12-16 10:55:29.667797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:2f:00.0
2024-12-16 10:55:29.669020: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:55:29.670157: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:55:29.671238: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:55:29.672315: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:55:29.673392: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:55:29.674455: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:55:29.675524: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:55:29.675536: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-12-16 10:55:29.675555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-16 10:55:29.675560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-16 10:55:29.675563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:61: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:87: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:15: sigmoid_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.sigmoid_cross_entropy instead. Note that the order of the predictions and labels arguments has been changed.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:322: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:82: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.


Verifying paths:
tc_path: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs exists
weight_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists
image_path: /scratch/hy2611/CNN_attention/Data/VGG16/images exists
save_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists

Initializing model...
('c11', [1, 224, 224, 64])
('c12', [1, 224, 224, 64])
('c21', [1, 112, 112, 128])
('c22', [1, 112, 112, 128])
('c31', [1, 56, 56, 256])
('c32', [1, 56, 56, 256])
('c33', [1, 56, 56, 256])
('c41', [1, 28, 28, 512])
('c42', [1, 28, 28, 512])
('c43', [1, 28, 28, 512])
('c51', [1, 14, 14, 512])
('c52', [1, 14, 14, 512])
('c53', [1, 14, 14, 512])
(0, 'conv1_1_W', (3, 3, 3, 64))
(1, 'conv1_1_b', (64,))
(2, 'conv1_2_W', (3, 3, 64, 64))
(3, 'conv1_2_b', (64,))
(4, 'conv2_1_W', (3, 3, 64, 128))
(5, 'conv2_1_b', (128,))
(6, 'conv2_2_W', (3, 3, 128, 128))
(7, 'conv2_2_b', (128,))
(8, 'conv3_1_W', (3, 3, 128, 256))
(9, 'conv3_1_b', (256,))
(10, 'conv3_2_W', (3, 3, 256, 256))
(11, 'conv3_2_b', (256,))
(12, 'conv3_3_W', (3, 3, 256, 256))
(13, 'conv3_3_b', (256,))
(14, 'conv4_1_W', (3, 3, 256, 512))
(15, 'conv4_1_b', (512,))
(16, 'conv4_2_W', (3, 3, 512, 512))
(17, 'conv4_2_b', (512,))
(18, 'conv4_3_W', (3, 3, 512, 512))
(19, 'conv4_3_b', (512,))
(20, 'conv5_1_W', (3, 3, 512, 512))
(21, 'conv5_1_b', (512,))
(22, 'conv5_2_W', (3, 3, 512, 512))
(23, 'conv5_2_b', (512,))
(24, 'conv5_3_W', (3, 3, 512, 512))
(25, 'conv5_3_b', (512,))
(26, 'fc6_W', (25088, 4096))
(27, 'fc6_b', (4096,))
(28, 'fc7_W', (4096, 4096))
(29, 'fc7_b', (4096,))
Checking checkpoint files:
Data file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.data-00000-of-00001 - Found
Index file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.index - Found
Loading checkpoint from: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt
Checkpoint loaded successfully

Initializing components...
Found tuning curves file: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs/featvecs20_train35_c.txt

Loading category 5 data...
Original positive images shape: (2, 224, 224, 3)

Processing data...

Processing attention strength 0.0
Attention vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

Processing batch 1/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.44677, std: 0.11590

Metrics for layer 0:
  pearson_correlation: -0.0008
  kl_divergence: -4742.2983
  ssim: 0.0493
  iou: 0.1404
Layer 0 metrics:
  pearson_correlation: -0.0008
  kl_divergence: -4742.2983
  ssim: 0.0493
  iou: 0.1404

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.41055, std: 0.11600

Metrics for layer 1:
  pearson_correlation: -0.0010
  kl_divergence: -4461.0039
  ssim: 0.0522
  iou: 0.1417
Layer 1 metrics:
  pearson_correlation: -0.0010
  kl_divergence: -4461.0039
  ssim: 0.0522
  iou: 0.1417

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.46228, std: 0.13732

Metrics for layer 2:
  pearson_correlation: -0.0071
  kl_divergence: -1396.1920
  ssim: 0.0473
  iou: 0.1402
Layer 2 metrics:
  pearson_correlation: -0.0071
  kl_divergence: -1396.1920
  ssim: 0.0473
  iou: 0.1402

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.43295, std: 0.12136

Metrics for layer 3:
  pearson_correlation: 0.0153
  kl_divergence: -1341.4487
  ssim: 0.0657
  iou: 0.1527
Layer 3 metrics:
  pearson_correlation: 0.0153
  kl_divergence: -1341.4487
  ssim: 0.0657
  iou: 0.1527

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46976, std: 0.15202

Metrics for layer 4:
  pearson_correlation: -0.0172
  kl_divergence: -361.1274
  ssim: 0.0483
  iou: 0.1272
Layer 4 metrics:
  pearson_correlation: -0.0172
  kl_divergence: -361.1274
  ssim: 0.0483
  iou: 0.1272

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.43656, std: 0.11898

Metrics for layer 5:
  pearson_correlation: 0.0089
  kl_divergence: -348.1084
  ssim: 0.0745
  iou: 0.1454
Layer 5 metrics:
  pearson_correlation: 0.0089
  kl_divergence: -348.1084
  ssim: 0.0745
  iou: 0.1454

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47254, std: 0.14557

Metrics for layer 6:
  pearson_correlation: 0.0045
  kl_divergence: -369.7009
  ssim: 0.0547
  iou: 0.1479
Layer 6 metrics:
  pearson_correlation: 0.0045
  kl_divergence: -369.7009
  ssim: 0.0547
  iou: 0.1479

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.49216, std: 0.15975

Metrics for layer 7:
  pearson_correlation: 0.0105
  kl_divergence: -93.6532
  ssim: 0.0355
  iou: 0.1529
Layer 7 metrics:
  pearson_correlation: 0.0105
  kl_divergence: -93.6532
  ssim: 0.0355
  iou: 0.1529

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.53550, std: 0.17034

Metrics for layer 8:
  pearson_correlation: -0.0058
  kl_divergence: -99.0124
  ssim: 0.0456
  iou: 0.1429
Layer 8 metrics:
  pearson_correlation: -0.0058
  kl_divergence: -99.0124
  ssim: 0.0456
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.52177, std: 0.13837

Metrics for layer 9:
  pearson_correlation: -0.0245
  kl_divergence: -100.2491
  ssim: 0.0532
  iou: 0.1264
Layer 9 metrics:
  pearson_correlation: -0.0245
  kl_divergence: -100.2491
  ssim: 0.0532
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49936, std: 0.21229

Metrics for layer 10:
  pearson_correlation: 0.1081
  kl_divergence: -21.3674
  ssim: 0.1373
  iou: 0.1807
Layer 10 metrics:
  pearson_correlation: 0.1081
  kl_divergence: -21.3674
  ssim: 0.1373
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.39887, std: 0.19545

Metrics for layer 11:
  pearson_correlation: 0.0675
  kl_divergence: -11.2937
  ssim: 0.1194
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: 0.0675
  kl_divergence: -11.2937
  ssim: 0.1194
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.44699, std: 0.20006

Metrics for layer 12:
  pearson_correlation: -0.0548
  kl_divergence: -12.1852
  ssim: 0.0109
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: -0.0548
  kl_divergence: -12.1852
  ssim: 0.0109
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer5/batch_0_strength_0.0_results.npy

Processing batch 2/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.42785, std: 0.11911

Metrics for layer 0:
  pearson_correlation: -0.0053
  kl_divergence: -3781.1548
  ssim: 0.0334
  iou: 0.1435
Layer 0 metrics:
  pearson_correlation: -0.0053
  kl_divergence: -3781.1548
  ssim: 0.0334
  iou: 0.1435

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.41654, std: 0.11956

Metrics for layer 1:
  pearson_correlation: 0.0049
  kl_divergence: -3732.1746
  ssim: 0.0359
  iou: 0.1433
Layer 1 metrics:
  pearson_correlation: 0.0049
  kl_divergence: -3732.1746
  ssim: 0.0359
  iou: 0.1433

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.47322, std: 0.13765

Metrics for layer 2:
  pearson_correlation: 0.0154
  kl_divergence: -1395.2607
  ssim: 0.0462
  iou: 0.1493
Layer 2 metrics:
  pearson_correlation: 0.0154
  kl_divergence: -1395.2607
  ssim: 0.0462
  iou: 0.1493

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.50185, std: 0.12565

Metrics for layer 3:
  pearson_correlation: -0.0051
  kl_divergence: -1455.9507
  ssim: 0.0472
  iou: 0.1393
Layer 3 metrics:
  pearson_correlation: -0.0051
  kl_divergence: -1455.9507
  ssim: 0.0472
  iou: 0.1393

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47966, std: 0.13580

Metrics for layer 4:
  pearson_correlation: -0.0020
  kl_divergence: -390.1733
  ssim: 0.0587
  iou: 0.1329
Layer 4 metrics:
  pearson_correlation: -0.0020
  kl_divergence: -390.1733
  ssim: 0.0587
  iou: 0.1329

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.40291, std: 0.11882

Metrics for layer 5:
  pearson_correlation: -0.0171
  kl_divergence: -322.4617
  ssim: 0.0770
  iou: 0.1445
Layer 5 metrics:
  pearson_correlation: -0.0171
  kl_divergence: -322.4617
  ssim: 0.0770
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.42621, std: 0.13879

Metrics for layer 6:
  pearson_correlation: 0.0127
  kl_divergence: -341.8212
  ssim: 0.0682
  iou: 0.1454
Layer 6 metrics:
  pearson_correlation: 0.0127
  kl_divergence: -341.8212
  ssim: 0.0682
  iou: 0.1454

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.49024, std: 0.16242

Metrics for layer 7:
  pearson_correlation: 0.0656
  kl_divergence: -88.8848
  ssim: 0.0599
  iou: 0.1632
Layer 7 metrics:
  pearson_correlation: 0.0656
  kl_divergence: -88.8848
  ssim: 0.0599
  iou: 0.1632

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.47273, std: 0.15863

Metrics for layer 8:
  pearson_correlation: -0.0541
  kl_divergence: -84.9519
  ssim: 0.0160
  iou: 0.1395
Layer 8 metrics:
  pearson_correlation: -0.0541
  kl_divergence: -84.9519
  ssim: 0.0160
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.50254, std: 0.16999

Metrics for layer 9:
  pearson_correlation: -0.0384
  kl_divergence: -87.9175
  ssim: 0.0291
  iou: 0.1136
Layer 9 metrics:
  pearson_correlation: -0.0384
  kl_divergence: -87.9175
  ssim: 0.0291
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.50746, std: 0.20242

Metrics for layer 10:
  pearson_correlation: 0.0329
  kl_divergence: -18.3343
  ssim: 0.0525
  iou: 0.1667
Layer 10 metrics:
  pearson_correlation: 0.0329
  kl_divergence: -18.3343
  ssim: 0.0525
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.48654, std: 0.19814

Metrics for layer 11:
  pearson_correlation: 0.0302
  kl_divergence: -17.0314
  ssim: 0.0205
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: 0.0302
  kl_divergence: -17.0314
  ssim: 0.0205
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.49635, std: 0.18887

Metrics for layer 12:
  pearson_correlation: 0.0185
  kl_divergence: -18.7955
  ssim: 0.0515
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: 0.0185
  kl_divergence: -18.7955
  ssim: 0.0515
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer5/batch_1_strength_0.0_results.npy

Processing attention strength 0.4
Attention vector: [0.  0.  0.  0.  0.  0.4 0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42130, std: 0.11413

Metrics for layer 0:
  pearson_correlation: -0.0013
  kl_divergence: -4549.9453
  ssim: 0.0539
  iou: 0.1407
Layer 0 metrics:
  pearson_correlation: -0.0013
  kl_divergence: -4549.9453
  ssim: 0.0539
  iou: 0.1407

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42869, std: 0.12432

Metrics for layer 1:
  pearson_correlation: 0.0113
  kl_divergence: -4595.8750
  ssim: 0.0477
  iou: 0.1464
Layer 1 metrics:
  pearson_correlation: 0.0113
  kl_divergence: -4595.8750
  ssim: 0.0477
  iou: 0.1464

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.50298, std: 0.12654

Metrics for layer 2:
  pearson_correlation: -0.0008
  kl_divergence: -1497.5037
  ssim: 0.0529
  iou: 0.1348
Layer 2 metrics:
  pearson_correlation: -0.0008
  kl_divergence: -1497.5037
  ssim: 0.0529
  iou: 0.1348

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.42471, std: 0.12765

Metrics for layer 3:
  pearson_correlation: 0.0025
  kl_divergence: -1310.5940
  ssim: 0.0595
  iou: 0.1393
Layer 3 metrics:
  pearson_correlation: 0.0025
  kl_divergence: -1310.5940
  ssim: 0.0595
  iou: 0.1393

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50556, std: 0.15351

Metrics for layer 4:
  pearson_correlation: 0.0150
  kl_divergence: -389.7126
  ssim: 0.0595
  iou: 0.1412
Layer 4 metrics:
  pearson_correlation: 0.0150
  kl_divergence: -389.7126
  ssim: 0.0595
  iou: 0.1412

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50395, std: 0.14397

Metrics for layer 5:
  pearson_correlation: -0.0128
  kl_divergence: -385.0551
  ssim: 0.0495
  iou: 0.1371
Layer 5 metrics:
  pearson_correlation: -0.0128
  kl_divergence: -385.0551
  ssim: 0.0495
  iou: 0.1371

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.41518, std: 0.13660

Metrics for layer 6:
  pearson_correlation: 0.0225
  kl_divergence: -321.3140
  ssim: 0.0763
  iou: 0.1454
Layer 6 metrics:
  pearson_correlation: 0.0225
  kl_divergence: -321.3140
  ssim: 0.0763
  iou: 0.1454

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.43315, std: 0.15745

Metrics for layer 7:
  pearson_correlation: -0.0703
  kl_divergence: -74.8674
  ssim: 0.0335
  iou: 0.1168
Layer 7 metrics:
  pearson_correlation: -0.0703
  kl_divergence: -74.8674
  ssim: 0.0335
  iou: 0.1168

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.46130, std: 0.14264

Metrics for layer 8:
  pearson_correlation: -0.0204
  kl_divergence: -87.4203
  ssim: 0.0574
  iou: 0.1429
Layer 8 metrics:
  pearson_correlation: -0.0204
  kl_divergence: -87.4203
  ssim: 0.0574
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.49783, std: 0.15565

Metrics for layer 9:
  pearson_correlation: 0.0371
  kl_divergence: -95.5463
  ssim: 0.0859
  iou: 0.1529
Layer 9 metrics:
  pearson_correlation: 0.0371
  kl_divergence: -95.5463
  ssim: 0.0859
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.51206, std: 0.16310

Metrics for layer 10:
  pearson_correlation: -0.1163
  kl_divergence: -16.7884
  ssim: 0.0509
  iou: 0.0538
Layer 10 metrics:
  pearson_correlation: -0.1163
  kl_divergence: -16.7884
  ssim: 0.0509
  iou: 0.0538

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.46674, std: 0.16767

Metrics for layer 11:
  pearson_correlation: -0.0620
  kl_divergence: -15.9183
  ssim: 0.0303
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: -0.0620
  kl_divergence: -15.9183
  ssim: 0.0303
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.38607, std: 0.17614

Metrics for layer 12:
  pearson_correlation: 0.0202
  kl_divergence: -12.3962
  ssim: 0.0378
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: 0.0202
  kl_divergence: -12.3962
  ssim: 0.0378
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer5/batch_0_strength_0.4_results.npy

Processing batch 2/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.42996, std: 0.11999

Metrics for layer 0:
  pearson_correlation: -0.0022
  kl_divergence: -3792.6594
  ssim: 0.0342
  iou: 0.1430
Layer 0 metrics:
  pearson_correlation: -0.0022
  kl_divergence: -3792.6594
  ssim: 0.0342
  iou: 0.1430

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.45891, std: 0.11889

Metrics for layer 1:
  pearson_correlation: 0.0026
  kl_divergence: -3928.3438
  ssim: 0.0318
  iou: 0.1448
Layer 1 metrics:
  pearson_correlation: 0.0026
  kl_divergence: -3928.3438
  ssim: 0.0318
  iou: 0.1448

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.44816, std: 0.12865

Metrics for layer 2:
  pearson_correlation: 0.0064
  kl_divergence: -1349.5149
  ssim: 0.0536
  iou: 0.1377
Layer 2 metrics:
  pearson_correlation: 0.0064
  kl_divergence: -1349.5149
  ssim: 0.0536
  iou: 0.1377

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.43858, std: 0.13472

Metrics for layer 3:
  pearson_correlation: 0.0088
  kl_divergence: -1321.2260
  ssim: 0.0499
  iou: 0.1477
Layer 3 metrics:
  pearson_correlation: 0.0088
  kl_divergence: -1321.2260
  ssim: 0.0499
  iou: 0.1477

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.46817, std: 0.14627

Metrics for layer 4:
  pearson_correlation: -0.0141
  kl_divergence: -376.1637
  ssim: 0.0478
  iou: 0.1429
Layer 4 metrics:
  pearson_correlation: -0.0141
  kl_divergence: -376.1637
  ssim: 0.0478
  iou: 0.1429

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48902, std: 0.14757

Metrics for layer 5:
  pearson_correlation: -0.0003
  kl_divergence: -391.3648
  ssim: 0.0565
  iou: 0.1289
Layer 5 metrics:
  pearson_correlation: -0.0003
  kl_divergence: -391.3648
  ssim: 0.0565
  iou: 0.1289

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.45941, std: 0.12751

Metrics for layer 6:
  pearson_correlation: 0.0007
  kl_divergence: -375.8466
  ssim: 0.0631
  iou: 0.1329
Layer 6 metrics:
  pearson_correlation: 0.0007
  kl_divergence: -375.8466
  ssim: 0.0631
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.52649, std: 0.15230

Metrics for layer 7:
  pearson_correlation: 0.0044
  kl_divergence: -90.1404
  ssim: 0.0397
  iou: 0.1395
Layer 7 metrics:
  pearson_correlation: 0.0044
  kl_divergence: -90.1404
  ssim: 0.0397
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.49230, std: 0.15711

Metrics for layer 8:
  pearson_correlation: -0.0445
  kl_divergence: -86.8618
  ssim: 0.0194
  iou: 0.1168
Layer 8 metrics:
  pearson_correlation: -0.0445
  kl_divergence: -86.8618
  ssim: 0.0194
  iou: 0.1168

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.48228, std: 0.16294

Metrics for layer 9:
  pearson_correlation: -0.0249
  kl_divergence: -85.6956
  ssim: 0.0189
  iou: 0.1362
Layer 9 metrics:
  pearson_correlation: -0.0249
  kl_divergence: -85.6956
  ssim: 0.0189
  iou: 0.1362

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.47899, std: 0.17623

Metrics for layer 10:
  pearson_correlation: 0.0561
  kl_divergence: -18.6909
  ssim: 0.0647
  iou: 0.1395
Layer 10 metrics:
  pearson_correlation: 0.0561
  kl_divergence: -18.6909
  ssim: 0.0647
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.46088, std: 0.20175

Metrics for layer 11:
  pearson_correlation: 0.0926
  kl_divergence: -13.7304
  ssim: 0.0967
  iou: 0.2099
Layer 11 metrics:
  pearson_correlation: 0.0926
  kl_divergence: -13.7304
  ssim: 0.0967
  iou: 0.2099

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.51202, std: 0.15451

Metrics for layer 12:
  pearson_correlation: 0.0129
  kl_divergence: -19.9880
  ssim: 0.0601
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: 0.0129
  kl_divergence: -19.9880
  ssim: 0.0601
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer5/batch_1_strength_0.4_results.npy

Processing attention strength 0.8
Attention vector: [0.  0.  0.  0.  0.  0.8 0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.41454, std: 0.12371

Metrics for layer 0:
  pearson_correlation: -0.0032
  kl_divergence: -4468.3379
  ssim: 0.0464
  iou: 0.1412
Layer 0 metrics:
  pearson_correlation: -0.0032
  kl_divergence: -4468.3379
  ssim: 0.0464
  iou: 0.1412

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.41774, std: 0.12065

Metrics for layer 1:
  pearson_correlation: -0.0053
  kl_divergence: -4502.5537
  ssim: 0.0480
  iou: 0.1409
Layer 1 metrics:
  pearson_correlation: -0.0053
  kl_divergence: -4502.5537
  ssim: 0.0480
  iou: 0.1409

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.47349, std: 0.13406

Metrics for layer 2:
  pearson_correlation: 0.0096
  kl_divergence: -1428.9546
  ssim: 0.0535
  iou: 0.1418
Layer 2 metrics:
  pearson_correlation: 0.0096
  kl_divergence: -1428.9546
  ssim: 0.0535
  iou: 0.1418

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.46262, std: 0.13080

Metrics for layer 3:
  pearson_correlation: 0.0008
  kl_divergence: -1404.0614
  ssim: 0.0526
  iou: 0.1391
Layer 3 metrics:
  pearson_correlation: 0.0008
  kl_divergence: -1404.0614
  ssim: 0.0526
  iou: 0.1391

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50285, std: 0.14205

Metrics for layer 4:
  pearson_correlation: 0.0431
  kl_divergence: -393.7747
  ssim: 0.0704
  iou: 0.1445
Layer 4 metrics:
  pearson_correlation: 0.0431
  kl_divergence: -393.7747
  ssim: 0.0704
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47145, std: 0.13974

Metrics for layer 5:
  pearson_correlation: -0.0150
  kl_divergence: -366.4300
  ssim: 0.0540
  iou: 0.1487
Layer 5 metrics:
  pearson_correlation: -0.0150
  kl_divergence: -366.4300
  ssim: 0.0540
  iou: 0.1487

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.43273, std: 0.13072

Metrics for layer 6:
  pearson_correlation: -0.0042
  kl_divergence: -336.1577
  ssim: 0.0636
  iou: 0.1354
Layer 6 metrics:
  pearson_correlation: -0.0042
  kl_divergence: -336.1577
  ssim: 0.0636
  iou: 0.1354

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.57265, std: 0.14652

Metrics for layer 7:
  pearson_correlation: 0.0036
  kl_divergence: -103.7957
  ssim: 0.0365
  iou: 0.1462
Layer 7 metrics:
  pearson_correlation: 0.0036
  kl_divergence: -103.7957
  ssim: 0.0365
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.45030, std: 0.16264

Metrics for layer 8:
  pearson_correlation: -0.0805
  kl_divergence: -74.6135
  ssim: 0.0089
  iou: 0.1329
Layer 8 metrics:
  pearson_correlation: -0.0805
  kl_divergence: -74.6135
  ssim: 0.0089
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.42820, std: 0.14145

Metrics for layer 9:
  pearson_correlation: -0.0447
  kl_divergence: -62.3946
  ssim: 0.0251
  iou: 0.1232
Layer 9 metrics:
  pearson_correlation: -0.0447
  kl_divergence: -62.3946
  ssim: 0.0251
  iou: 0.1232

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.53594, std: 0.20948

Metrics for layer 10:
  pearson_correlation: -0.0216
  kl_divergence: -22.7066
  ssim: 0.0556
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: -0.0216
  kl_divergence: -22.7066
  ssim: 0.0556
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.56179, std: 0.20946

Metrics for layer 11:
  pearson_correlation: -0.0201
  kl_divergence: -22.1259
  ssim: -0.0384
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: -0.0201
  kl_divergence: -22.1259
  ssim: -0.0384
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.50880, std: 0.17080

Metrics for layer 12:
  pearson_correlation: 0.0027
  kl_divergence: -19.9698
  ssim: 0.0749
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: 0.0027
  kl_divergence: -19.9698
  ssim: 0.0749
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer5/batch_0_strength_0.8_results.npy

Processing batch 2/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.42009, std: 0.12071

Metrics for layer 0:
  pearson_correlation: 0.0015
  kl_divergence: -3747.3394
  ssim: 0.0349
  iou: 0.1430
Layer 0 metrics:
  pearson_correlation: 0.0015
  kl_divergence: -3747.3394
  ssim: 0.0349
  iou: 0.1430

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43730, std: 0.12185

Metrics for layer 1:
  pearson_correlation: -0.0043
  kl_divergence: -3820.8267
  ssim: 0.0319
  iou: 0.1429
Layer 1 metrics:
  pearson_correlation: -0.0043
  kl_divergence: -3820.8267
  ssim: 0.0319
  iou: 0.1429

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.50476, std: 0.12319

Metrics for layer 2:
  pearson_correlation: 0.0028
  kl_divergence: -1467.2146
  ssim: 0.0498
  iou: 0.1472
Layer 2 metrics:
  pearson_correlation: 0.0028
  kl_divergence: -1467.2146
  ssim: 0.0498
  iou: 0.1472

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.42031, std: 0.13381

Metrics for layer 3:
  pearson_correlation: -0.0037
  kl_divergence: -1274.6154
  ssim: 0.0516
  iou: 0.1416
Layer 3 metrics:
  pearson_correlation: -0.0037
  kl_divergence: -1274.6154
  ssim: 0.0516
  iou: 0.1416

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.43792, std: 0.13738

Metrics for layer 4:
  pearson_correlation: -0.0232
  kl_divergence: -349.4058
  ssim: 0.0513
  iou: 0.1256
Layer 4 metrics:
  pearson_correlation: -0.0232
  kl_divergence: -349.4058
  ssim: 0.0513
  iou: 0.1256

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48839, std: 0.14901

Metrics for layer 5:
  pearson_correlation: -0.0176
  kl_divergence: -390.6583
  ssim: 0.0504
  iou: 0.1438
Layer 5 metrics:
  pearson_correlation: -0.0176
  kl_divergence: -390.6583
  ssim: 0.0504
  iou: 0.1438

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.49817, std: 0.13739

Metrics for layer 6:
  pearson_correlation: 0.0277
  kl_divergence: -408.3695
  ssim: 0.0628
  iou: 0.1420
Layer 6 metrics:
  pearson_correlation: 0.0277
  kl_divergence: -408.3695
  ssim: 0.0628
  iou: 0.1420

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.55463, std: 0.17114

Metrics for layer 7:
  pearson_correlation: -0.0258
  kl_divergence: -95.3734
  ssim: 0.0183
  iou: 0.1073
Layer 7 metrics:
  pearson_correlation: -0.0258
  kl_divergence: -95.3734
  ssim: 0.0183
  iou: 0.1073

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.43888, std: 0.15932

Metrics for layer 8:
  pearson_correlation: 0.0008
  kl_divergence: -79.2036
  ssim: 0.0314
  iou: 0.1529
Layer 8 metrics:
  pearson_correlation: 0.0008
  kl_divergence: -79.2036
  ssim: 0.0314
  iou: 0.1529

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.47786, std: 0.17991

Metrics for layer 9:
  pearson_correlation: -0.0392
  kl_divergence: -83.2801
  ssim: 0.0236
  iou: 0.1136
Layer 9 metrics:
  pearson_correlation: -0.0392
  kl_divergence: -83.2801
  ssim: 0.0236
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.45546, std: 0.16690

Metrics for layer 10:
  pearson_correlation: -0.0124
  kl_divergence: -15.9187
  ssim: -0.0305
  iou: 0.1264
Layer 10 metrics:
  pearson_correlation: -0.0124
  kl_divergence: -15.9187
  ssim: -0.0305
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.57080, std: 0.18141

Metrics for layer 11:
  pearson_correlation: 0.0320
  kl_divergence: -22.0083
  ssim: 0.0614
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: 0.0320
  kl_divergence: -22.0083
  ssim: 0.0614
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.46271, std: 0.17364

Metrics for layer 12:
  pearson_correlation: 0.0014
  kl_divergence: -13.9302
  ssim: 0.0394
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: 0.0014
  kl_divergence: -13.9302
  ssim: 0.0394
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer5/batch_1_strength_0.8_results.npy

Processing attention strength 1.2
Attention vector: [0.  0.  0.  0.  0.  1.2 0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.43277, std: 0.11845

Metrics for layer 0:
  pearson_correlation: 0.0036
  kl_divergence: -4635.8564
  ssim: 0.0514
  iou: 0.1450
Layer 0 metrics:
  pearson_correlation: 0.0036
  kl_divergence: -4635.8564
  ssim: 0.0514
  iou: 0.1450

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.45116, std: 0.12747

Metrics for layer 1:
  pearson_correlation: 0.0033
  kl_divergence: -4753.6826
  ssim: 0.0442
  iou: 0.1438
Layer 1 metrics:
  pearson_correlation: 0.0033
  kl_divergence: -4753.6826
  ssim: 0.0442
  iou: 0.1438

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.42822, std: 0.12717

Metrics for layer 2:
  pearson_correlation: 0.0140
  kl_divergence: -1322.1399
  ssim: 0.0615
  iou: 0.1527
Layer 2 metrics:
  pearson_correlation: 0.0140
  kl_divergence: -1322.1399
  ssim: 0.0615
  iou: 0.1527

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.48941, std: 0.13732

Metrics for layer 3:
  pearson_correlation: 0.0123
  kl_divergence: -1461.3943
  ssim: 0.0517
  iou: 0.1496
Layer 3 metrics:
  pearson_correlation: 0.0123
  kl_divergence: -1461.3943
  ssim: 0.0517
  iou: 0.1496

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.48290, std: 0.14530

Metrics for layer 4:
  pearson_correlation: -0.0002
  kl_divergence: -375.1947
  ssim: 0.0562
  iou: 0.1462
Layer 4 metrics:
  pearson_correlation: -0.0002
  kl_divergence: -375.1947
  ssim: 0.0562
  iou: 0.1462

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.48655, std: 0.14164

Metrics for layer 5:
  pearson_correlation: -0.0219
  kl_divergence: -380.0032
  ssim: 0.0399
  iou: 0.1297
Layer 5 metrics:
  pearson_correlation: -0.0219
  kl_divergence: -380.0032
  ssim: 0.0399
  iou: 0.1297

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.42100, std: 0.12332

Metrics for layer 6:
  pearson_correlation: -0.0191
  kl_divergence: -329.7319
  ssim: 0.0651
  iou: 0.1462
Layer 6 metrics:
  pearson_correlation: -0.0191
  kl_divergence: -329.7319
  ssim: 0.0651
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.45380, std: 0.15688

Metrics for layer 7:
  pearson_correlation: 0.0230
  kl_divergence: -83.0233
  ssim: 0.0611
  iou: 0.1496
Layer 7 metrics:
  pearson_correlation: 0.0230
  kl_divergence: -83.0233
  ssim: 0.0611
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.47686, std: 0.15471

Metrics for layer 8:
  pearson_correlation: -0.0069
  kl_divergence: -88.2663
  ssim: 0.0571
  iou: 0.1200
Layer 8 metrics:
  pearson_correlation: -0.0069
  kl_divergence: -88.2663
  ssim: 0.0571
  iou: 0.1200

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.54756, std: 0.13969

Metrics for layer 9:
  pearson_correlation: 0.0111
  kl_divergence: -103.9234
  ssim: 0.0477
  iou: 0.1632
Layer 9 metrics:
  pearson_correlation: 0.0111
  kl_divergence: -103.9234
  ssim: 0.0477
  iou: 0.1632

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.51683, std: 0.18863

Metrics for layer 10:
  pearson_correlation: -0.1900
  kl_divergence: -1.4193
  ssim: -0.1001
  iou: 0.1395
Layer 10 metrics:
  pearson_correlation: -0.1900
  kl_divergence: -1.4193
  ssim: -0.1001
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.42602, std: 0.21427

Metrics for layer 11:
  pearson_correlation: 0.0102
  kl_divergence: -10.9663
  ssim: 0.0052
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: 0.0102
  kl_divergence: -10.9663
  ssim: 0.0052
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.45749, std: 0.18391

Metrics for layer 12:
  pearson_correlation: 0.0646
  kl_divergence: -19.8647
  ssim: 0.0691
  iou: 0.1264
Layer 12 metrics:
  pearson_correlation: 0.0646
  kl_divergence: -19.8647
  ssim: 0.0691
  iou: 0.1264
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer5/batch_0_strength_1.2_results.npy

Processing batch 2/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.40749, std: 0.12100

Metrics for layer 0:
  pearson_correlation: 0.0039
  kl_divergence: -3684.8206
  ssim: 0.0355
  iou: 0.1417
Layer 0 metrics:
  pearson_correlation: 0.0039
  kl_divergence: -3684.8206
  ssim: 0.0355
  iou: 0.1417

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.45425, std: 0.12195

Metrics for layer 1:
  pearson_correlation: -0.0021
  kl_divergence: -3903.1145
  ssim: 0.0306
  iou: 0.1419
Layer 1 metrics:
  pearson_correlation: -0.0021
  kl_divergence: -3903.1145
  ssim: 0.0306
  iou: 0.1419

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.49656, std: 0.12766

Metrics for layer 2:
  pearson_correlation: 0.0020
  kl_divergence: -1449.0227
  ssim: 0.0475
  iou: 0.1381
Layer 2 metrics:
  pearson_correlation: 0.0020
  kl_divergence: -1449.0227
  ssim: 0.0475
  iou: 0.1381

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.47680, std: 0.13404

Metrics for layer 3:
  pearson_correlation: -0.0068
  kl_divergence: -1402.1411
  ssim: 0.0457
  iou: 0.1360
Layer 3 metrics:
  pearson_correlation: -0.0068
  kl_divergence: -1402.1411
  ssim: 0.0457
  iou: 0.1360

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.42441, std: 0.14111

Metrics for layer 4:
  pearson_correlation: -0.0381
  kl_divergence: -335.2051
  ssim: 0.0453
  iou: 0.1412
Layer 4 metrics:
  pearson_correlation: -0.0381
  kl_divergence: -335.2051
  ssim: 0.0453
  iou: 0.1412

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.49121, std: 0.14529

Metrics for layer 5:
  pearson_correlation: 0.0059
  kl_divergence: -397.4964
  ssim: 0.0557
  iou: 0.1305
Layer 5 metrics:
  pearson_correlation: 0.0059
  kl_divergence: -397.4964
  ssim: 0.0557
  iou: 0.1305

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.52361, std: 0.13850

Metrics for layer 6:
  pearson_correlation: -0.0222
  kl_divergence: -421.4905
  ssim: 0.0430
  iou: 0.1395
Layer 6 metrics:
  pearson_correlation: -0.0222
  kl_divergence: -421.4905
  ssim: 0.0430
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.47922, std: 0.16862

Metrics for layer 7:
  pearson_correlation: 0.0365
  kl_divergence: -86.3851
  ssim: 0.0451
  iou: 0.1362
Layer 7 metrics:
  pearson_correlation: 0.0365
  kl_divergence: -86.3851
  ssim: 0.0451
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.45695, std: 0.16159

Metrics for layer 8:
  pearson_correlation: -0.0200
  kl_divergence: -81.7393
  ssim: 0.0329
  iou: 0.1362
Layer 8 metrics:
  pearson_correlation: -0.0200
  kl_divergence: -81.7393
  ssim: 0.0329
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.41355, std: 0.15840

Metrics for layer 9:
  pearson_correlation: 0.0190
  kl_divergence: -75.4086
  ssim: 0.0461
  iou: 0.1462
Layer 9 metrics:
  pearson_correlation: 0.0190
  kl_divergence: -75.4086
  ssim: 0.0461
  iou: 0.1462

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.48313, std: 0.20038

Metrics for layer 10:
  pearson_correlation: -0.0121
  kl_divergence: -17.0299
  ssim: 0.0208
  iou: 0.1264
Layer 10 metrics:
  pearson_correlation: -0.0121
  kl_divergence: -17.0299
  ssim: 0.0208
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.53157, std: 0.19847

Metrics for layer 11:
  pearson_correlation: -0.1014
  kl_divergence: -20.3435
  ssim: -0.0564
  iou: 0.0889
Layer 11 metrics:
  pearson_correlation: -0.1014
  kl_divergence: -20.3435
  ssim: -0.0564
  iou: 0.0889

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.48513, std: 0.19479

Metrics for layer 12:
  pearson_correlation: -0.0165
  kl_divergence: -11.3800
  ssim: 0.0103
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: -0.0165
  kl_divergence: -11.3800
  ssim: 0.0103
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer5/batch_1_strength_1.2_results.npy

Analysis complete! Results saved to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer5
Completed experiment for category 5, layer 5
----------------------------------------
Running experiment for category 5, layer 6
===================================================
Starting experiment:
Category: 5
Layer: 6
Logs will be saved to: /scratch/hy2611/CNN_attention/logs/attention_analysis_20241216_104146/category5/layer6
===================================================
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-12-16 10:58:15.218369: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-16 10:58:15.237509: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2024-12-16 10:58:15.237947: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4b724e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-16 10:58:15.237962: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-16 10:58:15.240668: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-16 10:58:15.387830: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4b6b570 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-16 10:58:15.387853: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-12-16 10:58:15.388458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:2f:00.0
2024-12-16 10:58:15.389638: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:58:15.390693: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:58:15.391708: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:58:15.392733: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:58:15.393730: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:58:15.394727: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:58:15.395731: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:58:15.395742: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-12-16 10:58:15.395759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-16 10:58:15.395764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-16 10:58:15.395767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:61: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:87: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:15: sigmoid_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.sigmoid_cross_entropy instead. Note that the order of the predictions and labels arguments has been changed.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:322: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:82: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.


Verifying paths:
tc_path: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs exists
weight_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists
image_path: /scratch/hy2611/CNN_attention/Data/VGG16/images exists
save_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists

Initializing model...
('c11', [1, 224, 224, 64])
('c12', [1, 224, 224, 64])
('c21', [1, 112, 112, 128])
('c22', [1, 112, 112, 128])
('c31', [1, 56, 56, 256])
('c32', [1, 56, 56, 256])
('c33', [1, 56, 56, 256])
('c41', [1, 28, 28, 512])
('c42', [1, 28, 28, 512])
('c43', [1, 28, 28, 512])
('c51', [1, 14, 14, 512])
('c52', [1, 14, 14, 512])
('c53', [1, 14, 14, 512])
(0, 'conv1_1_W', (3, 3, 3, 64))
(1, 'conv1_1_b', (64,))
(2, 'conv1_2_W', (3, 3, 64, 64))
(3, 'conv1_2_b', (64,))
(4, 'conv2_1_W', (3, 3, 64, 128))
(5, 'conv2_1_b', (128,))
(6, 'conv2_2_W', (3, 3, 128, 128))
(7, 'conv2_2_b', (128,))
(8, 'conv3_1_W', (3, 3, 128, 256))
(9, 'conv3_1_b', (256,))
(10, 'conv3_2_W', (3, 3, 256, 256))
(11, 'conv3_2_b', (256,))
(12, 'conv3_3_W', (3, 3, 256, 256))
(13, 'conv3_3_b', (256,))
(14, 'conv4_1_W', (3, 3, 256, 512))
(15, 'conv4_1_b', (512,))
(16, 'conv4_2_W', (3, 3, 512, 512))
(17, 'conv4_2_b', (512,))
(18, 'conv4_3_W', (3, 3, 512, 512))
(19, 'conv4_3_b', (512,))
(20, 'conv5_1_W', (3, 3, 512, 512))
(21, 'conv5_1_b', (512,))
(22, 'conv5_2_W', (3, 3, 512, 512))
(23, 'conv5_2_b', (512,))
(24, 'conv5_3_W', (3, 3, 512, 512))
(25, 'conv5_3_b', (512,))
(26, 'fc6_W', (25088, 4096))
(27, 'fc6_b', (4096,))
(28, 'fc7_W', (4096, 4096))
(29, 'fc7_b', (4096,))
Checking checkpoint files:
Data file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.data-00000-of-00001 - Found
Index file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.index - Found
Loading checkpoint from: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt
Checkpoint loaded successfully

Initializing components...
Found tuning curves file: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs/featvecs20_train35_c.txt

Loading category 5 data...
Original positive images shape: (2, 224, 224, 3)

Processing data...

Processing attention strength 0.0
Attention vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

Processing batch 1/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.44316, std: 0.12315

Metrics for layer 0:
  pearson_correlation: -0.0065
  kl_divergence: -4692.1377
  ssim: 0.0463
  iou: 0.1395
Layer 0 metrics:
  pearson_correlation: -0.0065
  kl_divergence: -4692.1377
  ssim: 0.0463
  iou: 0.1395

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.45749, std: 0.13039

Metrics for layer 1:
  pearson_correlation: -0.0052
  kl_divergence: -4784.1753
  ssim: 0.0405
  iou: 0.1407
Layer 1 metrics:
  pearson_correlation: -0.0052
  kl_divergence: -4784.1753
  ssim: 0.0405
  iou: 0.1407

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.49734, std: 0.12649

Metrics for layer 2:
  pearson_correlation: 0.0195
  kl_divergence: -1486.7765
  ssim: 0.0571
  iou: 0.1487
Layer 2 metrics:
  pearson_correlation: 0.0195
  kl_divergence: -1486.7765
  ssim: 0.0571
  iou: 0.1487

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.48187, std: 0.12900

Metrics for layer 3:
  pearson_correlation: 0.0068
  kl_divergence: -1450.7798
  ssim: 0.0535
  iou: 0.1429
Layer 3 metrics:
  pearson_correlation: 0.0068
  kl_divergence: -1450.7798
  ssim: 0.0535
  iou: 0.1429

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.48219, std: 0.14874

Metrics for layer 4:
  pearson_correlation: -0.0225
  kl_divergence: -375.3386
  ssim: 0.0438
  iou: 0.1354
Layer 4 metrics:
  pearson_correlation: -0.0225
  kl_divergence: -375.3386
  ssim: 0.0438
  iou: 0.1354

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46971, std: 0.13681

Metrics for layer 5:
  pearson_correlation: -0.0096
  kl_divergence: -369.3701
  ssim: 0.0526
  iou: 0.1454
Layer 5 metrics:
  pearson_correlation: -0.0096
  kl_divergence: -369.3701
  ssim: 0.0526
  iou: 0.1454

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.38669, std: 0.13019

Metrics for layer 6:
  pearson_correlation: -0.0096
  kl_divergence: -291.4173
  ssim: 0.0776
  iou: 0.1412
Layer 6 metrics:
  pearson_correlation: -0.0096
  kl_divergence: -291.4173
  ssim: 0.0776
  iou: 0.1412

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.47146, std: 0.18631

Metrics for layer 7:
  pearson_correlation: 0.0501
  kl_divergence: -85.7714
  ssim: 0.0677
  iou: 0.1362
Layer 7 metrics:
  pearson_correlation: 0.0501
  kl_divergence: -85.7714
  ssim: 0.0677
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.51697, std: 0.18657

Metrics for layer 8:
  pearson_correlation: 0.0319
  kl_divergence: -95.9271
  ssim: 0.0401
  iou: 0.1529
Layer 8 metrics:
  pearson_correlation: 0.0319
  kl_divergence: -95.9271
  ssim: 0.0401
  iou: 0.1529

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.54322, std: 0.15857

Metrics for layer 9:
  pearson_correlation: 0.0164
  kl_divergence: -103.4568
  ssim: 0.0566
  iou: 0.1462
Layer 9 metrics:
  pearson_correlation: 0.0164
  kl_divergence: -103.4568
  ssim: 0.0566
  iou: 0.1462

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.50909, std: 0.16114

Metrics for layer 10:
  pearson_correlation: -0.0291
  kl_divergence: -18.3439
  ssim: 0.0428
  iou: 0.1807
Layer 10 metrics:
  pearson_correlation: -0.0291
  kl_divergence: -18.3439
  ssim: 0.0428
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49781, std: 0.17075

Metrics for layer 11:
  pearson_correlation: -0.0621
  kl_divergence: -19.7050
  ssim: -0.0249
  iou: 0.1807
Layer 11 metrics:
  pearson_correlation: -0.0621
  kl_divergence: -19.7050
  ssim: -0.0249
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.46133, std: 0.20918

Metrics for layer 12:
  pearson_correlation: 0.1208
  kl_divergence: -19.5554
  ssim: 0.2183
  iou: 0.2099
Layer 12 metrics:
  pearson_correlation: 0.1208
  kl_divergence: -19.5554
  ssim: 0.2183
  iou: 0.2099
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer6/batch_0_strength_0.0_results.npy

Processing batch 2/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.44170, std: 0.12809

Metrics for layer 0:
  pearson_correlation: -0.0016
  kl_divergence: -3835.9739
  ssim: 0.0299
  iou: 0.1384
Layer 0 metrics:
  pearson_correlation: -0.0016
  kl_divergence: -3835.9739
  ssim: 0.0299
  iou: 0.1384

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.41608, std: 0.12329

Metrics for layer 1:
  pearson_correlation: 0.0066
  kl_divergence: -3725.1292
  ssim: 0.0340
  iou: 0.1459
Layer 1 metrics:
  pearson_correlation: 0.0066
  kl_divergence: -3725.1292
  ssim: 0.0340
  iou: 0.1459

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.44215, std: 0.13301

Metrics for layer 2:
  pearson_correlation: 0.0107
  kl_divergence: -1332.1147
  ssim: 0.0519
  iou: 0.1466
Layer 2 metrics:
  pearson_correlation: 0.0107
  kl_divergence: -1332.1147
  ssim: 0.0519
  iou: 0.1466

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.41815, std: 0.12711

Metrics for layer 3:
  pearson_correlation: 0.0051
  kl_divergence: -1278.8624
  ssim: 0.0545
  iou: 0.1464
Layer 3 metrics:
  pearson_correlation: 0.0051
  kl_divergence: -1278.8624
  ssim: 0.0545
  iou: 0.1464

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.43264, std: 0.14322

Metrics for layer 4:
  pearson_correlation: 0.0109
  kl_divergence: -347.2995
  ssim: 0.0645
  iou: 0.1362
Layer 4 metrics:
  pearson_correlation: 0.0109
  kl_divergence: -347.2995
  ssim: 0.0645
  iou: 0.1362

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.42382, std: 0.13526

Metrics for layer 5:
  pearson_correlation: 0.0212
  kl_divergence: -338.7662
  ssim: 0.0763
  iou: 0.1581
Layer 5 metrics:
  pearson_correlation: 0.0212
  kl_divergence: -338.7662
  ssim: 0.0763
  iou: 0.1581

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.44289, std: 0.13072

Metrics for layer 6:
  pearson_correlation: 0.0373
  kl_divergence: -362.3783
  ssim: 0.0726
  iou: 0.1496
Layer 6 metrics:
  pearson_correlation: 0.0373
  kl_divergence: -362.3783
  ssim: 0.0726
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.48077, std: 0.17405

Metrics for layer 7:
  pearson_correlation: 0.0257
  kl_divergence: -84.0513
  ssim: 0.0318
  iou: 0.1667
Layer 7 metrics:
  pearson_correlation: 0.0257
  kl_divergence: -84.0513
  ssim: 0.0318
  iou: 0.1667

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.49062, std: 0.18423

Metrics for layer 8:
  pearson_correlation: 0.0064
  kl_divergence: -85.4751
  ssim: 0.0307
  iou: 0.1200
Layer 8 metrics:
  pearson_correlation: 0.0064
  kl_divergence: -85.4751
  ssim: 0.0307
  iou: 0.1200

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.49384, std: 0.15876

Metrics for layer 9:
  pearson_correlation: 0.0267
  kl_divergence: -87.3804
  ssim: 0.0488
  iou: 0.1362
Layer 9 metrics:
  pearson_correlation: 0.0267
  kl_divergence: -87.3804
  ssim: 0.0488
  iou: 0.1362

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.53303, std: 0.19942

Metrics for layer 10:
  pearson_correlation: -0.0252
  kl_divergence: -11.3991
  ssim: 0.0089
  iou: 0.1395
Layer 10 metrics:
  pearson_correlation: -0.0252
  kl_divergence: -11.3991
  ssim: 0.0089
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.49027, std: 0.19871

Metrics for layer 11:
  pearson_correlation: 0.0196
  kl_divergence: -17.8651
  ssim: 0.0896
  iou: 0.1011
Layer 11 metrics:
  pearson_correlation: 0.0196
  kl_divergence: -17.8651
  ssim: 0.0896
  iou: 0.1011

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.47928, std: 0.18225

Metrics for layer 12:
  pearson_correlation: 0.1429
  kl_divergence: -18.3204
  ssim: 0.1349
  iou: 0.1951
Layer 12 metrics:
  pearson_correlation: 0.1429
  kl_divergence: -18.3204
  ssim: 0.1349
  iou: 0.1951
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer6/batch_1_strength_0.0_results.npy

Processing attention strength 0.4
Attention vector: [0.  0.  0.  0.  0.  0.  0.4 0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.47438, std: 0.12223

Metrics for layer 0:
  pearson_correlation: 0.0016
  kl_divergence: -4927.8384
  ssim: 0.0436
  iou: 0.1428
Layer 0 metrics:
  pearson_correlation: 0.0016
  kl_divergence: -4927.8384
  ssim: 0.0436
  iou: 0.1428

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.40840, std: 0.11371

Metrics for layer 1:
  pearson_correlation: -0.0033
  kl_divergence: -4447.2246
  ssim: 0.0535
  iou: 0.1403
Layer 1 metrics:
  pearson_correlation: -0.0033
  kl_divergence: -4447.2246
  ssim: 0.0535
  iou: 0.1403

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.41533, std: 0.12210

Metrics for layer 2:
  pearson_correlation: 0.0217
  kl_divergence: -1296.4419
  ssim: 0.0702
  iou: 0.1443
Layer 2 metrics:
  pearson_correlation: 0.0217
  kl_divergence: -1296.4419
  ssim: 0.0702
  iou: 0.1443

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.48281, std: 0.13698

Metrics for layer 3:
  pearson_correlation: 0.0042
  kl_divergence: -1447.5959
  ssim: 0.0474
  iou: 0.1452
Layer 3 metrics:
  pearson_correlation: 0.0042
  kl_divergence: -1447.5959
  ssim: 0.0474
  iou: 0.1452

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.42270, std: 0.13995

Metrics for layer 4:
  pearson_correlation: 0.0108
  kl_divergence: -328.4099
  ssim: 0.0711
  iou: 0.1429
Layer 4 metrics:
  pearson_correlation: 0.0108
  kl_divergence: -328.4099
  ssim: 0.0711
  iou: 0.1429

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50560, std: 0.14206

Metrics for layer 5:
  pearson_correlation: 0.0148
  kl_divergence: -393.8235
  ssim: 0.0688
  iou: 0.1504
Layer 5 metrics:
  pearson_correlation: 0.0148
  kl_divergence: -393.8235
  ssim: 0.0688
  iou: 0.1504

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.52579, std: 0.13777

Metrics for layer 6:
  pearson_correlation: -0.0135
  kl_divergence: -410.5425
  ssim: 0.0515
  iou: 0.1387
Layer 6 metrics:
  pearson_correlation: -0.0135
  kl_divergence: -410.5425
  ssim: 0.0515
  iou: 0.1387

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.53212, std: 0.15933

Metrics for layer 7:
  pearson_correlation: 0.0003
  kl_divergence: -101.5437
  ssim: 0.0649
  iou: 0.1362
Layer 7 metrics:
  pearson_correlation: 0.0003
  kl_divergence: -101.5437
  ssim: 0.0649
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.50752, std: 0.13889

Metrics for layer 8:
  pearson_correlation: -0.0005
  kl_divergence: -97.9487
  ssim: 0.0547
  iou: 0.1362
Layer 8 metrics:
  pearson_correlation: -0.0005
  kl_divergence: -97.9487
  ssim: 0.0547
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.45407, std: 0.15997

Metrics for layer 9:
  pearson_correlation: 0.0054
  kl_divergence: -84.4232
  ssim: 0.0388
  iou: 0.1496
Layer 9 metrics:
  pearson_correlation: 0.0054
  kl_divergence: -84.4232
  ssim: 0.0388
  iou: 0.1496

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.48258, std: 0.19063

Metrics for layer 10:
  pearson_correlation: 0.0084
  kl_divergence: -15.7059
  ssim: 0.0384
  iou: 0.1807
Layer 10 metrics:
  pearson_correlation: 0.0084
  kl_divergence: -15.7059
  ssim: 0.0384
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.42729, std: 0.17661

Metrics for layer 11:
  pearson_correlation: 0.0180
  kl_divergence: -10.8450
  ssim: 0.1022
  iou: 0.2099
Layer 11 metrics:
  pearson_correlation: 0.0180
  kl_divergence: -10.8450
  ssim: 0.1022
  iou: 0.2099

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.62556, std: 0.17510

Metrics for layer 12:
  pearson_correlation: -0.0125
  kl_divergence: -29.0884
  ssim: 0.0634
  iou: 0.1951
Layer 12 metrics:
  pearson_correlation: -0.0125
  kl_divergence: -29.0884
  ssim: 0.0634
  iou: 0.1951
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer6/batch_0_strength_0.4_results.npy

Processing batch 2/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.41857, std: 0.11995

Metrics for layer 0:
  pearson_correlation: 0.0019
  kl_divergence: -3741.0181
  ssim: 0.0346
  iou: 0.1448
Layer 0 metrics:
  pearson_correlation: 0.0019
  kl_divergence: -3741.0181
  ssim: 0.0346
  iou: 0.1448

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43234, std: 0.12384

Metrics for layer 1:
  pearson_correlation: 0.0015
  kl_divergence: -3800.7322
  ssim: 0.0325
  iou: 0.1419
Layer 1 metrics:
  pearson_correlation: 0.0015
  kl_divergence: -3800.7322
  ssim: 0.0325
  iou: 0.1419

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.42473, std: 0.12616

Metrics for layer 2:
  pearson_correlation: -0.0026
  kl_divergence: -1294.7024
  ssim: 0.0546
  iou: 0.1412
Layer 2 metrics:
  pearson_correlation: -0.0026
  kl_divergence: -1294.7024
  ssim: 0.0546
  iou: 0.1412

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.46803, std: 0.13154

Metrics for layer 3:
  pearson_correlation: 0.0136
  kl_divergence: -1389.8513
  ssim: 0.0493
  iou: 0.1506
Layer 3 metrics:
  pearson_correlation: 0.0136
  kl_divergence: -1389.8513
  ssim: 0.0493
  iou: 0.1506

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.46025, std: 0.13700

Metrics for layer 4:
  pearson_correlation: -0.0231
  kl_divergence: -370.2286
  ssim: 0.0535
  iou: 0.1248
Layer 4 metrics:
  pearson_correlation: -0.0231
  kl_divergence: -370.2286
  ssim: 0.0535
  iou: 0.1248

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48853, std: 0.14199

Metrics for layer 5:
  pearson_correlation: 0.0090
  kl_divergence: -395.6640
  ssim: 0.0485
  iou: 0.1623
Layer 5 metrics:
  pearson_correlation: 0.0090
  kl_divergence: -395.6640
  ssim: 0.0485
  iou: 0.1623

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.55347, std: 0.13495

Metrics for layer 6:
  pearson_correlation: 0.0111
  kl_divergence: -444.5768
  ssim: 0.0576
  iou: 0.1572
Layer 6 metrics:
  pearson_correlation: 0.0111
  kl_divergence: -444.5768
  ssim: 0.0576
  iou: 0.1572

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.46496, std: 0.15478

Metrics for layer 7:
  pearson_correlation: -0.0076
  kl_divergence: -84.7838
  ssim: 0.0362
  iou: 0.1136
Layer 7 metrics:
  pearson_correlation: -0.0076
  kl_divergence: -84.7838
  ssim: 0.0362
  iou: 0.1136

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.47318, std: 0.14354

Metrics for layer 8:
  pearson_correlation: -0.0006
  kl_divergence: -86.5085
  ssim: 0.0379
  iou: 0.1496
Layer 8 metrics:
  pearson_correlation: -0.0006
  kl_divergence: -86.5085
  ssim: 0.0379
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.48096, std: 0.16247

Metrics for layer 9:
  pearson_correlation: -0.0006
  kl_divergence: -86.0635
  ssim: 0.0347
  iou: 0.1073
Layer 9 metrics:
  pearson_correlation: -0.0006
  kl_divergence: -86.0635
  ssim: 0.0347
  iou: 0.1073

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.47108, std: 0.19446

Metrics for layer 10:
  pearson_correlation: -0.0639
  kl_divergence: -12.4166
  ssim: 0.0258
  iou: 0.1011
Layer 10 metrics:
  pearson_correlation: -0.0639
  kl_divergence: -12.4166
  ssim: 0.0258
  iou: 0.1011

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.49627, std: 0.17615

Metrics for layer 11:
  pearson_correlation: -0.0393
  kl_divergence: -19.3373
  ssim: 0.0347
  iou: 0.0889
Layer 11 metrics:
  pearson_correlation: -0.0393
  kl_divergence: -19.3373
  ssim: 0.0347
  iou: 0.0889

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.45591, std: 0.15687

Metrics for layer 12:
  pearson_correlation: 0.0564
  kl_divergence: -15.9145
  ssim: 0.0703
  iou: 0.1807
Layer 12 metrics:
  pearson_correlation: 0.0564
  kl_divergence: -15.9145
  ssim: 0.0703
  iou: 0.1807
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer6/batch_1_strength_0.4_results.npy

Processing attention strength 0.8
Attention vector: [0.  0.  0.  0.  0.  0.  0.8 0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.39707, std: 0.11318

Metrics for layer 0:
  pearson_correlation: 0.0001
  kl_divergence: -4358.2852
  ssim: 0.0581
  iou: 0.1403
Layer 0 metrics:
  pearson_correlation: 0.0001
  kl_divergence: -4358.2852
  ssim: 0.0581
  iou: 0.1403

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.36675, std: 0.09958

Metrics for layer 1:
  pearson_correlation: -0.0033
  kl_divergence: -4126.3311
  ssim: 0.0709
  iou: 0.1413
Layer 1 metrics:
  pearson_correlation: -0.0033
  kl_divergence: -4126.3311
  ssim: 0.0709
  iou: 0.1413

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.43990, std: 0.13219

Metrics for layer 2:
  pearson_correlation: -0.0028
  kl_divergence: -1345.1726
  ssim: 0.0540
  iou: 0.1431
Layer 2 metrics:
  pearson_correlation: -0.0028
  kl_divergence: -1345.1726
  ssim: 0.0540
  iou: 0.1431

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.44499, std: 0.13047

Metrics for layer 3:
  pearson_correlation: 0.0144
  kl_divergence: -1366.2034
  ssim: 0.0556
  iou: 0.1449
Layer 3 metrics:
  pearson_correlation: 0.0144
  kl_divergence: -1366.2034
  ssim: 0.0556
  iou: 0.1449

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.52630, std: 0.13825

Metrics for layer 4:
  pearson_correlation: -0.0298
  kl_divergence: -409.0574
  ssim: 0.0524
  iou: 0.1264
Layer 4 metrics:
  pearson_correlation: -0.0298
  kl_divergence: -409.0574
  ssim: 0.0524
  iou: 0.1264

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47306, std: 0.14695

Metrics for layer 5:
  pearson_correlation: 0.0243
  kl_divergence: -370.5228
  ssim: 0.0674
  iou: 0.1512
Layer 5 metrics:
  pearson_correlation: 0.0243
  kl_divergence: -370.5228
  ssim: 0.0674
  iou: 0.1512

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.53038, std: 0.14249

Metrics for layer 6:
  pearson_correlation: 0.0130
  kl_divergence: -411.5355
  ssim: 0.0550
  iou: 0.1371
Layer 6 metrics:
  pearson_correlation: 0.0130
  kl_divergence: -411.5355
  ssim: 0.0550
  iou: 0.1371

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.52545, std: 0.14251

Metrics for layer 7:
  pearson_correlation: 0.0469
  kl_divergence: -102.7028
  ssim: 0.0759
  iou: 0.1772
Layer 7 metrics:
  pearson_correlation: 0.0469
  kl_divergence: -102.7028
  ssim: 0.0759
  iou: 0.1772

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.50208, std: 0.17338

Metrics for layer 8:
  pearson_correlation: 0.0326
  kl_divergence: -95.0143
  ssim: 0.0528
  iou: 0.1598
Layer 8 metrics:
  pearson_correlation: 0.0326
  kl_divergence: -95.0143
  ssim: 0.0528
  iou: 0.1598

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.50750, std: 0.16214

Metrics for layer 9:
  pearson_correlation: 0.0928
  kl_divergence: -99.3863
  ssim: 0.0687
  iou: 0.1632
Layer 9 metrics:
  pearson_correlation: 0.0928
  kl_divergence: -99.3863
  ssim: 0.0687
  iou: 0.1632

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.44974, std: 0.16816

Metrics for layer 10:
  pearson_correlation: -0.0268
  kl_divergence: -9.5685
  ssim: 0.0162
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: -0.0268
  kl_divergence: -9.5685
  ssim: 0.0162
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49556, std: 0.17145

Metrics for layer 11:
  pearson_correlation: -0.1017
  kl_divergence: -16.6269
  ssim: -0.0360
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: -0.1017
  kl_divergence: -16.6269
  ssim: -0.0360
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.44312, std: 0.18206

Metrics for layer 12:
  pearson_correlation: -0.0099
  kl_divergence: -18.0676
  ssim: -0.0059
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: -0.0099
  kl_divergence: -18.0676
  ssim: -0.0059
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer6/batch_0_strength_0.8_results.npy

Processing batch 2/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.44315, std: 0.11670

Metrics for layer 0:
  pearson_correlation: 0.0021
  kl_divergence: -3862.5420
  ssim: 0.0343
  iou: 0.1429
Layer 0 metrics:
  pearson_correlation: 0.0021
  kl_divergence: -3862.5420
  ssim: 0.0343
  iou: 0.1429

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.39218, std: 0.11578

Metrics for layer 1:
  pearson_correlation: -0.0045
  kl_divergence: -3611.1943
  ssim: 0.0384
  iou: 0.1414
Layer 1 metrics:
  pearson_correlation: -0.0045
  kl_divergence: -3611.1943
  ssim: 0.0384
  iou: 0.1414

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.43849, std: 0.12845

Metrics for layer 2:
  pearson_correlation: -0.0037
  kl_divergence: -1322.5798
  ssim: 0.0530
  iou: 0.1441
Layer 2 metrics:
  pearson_correlation: -0.0037
  kl_divergence: -1322.5798
  ssim: 0.0530
  iou: 0.1441

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.47691, std: 0.13753

Metrics for layer 3:
  pearson_correlation: 0.0042
  kl_divergence: -1403.4351
  ssim: 0.0410
  iou: 0.1404
Layer 3 metrics:
  pearson_correlation: 0.0042
  kl_divergence: -1403.4351
  ssim: 0.0410
  iou: 0.1404

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.46191, std: 0.15153

Metrics for layer 4:
  pearson_correlation: -0.0065
  kl_divergence: -368.9003
  ssim: 0.0488
  iou: 0.1512
Layer 4 metrics:
  pearson_correlation: -0.0065
  kl_divergence: -368.9003
  ssim: 0.0488
  iou: 0.1512

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.50344, std: 0.13806

Metrics for layer 5:
  pearson_correlation: -0.0092
  kl_divergence: -406.4167
  ssim: 0.0535
  iou: 0.1362
Layer 5 metrics:
  pearson_correlation: -0.0092
  kl_divergence: -406.4167
  ssim: 0.0535
  iou: 0.1362

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.51343, std: 0.13449

Metrics for layer 6:
  pearson_correlation: 0.0004
  kl_divergence: -414.6082
  ssim: 0.0519
  iou: 0.1420
Layer 6 metrics:
  pearson_correlation: 0.0004
  kl_divergence: -414.6082
  ssim: 0.0519
  iou: 0.1420

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.51200, std: 0.15739

Metrics for layer 7:
  pearson_correlation: -0.0565
  kl_divergence: -91.0510
  ssim: 0.0287
  iou: 0.1200
Layer 7 metrics:
  pearson_correlation: -0.0565
  kl_divergence: -91.0510
  ssim: 0.0287
  iou: 0.1200

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.43250, std: 0.16178

Metrics for layer 8:
  pearson_correlation: 0.0251
  kl_divergence: -79.7869
  ssim: 0.0459
  iou: 0.1632
Layer 8 metrics:
  pearson_correlation: 0.0251
  kl_divergence: -79.7869
  ssim: 0.0459
  iou: 0.1632

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.52887, std: 0.14625

Metrics for layer 9:
  pearson_correlation: -0.0173
  kl_divergence: -92.8076
  ssim: 0.0367
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: -0.0173
  kl_divergence: -92.8076
  ssim: 0.0367
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.47584, std: 0.18066

Metrics for layer 10:
  pearson_correlation: -0.1491
  kl_divergence: -14.7586
  ssim: -0.1090
  iou: 0.1136
Layer 10 metrics:
  pearson_correlation: -0.1491
  kl_divergence: -14.7586
  ssim: -0.1090
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.42420, std: 0.19158

Metrics for layer 11:
  pearson_correlation: -0.0475
  kl_divergence: -11.8995
  ssim: -0.0041
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: -0.0475
  kl_divergence: -11.8995
  ssim: -0.0041
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.47454, std: 0.17477

Metrics for layer 12:
  pearson_correlation: -0.0510
  kl_divergence: -16.8141
  ssim: -0.0106
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: -0.0510
  kl_divergence: -16.8141
  ssim: -0.0106
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer6/batch_1_strength_0.8_results.npy

Processing attention strength 1.2
Attention vector: [0.  0.  0.  0.  0.  0.  1.2 0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.45221, std: 0.12679

Metrics for layer 0:
  pearson_correlation: -0.0048
  kl_divergence: -4755.1392
  ssim: 0.0416
  iou: 0.1425
Layer 0 metrics:
  pearson_correlation: -0.0048
  kl_divergence: -4755.1392
  ssim: 0.0416
  iou: 0.1425

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42086, std: 0.12131

Metrics for layer 1:
  pearson_correlation: 0.0018
  kl_divergence: -4529.6157
  ssim: 0.0501
  iou: 0.1440
Layer 1 metrics:
  pearson_correlation: 0.0018
  kl_divergence: -4529.6157
  ssim: 0.0501
  iou: 0.1440

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.44039, std: 0.12951

Metrics for layer 2:
  pearson_correlation: 0.0015
  kl_divergence: -1350.0283
  ssim: 0.0602
  iou: 0.1327
Layer 2 metrics:
  pearson_correlation: 0.0015
  kl_divergence: -1350.0283
  ssim: 0.0602
  iou: 0.1327

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.44993, std: 0.12075

Metrics for layer 3:
  pearson_correlation: 0.0107
  kl_divergence: -1383.2537
  ssim: 0.0645
  iou: 0.1462
Layer 3 metrics:
  pearson_correlation: 0.0107
  kl_divergence: -1383.2537
  ssim: 0.0645
  iou: 0.1462

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50617, std: 0.15298

Metrics for layer 4:
  pearson_correlation: -0.0184
  kl_divergence: -390.4158
  ssim: 0.0537
  iou: 0.1289
Layer 4 metrics:
  pearson_correlation: -0.0184
  kl_divergence: -390.4158
  ssim: 0.0537
  iou: 0.1289

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47008, std: 0.14176

Metrics for layer 5:
  pearson_correlation: -0.0056
  kl_divergence: -364.9849
  ssim: 0.0569
  iou: 0.1479
Layer 5 metrics:
  pearson_correlation: -0.0056
  kl_divergence: -364.9849
  ssim: 0.0569
  iou: 0.1479

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.48958, std: 0.12581

Metrics for layer 6:
  pearson_correlation: 0.0020
  kl_divergence: -387.9091
  ssim: 0.0606
  iou: 0.1371
Layer 6 metrics:
  pearson_correlation: 0.0020
  kl_divergence: -387.9091
  ssim: 0.0606
  iou: 0.1371

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.45902, std: 0.15082

Metrics for layer 7:
  pearson_correlation: -0.0842
  kl_divergence: -82.9460
  ssim: 0.0426
  iou: 0.0980
Layer 7 metrics:
  pearson_correlation: -0.0842
  kl_divergence: -82.9460
  ssim: 0.0426
  iou: 0.0980

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.47794, std: 0.13775

Metrics for layer 8:
  pearson_correlation: 0.0298
  kl_divergence: -91.4433
  ssim: 0.0797
  iou: 0.1462
Layer 8 metrics:
  pearson_correlation: 0.0298
  kl_divergence: -91.4433
  ssim: 0.0797
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.48781, std: 0.15682

Metrics for layer 9:
  pearson_correlation: 0.0052
  kl_divergence: -93.3995
  ssim: 0.0425
  iou: 0.1200
Layer 9 metrics:
  pearson_correlation: 0.0052
  kl_divergence: -93.3995
  ssim: 0.0425
  iou: 0.1200

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.50586, std: 0.18843

Metrics for layer 10:
  pearson_correlation: 0.0682
  kl_divergence: -18.5318
  ssim: 0.0951
  iou: 0.1951
Layer 10 metrics:
  pearson_correlation: 0.0682
  kl_divergence: -18.5318
  ssim: 0.0951
  iou: 0.1951

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.48397, std: 0.20609

Metrics for layer 11:
  pearson_correlation: -0.0205
  kl_divergence: -13.5895
  ssim: 0.0450
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: -0.0205
  kl_divergence: -13.5895
  ssim: 0.0450
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.46510, std: 0.22080

Metrics for layer 12:
  pearson_correlation: -0.0551
  kl_divergence: -18.0897
  ssim: -0.0565
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: -0.0551
  kl_divergence: -18.0897
  ssim: -0.0565
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer6/batch_0_strength_1.2_results.npy

Processing batch 2/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.42740, std: 0.11549

Metrics for layer 0:
  pearson_correlation: 0.0025
  kl_divergence: -3789.8740
  ssim: 0.0361
  iou: 0.1450
Layer 0 metrics:
  pearson_correlation: 0.0025
  kl_divergence: -3789.8740
  ssim: 0.0361
  iou: 0.1450

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.41185, std: 0.11880

Metrics for layer 1:
  pearson_correlation: 0.0030
  kl_divergence: -3708.9744
  ssim: 0.0354
  iou: 0.1482
Layer 1 metrics:
  pearson_correlation: 0.0030
  kl_divergence: -3708.9744
  ssim: 0.0354
  iou: 0.1482

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.41685, std: 0.13149

Metrics for layer 2:
  pearson_correlation: 0.0104
  kl_divergence: -1274.5818
  ssim: 0.0539
  iou: 0.1408
Layer 2 metrics:
  pearson_correlation: 0.0104
  kl_divergence: -1274.5818
  ssim: 0.0539
  iou: 0.1408

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.45439, std: 0.13305

Metrics for layer 3:
  pearson_correlation: -0.0104
  kl_divergence: -1353.9106
  ssim: 0.0464
  iou: 0.1410
Layer 3 metrics:
  pearson_correlation: -0.0104
  kl_divergence: -1353.9106
  ssim: 0.0464
  iou: 0.1410

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47387, std: 0.12237

Metrics for layer 4:
  pearson_correlation: -0.0171
  kl_divergence: -387.7816
  ssim: 0.0637
  iou: 0.1445
Layer 4 metrics:
  pearson_correlation: -0.0171
  kl_divergence: -387.7816
  ssim: 0.0637
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47752, std: 0.14460

Metrics for layer 5:
  pearson_correlation: 0.0190
  kl_divergence: -387.9899
  ssim: 0.0611
  iou: 0.1387
Layer 5 metrics:
  pearson_correlation: 0.0190
  kl_divergence: -387.9899
  ssim: 0.0611
  iou: 0.1387

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.46734, std: 0.13320

Metrics for layer 6:
  pearson_correlation: 0.0038
  kl_divergence: -379.5356
  ssim: 0.0570
  iou: 0.1429
Layer 6 metrics:
  pearson_correlation: 0.0038
  kl_divergence: -379.5356
  ssim: 0.0570
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.51222, std: 0.15271

Metrics for layer 7:
  pearson_correlation: -0.0118
  kl_divergence: -89.3107
  ssim: 0.0407
  iou: 0.1462
Layer 7 metrics:
  pearson_correlation: -0.0118
  kl_divergence: -89.3107
  ssim: 0.0407
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.49294, std: 0.16897

Metrics for layer 8:
  pearson_correlation: -0.0944
  kl_divergence: -86.6432
  ssim: 0.0120
  iou: 0.1329
Layer 8 metrics:
  pearson_correlation: -0.0944
  kl_divergence: -86.6432
  ssim: 0.0120
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.51776, std: 0.15974

Metrics for layer 9:
  pearson_correlation: 0.0492
  kl_divergence: -91.7729
  ssim: 0.0356
  iou: 0.1737
Layer 9 metrics:
  pearson_correlation: 0.0492
  kl_divergence: -91.7729
  ssim: 0.0356
  iou: 0.1737

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.44097, std: 0.17827

Metrics for layer 10:
  pearson_correlation: 0.1466
  kl_divergence: -15.7385
  ssim: 0.1788
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: 0.1466
  kl_divergence: -15.7385
  ssim: 0.1788
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.49590, std: 0.17501

Metrics for layer 11:
  pearson_correlation: -0.0653
  kl_divergence: -16.1891
  ssim: -0.0319
  iou: 0.1951
Layer 11 metrics:
  pearson_correlation: -0.0653
  kl_divergence: -16.1891
  ssim: -0.0319
  iou: 0.1951

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.43681, std: 0.18710

Metrics for layer 12:
  pearson_correlation: 0.0447
  kl_divergence: -14.0967
  ssim: -0.0107
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: 0.0447
  kl_divergence: -14.0967
  ssim: -0.0107
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer6/batch_1_strength_1.2_results.npy

Analysis complete! Results saved to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer6
Completed experiment for category 5, layer 6
----------------------------------------
Running experiment for category 5, layer 7
===================================================
Starting experiment:
Category: 5
Layer: 7
Logs will be saved to: /scratch/hy2611/CNN_attention/logs/attention_analysis_20241216_104146/category5/layer7
===================================================
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-12-16 11:01:04.583769: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-16 11:01:04.617504: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2024-12-16 11:01:04.617885: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5a06cf0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:01:04.617894: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-16 11:01:04.620871: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-16 11:01:04.771660: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x59e2ef0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:01:04.771678: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-12-16 11:01:04.772195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:2f:00.0
2024-12-16 11:01:04.773431: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:01:04.774532: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:01:04.775602: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:01:04.776678: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:01:04.777726: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:01:04.778767: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:01:04.779846: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:01:04.779858: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-12-16 11:01:04.780003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-16 11:01:04.780009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-16 11:01:04.780012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:61: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:87: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:15: sigmoid_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.sigmoid_cross_entropy instead. Note that the order of the predictions and labels arguments has been changed.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:322: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:82: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.


Verifying paths:
tc_path: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs exists
weight_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists
image_path: /scratch/hy2611/CNN_attention/Data/VGG16/images exists
save_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists

Initializing model...
('c11', [1, 224, 224, 64])
('c12', [1, 224, 224, 64])
('c21', [1, 112, 112, 128])
('c22', [1, 112, 112, 128])
('c31', [1, 56, 56, 256])
('c32', [1, 56, 56, 256])
('c33', [1, 56, 56, 256])
('c41', [1, 28, 28, 512])
('c42', [1, 28, 28, 512])
('c43', [1, 28, 28, 512])
('c51', [1, 14, 14, 512])
('c52', [1, 14, 14, 512])
('c53', [1, 14, 14, 512])
(0, 'conv1_1_W', (3, 3, 3, 64))
(1, 'conv1_1_b', (64,))
(2, 'conv1_2_W', (3, 3, 64, 64))
(3, 'conv1_2_b', (64,))
(4, 'conv2_1_W', (3, 3, 64, 128))
(5, 'conv2_1_b', (128,))
(6, 'conv2_2_W', (3, 3, 128, 128))
(7, 'conv2_2_b', (128,))
(8, 'conv3_1_W', (3, 3, 128, 256))
(9, 'conv3_1_b', (256,))
(10, 'conv3_2_W', (3, 3, 256, 256))
(11, 'conv3_2_b', (256,))
(12, 'conv3_3_W', (3, 3, 256, 256))
(13, 'conv3_3_b', (256,))
(14, 'conv4_1_W', (3, 3, 256, 512))
(15, 'conv4_1_b', (512,))
(16, 'conv4_2_W', (3, 3, 512, 512))
(17, 'conv4_2_b', (512,))
(18, 'conv4_3_W', (3, 3, 512, 512))
(19, 'conv4_3_b', (512,))
(20, 'conv5_1_W', (3, 3, 512, 512))
(21, 'conv5_1_b', (512,))
(22, 'conv5_2_W', (3, 3, 512, 512))
(23, 'conv5_2_b', (512,))
(24, 'conv5_3_W', (3, 3, 512, 512))
(25, 'conv5_3_b', (512,))
(26, 'fc6_W', (25088, 4096))
(27, 'fc6_b', (4096,))
(28, 'fc7_W', (4096, 4096))
(29, 'fc7_b', (4096,))
Checking checkpoint files:
Data file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.data-00000-of-00001 - Found
Index file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.index - Found
Loading checkpoint from: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt
Checkpoint loaded successfully

Initializing components...
Found tuning curves file: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs/featvecs20_train35_c.txt

Loading category 5 data...
Original positive images shape: (2, 224, 224, 3)

Processing data...

Processing attention strength 0.0
Attention vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

Processing batch 1/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42357, std: 0.12483

Metrics for layer 0:
  pearson_correlation: 0.0031
  kl_divergence: -4547.8311
  ssim: 0.0474
  iou: 0.1458
Layer 0 metrics:
  pearson_correlation: 0.0031
  kl_divergence: -4547.8311
  ssim: 0.0474
  iou: 0.1458

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.44369, std: 0.12118

Metrics for layer 1:
  pearson_correlation: 0.0085
  kl_divergence: -4717.6660
  ssim: 0.0484
  iou: 0.1455
Layer 1 metrics:
  pearson_correlation: 0.0085
  kl_divergence: -4717.6660
  ssim: 0.0484
  iou: 0.1455

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.50048, std: 0.11833

Metrics for layer 2:
  pearson_correlation: 0.0119
  kl_divergence: -1497.1707
  ssim: 0.0570
  iou: 0.1435
Layer 2 metrics:
  pearson_correlation: 0.0119
  kl_divergence: -1497.1707
  ssim: 0.0570
  iou: 0.1435

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.40939, std: 0.12776

Metrics for layer 3:
  pearson_correlation: 0.0206
  kl_divergence: -1275.8928
  ssim: 0.0643
  iou: 0.1479
Layer 3 metrics:
  pearson_correlation: 0.0206
  kl_divergence: -1275.8928
  ssim: 0.0643
  iou: 0.1479

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.44913, std: 0.15741

Metrics for layer 4:
  pearson_correlation: 0.0025
  kl_divergence: -343.0372
  ssim: 0.0486
  iou: 0.1412
Layer 4 metrics:
  pearson_correlation: 0.0025
  kl_divergence: -343.0372
  ssim: 0.0486
  iou: 0.1412

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50441, std: 0.14606

Metrics for layer 5:
  pearson_correlation: 0.0055
  kl_divergence: -393.8430
  ssim: 0.0530
  iou: 0.1437
Layer 5 metrics:
  pearson_correlation: 0.0055
  kl_divergence: -393.8430
  ssim: 0.0530
  iou: 0.1437

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.51345, std: 0.13955

Metrics for layer 6:
  pearson_correlation: 0.0064
  kl_divergence: -402.1536
  ssim: 0.0579
  iou: 0.1496
Layer 6 metrics:
  pearson_correlation: 0.0064
  kl_divergence: -402.1536
  ssim: 0.0579
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.46482, std: 0.16500

Metrics for layer 7:
  pearson_correlation: 0.0375
  kl_divergence: -87.9431
  ssim: 0.0489
  iou: 0.1429
Layer 7 metrics:
  pearson_correlation: 0.0375
  kl_divergence: -87.9431
  ssim: 0.0489
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.45321, std: 0.17625

Metrics for layer 8:
  pearson_correlation: 0.0701
  kl_divergence: -84.8506
  ssim: 0.0648
  iou: 0.1737
Layer 8 metrics:
  pearson_correlation: 0.0701
  kl_divergence: -84.8506
  ssim: 0.0648
  iou: 0.1737

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.50142, std: 0.15545

Metrics for layer 9:
  pearson_correlation: 0.0602
  kl_divergence: -93.1100
  ssim: 0.0660
  iou: 0.1598
Layer 9 metrics:
  pearson_correlation: 0.0602
  kl_divergence: -93.1100
  ssim: 0.0660
  iou: 0.1598

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.45153, std: 0.16799

Metrics for layer 10:
  pearson_correlation: 0.0124
  kl_divergence: -19.6341
  ssim: 0.1003
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: 0.0124
  kl_divergence: -19.6341
  ssim: 0.1003
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49331, std: 0.15740

Metrics for layer 11:
  pearson_correlation: 0.0381
  kl_divergence: -23.2471
  ssim: 0.0981
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: 0.0381
  kl_divergence: -23.2471
  ssim: 0.0981
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.51127, std: 0.18660

Metrics for layer 12:
  pearson_correlation: -0.0138
  kl_divergence: -22.0280
  ssim: 0.0391
  iou: 0.1136
Layer 12 metrics:
  pearson_correlation: -0.0138
  kl_divergence: -22.0280
  ssim: 0.0391
  iou: 0.1136
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer7/batch_0_strength_0.0_results.npy

Processing batch 2/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43870, std: 0.12186

Metrics for layer 0:
  pearson_correlation: 0.0016
  kl_divergence: -3834.3787
  ssim: 0.0325
  iou: 0.1443
Layer 0 metrics:
  pearson_correlation: 0.0016
  kl_divergence: -3834.3787
  ssim: 0.0325
  iou: 0.1443

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.44141, std: 0.12155

Metrics for layer 1:
  pearson_correlation: 0.0056
  kl_divergence: -3847.7810
  ssim: 0.0328
  iou: 0.1437
Layer 1 metrics:
  pearson_correlation: 0.0056
  kl_divergence: -3847.7810
  ssim: 0.0328
  iou: 0.1437

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.44102, std: 0.14203

Metrics for layer 2:
  pearson_correlation: -0.0090
  kl_divergence: -1313.6644
  ssim: 0.0429
  iou: 0.1368
Layer 2 metrics:
  pearson_correlation: -0.0090
  kl_divergence: -1313.6644
  ssim: 0.0429
  iou: 0.1368

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.45136, std: 0.13687

Metrics for layer 3:
  pearson_correlation: -0.0116
  kl_divergence: -1345.3875
  ssim: 0.0433
  iou: 0.1383
Layer 3 metrics:
  pearson_correlation: -0.0116
  kl_divergence: -1345.3875
  ssim: 0.0433
  iou: 0.1383

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.49596, std: 0.13791

Metrics for layer 4:
  pearson_correlation: 0.0093
  kl_divergence: -398.3365
  ssim: 0.0611
  iou: 0.1563
Layer 4 metrics:
  pearson_correlation: 0.0093
  kl_divergence: -398.3365
  ssim: 0.0611
  iou: 0.1563

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.50588, std: 0.13863

Metrics for layer 5:
  pearson_correlation: 0.0178
  kl_divergence: -411.1227
  ssim: 0.0590
  iou: 0.1479
Layer 5 metrics:
  pearson_correlation: 0.0178
  kl_divergence: -411.1227
  ssim: 0.0590
  iou: 0.1479

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.46293, std: 0.13180

Metrics for layer 6:
  pearson_correlation: 0.0017
  kl_divergence: -376.2189
  ssim: 0.0608
  iou: 0.1445
Layer 6 metrics:
  pearson_correlation: 0.0017
  kl_divergence: -376.2189
  ssim: 0.0608
  iou: 0.1445

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.47963, std: 0.16546

Metrics for layer 7:
  pearson_correlation: 0.0209
  kl_divergence: -86.3305
  ssim: 0.0337
  iou: 0.1563
Layer 7 metrics:
  pearson_correlation: 0.0209
  kl_divergence: -86.3305
  ssim: 0.0337
  iou: 0.1563

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.47768, std: 0.13960

Metrics for layer 8:
  pearson_correlation: 0.0408
  kl_divergence: -87.9407
  ssim: 0.0532
  iou: 0.1429
Layer 8 metrics:
  pearson_correlation: 0.0408
  kl_divergence: -87.9407
  ssim: 0.0532
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.50188, std: 0.14592

Metrics for layer 9:
  pearson_correlation: 0.0708
  kl_divergence: -92.0675
  ssim: 0.0575
  iou: 0.1598
Layer 9 metrics:
  pearson_correlation: 0.0708
  kl_divergence: -92.0675
  ssim: 0.0575
  iou: 0.1598

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.48634, std: 0.21559

Metrics for layer 10:
  pearson_correlation: -0.0141
  kl_divergence: -6.9140
  ssim: -0.0058
  iou: 0.2099
Layer 10 metrics:
  pearson_correlation: -0.0141
  kl_divergence: -6.9140
  ssim: -0.0058
  iou: 0.2099

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.54462, std: 0.19487

Metrics for layer 11:
  pearson_correlation: -0.0107
  kl_divergence: -22.7172
  ssim: -0.0596
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: -0.0107
  kl_divergence: -22.7172
  ssim: -0.0596
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.49193, std: 0.19378

Metrics for layer 12:
  pearson_correlation: 0.0369
  kl_divergence: -19.8649
  ssim: 0.0943
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: 0.0369
  kl_divergence: -19.8649
  ssim: 0.0943
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer7/batch_1_strength_0.0_results.npy

Processing attention strength 0.4
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.4 0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42996, std: 0.12544

Metrics for layer 0:
  pearson_correlation: 0.0031
  kl_divergence: -4595.8394
  ssim: 0.0460
  iou: 0.1443
Layer 0 metrics:
  pearson_correlation: 0.0031
  kl_divergence: -4595.8394
  ssim: 0.0460
  iou: 0.1443

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.47395, std: 0.11477

Metrics for layer 1:
  pearson_correlation: 0.0038
  kl_divergence: -4941.7290
  ssim: 0.0476
  iou: 0.1449
Layer 1 metrics:
  pearson_correlation: 0.0038
  kl_divergence: -4941.7290
  ssim: 0.0476
  iou: 0.1449

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.45952, std: 0.13404

Metrics for layer 2:
  pearson_correlation: -0.0006
  kl_divergence: -1394.2821
  ssim: 0.0535
  iou: 0.1389
Layer 2 metrics:
  pearson_correlation: -0.0006
  kl_divergence: -1394.2821
  ssim: 0.0535
  iou: 0.1389

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.44682, std: 0.12640

Metrics for layer 3:
  pearson_correlation: 0.0049
  kl_divergence: -1368.9531
  ssim: 0.0576
  iou: 0.1500
Layer 3 metrics:
  pearson_correlation: 0.0049
  kl_divergence: -1368.9531
  ssim: 0.0576
  iou: 0.1500

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50180, std: 0.15597

Metrics for layer 4:
  pearson_correlation: -0.0087
  kl_divergence: -381.7893
  ssim: 0.0485
  iou: 0.1297
Layer 4 metrics:
  pearson_correlation: -0.0087
  kl_divergence: -381.7893
  ssim: 0.0485
  iou: 0.1297

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.48368, std: 0.14020

Metrics for layer 5:
  pearson_correlation: -0.0101
  kl_divergence: -379.1096
  ssim: 0.0528
  iou: 0.1429
Layer 5 metrics:
  pearson_correlation: -0.0101
  kl_divergence: -379.1096
  ssim: 0.0528
  iou: 0.1429

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.57595, std: 0.13581

Metrics for layer 6:
  pearson_correlation: 0.0298
  kl_divergence: -448.0533
  ssim: 0.0511
  iou: 0.1479
Layer 6 metrics:
  pearson_correlation: 0.0298
  kl_divergence: -448.0533
  ssim: 0.0511
  iou: 0.1479

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.46757, std: 0.15728

Metrics for layer 7:
  pearson_correlation: 0.0558
  kl_divergence: -88.7970
  ssim: 0.0819
  iou: 0.1362
Layer 7 metrics:
  pearson_correlation: 0.0558
  kl_divergence: -88.7970
  ssim: 0.0819
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.53796, std: 0.15713

Metrics for layer 8:
  pearson_correlation: -0.0091
  kl_divergence: -101.1979
  ssim: 0.0446
  iou: 0.1429
Layer 8 metrics:
  pearson_correlation: -0.0091
  kl_divergence: -101.1979
  ssim: 0.0446
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.47588, std: 0.16636

Metrics for layer 9:
  pearson_correlation: 0.0437
  kl_divergence: -87.7804
  ssim: 0.0478
  iou: 0.1496
Layer 9 metrics:
  pearson_correlation: 0.0437
  kl_divergence: -87.7804
  ssim: 0.0478
  iou: 0.1496

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.43907, std: 0.20407

Metrics for layer 10:
  pearson_correlation: -0.0477
  kl_divergence: -14.9215
  ssim: 0.0319
  iou: 0.1136
Layer 10 metrics:
  pearson_correlation: -0.0477
  kl_divergence: -14.9215
  ssim: 0.0319
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.53376, std: 0.19473

Metrics for layer 11:
  pearson_correlation: 0.0677
  kl_divergence: -22.9546
  ssim: 0.0777
  iou: 0.1667
Layer 11 metrics:
  pearson_correlation: 0.0677
  kl_divergence: -22.9546
  ssim: 0.0777
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49603, std: 0.18330

Metrics for layer 12:
  pearson_correlation: -0.0507
  kl_divergence: -21.5234
  ssim: -0.0084
  iou: 0.1136
Layer 12 metrics:
  pearson_correlation: -0.0507
  kl_divergence: -21.5234
  ssim: -0.0084
  iou: 0.1136
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer7/batch_0_strength_0.4_results.npy

Processing batch 2/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.44574, std: 0.12154

Metrics for layer 0:
  pearson_correlation: 0.0008
  kl_divergence: -3866.1082
  ssim: 0.0324
  iou: 0.1450
Layer 0 metrics:
  pearson_correlation: 0.0008
  kl_divergence: -3866.1082
  ssim: 0.0324
  iou: 0.1450

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.46143, std: 0.11818

Metrics for layer 1:
  pearson_correlation: 0.0008
  kl_divergence: -3939.5532
  ssim: 0.0321
  iou: 0.1421
Layer 1 metrics:
  pearson_correlation: 0.0008
  kl_divergence: -3939.5532
  ssim: 0.0321
  iou: 0.1421

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.46419, std: 0.13256

Metrics for layer 2:
  pearson_correlation: 0.0194
  kl_divergence: -1382.4431
  ssim: 0.0473
  iou: 0.1504
Layer 2 metrics:
  pearson_correlation: 0.0194
  kl_divergence: -1382.4431
  ssim: 0.0473
  iou: 0.1504

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.44531, std: 0.12702

Metrics for layer 3:
  pearson_correlation: 0.0047
  kl_divergence: -1341.1670
  ssim: 0.0539
  iou: 0.1472
Layer 3 metrics:
  pearson_correlation: 0.0047
  kl_divergence: -1341.1670
  ssim: 0.0539
  iou: 0.1472

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.49432, std: 0.13826

Metrics for layer 4:
  pearson_correlation: -0.0075
  kl_divergence: -401.5521
  ssim: 0.0483
  iou: 0.1346
Layer 4 metrics:
  pearson_correlation: -0.0075
  kl_divergence: -401.5521
  ssim: 0.0483
  iou: 0.1346

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.50578, std: 0.14418

Metrics for layer 5:
  pearson_correlation: -0.0030
  kl_divergence: -407.0548
  ssim: 0.0446
  iou: 0.1404
Layer 5 metrics:
  pearson_correlation: -0.0030
  kl_divergence: -407.0548
  ssim: 0.0446
  iou: 0.1404

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.45571, std: 0.14886

Metrics for layer 6:
  pearson_correlation: 0.0099
  kl_divergence: -366.4725
  ssim: 0.0589
  iou: 0.1379
Layer 6 metrics:
  pearson_correlation: 0.0099
  kl_divergence: -366.4725
  ssim: 0.0589
  iou: 0.1379

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.48744, std: 0.16255

Metrics for layer 7:
  pearson_correlation: -0.0233
  kl_divergence: -86.0137
  ssim: 0.0261
  iou: 0.1496
Layer 7 metrics:
  pearson_correlation: -0.0233
  kl_divergence: -86.0137
  ssim: 0.0261
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.49606, std: 0.13472

Metrics for layer 8:
  pearson_correlation: 0.0834
  kl_divergence: -91.4584
  ssim: 0.0625
  iou: 0.1951
Layer 8 metrics:
  pearson_correlation: 0.0834
  kl_divergence: -91.4584
  ssim: 0.0625
  iou: 0.1951

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.45758, std: 0.16318

Metrics for layer 9:
  pearson_correlation: 0.0143
  kl_divergence: -83.8505
  ssim: 0.0419
  iou: 0.1329
Layer 9 metrics:
  pearson_correlation: 0.0143
  kl_divergence: -83.8505
  ssim: 0.0419
  iou: 0.1329

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.52835, std: 0.19741

Metrics for layer 10:
  pearson_correlation: -0.0093
  kl_divergence: -21.3218
  ssim: -0.0010
  iou: 0.1667
Layer 10 metrics:
  pearson_correlation: -0.0093
  kl_divergence: -21.3218
  ssim: -0.0010
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.50787, std: 0.15653

Metrics for layer 11:
  pearson_correlation: 0.0081
  kl_divergence: -22.1786
  ssim: 0.0695
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: 0.0081
  kl_divergence: -22.1786
  ssim: 0.0695
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.50297, std: 0.15142

Metrics for layer 12:
  pearson_correlation: 0.0311
  kl_divergence: -21.9199
  ssim: 0.0551
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: 0.0311
  kl_divergence: -21.9199
  ssim: 0.0551
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer7/batch_1_strength_0.4_results.npy

Processing attention strength 0.8
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.8 0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42435, std: 0.12413

Metrics for layer 0:
  pearson_correlation: -0.0047
  kl_divergence: -4547.8477
  ssim: 0.0462
  iou: 0.1426
Layer 0 metrics:
  pearson_correlation: -0.0047
  kl_divergence: -4547.8477
  ssim: 0.0462
  iou: 0.1426

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.46121, std: 0.11699

Metrics for layer 1:
  pearson_correlation: -0.0030
  kl_divergence: -4841.4829
  ssim: 0.0464
  iou: 0.1429
Layer 1 metrics:
  pearson_correlation: -0.0030
  kl_divergence: -4841.4829
  ssim: 0.0464
  iou: 0.1429

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.45405, std: 0.11890

Metrics for layer 2:
  pearson_correlation: -0.0156
  kl_divergence: -1387.9384
  ssim: 0.0607
  iou: 0.1366
Layer 2 metrics:
  pearson_correlation: -0.0156
  kl_divergence: -1387.9384
  ssim: 0.0607
  iou: 0.1366

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.47840, std: 0.13086

Metrics for layer 3:
  pearson_correlation: -0.0071
  kl_divergence: -1438.8450
  ssim: 0.0514
  iou: 0.1387
Layer 3 metrics:
  pearson_correlation: -0.0071
  kl_divergence: -1438.8450
  ssim: 0.0514
  iou: 0.1387

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.48726, std: 0.14151

Metrics for layer 4:
  pearson_correlation: 0.0018
  kl_divergence: -383.8548
  ssim: 0.0551
  iou: 0.1429
Layer 4 metrics:
  pearson_correlation: 0.0018
  kl_divergence: -383.8548
  ssim: 0.0551
  iou: 0.1429

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46946, std: 0.12714

Metrics for layer 5:
  pearson_correlation: -0.0120
  kl_divergence: -369.1354
  ssim: 0.0622
  iou: 0.1248
Layer 5 metrics:
  pearson_correlation: -0.0120
  kl_divergence: -369.1354
  ssim: 0.0622
  iou: 0.1248

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.55129, std: 0.14021

Metrics for layer 6:
  pearson_correlation: 0.0129
  kl_divergence: -430.9246
  ssim: 0.0597
  iou: 0.1563
Layer 6 metrics:
  pearson_correlation: 0.0129
  kl_divergence: -430.9246
  ssim: 0.0597
  iou: 0.1563

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.46632, std: 0.16365

Metrics for layer 7:
  pearson_correlation: 0.0120
  kl_divergence: -85.5509
  ssim: 0.0616
  iou: 0.1264
Layer 7 metrics:
  pearson_correlation: 0.0120
  kl_divergence: -85.5509
  ssim: 0.0616
  iou: 0.1264

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.46799, std: 0.16249

Metrics for layer 8:
  pearson_correlation: 0.0268
  kl_divergence: -86.8046
  ssim: 0.0893
  iou: 0.1462
Layer 8 metrics:
  pearson_correlation: 0.0268
  kl_divergence: -86.8046
  ssim: 0.0893
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.48988, std: 0.14954

Metrics for layer 9:
  pearson_correlation: 0.0531
  kl_divergence: -94.2288
  ssim: 0.0796
  iou: 0.1632
Layer 9 metrics:
  pearson_correlation: 0.0531
  kl_divergence: -94.2288
  ssim: 0.0796
  iou: 0.1632

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.56187, std: 0.20600

Metrics for layer 10:
  pearson_correlation: -0.1122
  kl_divergence: -20.4606
  ssim: -0.0680
  iou: 0.1264
Layer 10 metrics:
  pearson_correlation: -0.1122
  kl_divergence: -20.4606
  ssim: -0.0680
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.53125, std: 0.19601

Metrics for layer 11:
  pearson_correlation: -0.0731
  kl_divergence: -23.6166
  ssim: 0.0022
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: -0.0731
  kl_divergence: -23.6166
  ssim: 0.0022
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.45277, std: 0.17950

Metrics for layer 12:
  pearson_correlation: -0.0045
  kl_divergence: -17.0382
  ssim: -0.0110
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: -0.0045
  kl_divergence: -17.0382
  ssim: -0.0110
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer7/batch_0_strength_0.8_results.npy

Processing batch 2/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.48991, std: 0.12200

Metrics for layer 0:
  pearson_correlation: -0.0011
  kl_divergence: -4055.1753
  ssim: 0.0297
  iou: 0.1424
Layer 0 metrics:
  pearson_correlation: -0.0011
  kl_divergence: -4055.1753
  ssim: 0.0297
  iou: 0.1424

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43316, std: 0.11507

Metrics for layer 1:
  pearson_correlation: 0.0054
  kl_divergence: -3820.3921
  ssim: 0.0361
  iou: 0.1453
Layer 1 metrics:
  pearson_correlation: 0.0054
  kl_divergence: -3820.3921
  ssim: 0.0361
  iou: 0.1453

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.42765, std: 0.12038

Metrics for layer 2:
  pearson_correlation: -0.0066
  kl_divergence: -1304.5371
  ssim: 0.0574
  iou: 0.1348
Layer 2 metrics:
  pearson_correlation: -0.0066
  kl_divergence: -1304.5371
  ssim: 0.0574
  iou: 0.1348

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.48633, std: 0.14397

Metrics for layer 3:
  pearson_correlation: -0.0029
  kl_divergence: -1415.7421
  ssim: 0.0402
  iou: 0.1462
Layer 3 metrics:
  pearson_correlation: -0.0029
  kl_divergence: -1415.7421
  ssim: 0.0402
  iou: 0.1462

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.45103, std: 0.14244

Metrics for layer 4:
  pearson_correlation: -0.0129
  kl_divergence: -360.6854
  ssim: 0.0551
  iou: 0.1404
Layer 4 metrics:
  pearson_correlation: -0.0129
  kl_divergence: -360.6854
  ssim: 0.0551
  iou: 0.1404

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.50174, std: 0.14076

Metrics for layer 5:
  pearson_correlation: -0.0212
  kl_divergence: -404.3864
  ssim: 0.0435
  iou: 0.1338
Layer 5 metrics:
  pearson_correlation: -0.0212
  kl_divergence: -404.3864
  ssim: 0.0435
  iou: 0.1338

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.51044, std: 0.13608

Metrics for layer 6:
  pearson_correlation: 0.0061
  kl_divergence: -415.1335
  ssim: 0.0635
  iou: 0.1354
Layer 6 metrics:
  pearson_correlation: 0.0061
  kl_divergence: -415.1335
  ssim: 0.0635
  iou: 0.1354

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.56555, std: 0.14278

Metrics for layer 7:
  pearson_correlation: 0.0175
  kl_divergence: -98.4043
  ssim: 0.0449
  iou: 0.1362
Layer 7 metrics:
  pearson_correlation: 0.0175
  kl_divergence: -98.4043
  ssim: 0.0449
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.42192, std: 0.15606

Metrics for layer 8:
  pearson_correlation: -0.0319
  kl_divergence: -77.5393
  ssim: 0.0330
  iou: 0.1011
Layer 8 metrics:
  pearson_correlation: -0.0319
  kl_divergence: -77.5393
  ssim: 0.0330
  iou: 0.1011

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.54197, std: 0.15259

Metrics for layer 9:
  pearson_correlation: -0.0294
  kl_divergence: -92.1107
  ssim: 0.0202
  iou: 0.1362
Layer 9 metrics:
  pearson_correlation: -0.0294
  kl_divergence: -92.1107
  ssim: 0.0202
  iou: 0.1362

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.44995, std: 0.16255

Metrics for layer 10:
  pearson_correlation: -0.0648
  kl_divergence: -14.7488
  ssim: 0.0140
  iou: 0.0769
Layer 10 metrics:
  pearson_correlation: -0.0648
  kl_divergence: -14.7488
  ssim: 0.0140
  iou: 0.0769

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.48343, std: 0.16583

Metrics for layer 11:
  pearson_correlation: -0.0747
  kl_divergence: -18.3892
  ssim: -0.0838
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: -0.0747
  kl_divergence: -18.3892
  ssim: -0.0838
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.54470, std: 0.16523

Metrics for layer 12:
  pearson_correlation: -0.0387
  kl_divergence: -22.8045
  ssim: 0.0043
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: -0.0387
  kl_divergence: -22.8045
  ssim: 0.0043
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer7/batch_1_strength_0.8_results.npy

Processing attention strength 1.2
Attention vector: [0.  0.  0.  0.  0.  0.  0.  1.2 0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.41490, std: 0.12285

Metrics for layer 0:
  pearson_correlation: 0.0008
  kl_divergence: -4480.0742
  ssim: 0.0485
  iou: 0.1430
Layer 0 metrics:
  pearson_correlation: 0.0008
  kl_divergence: -4480.0742
  ssim: 0.0485
  iou: 0.1430

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.43605, std: 0.12222

Metrics for layer 1:
  pearson_correlation: -0.0002
  kl_divergence: -4648.9341
  ssim: 0.0470
  iou: 0.1424
Layer 1 metrics:
  pearson_correlation: -0.0002
  kl_divergence: -4648.9341
  ssim: 0.0470
  iou: 0.1424

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.44857, std: 0.12752

Metrics for layer 2:
  pearson_correlation: 0.0046
  kl_divergence: -1374.3809
  ssim: 0.0602
  iou: 0.1458
Layer 2 metrics:
  pearson_correlation: 0.0046
  kl_divergence: -1374.3809
  ssim: 0.0602
  iou: 0.1458

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.45656, std: 0.13424

Metrics for layer 3:
  pearson_correlation: -0.0047
  kl_divergence: -1383.9839
  ssim: 0.0535
  iou: 0.1414
Layer 3 metrics:
  pearson_correlation: -0.0047
  kl_divergence: -1383.9839
  ssim: 0.0535
  iou: 0.1414

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47417, std: 0.13051

Metrics for layer 4:
  pearson_correlation: -0.0070
  kl_divergence: -374.1836
  ssim: 0.0663
  iou: 0.1404
Layer 4 metrics:
  pearson_correlation: -0.0070
  kl_divergence: -374.1836
  ssim: 0.0663
  iou: 0.1404

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46250, std: 0.13108

Metrics for layer 5:
  pearson_correlation: 0.0122
  kl_divergence: -357.9631
  ssim: 0.0667
  iou: 0.1546
Layer 5 metrics:
  pearson_correlation: 0.0122
  kl_divergence: -357.9631
  ssim: 0.0667
  iou: 0.1546

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.42728, std: 0.13224

Metrics for layer 6:
  pearson_correlation: -0.0088
  kl_divergence: -333.0736
  ssim: 0.0720
  iou: 0.1305
Layer 6 metrics:
  pearson_correlation: -0.0088
  kl_divergence: -333.0736
  ssim: 0.0720
  iou: 0.1305

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.60072, std: 0.15377

Metrics for layer 7:
  pearson_correlation: -0.0132
  kl_divergence: -113.0887
  ssim: 0.0449
  iou: 0.1329
Layer 7 metrics:
  pearson_correlation: -0.0132
  kl_divergence: -113.0887
  ssim: 0.0449
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.50391, std: 0.16933

Metrics for layer 8:
  pearson_correlation: 0.0004
  kl_divergence: -94.2146
  ssim: 0.0792
  iou: 0.1496
Layer 8 metrics:
  pearson_correlation: 0.0004
  kl_divergence: -94.2146
  ssim: 0.0792
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.42768, std: 0.15749

Metrics for layer 9:
  pearson_correlation: -0.0163
  kl_divergence: -77.5174
  ssim: 0.0434
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: -0.0163
  kl_divergence: -77.5174
  ssim: 0.0434
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.55133, std: 0.19224

Metrics for layer 10:
  pearson_correlation: 0.0150
  kl_divergence: -25.8907
  ssim: 0.1398
  iou: 0.1395
Layer 10 metrics:
  pearson_correlation: 0.0150
  kl_divergence: -25.8907
  ssim: 0.1398
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.43543, std: 0.17361

Metrics for layer 11:
  pearson_correlation: -0.1192
  kl_divergence: -11.4918
  ssim: -0.1428
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: -0.1192
  kl_divergence: -11.4918
  ssim: -0.1428
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.47323, std: 0.21131

Metrics for layer 12:
  pearson_correlation: -0.0385
  kl_divergence: -5.6825
  ssim: -0.0299
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: -0.0385
  kl_divergence: -5.6825
  ssim: -0.0299
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer7/batch_0_strength_1.2_results.npy

Processing batch 2/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43984, std: 0.12466

Metrics for layer 0:
  pearson_correlation: 0.0051
  kl_divergence: -3835.7915
  ssim: 0.0313
  iou: 0.1435
Layer 0 metrics:
  pearson_correlation: 0.0051
  kl_divergence: -3835.7915
  ssim: 0.0313
  iou: 0.1435

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.42938, std: 0.12293

Metrics for layer 1:
  pearson_correlation: 0.0047
  kl_divergence: -3790.4727
  ssim: 0.0329
  iou: 0.1443
Layer 1 metrics:
  pearson_correlation: 0.0047
  kl_divergence: -3790.4727
  ssim: 0.0329
  iou: 0.1443

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.44654, std: 0.13839

Metrics for layer 2:
  pearson_correlation: -0.0057
  kl_divergence: -1335.3601
  ssim: 0.0467
  iou: 0.1381
Layer 2 metrics:
  pearson_correlation: -0.0057
  kl_divergence: -1335.3601
  ssim: 0.0467
  iou: 0.1381

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.44717, std: 0.11291

Metrics for layer 3:
  pearson_correlation: 0.0083
  kl_divergence: -1354.9502
  ssim: 0.0608
  iou: 0.1481
Layer 3 metrics:
  pearson_correlation: 0.0083
  kl_divergence: -1354.9502
  ssim: 0.0608
  iou: 0.1481

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48027, std: 0.14642

Metrics for layer 4:
  pearson_correlation: 0.0254
  kl_divergence: -387.0942
  ssim: 0.0618
  iou: 0.1563
Layer 4 metrics:
  pearson_correlation: 0.0254
  kl_divergence: -387.0942
  ssim: 0.0618
  iou: 0.1563

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.43873, std: 0.13556

Metrics for layer 5:
  pearson_correlation: -0.0143
  kl_divergence: -347.1562
  ssim: 0.0574
  iou: 0.1412
Layer 5 metrics:
  pearson_correlation: -0.0143
  kl_divergence: -347.1562
  ssim: 0.0574
  iou: 0.1412

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47708, std: 0.15214

Metrics for layer 6:
  pearson_correlation: -0.0195
  kl_divergence: -381.0433
  ssim: 0.0440
  iou: 0.1338
Layer 6 metrics:
  pearson_correlation: -0.0195
  kl_divergence: -381.0433
  ssim: 0.0440
  iou: 0.1338

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.44108, std: 0.14025

Metrics for layer 7:
  pearson_correlation: -0.0012
  kl_divergence: -81.7221
  ssim: 0.0421
  iou: 0.1529
Layer 7 metrics:
  pearson_correlation: -0.0012
  kl_divergence: -81.7221
  ssim: 0.0421
  iou: 0.1529

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.46821, std: 0.17540

Metrics for layer 8:
  pearson_correlation: 0.1055
  kl_divergence: -86.6397
  ssim: 0.0608
  iou: 0.1667
Layer 8 metrics:
  pearson_correlation: 0.1055
  kl_divergence: -86.6397
  ssim: 0.0608
  iou: 0.1667

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.54707, std: 0.14202

Metrics for layer 9:
  pearson_correlation: -0.0525
  kl_divergence: -96.3077
  ssim: 0.0242
  iou: 0.1168
Layer 9 metrics:
  pearson_correlation: -0.0525
  kl_divergence: -96.3077
  ssim: 0.0242
  iou: 0.1168

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.49932, std: 0.16897

Metrics for layer 10:
  pearson_correlation: -0.0164
  kl_divergence: -11.3653
  ssim: -0.0373
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: -0.0164
  kl_divergence: -11.3653
  ssim: -0.0373
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.49181, std: 0.20802

Metrics for layer 11:
  pearson_correlation: 0.0126
  kl_divergence: -14.2342
  ssim: 0.0843
  iou: 0.1807
Layer 11 metrics:
  pearson_correlation: 0.0126
  kl_divergence: -14.2342
  ssim: 0.0843
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.53269, std: 0.18157

Metrics for layer 12:
  pearson_correlation: -0.0392
  kl_divergence: -23.0780
  ssim: -0.0030
  iou: 0.1264
Layer 12 metrics:
  pearson_correlation: -0.0392
  kl_divergence: -23.0780
  ssim: -0.0030
  iou: 0.1264
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer7/batch_1_strength_1.2_results.npy

Analysis complete! Results saved to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer7
Completed experiment for category 5, layer 7
----------------------------------------
Running experiment for category 5, layer 8
===================================================
Starting experiment:
Category: 5
Layer: 8
Logs will be saved to: /scratch/hy2611/CNN_attention/logs/attention_analysis_20241216_104146/category5/layer8
===================================================
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-12-16 11:03:52.445482: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-16 11:03:52.464504: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2024-12-16 11:03:52.465039: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4dbbea0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:03:52.465054: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-16 11:03:52.467734: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-16 11:03:52.597407: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4db9170 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:03:52.597428: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-12-16 11:03:52.597980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:2f:00.0
2024-12-16 11:03:52.599117: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:03:52.600092: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:03:52.601038: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:03:52.601967: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:03:52.602894: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:03:52.603815: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:03:52.604738: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:03:52.604749: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-12-16 11:03:52.604767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-16 11:03:52.604772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-16 11:03:52.604775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:61: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:87: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:15: sigmoid_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.sigmoid_cross_entropy instead. Note that the order of the predictions and labels arguments has been changed.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:322: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:82: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.


Verifying paths:
tc_path: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs exists
weight_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists
image_path: /scratch/hy2611/CNN_attention/Data/VGG16/images exists
save_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists

Initializing model...
('c11', [1, 224, 224, 64])
('c12', [1, 224, 224, 64])
('c21', [1, 112, 112, 128])
('c22', [1, 112, 112, 128])
('c31', [1, 56, 56, 256])
('c32', [1, 56, 56, 256])
('c33', [1, 56, 56, 256])
('c41', [1, 28, 28, 512])
('c42', [1, 28, 28, 512])
('c43', [1, 28, 28, 512])
('c51', [1, 14, 14, 512])
('c52', [1, 14, 14, 512])
('c53', [1, 14, 14, 512])
(0, 'conv1_1_W', (3, 3, 3, 64))
(1, 'conv1_1_b', (64,))
(2, 'conv1_2_W', (3, 3, 64, 64))
(3, 'conv1_2_b', (64,))
(4, 'conv2_1_W', (3, 3, 64, 128))
(5, 'conv2_1_b', (128,))
(6, 'conv2_2_W', (3, 3, 128, 128))
(7, 'conv2_2_b', (128,))
(8, 'conv3_1_W', (3, 3, 128, 256))
(9, 'conv3_1_b', (256,))
(10, 'conv3_2_W', (3, 3, 256, 256))
(11, 'conv3_2_b', (256,))
(12, 'conv3_3_W', (3, 3, 256, 256))
(13, 'conv3_3_b', (256,))
(14, 'conv4_1_W', (3, 3, 256, 512))
(15, 'conv4_1_b', (512,))
(16, 'conv4_2_W', (3, 3, 512, 512))
(17, 'conv4_2_b', (512,))
(18, 'conv4_3_W', (3, 3, 512, 512))
(19, 'conv4_3_b', (512,))
(20, 'conv5_1_W', (3, 3, 512, 512))
(21, 'conv5_1_b', (512,))
(22, 'conv5_2_W', (3, 3, 512, 512))
(23, 'conv5_2_b', (512,))
(24, 'conv5_3_W', (3, 3, 512, 512))
(25, 'conv5_3_b', (512,))
(26, 'fc6_W', (25088, 4096))
(27, 'fc6_b', (4096,))
(28, 'fc7_W', (4096, 4096))
(29, 'fc7_b', (4096,))
Checking checkpoint files:
Data file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.data-00000-of-00001 - Found
Index file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.index - Found
Loading checkpoint from: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt
Checkpoint loaded successfully

Initializing components...
Found tuning curves file: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs/featvecs20_train35_c.txt

Loading category 5 data...
Original positive images shape: (2, 224, 224, 3)

Processing data...

Processing attention strength 0.0
Attention vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

Processing batch 1/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.41419, std: 0.11285

Metrics for layer 0:
  pearson_correlation: -0.0032
  kl_divergence: -4495.4097
  ssim: 0.0547
  iou: 0.1388
Layer 0 metrics:
  pearson_correlation: -0.0032
  kl_divergence: -4495.4097
  ssim: 0.0547
  iou: 0.1388

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.40731, std: 0.12081

Metrics for layer 1:
  pearson_correlation: 0.0015
  kl_divergence: -4421.3105
  ssim: 0.0518
  iou: 0.1452
Layer 1 metrics:
  pearson_correlation: 0.0015
  kl_divergence: -4421.3105
  ssim: 0.0518
  iou: 0.1452

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.43593, std: 0.12838

Metrics for layer 2:
  pearson_correlation: -0.0019
  kl_divergence: -1339.3843
  ssim: 0.0568
  iou: 0.1364
Layer 2 metrics:
  pearson_correlation: -0.0019
  kl_divergence: -1339.3843
  ssim: 0.0568
  iou: 0.1364

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.38790, std: 0.12417

Metrics for layer 3:
  pearson_correlation: -0.0039
  kl_divergence: -1211.1510
  ssim: 0.0641
  iou: 0.1435
Layer 3 metrics:
  pearson_correlation: -0.0039
  kl_divergence: -1211.1510
  ssim: 0.0641
  iou: 0.1435

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.52122, std: 0.13993

Metrics for layer 4:
  pearson_correlation: -0.0113
  kl_divergence: -404.6023
  ssim: 0.0489
  iou: 0.1329
Layer 4 metrics:
  pearson_correlation: -0.0113
  kl_divergence: -404.6023
  ssim: 0.0489
  iou: 0.1329

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.39932, std: 0.12522

Metrics for layer 5:
  pearson_correlation: 0.0001
  kl_divergence: -311.1608
  ssim: 0.0814
  iou: 0.1338
Layer 5 metrics:
  pearson_correlation: 0.0001
  kl_divergence: -311.1608
  ssim: 0.0814
  iou: 0.1338

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.40023, std: 0.14173

Metrics for layer 6:
  pearson_correlation: 0.0036
  kl_divergence: -300.5494
  ssim: 0.0604
  iou: 0.1437
Layer 6 metrics:
  pearson_correlation: 0.0036
  kl_divergence: -300.5494
  ssim: 0.0604
  iou: 0.1437

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.55308, std: 0.14900

Metrics for layer 7:
  pearson_correlation: 0.0129
  kl_divergence: -107.0383
  ssim: 0.0455
  iou: 0.1136
Layer 7 metrics:
  pearson_correlation: 0.0129
  kl_divergence: -107.0383
  ssim: 0.0455
  iou: 0.1136

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.49583, std: 0.17798

Metrics for layer 8:
  pearson_correlation: 0.0159
  kl_divergence: -91.6355
  ssim: 0.0532
  iou: 0.1429
Layer 8 metrics:
  pearson_correlation: 0.0159
  kl_divergence: -91.6355
  ssim: 0.0532
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.42174, std: 0.14751

Metrics for layer 9:
  pearson_correlation: 0.0288
  kl_divergence: -73.3508
  ssim: 0.0750
  iou: 0.1737
Layer 9 metrics:
  pearson_correlation: 0.0288
  kl_divergence: -73.3508
  ssim: 0.0750
  iou: 0.1737

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.48100, std: 0.19441

Metrics for layer 10:
  pearson_correlation: -0.0776
  kl_divergence: -8.8395
  ssim: 0.0455
  iou: 0.1395
Layer 10 metrics:
  pearson_correlation: -0.0776
  kl_divergence: -8.8395
  ssim: 0.0455
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.53573, std: 0.21619

Metrics for layer 11:
  pearson_correlation: 0.0683
  kl_divergence: -20.4757
  ssim: 0.0544
  iou: 0.1951
Layer 11 metrics:
  pearson_correlation: 0.0683
  kl_divergence: -20.4757
  ssim: 0.0544
  iou: 0.1951

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.48329, std: 0.17250

Metrics for layer 12:
  pearson_correlation: 0.0230
  kl_divergence: -20.3150
  ssim: 0.0888
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: 0.0230
  kl_divergence: -20.3150
  ssim: 0.0888
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer8/batch_0_strength_0.0_results.npy

Processing batch 2/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.45178, std: 0.11383

Metrics for layer 0:
  pearson_correlation: -0.0009
  kl_divergence: -3902.3206
  ssim: 0.0345
  iou: 0.1420
Layer 0 metrics:
  pearson_correlation: -0.0009
  kl_divergence: -3902.3206
  ssim: 0.0345
  iou: 0.1420

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.45701, std: 0.12470

Metrics for layer 1:
  pearson_correlation: 0.0021
  kl_divergence: -3911.8291
  ssim: 0.0303
  iou: 0.1442
Layer 1 metrics:
  pearson_correlation: 0.0021
  kl_divergence: -3911.8291
  ssim: 0.0303
  iou: 0.1442

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.45815, std: 0.13799

Metrics for layer 2:
  pearson_correlation: -0.0090
  kl_divergence: -1356.4612
  ssim: 0.0431
  iou: 0.1445
Layer 2 metrics:
  pearson_correlation: -0.0090
  kl_divergence: -1356.4612
  ssim: 0.0431
  iou: 0.1445

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.40345, std: 0.12363

Metrics for layer 3:
  pearson_correlation: -0.0042
  kl_divergence: -1246.0549
  ssim: 0.0581
  iou: 0.1389
Layer 3 metrics:
  pearson_correlation: -0.0042
  kl_divergence: -1246.0549
  ssim: 0.0581
  iou: 0.1389

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47354, std: 0.15086

Metrics for layer 4:
  pearson_correlation: -0.0046
  kl_divergence: -377.1266
  ssim: 0.0471
  iou: 0.1470
Layer 4 metrics:
  pearson_correlation: -0.0046
  kl_divergence: -377.1266
  ssim: 0.0471
  iou: 0.1470

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.46460, std: 0.15058

Metrics for layer 5:
  pearson_correlation: -0.0128
  kl_divergence: -371.6245
  ssim: 0.0411
  iou: 0.1445
Layer 5 metrics:
  pearson_correlation: -0.0128
  kl_divergence: -371.6245
  ssim: 0.0411
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.41305, std: 0.13099

Metrics for layer 6:
  pearson_correlation: -0.0000
  kl_divergence: -330.1843
  ssim: 0.0631
  iou: 0.1420
Layer 6 metrics:
  pearson_correlation: -0.0000
  kl_divergence: -330.1843
  ssim: 0.0631
  iou: 0.1420

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.47051, std: 0.17153

Metrics for layer 7:
  pearson_correlation: -0.0145
  kl_divergence: -84.1196
  ssim: 0.0341
  iou: 0.1329
Layer 7 metrics:
  pearson_correlation: -0.0145
  kl_divergence: -84.1196
  ssim: 0.0341
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.51306, std: 0.16387

Metrics for layer 8:
  pearson_correlation: -0.0645
  kl_divergence: -90.5108
  ssim: 0.0094
  iou: 0.0919
Layer 8 metrics:
  pearson_correlation: -0.0645
  kl_divergence: -90.5108
  ssim: 0.0094
  iou: 0.0919

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.47040, std: 0.16928

Metrics for layer 9:
  pearson_correlation: -0.0122
  kl_divergence: -82.4620
  ssim: 0.0290
  iou: 0.1462
Layer 9 metrics:
  pearson_correlation: -0.0122
  kl_divergence: -82.4620
  ssim: 0.0290
  iou: 0.1462

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.49735, std: 0.19464

Metrics for layer 10:
  pearson_correlation: -0.0314
  kl_divergence: -16.9522
  ssim: 0.0281
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: -0.0314
  kl_divergence: -16.9522
  ssim: 0.0281
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.47724, std: 0.19879

Metrics for layer 11:
  pearson_correlation: 0.0055
  kl_divergence: -17.6879
  ssim: 0.0513
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: 0.0055
  kl_divergence: -17.6879
  ssim: 0.0513
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.44567, std: 0.19125

Metrics for layer 12:
  pearson_correlation: -0.0286
  kl_divergence: 1.4172
  ssim: 0.0029
  iou: 0.1011
Layer 12 metrics:
  pearson_correlation: -0.0286
  kl_divergence: 1.4172
  ssim: 0.0029
  iou: 0.1011
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer8/batch_1_strength_0.0_results.npy

Processing attention strength 0.4
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.  0.4 0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.44819, std: 0.12099

Metrics for layer 0:
  pearson_correlation: 0.0022
  kl_divergence: -4744.2822
  ssim: 0.0474
  iou: 0.1443
Layer 0 metrics:
  pearson_correlation: 0.0022
  kl_divergence: -4744.2822
  ssim: 0.0474
  iou: 0.1443

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.41850, std: 0.11494

Metrics for layer 1:
  pearson_correlation: 0.0029
  kl_divergence: -4532.8076
  ssim: 0.0527
  iou: 0.1435
Layer 1 metrics:
  pearson_correlation: 0.0029
  kl_divergence: -4532.8076
  ssim: 0.0527
  iou: 0.1435

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.44751, std: 0.13378

Metrics for layer 2:
  pearson_correlation: 0.0006
  kl_divergence: -1365.4304
  ssim: 0.0542
  iou: 0.1356
Layer 2 metrics:
  pearson_correlation: 0.0006
  kl_divergence: -1365.4304
  ssim: 0.0542
  iou: 0.1356

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.42467, std: 0.12969

Metrics for layer 3:
  pearson_correlation: 0.0089
  kl_divergence: -1311.3518
  ssim: 0.0593
  iou: 0.1487
Layer 3 metrics:
  pearson_correlation: 0.0089
  kl_divergence: -1311.3518
  ssim: 0.0593
  iou: 0.1487

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47354, std: 0.13623

Metrics for layer 4:
  pearson_correlation: -0.0098
  kl_divergence: -371.9889
  ssim: 0.0642
  iou: 0.1404
Layer 4 metrics:
  pearson_correlation: -0.0098
  kl_divergence: -371.9889
  ssim: 0.0642
  iou: 0.1404

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47426, std: 0.13738

Metrics for layer 5:
  pearson_correlation: 0.0099
  kl_divergence: -371.2232
  ssim: 0.0521
  iou: 0.1512
Layer 5 metrics:
  pearson_correlation: 0.0099
  kl_divergence: -371.2232
  ssim: 0.0521
  iou: 0.1512

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.49411, std: 0.14640

Metrics for layer 6:
  pearson_correlation: -0.0033
  kl_divergence: -384.0564
  ssim: 0.0502
  iou: 0.1429
Layer 6 metrics:
  pearson_correlation: -0.0033
  kl_divergence: -384.0564
  ssim: 0.0502
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.48635, std: 0.16146

Metrics for layer 7:
  pearson_correlation: -0.0307
  kl_divergence: -90.6556
  ssim: -0.0001
  iou: 0.1329
Layer 7 metrics:
  pearson_correlation: -0.0307
  kl_divergence: -90.6556
  ssim: -0.0001
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.50855, std: 0.13641

Metrics for layer 8:
  pearson_correlation: -0.0258
  kl_divergence: -92.3186
  ssim: 0.0285
  iou: 0.1395
Layer 8 metrics:
  pearson_correlation: -0.0258
  kl_divergence: -92.3186
  ssim: 0.0285
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.49503, std: 0.17319

Metrics for layer 9:
  pearson_correlation: 0.0225
  kl_divergence: -91.1664
  ssim: 0.0414
  iou: 0.1329
Layer 9 metrics:
  pearson_correlation: 0.0225
  kl_divergence: -91.1664
  ssim: 0.0414
  iou: 0.1329

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.48930, std: 0.17035

Metrics for layer 10:
  pearson_correlation: 0.0470
  kl_divergence: -21.7382
  ssim: 0.0468
  iou: 0.1395
Layer 10 metrics:
  pearson_correlation: 0.0470
  kl_divergence: -21.7382
  ssim: 0.0468
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.53820, std: 0.17305

Metrics for layer 11:
  pearson_correlation: -0.0562
  kl_divergence: -14.5435
  ssim: -0.0135
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: -0.0562
  kl_divergence: -14.5435
  ssim: -0.0135
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.47519, std: 0.18900

Metrics for layer 12:
  pearson_correlation: -0.0104
  kl_divergence: -19.7435
  ssim: 0.0653
  iou: 0.1136
Layer 12 metrics:
  pearson_correlation: -0.0104
  kl_divergence: -19.7435
  ssim: 0.0653
  iou: 0.1136
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer8/batch_0_strength_0.4_results.npy

Processing batch 2/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.41616, std: 0.11533

Metrics for layer 0:
  pearson_correlation: -0.0035
  kl_divergence: -3734.0803
  ssim: 0.0376
  iou: 0.1431
Layer 0 metrics:
  pearson_correlation: -0.0035
  kl_divergence: -3734.0803
  ssim: 0.0376
  iou: 0.1431

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.41913, std: 0.11333

Metrics for layer 1:
  pearson_correlation: -0.0033
  kl_divergence: -3752.4014
  ssim: 0.0376
  iou: 0.1422
Layer 1 metrics:
  pearson_correlation: -0.0033
  kl_divergence: -3752.4014
  ssim: 0.0376
  iou: 0.1422

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.47198, std: 0.13393

Metrics for layer 2:
  pearson_correlation: 0.0047
  kl_divergence: -1396.3801
  ssim: 0.0461
  iou: 0.1487
Layer 2 metrics:
  pearson_correlation: 0.0047
  kl_divergence: -1396.3801
  ssim: 0.0461
  iou: 0.1487

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.42535, std: 0.12359

Metrics for layer 3:
  pearson_correlation: 0.0004
  kl_divergence: -1299.3453
  ssim: 0.0579
  iou: 0.1385
Layer 3 metrics:
  pearson_correlation: 0.0004
  kl_divergence: -1299.3453
  ssim: 0.0579
  iou: 0.1385

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.50588, std: 0.14539

Metrics for layer 4:
  pearson_correlation: -0.0148
  kl_divergence: -406.6438
  ssim: 0.0500
  iou: 0.1420
Layer 4 metrics:
  pearson_correlation: -0.0148
  kl_divergence: -406.6438
  ssim: 0.0500
  iou: 0.1420

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47730, std: 0.12639

Metrics for layer 5:
  pearson_correlation: -0.0271
  kl_divergence: -388.0215
  ssim: 0.0542
  iou: 0.1338
Layer 5 metrics:
  pearson_correlation: -0.0271
  kl_divergence: -388.0215
  ssim: 0.0542
  iou: 0.1338

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47833, std: 0.15723

Metrics for layer 6:
  pearson_correlation: 0.0046
  kl_divergence: -381.6201
  ssim: 0.0542
  iou: 0.1437
Layer 6 metrics:
  pearson_correlation: 0.0046
  kl_divergence: -381.6201
  ssim: 0.0542
  iou: 0.1437

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.45192, std: 0.15815

Metrics for layer 7:
  pearson_correlation: 0.0253
  kl_divergence: -80.2214
  ssim: 0.0451
  iou: 0.1429
Layer 7 metrics:
  pearson_correlation: 0.0253
  kl_divergence: -80.2214
  ssim: 0.0451
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.44914, std: 0.14579

Metrics for layer 8:
  pearson_correlation: -0.0012
  kl_divergence: -80.3291
  ssim: 0.0409
  iou: 0.1297
Layer 8 metrics:
  pearson_correlation: -0.0012
  kl_divergence: -80.3291
  ssim: 0.0409
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.45105, std: 0.16386

Metrics for layer 9:
  pearson_correlation: -0.0355
  kl_divergence: -81.4789
  ssim: 0.0291
  iou: 0.1297
Layer 9 metrics:
  pearson_correlation: -0.0355
  kl_divergence: -81.4789
  ssim: 0.0291
  iou: 0.1297

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.44717, std: 0.20966

Metrics for layer 10:
  pearson_correlation: 0.0495
  kl_divergence: -13.6682
  ssim: 0.1431
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: 0.0495
  kl_divergence: -13.6682
  ssim: 0.1431
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.49692, std: 0.17602

Metrics for layer 11:
  pearson_correlation: 0.1202
  kl_divergence: -17.3264
  ssim: 0.1379
  iou: 0.2405
Layer 11 metrics:
  pearson_correlation: 0.1202
  kl_divergence: -17.3264
  ssim: 0.1379
  iou: 0.2405

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.47489, std: 0.19109

Metrics for layer 12:
  pearson_correlation: -0.1007
  kl_divergence: -14.6392
  ssim: -0.0494
  iou: 0.1264
Layer 12 metrics:
  pearson_correlation: -0.1007
  kl_divergence: -14.6392
  ssim: -0.0494
  iou: 0.1264
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer8/batch_1_strength_0.4_results.npy

Processing attention strength 0.8
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.  0.8 0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.44467, std: 0.12489

Metrics for layer 0:
  pearson_correlation: 0.0069
  kl_divergence: -4712.5439
  ssim: 0.0462
  iou: 0.1468
Layer 0 metrics:
  pearson_correlation: 0.0069
  kl_divergence: -4712.5439
  ssim: 0.0462
  iou: 0.1468

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.44917, std: 0.12257

Metrics for layer 1:
  pearson_correlation: 0.0022
  kl_divergence: -4747.2661
  ssim: 0.0464
  iou: 0.1448
Layer 1 metrics:
  pearson_correlation: 0.0022
  kl_divergence: -4747.2661
  ssim: 0.0464
  iou: 0.1448

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.43429, std: 0.13528

Metrics for layer 2:
  pearson_correlation: 0.0061
  kl_divergence: -1331.3613
  ssim: 0.0558
  iou: 0.1437
Layer 2 metrics:
  pearson_correlation: 0.0061
  kl_divergence: -1331.3613
  ssim: 0.0558
  iou: 0.1437

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.45502, std: 0.13410

Metrics for layer 3:
  pearson_correlation: -0.0018
  kl_divergence: -1382.1067
  ssim: 0.0519
  iou: 0.1435
Layer 3 metrics:
  pearson_correlation: -0.0018
  kl_divergence: -1382.1067
  ssim: 0.0519
  iou: 0.1435

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50843, std: 0.14674

Metrics for layer 4:
  pearson_correlation: 0.0115
  kl_divergence: -395.6738
  ssim: 0.0437
  iou: 0.1462
Layer 4 metrics:
  pearson_correlation: 0.0115
  kl_divergence: -395.6738
  ssim: 0.0437
  iou: 0.1462

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.48435, std: 0.15342

Metrics for layer 5:
  pearson_correlation: -0.0027
  kl_divergence: -375.2836
  ssim: 0.0520
  iou: 0.1487
Layer 5 metrics:
  pearson_correlation: -0.0027
  kl_divergence: -375.2836
  ssim: 0.0520
  iou: 0.1487

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.51645, std: 0.14550

Metrics for layer 6:
  pearson_correlation: -0.0195
  kl_divergence: -398.0059
  ssim: 0.0478
  iou: 0.1338
Layer 6 metrics:
  pearson_correlation: -0.0195
  kl_divergence: -398.0059
  ssim: 0.0478
  iou: 0.1338

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.55080, std: 0.14602

Metrics for layer 7:
  pearson_correlation: -0.0169
  kl_divergence: -98.5556
  ssim: 0.0407
  iou: 0.1200
Layer 7 metrics:
  pearson_correlation: -0.0169
  kl_divergence: -98.5556
  ssim: 0.0407
  iou: 0.1200

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.53251, std: 0.15743

Metrics for layer 8:
  pearson_correlation: 0.0403
  kl_divergence: -102.9299
  ssim: 0.0533
  iou: 0.1563
Layer 8 metrics:
  pearson_correlation: 0.0403
  kl_divergence: -102.9299
  ssim: 0.0533
  iou: 0.1563

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.52990, std: 0.17434

Metrics for layer 9:
  pearson_correlation: 0.0569
  kl_divergence: -101.4646
  ssim: 0.0603
  iou: 0.1563
Layer 9 metrics:
  pearson_correlation: 0.0569
  kl_divergence: -101.4646
  ssim: 0.0603
  iou: 0.1563

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.50202, std: 0.18454

Metrics for layer 10:
  pearson_correlation: -0.1562
  kl_divergence: -20.2114
  ssim: -0.0135
  iou: 0.0652
Layer 10 metrics:
  pearson_correlation: -0.1562
  kl_divergence: -20.2114
  ssim: -0.0135
  iou: 0.0652

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.51807, std: 0.17472

Metrics for layer 11:
  pearson_correlation: 0.0005
  kl_divergence: -22.7296
  ssim: 0.1290
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: 0.0005
  kl_divergence: -22.7296
  ssim: 0.1290
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.48260, std: 0.15989

Metrics for layer 12:
  pearson_correlation: 0.0347
  kl_divergence: -22.1152
  ssim: 0.1415
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: 0.0347
  kl_divergence: -22.1152
  ssim: 0.1415
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer8/batch_0_strength_0.8_results.npy

Processing batch 2/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.42536, std: 0.12025

Metrics for layer 0:
  pearson_correlation: 0.0023
  kl_divergence: -3775.2302
  ssim: 0.0337
  iou: 0.1440
Layer 0 metrics:
  pearson_correlation: 0.0023
  kl_divergence: -3775.2302
  ssim: 0.0337
  iou: 0.1440

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.37674, std: 0.10835

Metrics for layer 1:
  pearson_correlation: -0.0036
  kl_divergence: -3542.0935
  ssim: 0.0441
  iou: 0.1419
Layer 1 metrics:
  pearson_correlation: -0.0036
  kl_divergence: -3542.0935
  ssim: 0.0441
  iou: 0.1419

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.38601, std: 0.11330

Metrics for layer 2:
  pearson_correlation: -0.0072
  kl_divergence: -1208.6233
  ssim: 0.0683
  iou: 0.1498
Layer 2 metrics:
  pearson_correlation: -0.0072
  kl_divergence: -1208.6233
  ssim: 0.0683
  iou: 0.1498

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.41803, std: 0.12790

Metrics for layer 3:
  pearson_correlation: 0.0021
  kl_divergence: -1278.5359
  ssim: 0.0537
  iou: 0.1426
Layer 3 metrics:
  pearson_correlation: 0.0021
  kl_divergence: -1278.5359
  ssim: 0.0537
  iou: 0.1426

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.44882, std: 0.15003

Metrics for layer 4:
  pearson_correlation: 0.0020
  kl_divergence: -356.9703
  ssim: 0.0513
  iou: 0.1487
Layer 4 metrics:
  pearson_correlation: 0.0020
  kl_divergence: -356.9703
  ssim: 0.0513
  iou: 0.1487

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.50173, std: 0.14411

Metrics for layer 5:
  pearson_correlation: 0.0384
  kl_divergence: -407.4100
  ssim: 0.0634
  iou: 0.1581
Layer 5 metrics:
  pearson_correlation: 0.0384
  kl_divergence: -407.4100
  ssim: 0.0634
  iou: 0.1581

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47572, std: 0.14493

Metrics for layer 6:
  pearson_correlation: 0.0040
  kl_divergence: -383.0374
  ssim: 0.0495
  iou: 0.1529
Layer 6 metrics:
  pearson_correlation: 0.0040
  kl_divergence: -383.0374
  ssim: 0.0495
  iou: 0.1529

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.49294, std: 0.17260

Metrics for layer 7:
  pearson_correlation: 0.0222
  kl_divergence: -88.0386
  ssim: 0.0355
  iou: 0.1598
Layer 7 metrics:
  pearson_correlation: 0.0222
  kl_divergence: -88.0386
  ssim: 0.0355
  iou: 0.1598

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.49518, std: 0.15706

Metrics for layer 8:
  pearson_correlation: -0.0143
  kl_divergence: -82.4664
  ssim: 0.0439
  iou: 0.1329
Layer 8 metrics:
  pearson_correlation: -0.0143
  kl_divergence: -82.4664
  ssim: 0.0439
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.45944, std: 0.17514

Metrics for layer 9:
  pearson_correlation: 0.0356
  kl_divergence: -80.6329
  ssim: 0.0460
  iou: 0.1529
Layer 9 metrics:
  pearson_correlation: 0.0356
  kl_divergence: -80.6329
  ssim: 0.0460
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.45863, std: 0.20009

Metrics for layer 10:
  pearson_correlation: -0.0397
  kl_divergence: -7.7040
  ssim: 0.0717
  iou: 0.1395
Layer 10 metrics:
  pearson_correlation: -0.0397
  kl_divergence: -7.7040
  ssim: 0.0717
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.44407, std: 0.18524

Metrics for layer 11:
  pearson_correlation: 0.0652
  kl_divergence: -5.7798
  ssim: 0.0401
  iou: 0.1667
Layer 11 metrics:
  pearson_correlation: 0.0652
  kl_divergence: -5.7798
  ssim: 0.0401
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.47557, std: 0.19056

Metrics for layer 12:
  pearson_correlation: 0.1070
  kl_divergence: -14.0113
  ssim: 0.1989
  iou: 0.1951
Layer 12 metrics:
  pearson_correlation: 0.1070
  kl_divergence: -14.0113
  ssim: 0.1989
  iou: 0.1951
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer8/batch_1_strength_0.8_results.npy

Processing attention strength 1.2
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.  1.2 0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.41839, std: 0.12357

Metrics for layer 0:
  pearson_correlation: -0.0037
  kl_divergence: -4500.1763
  ssim: 0.0468
  iou: 0.1392
Layer 0 metrics:
  pearson_correlation: -0.0037
  kl_divergence: -4500.1763
  ssim: 0.0468
  iou: 0.1392

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.38367, std: 0.11423

Metrics for layer 1:
  pearson_correlation: -0.0040
  kl_divergence: -4233.0537
  ssim: 0.0573
  iou: 0.1420
Layer 1 metrics:
  pearson_correlation: -0.0040
  kl_divergence: -4233.0537
  ssim: 0.0573
  iou: 0.1420

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.44221, std: 0.12804

Metrics for layer 2:
  pearson_correlation: 0.0003
  kl_divergence: -1356.6377
  ssim: 0.0570
  iou: 0.1433
Layer 2 metrics:
  pearson_correlation: 0.0003
  kl_divergence: -1356.6377
  ssim: 0.0570
  iou: 0.1433

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.45814, std: 0.12570

Metrics for layer 3:
  pearson_correlation: 0.0075
  kl_divergence: -1399.7063
  ssim: 0.0593
  iou: 0.1460
Layer 3 metrics:
  pearson_correlation: 0.0075
  kl_divergence: -1399.7063
  ssim: 0.0593
  iou: 0.1460

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.45160, std: 0.13352

Metrics for layer 4:
  pearson_correlation: -0.0250
  kl_divergence: -352.6083
  ssim: 0.0527
  iou: 0.1321
Layer 4 metrics:
  pearson_correlation: -0.0250
  kl_divergence: -352.6083
  ssim: 0.0527
  iou: 0.1321

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.43285, std: 0.13206

Metrics for layer 5:
  pearson_correlation: 0.0021
  kl_divergence: -338.9435
  ssim: 0.0632
  iou: 0.1496
Layer 5 metrics:
  pearson_correlation: 0.0021
  kl_divergence: -338.9435
  ssim: 0.0632
  iou: 0.1496

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.49202, std: 0.15519

Metrics for layer 6:
  pearson_correlation: 0.0043
  kl_divergence: -382.3864
  ssim: 0.0516
  iou: 0.1504
Layer 6 metrics:
  pearson_correlation: 0.0043
  kl_divergence: -382.3864
  ssim: 0.0516
  iou: 0.1504

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.44281, std: 0.15985

Metrics for layer 7:
  pearson_correlation: 0.0210
  kl_divergence: -81.9227
  ssim: 0.0701
  iou: 0.1598
Layer 7 metrics:
  pearson_correlation: 0.0210
  kl_divergence: -81.9227
  ssim: 0.0701
  iou: 0.1598

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.57587, std: 0.12471

Metrics for layer 8:
  pearson_correlation: -0.0235
  kl_divergence: -100.9781
  ssim: 0.0466
  iou: 0.1297
Layer 8 metrics:
  pearson_correlation: -0.0235
  kl_divergence: -100.9781
  ssim: 0.0466
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.40811, std: 0.14502

Metrics for layer 9:
  pearson_correlation: -0.0114
  kl_divergence: -71.9070
  ssim: 0.0568
  iou: 0.1429
Layer 9 metrics:
  pearson_correlation: -0.0114
  kl_divergence: -71.9070
  ssim: 0.0568
  iou: 0.1429

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.57192, std: 0.18331

Metrics for layer 10:
  pearson_correlation: 0.0669
  kl_divergence: -27.4360
  ssim: 0.0932
  iou: 0.1395
Layer 10 metrics:
  pearson_correlation: 0.0669
  kl_divergence: -27.4360
  ssim: 0.0932
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.42702, std: 0.19194

Metrics for layer 11:
  pearson_correlation: -0.0390
  kl_divergence: -12.9683
  ssim: 0.0252
  iou: 0.0652
Layer 11 metrics:
  pearson_correlation: -0.0390
  kl_divergence: -12.9683
  ssim: 0.0252
  iou: 0.0652

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.51389, std: 0.19298

Metrics for layer 12:
  pearson_correlation: 0.0088
  kl_divergence: -21.4049
  ssim: -0.0052
  iou: 0.1951
Layer 12 metrics:
  pearson_correlation: 0.0088
  kl_divergence: -21.4049
  ssim: -0.0052
  iou: 0.1951
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer8/batch_0_strength_1.2_results.npy

Processing batch 2/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43231, std: 0.12176

Metrics for layer 0:
  pearson_correlation: -0.0039
  kl_divergence: -3802.2646
  ssim: 0.0324
  iou: 0.1436
Layer 0 metrics:
  pearson_correlation: -0.0039
  kl_divergence: -3802.2646
  ssim: 0.0324
  iou: 0.1436

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.44285, std: 0.12311

Metrics for layer 1:
  pearson_correlation: 0.0063
  kl_divergence: -3853.9580
  ssim: 0.0318
  iou: 0.1461
Layer 1 metrics:
  pearson_correlation: 0.0063
  kl_divergence: -3853.9580
  ssim: 0.0318
  iou: 0.1461

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.46147, std: 0.13379

Metrics for layer 2:
  pearson_correlation: 0.0001
  kl_divergence: -1371.0328
  ssim: 0.0476
  iou: 0.1387
Layer 2 metrics:
  pearson_correlation: 0.0001
  kl_divergence: -1371.0328
  ssim: 0.0476
  iou: 0.1387

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.41799, std: 0.11757

Metrics for layer 3:
  pearson_correlation: 0.0123
  kl_divergence: -1287.9005
  ssim: 0.0622
  iou: 0.1424
Layer 3 metrics:
  pearson_correlation: 0.0123
  kl_divergence: -1287.9005
  ssim: 0.0622
  iou: 0.1424

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.41779, std: 0.14167

Metrics for layer 4:
  pearson_correlation: -0.0047
  kl_divergence: -328.0688
  ssim: 0.0526
  iou: 0.1395
Layer 4 metrics:
  pearson_correlation: -0.0047
  kl_divergence: -328.0688
  ssim: 0.0526
  iou: 0.1395

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.49896, std: 0.14317

Metrics for layer 5:
  pearson_correlation: 0.0342
  kl_divergence: -404.9091
  ssim: 0.0622
  iou: 0.1546
Layer 5 metrics:
  pearson_correlation: 0.0342
  kl_divergence: -404.9091
  ssim: 0.0622
  iou: 0.1546

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.57559, std: 0.13004

Metrics for layer 6:
  pearson_correlation: -0.0004
  kl_divergence: -457.3254
  ssim: 0.0465
  iou: 0.1321
Layer 6 metrics:
  pearson_correlation: -0.0004
  kl_divergence: -457.3254
  ssim: 0.0465
  iou: 0.1321

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.50858, std: 0.16028

Metrics for layer 7:
  pearson_correlation: -0.0637
  kl_divergence: -89.7495
  ssim: 0.0153
  iou: 0.1073
Layer 7 metrics:
  pearson_correlation: -0.0637
  kl_divergence: -89.7495
  ssim: 0.0153
  iou: 0.1073

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.48754, std: 0.16776

Metrics for layer 8:
  pearson_correlation: 0.0182
  kl_divergence: -87.0439
  ssim: 0.0413
  iou: 0.1362
Layer 8 metrics:
  pearson_correlation: 0.0182
  kl_divergence: -87.0439
  ssim: 0.0413
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.46721, std: 0.16510

Metrics for layer 9:
  pearson_correlation: -0.0496
  kl_divergence: -83.8318
  ssim: 0.0179
  iou: 0.1429
Layer 9 metrics:
  pearson_correlation: -0.0496
  kl_divergence: -83.8318
  ssim: 0.0179
  iou: 0.1429

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.47453, std: 0.20174

Metrics for layer 10:
  pearson_correlation: -0.0848
  kl_divergence: -8.1200
  ssim: -0.0007
  iou: 0.0889
Layer 10 metrics:
  pearson_correlation: -0.0848
  kl_divergence: -8.1200
  ssim: -0.0007
  iou: 0.0889

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.49293, std: 0.18295

Metrics for layer 11:
  pearson_correlation: -0.0030
  kl_divergence: -17.3762
  ssim: 0.0005
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: -0.0030
  kl_divergence: -17.3762
  ssim: 0.0005
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.47857, std: 0.17050

Metrics for layer 12:
  pearson_correlation: 0.0264
  kl_divergence: -19.4313
  ssim: 0.0491
  iou: 0.1807
Layer 12 metrics:
  pearson_correlation: 0.0264
  kl_divergence: -19.4313
  ssim: 0.0491
  iou: 0.1807
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer8/batch_1_strength_1.2_results.npy

Analysis complete! Results saved to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer8
Completed experiment for category 5, layer 8
----------------------------------------
Running experiment for category 5, layer 9
===================================================
Starting experiment:
Category: 5
Layer: 9
Logs will be saved to: /scratch/hy2611/CNN_attention/logs/attention_analysis_20241216_104146/category5/layer9
===================================================
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-12-16 11:06:51.529215: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-16 11:06:51.551500: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2024-12-16 11:06:51.552017: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3cf9090 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:06:51.552027: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-16 11:06:51.554681: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-16 11:06:51.683376: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3cdfc00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:06:51.683402: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-12-16 11:06:51.683871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:2f:00.0
2024-12-16 11:06:51.685001: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:06:51.686341: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:06:51.687347: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:06:51.688295: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:06:51.689238: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:06:51.690168: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:06:51.691095: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:06:51.691105: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-12-16 11:06:51.691124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-16 11:06:51.691129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-16 11:06:51.691132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:61: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:87: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:15: sigmoid_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.sigmoid_cross_entropy instead. Note that the order of the predictions and labels arguments has been changed.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:322: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:82: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.


Verifying paths:
tc_path: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs exists
weight_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists
image_path: /scratch/hy2611/CNN_attention/Data/VGG16/images exists
save_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists

Initializing model...
('c11', [1, 224, 224, 64])
('c12', [1, 224, 224, 64])
('c21', [1, 112, 112, 128])
('c22', [1, 112, 112, 128])
('c31', [1, 56, 56, 256])
('c32', [1, 56, 56, 256])
('c33', [1, 56, 56, 256])
('c41', [1, 28, 28, 512])
('c42', [1, 28, 28, 512])
('c43', [1, 28, 28, 512])
('c51', [1, 14, 14, 512])
('c52', [1, 14, 14, 512])
('c53', [1, 14, 14, 512])
(0, 'conv1_1_W', (3, 3, 3, 64))
(1, 'conv1_1_b', (64,))
(2, 'conv1_2_W', (3, 3, 64, 64))
(3, 'conv1_2_b', (64,))
(4, 'conv2_1_W', (3, 3, 64, 128))
(5, 'conv2_1_b', (128,))
(6, 'conv2_2_W', (3, 3, 128, 128))
(7, 'conv2_2_b', (128,))
(8, 'conv3_1_W', (3, 3, 128, 256))
(9, 'conv3_1_b', (256,))
(10, 'conv3_2_W', (3, 3, 256, 256))
(11, 'conv3_2_b', (256,))
(12, 'conv3_3_W', (3, 3, 256, 256))
(13, 'conv3_3_b', (256,))
(14, 'conv4_1_W', (3, 3, 256, 512))
(15, 'conv4_1_b', (512,))
(16, 'conv4_2_W', (3, 3, 512, 512))
(17, 'conv4_2_b', (512,))
(18, 'conv4_3_W', (3, 3, 512, 512))
(19, 'conv4_3_b', (512,))
(20, 'conv5_1_W', (3, 3, 512, 512))
(21, 'conv5_1_b', (512,))
(22, 'conv5_2_W', (3, 3, 512, 512))
(23, 'conv5_2_b', (512,))
(24, 'conv5_3_W', (3, 3, 512, 512))
(25, 'conv5_3_b', (512,))
(26, 'fc6_W', (25088, 4096))
(27, 'fc6_b', (4096,))
(28, 'fc7_W', (4096, 4096))
(29, 'fc7_b', (4096,))
Checking checkpoint files:
Data file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.data-00000-of-00001 - Found
Index file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.index - Found
Loading checkpoint from: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt
Checkpoint loaded successfully

Initializing components...
Found tuning curves file: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs/featvecs20_train35_c.txt

Loading category 5 data...
Original positive images shape: (2, 224, 224, 3)

Processing data...

Processing attention strength 0.0
Attention vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

Processing batch 1/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.40286, std: 0.12046

Metrics for layer 0:
  pearson_correlation: -0.0027
  kl_divergence: -4383.4224
  ssim: 0.0522
  iou: 0.1398
Layer 0 metrics:
  pearson_correlation: -0.0027
  kl_divergence: -4383.4224
  ssim: 0.0522
  iou: 0.1398

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.46678, std: 0.11471

Metrics for layer 1:
  pearson_correlation: 0.0041
  kl_divergence: -4892.0093
  ssim: 0.0483
  iou: 0.1460
Layer 1 metrics:
  pearson_correlation: 0.0041
  kl_divergence: -4892.0093
  ssim: 0.0483
  iou: 0.1460

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.49420, std: 0.13354

Metrics for layer 2:
  pearson_correlation: 0.0077
  kl_divergence: -1475.6335
  ssim: 0.0498
  iou: 0.1443
Layer 2 metrics:
  pearson_correlation: 0.0077
  kl_divergence: -1475.6335
  ssim: 0.0498
  iou: 0.1443

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.47496, std: 0.13873

Metrics for layer 3:
  pearson_correlation: 0.0030
  kl_divergence: -1427.9312
  ssim: 0.0493
  iou: 0.1422
Layer 3 metrics:
  pearson_correlation: 0.0030
  kl_divergence: -1427.9312
  ssim: 0.0493
  iou: 0.1422

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.35615, std: 0.12679

Metrics for layer 4:
  pearson_correlation: 0.0217
  kl_divergence: -258.9319
  ssim: 0.0989
  iou: 0.1420
Layer 4 metrics:
  pearson_correlation: 0.0217
  kl_divergence: -258.9319
  ssim: 0.0989
  iou: 0.1420

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.49967, std: 0.14725

Metrics for layer 5:
  pearson_correlation: -0.0387
  kl_divergence: -386.0103
  ssim: 0.0428
  iou: 0.1305
Layer 5 metrics:
  pearson_correlation: -0.0387
  kl_divergence: -386.0103
  ssim: 0.0428
  iou: 0.1305

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46884, std: 0.14095

Metrics for layer 6:
  pearson_correlation: 0.0102
  kl_divergence: -369.4884
  ssim: 0.0593
  iou: 0.1470
Layer 6 metrics:
  pearson_correlation: 0.0102
  kl_divergence: -369.4884
  ssim: 0.0593
  iou: 0.1470

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.45305, std: 0.14404

Metrics for layer 7:
  pearson_correlation: 0.0538
  kl_divergence: -85.3420
  ssim: 0.0911
  iou: 0.1395
Layer 7 metrics:
  pearson_correlation: 0.0538
  kl_divergence: -85.3420
  ssim: 0.0911
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.47342, std: 0.15645

Metrics for layer 8:
  pearson_correlation: 0.0134
  kl_divergence: -88.3023
  ssim: 0.0678
  iou: 0.1667
Layer 8 metrics:
  pearson_correlation: 0.0134
  kl_divergence: -88.3023
  ssim: 0.0678
  iou: 0.1667

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.49701, std: 0.16740

Metrics for layer 9:
  pearson_correlation: -0.0389
  kl_divergence: -89.5686
  ssim: 0.0183
  iou: 0.1737
Layer 9 metrics:
  pearson_correlation: -0.0389
  kl_divergence: -89.5686
  ssim: 0.0183
  iou: 0.1737

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.39263, std: 0.18016

Metrics for layer 10:
  pearson_correlation: 0.0279
  kl_divergence: -14.4285
  ssim: 0.0086
  iou: 0.1264
Layer 10 metrics:
  pearson_correlation: 0.0279
  kl_divergence: -14.4285
  ssim: 0.0086
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49125, std: 0.19985

Metrics for layer 11:
  pearson_correlation: 0.0648
  kl_divergence: -20.8443
  ssim: 0.0073
  iou: 0.1807
Layer 11 metrics:
  pearson_correlation: 0.0648
  kl_divergence: -20.8443
  ssim: 0.0073
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.39890, std: 0.18666

Metrics for layer 12:
  pearson_correlation: 0.0141
  kl_divergence: -7.7011
  ssim: 0.0473
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: 0.0141
  kl_divergence: -7.7011
  ssim: 0.0473
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer9/batch_0_strength_0.0_results.npy

Processing batch 2/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.42611, std: 0.12730

Metrics for layer 0:
  pearson_correlation: -0.0010
  kl_divergence: -3763.3362
  ssim: 0.0314
  iou: 0.1445
Layer 0 metrics:
  pearson_correlation: -0.0010
  kl_divergence: -3763.3362
  ssim: 0.0314
  iou: 0.1445

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.42735, std: 0.12081

Metrics for layer 1:
  pearson_correlation: -0.0059
  kl_divergence: -3777.7229
  ssim: 0.0331
  iou: 0.1370
Layer 1 metrics:
  pearson_correlation: -0.0059
  kl_divergence: -3777.7229
  ssim: 0.0331
  iou: 0.1370

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.44472, std: 0.13186

Metrics for layer 2:
  pearson_correlation: 0.0100
  kl_divergence: -1337.6969
  ssim: 0.0507
  iou: 0.1510
Layer 2 metrics:
  pearson_correlation: 0.0100
  kl_divergence: -1337.6969
  ssim: 0.0507
  iou: 0.1510

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.44813, std: 0.13317

Metrics for layer 3:
  pearson_correlation: -0.0035
  kl_divergence: -1342.8351
  ssim: 0.0484
  iou: 0.1422
Layer 3 metrics:
  pearson_correlation: -0.0035
  kl_divergence: -1342.8351
  ssim: 0.0484
  iou: 0.1422

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.51748, std: 0.15908

Metrics for layer 4:
  pearson_correlation: 0.0227
  kl_divergence: -398.9630
  ssim: 0.0456
  iou: 0.1445
Layer 4 metrics:
  pearson_correlation: 0.0227
  kl_divergence: -398.9630
  ssim: 0.0456
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.46289, std: 0.14715

Metrics for layer 5:
  pearson_correlation: -0.0102
  kl_divergence: -367.5609
  ssim: 0.0491
  iou: 0.1445
Layer 5 metrics:
  pearson_correlation: -0.0102
  kl_divergence: -367.5609
  ssim: 0.0491
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.49883, std: 0.15082

Metrics for layer 6:
  pearson_correlation: -0.0215
  kl_divergence: -398.7167
  ssim: 0.0429
  iou: 0.1462
Layer 6 metrics:
  pearson_correlation: -0.0215
  kl_divergence: -398.7167
  ssim: 0.0429
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.48732, std: 0.15027

Metrics for layer 7:
  pearson_correlation: 0.0059
  kl_divergence: -88.0546
  ssim: 0.0293
  iou: 0.1529
Layer 7 metrics:
  pearson_correlation: 0.0059
  kl_divergence: -88.0546
  ssim: 0.0293
  iou: 0.1529

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.54574, std: 0.15111

Metrics for layer 8:
  pearson_correlation: 0.0263
  kl_divergence: -95.1174
  ssim: 0.0467
  iou: 0.1232
Layer 8 metrics:
  pearson_correlation: 0.0263
  kl_divergence: -95.1174
  ssim: 0.0467
  iou: 0.1232

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.50018, std: 0.15994

Metrics for layer 9:
  pearson_correlation: -0.0308
  kl_divergence: -89.2089
  ssim: 0.0338
  iou: 0.1598
Layer 9 metrics:
  pearson_correlation: -0.0308
  kl_divergence: -89.2089
  ssim: 0.0338
  iou: 0.1598

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.50459, std: 0.17585

Metrics for layer 10:
  pearson_correlation: -0.1230
  kl_divergence: -19.6301
  ssim: -0.0734
  iou: 0.0889
Layer 10 metrics:
  pearson_correlation: -0.1230
  kl_divergence: -19.6301
  ssim: -0.0734
  iou: 0.0889

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.51337, std: 0.18047

Metrics for layer 11:
  pearson_correlation: 0.0268
  kl_divergence: -19.6920
  ssim: 0.1285
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: 0.0268
  kl_divergence: -19.6920
  ssim: 0.1285
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.48844, std: 0.19435

Metrics for layer 12:
  pearson_correlation: -0.0870
  kl_divergence: -13.3770
  ssim: -0.0191
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: -0.0870
  kl_divergence: -13.3770
  ssim: -0.0191
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer9/batch_1_strength_0.0_results.npy

Processing attention strength 0.4
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.4 0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.43795, std: 0.12608

Metrics for layer 0:
  pearson_correlation: 0.0005
  kl_divergence: -4650.8706
  ssim: 0.0448
  iou: 0.1412
Layer 0 metrics:
  pearson_correlation: 0.0005
  kl_divergence: -4650.8706
  ssim: 0.0448
  iou: 0.1412

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.44182, std: 0.12250

Metrics for layer 1:
  pearson_correlation: -0.0001
  kl_divergence: -4690.4233
  ssim: 0.0470
  iou: 0.1440
Layer 1 metrics:
  pearson_correlation: -0.0001
  kl_divergence: -4690.4233
  ssim: 0.0470
  iou: 0.1440

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.43659, std: 0.12536

Metrics for layer 2:
  pearson_correlation: 0.0025
  kl_divergence: -1342.8820
  ssim: 0.0600
  iou: 0.1420
Layer 2 metrics:
  pearson_correlation: 0.0025
  kl_divergence: -1342.8820
  ssim: 0.0600
  iou: 0.1420

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.45657, std: 0.12827

Metrics for layer 3:
  pearson_correlation: -0.0035
  kl_divergence: -1389.2878
  ssim: 0.0543
  iou: 0.1487
Layer 3 metrics:
  pearson_correlation: -0.0035
  kl_divergence: -1389.2878
  ssim: 0.0543
  iou: 0.1487

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.42359, std: 0.14151

Metrics for layer 4:
  pearson_correlation: -0.0046
  kl_divergence: -325.0127
  ssim: 0.0581
  iou: 0.1321
Layer 4 metrics:
  pearson_correlation: -0.0046
  kl_divergence: -325.0127
  ssim: 0.0581
  iou: 0.1321

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50492, std: 0.16296

Metrics for layer 5:
  pearson_correlation: 0.0166
  kl_divergence: -389.4326
  ssim: 0.0548
  iou: 0.1379
Layer 5 metrics:
  pearson_correlation: 0.0166
  kl_divergence: -389.4326
  ssim: 0.0548
  iou: 0.1379

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.49541, std: 0.14110

Metrics for layer 6:
  pearson_correlation: 0.0049
  kl_divergence: -386.0701
  ssim: 0.0593
  iou: 0.1354
Layer 6 metrics:
  pearson_correlation: 0.0049
  kl_divergence: -386.0701
  ssim: 0.0593
  iou: 0.1354

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.55919, std: 0.15965

Metrics for layer 7:
  pearson_correlation: 0.0588
  kl_divergence: -107.1927
  ssim: 0.0602
  iou: 0.1843
Layer 7 metrics:
  pearson_correlation: 0.0588
  kl_divergence: -107.1927
  ssim: 0.0602
  iou: 0.1843

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.53467, std: 0.14349

Metrics for layer 8:
  pearson_correlation: 0.0013
  kl_divergence: -103.5453
  ssim: 0.0703
  iou: 0.1529
Layer 8 metrics:
  pearson_correlation: 0.0013
  kl_divergence: -103.5453
  ssim: 0.0703
  iou: 0.1529

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.48747, std: 0.13893

Metrics for layer 9:
  pearson_correlation: -0.0057
  kl_divergence: -91.5723
  ssim: 0.0693
  iou: 0.1529
Layer 9 metrics:
  pearson_correlation: -0.0057
  kl_divergence: -91.5723
  ssim: 0.0693
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.44224, std: 0.17799

Metrics for layer 10:
  pearson_correlation: 0.0883
  kl_divergence: -15.3312
  ssim: 0.0574
  iou: 0.1807
Layer 10 metrics:
  pearson_correlation: 0.0883
  kl_divergence: -15.3312
  ssim: 0.0574
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.54386, std: 0.18709

Metrics for layer 11:
  pearson_correlation: 0.0434
  kl_divergence: -24.7532
  ssim: 0.0234
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: 0.0434
  kl_divergence: -24.7532
  ssim: 0.0234
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.46522, std: 0.17636

Metrics for layer 12:
  pearson_correlation: -0.0276
  kl_divergence: -18.8316
  ssim: 0.0593
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: -0.0276
  kl_divergence: -18.8316
  ssim: 0.0593
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer9/batch_0_strength_0.4_results.npy

Processing batch 2/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43533, std: 0.12038

Metrics for layer 0:
  pearson_correlation: 0.0026
  kl_divergence: -3821.0679
  ssim: 0.0334
  iou: 0.1455
Layer 0 metrics:
  pearson_correlation: 0.0026
  kl_divergence: -3821.0679
  ssim: 0.0334
  iou: 0.1455

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.44034, std: 0.11724

Metrics for layer 1:
  pearson_correlation: 0.0016
  kl_divergence: -3848.8057
  ssim: 0.0340
  iou: 0.1462
Layer 1 metrics:
  pearson_correlation: 0.0016
  kl_divergence: -3848.8057
  ssim: 0.0340
  iou: 0.1462

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.44307, std: 0.14225

Metrics for layer 2:
  pearson_correlation: 0.0030
  kl_divergence: -1324.9209
  ssim: 0.0440
  iou: 0.1422
Layer 2 metrics:
  pearson_correlation: 0.0030
  kl_divergence: -1324.9209
  ssim: 0.0440
  iou: 0.1422

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.49006, std: 0.14540

Metrics for layer 3:
  pearson_correlation: 0.0026
  kl_divergence: -1422.7703
  ssim: 0.0392
  iou: 0.1420
Layer 3 metrics:
  pearson_correlation: 0.0026
  kl_divergence: -1422.7703
  ssim: 0.0392
  iou: 0.1420

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.46622, std: 0.13213

Metrics for layer 4:
  pearson_correlation: 0.0025
  kl_divergence: -380.3528
  ssim: 0.0621
  iou: 0.1272
Layer 4 metrics:
  pearson_correlation: 0.0025
  kl_divergence: -380.3528
  ssim: 0.0621
  iou: 0.1272

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48809, std: 0.13816

Metrics for layer 5:
  pearson_correlation: 0.0359
  kl_divergence: -397.5771
  ssim: 0.0590
  iou: 0.1329
Layer 5 metrics:
  pearson_correlation: 0.0359
  kl_divergence: -397.5771
  ssim: 0.0590
  iou: 0.1329

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.41728, std: 0.13135

Metrics for layer 6:
  pearson_correlation: 0.0022
  kl_divergence: -335.9899
  ssim: 0.0551
  iou: 0.1429
Layer 6 metrics:
  pearson_correlation: 0.0022
  kl_divergence: -335.9899
  ssim: 0.0551
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.45690, std: 0.16813

Metrics for layer 7:
  pearson_correlation: -0.0068
  kl_divergence: -81.2287
  ssim: 0.0296
  iou: 0.1462
Layer 7 metrics:
  pearson_correlation: -0.0068
  kl_divergence: -81.2287
  ssim: 0.0296
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.50153, std: 0.16107

Metrics for layer 8:
  pearson_correlation: -0.0390
  kl_divergence: -88.4880
  ssim: 0.0219
  iou: 0.1462
Layer 8 metrics:
  pearson_correlation: -0.0390
  kl_divergence: -88.4880
  ssim: 0.0219
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.52271, std: 0.14755

Metrics for layer 9:
  pearson_correlation: 0.0113
  kl_divergence: -91.6825
  ssim: 0.0322
  iou: 0.1429
Layer 9 metrics:
  pearson_correlation: 0.0113
  kl_divergence: -91.6825
  ssim: 0.0322
  iou: 0.1429

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.43772, std: 0.17943

Metrics for layer 10:
  pearson_correlation: 0.1407
  kl_divergence: -15.7853
  ssim: 0.1418
  iou: 0.1951
Layer 10 metrics:
  pearson_correlation: 0.1407
  kl_divergence: -15.7853
  ssim: 0.1418
  iou: 0.1951

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.56769, std: 0.18808

Metrics for layer 11:
  pearson_correlation: -0.0166
  kl_divergence: -24.6752
  ssim: -0.0441
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: -0.0166
  kl_divergence: -24.6752
  ssim: -0.0441
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.51408, std: 0.19401

Metrics for layer 12:
  pearson_correlation: 0.1197
  kl_divergence: -20.7701
  ssim: 0.1289
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: 0.1197
  kl_divergence: -20.7701
  ssim: 0.1289
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer9/batch_1_strength_0.4_results.npy

Processing attention strength 0.8
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.8 0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.40672, std: 0.11824

Metrics for layer 0:
  pearson_correlation: 0.0007
  kl_divergence: -4421.4219
  ssim: 0.0531
  iou: 0.1423
Layer 0 metrics:
  pearson_correlation: 0.0007
  kl_divergence: -4421.4219
  ssim: 0.0531
  iou: 0.1423

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.45917, std: 0.12120

Metrics for layer 1:
  pearson_correlation: 0.0034
  kl_divergence: -4823.5796
  ssim: 0.0465
  iou: 0.1407
Layer 1 metrics:
  pearson_correlation: 0.0034
  kl_divergence: -4823.5796
  ssim: 0.0465
  iou: 0.1407

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.43420, std: 0.13668

Metrics for layer 2:
  pearson_correlation: 0.0097
  kl_divergence: -1325.5842
  ssim: 0.0567
  iou: 0.1389
Layer 2 metrics:
  pearson_correlation: 0.0097
  kl_divergence: -1325.5842
  ssim: 0.0567
  iou: 0.1389

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.48515, std: 0.12587

Metrics for layer 3:
  pearson_correlation: 0.0179
  kl_divergence: -1462.7189
  ssim: 0.0549
  iou: 0.1443
Layer 3 metrics:
  pearson_correlation: 0.0179
  kl_divergence: -1462.7189
  ssim: 0.0549
  iou: 0.1443

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.45981, std: 0.12561

Metrics for layer 4:
  pearson_correlation: 0.0043
  kl_divergence: -364.2590
  ssim: 0.0672
  iou: 0.1462
Layer 4 metrics:
  pearson_correlation: 0.0043
  kl_divergence: -364.2590
  ssim: 0.0672
  iou: 0.1462

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.48971, std: 0.14611

Metrics for layer 5:
  pearson_correlation: 0.0294
  kl_divergence: -382.0869
  ssim: 0.0755
  iou: 0.1563
Layer 5 metrics:
  pearson_correlation: 0.0294
  kl_divergence: -382.0869
  ssim: 0.0755
  iou: 0.1563

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.45612, std: 0.14278

Metrics for layer 6:
  pearson_correlation: 0.0129
  kl_divergence: -349.4545
  ssim: 0.0491
  iou: 0.1589
Layer 6 metrics:
  pearson_correlation: 0.0129
  kl_divergence: -349.4545
  ssim: 0.0491
  iou: 0.1589

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.44172, std: 0.16216

Metrics for layer 7:
  pearson_correlation: -0.0241
  kl_divergence: -80.3054
  ssim: 0.0372
  iou: 0.1105
Layer 7 metrics:
  pearson_correlation: -0.0241
  kl_divergence: -80.3054
  ssim: 0.0372
  iou: 0.1105

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.47436, std: 0.16335

Metrics for layer 8:
  pearson_correlation: -0.0190
  kl_divergence: -87.4456
  ssim: 0.0577
  iou: 0.1429
Layer 8 metrics:
  pearson_correlation: -0.0190
  kl_divergence: -87.4456
  ssim: 0.0577
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.52142, std: 0.14507

Metrics for layer 9:
  pearson_correlation: 0.0118
  kl_divergence: -99.4358
  ssim: 0.0276
  iou: 0.1807
Layer 9 metrics:
  pearson_correlation: 0.0118
  kl_divergence: -99.4358
  ssim: 0.0276
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.43528, std: 0.21565

Metrics for layer 10:
  pearson_correlation: -0.0181
  kl_divergence: -14.8618
  ssim: -0.0168
  iou: 0.1011
Layer 10 metrics:
  pearson_correlation: -0.0181
  kl_divergence: -14.8618
  ssim: -0.0168
  iou: 0.1011

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.42228, std: 0.17430

Metrics for layer 11:
  pearson_correlation: 0.0130
  kl_divergence: -10.4718
  ssim: 0.1073
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: 0.0130
  kl_divergence: -10.4718
  ssim: 0.1073
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.45824, std: 0.18530

Metrics for layer 12:
  pearson_correlation: -0.0385
  kl_divergence: -16.5397
  ssim: -0.0409
  iou: 0.2099
Layer 12 metrics:
  pearson_correlation: -0.0385
  kl_divergence: -16.5397
  ssim: -0.0409
  iou: 0.2099
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer9/batch_0_strength_0.8_results.npy

Processing batch 2/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43439, std: 0.12185

Metrics for layer 0:
  pearson_correlation: 0.0028
  kl_divergence: -3813.8345
  ssim: 0.0326
  iou: 0.1443
Layer 0 metrics:
  pearson_correlation: 0.0028
  kl_divergence: -3813.8345
  ssim: 0.0326
  iou: 0.1443

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.44296, std: 0.12743

Metrics for layer 1:
  pearson_correlation: 0.0053
  kl_divergence: -3846.6772
  ssim: 0.0304
  iou: 0.1430
Layer 1 metrics:
  pearson_correlation: 0.0053
  kl_divergence: -3846.6772
  ssim: 0.0304
  iou: 0.1430

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.43214, std: 0.12537

Metrics for layer 2:
  pearson_correlation: 0.0213
  kl_divergence: -1318.1863
  ssim: 0.0603
  iou: 0.1510
Layer 2 metrics:
  pearson_correlation: 0.0213
  kl_divergence: -1318.1863
  ssim: 0.0603
  iou: 0.1510

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.47193, std: 0.13070

Metrics for layer 3:
  pearson_correlation: -0.0081
  kl_divergence: -1391.3364
  ssim: 0.0452
  iou: 0.1437
Layer 3 metrics:
  pearson_correlation: -0.0081
  kl_divergence: -1391.3364
  ssim: 0.0452
  iou: 0.1437

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.43871, std: 0.13856

Metrics for layer 4:
  pearson_correlation: 0.0166
  kl_divergence: -352.5057
  ssim: 0.0562
  iou: 0.1512
Layer 4 metrics:
  pearson_correlation: 0.0166
  kl_divergence: -352.5057
  ssim: 0.0562
  iou: 0.1512

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48476, std: 0.15002

Metrics for layer 5:
  pearson_correlation: 0.0089
  kl_divergence: -391.6406
  ssim: 0.0538
  iou: 0.1387
Layer 5 metrics:
  pearson_correlation: 0.0089
  kl_divergence: -391.6406
  ssim: 0.0538
  iou: 0.1387

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47483, std: 0.14417

Metrics for layer 6:
  pearson_correlation: -0.0202
  kl_divergence: -382.0146
  ssim: 0.0464
  iou: 0.1445
Layer 6 metrics:
  pearson_correlation: -0.0202
  kl_divergence: -382.0146
  ssim: 0.0464
  iou: 0.1445

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.56068, std: 0.14564

Metrics for layer 7:
  pearson_correlation: -0.0224
  kl_divergence: -97.1962
  ssim: 0.0306
  iou: 0.1496
Layer 7 metrics:
  pearson_correlation: -0.0224
  kl_divergence: -97.1962
  ssim: 0.0306
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.46241, std: 0.17899

Metrics for layer 8:
  pearson_correlation: 0.0389
  kl_divergence: -83.5309
  ssim: 0.0531
  iou: 0.1200
Layer 8 metrics:
  pearson_correlation: 0.0389
  kl_divergence: -83.5309
  ssim: 0.0531
  iou: 0.1200

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.50559, std: 0.16219

Metrics for layer 9:
  pearson_correlation: -0.0131
  kl_divergence: -89.5124
  ssim: 0.0413
  iou: 0.1529
Layer 9 metrics:
  pearson_correlation: -0.0131
  kl_divergence: -89.5124
  ssim: 0.0413
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.37188, std: 0.18395

Metrics for layer 10:
  pearson_correlation: -0.0059
  kl_divergence: -2.4972
  ssim: 0.0320
  iou: 0.1264
Layer 10 metrics:
  pearson_correlation: -0.0059
  kl_divergence: -2.4972
  ssim: 0.0320
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.52158, std: 0.17186

Metrics for layer 11:
  pearson_correlation: 0.0483
  kl_divergence: -21.2816
  ssim: 0.0845
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: 0.0483
  kl_divergence: -21.2816
  ssim: 0.0845
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.48550, std: 0.19800

Metrics for layer 12:
  pearson_correlation: 0.0083
  kl_divergence: -17.5790
  ssim: 0.0582
  iou: 0.1136
Layer 12 metrics:
  pearson_correlation: 0.0083
  kl_divergence: -17.5790
  ssim: 0.0582
  iou: 0.1136
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer9/batch_1_strength_0.8_results.npy

Processing attention strength 1.2
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.  0.  1.2 0.  0.  0. ]

Processing batch 1/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.44872, std: 0.12452

Metrics for layer 0:
  pearson_correlation: 0.0025
  kl_divergence: -4741.0269
  ssim: 0.0459
  iou: 0.1446
Layer 0 metrics:
  pearson_correlation: 0.0025
  kl_divergence: -4741.0269
  ssim: 0.0459
  iou: 0.1446

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.43562, std: 0.12272

Metrics for layer 1:
  pearson_correlation: -0.0077
  kl_divergence: -4636.1538
  ssim: 0.0456
  iou: 0.1415
Layer 1 metrics:
  pearson_correlation: -0.0077
  kl_divergence: -4636.1538
  ssim: 0.0456
  iou: 0.1415

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.45950, std: 0.13206

Metrics for layer 2:
  pearson_correlation: -0.0009
  kl_divergence: -1394.1514
  ssim: 0.0529
  iou: 0.1397
Layer 2 metrics:
  pearson_correlation: -0.0009
  kl_divergence: -1394.1514
  ssim: 0.0529
  iou: 0.1397

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.46009, std: 0.14165

Metrics for layer 3:
  pearson_correlation: 0.0027
  kl_divergence: -1386.6693
  ssim: 0.0492
  iou: 0.1447
Layer 3 metrics:
  pearson_correlation: 0.0027
  kl_divergence: -1386.6693
  ssim: 0.0492
  iou: 0.1447

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46318, std: 0.13407

Metrics for layer 4:
  pearson_correlation: -0.0077
  kl_divergence: -360.8972
  ssim: 0.0629
  iou: 0.1487
Layer 4 metrics:
  pearson_correlation: -0.0077
  kl_divergence: -360.8972
  ssim: 0.0629
  iou: 0.1487

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.51636, std: 0.14508

Metrics for layer 5:
  pearson_correlation: 0.0148
  kl_divergence: -404.6835
  ssim: 0.0574
  iou: 0.1479
Layer 5 metrics:
  pearson_correlation: 0.0148
  kl_divergence: -404.6835
  ssim: 0.0574
  iou: 0.1479

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50989, std: 0.15562

Metrics for layer 6:
  pearson_correlation: -0.0164
  kl_divergence: -393.3237
  ssim: 0.0408
  iou: 0.1379
Layer 6 metrics:
  pearson_correlation: -0.0164
  kl_divergence: -393.3237
  ssim: 0.0408
  iou: 0.1379

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.43239, std: 0.16356

Metrics for layer 7:
  pearson_correlation: -0.0072
  kl_divergence: -77.6691
  ssim: 0.0519
  iou: 0.1264
Layer 7 metrics:
  pearson_correlation: -0.0072
  kl_divergence: -77.6691
  ssim: 0.0519
  iou: 0.1264

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.51175, std: 0.13683

Metrics for layer 8:
  pearson_correlation: -0.0355
  kl_divergence: -94.6722
  ssim: 0.0348
  iou: 0.1667
Layer 8 metrics:
  pearson_correlation: -0.0355
  kl_divergence: -94.6722
  ssim: 0.0348
  iou: 0.1667

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.41679, std: 0.14976

Metrics for layer 9:
  pearson_correlation: 0.0226
  kl_divergence: -70.8542
  ssim: 0.0818
  iou: 0.1529
Layer 9 metrics:
  pearson_correlation: 0.0226
  kl_divergence: -70.8542
  ssim: 0.0818
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.43538, std: 0.18259

Metrics for layer 10:
  pearson_correlation: -0.0084
  kl_divergence: -11.7246
  ssim: 0.0249
  iou: 0.1264
Layer 10 metrics:
  pearson_correlation: -0.0084
  kl_divergence: -11.7246
  ssim: 0.0249
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.52580, std: 0.17745

Metrics for layer 11:
  pearson_correlation: 0.0369
  kl_divergence: -23.5803
  ssim: 0.0262
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: 0.0369
  kl_divergence: -23.5803
  ssim: 0.0262
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.44906, std: 0.18802

Metrics for layer 12:
  pearson_correlation: -0.1374
  kl_divergence: -14.0504
  ssim: -0.0797
  iou: 0.0889
Layer 12 metrics:
  pearson_correlation: -0.1374
  kl_divergence: -14.0504
  ssim: -0.0797
  iou: 0.0889
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer9/batch_0_strength_1.2_results.npy

Processing batch 2/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.44441, std: 0.11370

Metrics for layer 0:
  pearson_correlation: -0.0024
  kl_divergence: -3868.7646
  ssim: 0.0349
  iou: 0.1411
Layer 0 metrics:
  pearson_correlation: -0.0024
  kl_divergence: -3868.7646
  ssim: 0.0349
  iou: 0.1411

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43995, std: 0.12746

Metrics for layer 1:
  pearson_correlation: 0.0038
  kl_divergence: -3829.6509
  ssim: 0.0301
  iou: 0.1471
Layer 1 metrics:
  pearson_correlation: 0.0038
  kl_divergence: -3829.6509
  ssim: 0.0301
  iou: 0.1471

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.44124, std: 0.13203

Metrics for layer 2:
  pearson_correlation: -0.0162
  kl_divergence: -1324.4047
  ssim: 0.0481
  iou: 0.1350
Layer 2 metrics:
  pearson_correlation: -0.0162
  kl_divergence: -1324.4047
  ssim: 0.0481
  iou: 0.1350

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.43921, std: 0.12690

Metrics for layer 3:
  pearson_correlation: 0.0269
  kl_divergence: -1333.2000
  ssim: 0.0531
  iou: 0.1470
Layer 3 metrics:
  pearson_correlation: 0.0269
  kl_divergence: -1333.2000
  ssim: 0.0531
  iou: 0.1470

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47622, std: 0.13793

Metrics for layer 4:
  pearson_correlation: 0.0297
  kl_divergence: -389.3981
  ssim: 0.0633
  iou: 0.1693
Layer 4 metrics:
  pearson_correlation: 0.0297
  kl_divergence: -389.3981
  ssim: 0.0633
  iou: 0.1693

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.51409, std: 0.13216

Metrics for layer 5:
  pearson_correlation: -0.0122
  kl_divergence: -416.2969
  ssim: 0.0469
  iou: 0.1289
Layer 5 metrics:
  pearson_correlation: -0.0122
  kl_divergence: -416.2969
  ssim: 0.0469
  iou: 0.1289

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.44484, std: 0.12246

Metrics for layer 6:
  pearson_correlation: -0.0005
  kl_divergence: -364.9794
  ssim: 0.0709
  iou: 0.1454
Layer 6 metrics:
  pearson_correlation: -0.0005
  kl_divergence: -364.9794
  ssim: 0.0709
  iou: 0.1454

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.45566, std: 0.15988

Metrics for layer 7:
  pearson_correlation: -0.0264
  kl_divergence: -80.8055
  ssim: 0.0346
  iou: 0.1362
Layer 7 metrics:
  pearson_correlation: -0.0264
  kl_divergence: -80.8055
  ssim: 0.0346
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.49547, std: 0.16016

Metrics for layer 8:
  pearson_correlation: 0.0228
  kl_divergence: -88.8453
  ssim: 0.0505
  iou: 0.1598
Layer 8 metrics:
  pearson_correlation: 0.0228
  kl_divergence: -88.8453
  ssim: 0.0505
  iou: 0.1598

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.44613, std: 0.15434

Metrics for layer 9:
  pearson_correlation: 0.0262
  kl_divergence: -82.4324
  ssim: 0.0412
  iou: 0.1399
Layer 9 metrics:
  pearson_correlation: 0.0262
  kl_divergence: -82.4324
  ssim: 0.0412
  iou: 0.1399

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.52234, std: 0.18203

Metrics for layer 10:
  pearson_correlation: 0.0753
  kl_divergence: -21.2889
  ssim: 0.1418
  iou: 0.1807
Layer 10 metrics:
  pearson_correlation: 0.0753
  kl_divergence: -21.2889
  ssim: 0.1418
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.43525, std: 0.20368

Metrics for layer 11:
  pearson_correlation: -0.0247
  kl_divergence: -10.3514
  ssim: -0.0783
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: -0.0247
  kl_divergence: -10.3514
  ssim: -0.0783
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.39809, std: 0.16676

Metrics for layer 12:
  pearson_correlation: 0.0456
  kl_divergence: -6.1033
  ssim: 0.0789
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: 0.0456
  kl_divergence: -6.1033
  ssim: 0.0789
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer9/batch_1_strength_1.2_results.npy

Analysis complete! Results saved to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer9
Completed experiment for category 5, layer 9
----------------------------------------
Running experiment for category 5, layer 10
===================================================
Starting experiment:
Category: 5
Layer: 10
Logs will be saved to: /scratch/hy2611/CNN_attention/logs/attention_analysis_20241216_104146/category5/layer10
===================================================
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-12-16 11:09:50.853513: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-16 11:09:50.872501: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2024-12-16 11:09:50.872953: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3f3f0f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:09:50.872971: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-16 11:09:50.875991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-16 11:09:51.010911: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3f120e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:09:51.010931: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-12-16 11:09:51.011455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:2f:00.0
2024-12-16 11:09:51.012541: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:09:51.013535: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:09:51.014491: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:09:51.015441: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:09:51.016366: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:09:51.017347: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:09:51.018312: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:09:51.018325: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-12-16 11:09:51.018344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-16 11:09:51.018349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-16 11:09:51.018352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:61: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:87: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:15: sigmoid_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.sigmoid_cross_entropy instead. Note that the order of the predictions and labels arguments has been changed.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:322: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:82: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.


Verifying paths:
tc_path: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs exists
weight_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists
image_path: /scratch/hy2611/CNN_attention/Data/VGG16/images exists
save_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists

Initializing model...
('c11', [1, 224, 224, 64])
('c12', [1, 224, 224, 64])
('c21', [1, 112, 112, 128])
('c22', [1, 112, 112, 128])
('c31', [1, 56, 56, 256])
('c32', [1, 56, 56, 256])
('c33', [1, 56, 56, 256])
('c41', [1, 28, 28, 512])
('c42', [1, 28, 28, 512])
('c43', [1, 28, 28, 512])
('c51', [1, 14, 14, 512])
('c52', [1, 14, 14, 512])
('c53', [1, 14, 14, 512])
(0, 'conv1_1_W', (3, 3, 3, 64))
(1, 'conv1_1_b', (64,))
(2, 'conv1_2_W', (3, 3, 64, 64))
(3, 'conv1_2_b', (64,))
(4, 'conv2_1_W', (3, 3, 64, 128))
(5, 'conv2_1_b', (128,))
(6, 'conv2_2_W', (3, 3, 128, 128))
(7, 'conv2_2_b', (128,))
(8, 'conv3_1_W', (3, 3, 128, 256))
(9, 'conv3_1_b', (256,))
(10, 'conv3_2_W', (3, 3, 256, 256))
(11, 'conv3_2_b', (256,))
(12, 'conv3_3_W', (3, 3, 256, 256))
(13, 'conv3_3_b', (256,))
(14, 'conv4_1_W', (3, 3, 256, 512))
(15, 'conv4_1_b', (512,))
(16, 'conv4_2_W', (3, 3, 512, 512))
(17, 'conv4_2_b', (512,))
(18, 'conv4_3_W', (3, 3, 512, 512))
(19, 'conv4_3_b', (512,))
(20, 'conv5_1_W', (3, 3, 512, 512))
(21, 'conv5_1_b', (512,))
(22, 'conv5_2_W', (3, 3, 512, 512))
(23, 'conv5_2_b', (512,))
(24, 'conv5_3_W', (3, 3, 512, 512))
(25, 'conv5_3_b', (512,))
(26, 'fc6_W', (25088, 4096))
(27, 'fc6_b', (4096,))
(28, 'fc7_W', (4096, 4096))
(29, 'fc7_b', (4096,))
Checking checkpoint files:
Data file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.data-00000-of-00001 - Found
Index file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.index - Found
Loading checkpoint from: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt
Checkpoint loaded successfully

Initializing components...
Found tuning curves file: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs/featvecs20_train35_c.txt

Loading category 5 data...
Original positive images shape: (2, 224, 224, 3)

Processing data...

Processing attention strength 0.0
Attention vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

Processing batch 1/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42458, std: 0.12126

Metrics for layer 0:
  pearson_correlation: -0.0034
  kl_divergence: -4557.7329
  ssim: 0.0484
  iou: 0.1376
Layer 0 metrics:
  pearson_correlation: -0.0034
  kl_divergence: -4557.7329
  ssim: 0.0484
  iou: 0.1376

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.40447, std: 0.11710

Metrics for layer 1:
  pearson_correlation: -0.0004
  kl_divergence: -4405.6060
  ssim: 0.0515
  iou: 0.1425
Layer 1 metrics:
  pearson_correlation: -0.0004
  kl_divergence: -4405.6060
  ssim: 0.0515
  iou: 0.1425

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.47142, std: 0.13125

Metrics for layer 2:
  pearson_correlation: -0.0141
  kl_divergence: -1421.2747
  ssim: 0.0465
  iou: 0.1350
Layer 2 metrics:
  pearson_correlation: -0.0141
  kl_divergence: -1421.2747
  ssim: 0.0465
  iou: 0.1350

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.46040, std: 0.13115

Metrics for layer 3:
  pearson_correlation: -0.0057
  kl_divergence: -1393.4181
  ssim: 0.0517
  iou: 0.1414
Layer 3 metrics:
  pearson_correlation: -0.0057
  kl_divergence: -1393.4181
  ssim: 0.0517
  iou: 0.1414

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47833, std: 0.14049

Metrics for layer 4:
  pearson_correlation: -0.0080
  kl_divergence: -372.5096
  ssim: 0.0566
  iou: 0.1538
Layer 4 metrics:
  pearson_correlation: -0.0080
  kl_divergence: -372.5096
  ssim: 0.0566
  iou: 0.1538

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.49203, std: 0.14953

Metrics for layer 5:
  pearson_correlation: -0.0347
  kl_divergence: -378.1055
  ssim: 0.0302
  iou: 0.1354
Layer 5 metrics:
  pearson_correlation: -0.0347
  kl_divergence: -378.1055
  ssim: 0.0302
  iou: 0.1354

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47374, std: 0.14198

Metrics for layer 6:
  pearson_correlation: 0.0044
  kl_divergence: -365.3451
  ssim: 0.0567
  iou: 0.1445
Layer 6 metrics:
  pearson_correlation: 0.0044
  kl_divergence: -365.3451
  ssim: 0.0567
  iou: 0.1445

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.47712, std: 0.17069

Metrics for layer 7:
  pearson_correlation: -0.0068
  kl_divergence: -88.2862
  ssim: 0.0480
  iou: 0.1105
Layer 7 metrics:
  pearson_correlation: -0.0068
  kl_divergence: -88.2862
  ssim: 0.0480
  iou: 0.1105

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.45631, std: 0.14302

Metrics for layer 8:
  pearson_correlation: -0.0122
  kl_divergence: -85.8203
  ssim: 0.0786
  iou: 0.1667
Layer 8 metrics:
  pearson_correlation: -0.0122
  kl_divergence: -85.8203
  ssim: 0.0786
  iou: 0.1667

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.51600, std: 0.16114

Metrics for layer 9:
  pearson_correlation: -0.0328
  kl_divergence: -92.9317
  ssim: 0.0261
  iou: 0.1200
Layer 9 metrics:
  pearson_correlation: -0.0328
  kl_divergence: -92.9317
  ssim: 0.0261
  iou: 0.1200

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.53151, std: 0.19295

Metrics for layer 10:
  pearson_correlation: -0.0136
  kl_divergence: -24.5699
  ssim: 0.0489
  iou: 0.1264
Layer 10 metrics:
  pearson_correlation: -0.0136
  kl_divergence: -24.5699
  ssim: 0.0489
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.46690, std: 0.17995

Metrics for layer 11:
  pearson_correlation: -0.0127
  kl_divergence: -19.0178
  ssim: 0.0126
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: -0.0127
  kl_divergence: -19.0178
  ssim: 0.0126
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49817, std: 0.19675

Metrics for layer 12:
  pearson_correlation: -0.0949
  kl_divergence: -20.5129
  ssim: 0.0601
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: -0.0949
  kl_divergence: -20.5129
  ssim: 0.0601
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer10/batch_0_strength_0.0_results.npy

Processing batch 2/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43197, std: 0.12463

Metrics for layer 0:
  pearson_correlation: 0.0035
  kl_divergence: -3797.5173
  ssim: 0.0320
  iou: 0.1448
Layer 0 metrics:
  pearson_correlation: 0.0035
  kl_divergence: -3797.5173
  ssim: 0.0320
  iou: 0.1448

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43632, std: 0.12164

Metrics for layer 1:
  pearson_correlation: -0.0018
  kl_divergence: -3821.4858
  ssim: 0.0327
  iou: 0.1404
Layer 1 metrics:
  pearson_correlation: -0.0018
  kl_divergence: -3821.4858
  ssim: 0.0327
  iou: 0.1404

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.47752, std: 0.12753

Metrics for layer 2:
  pearson_correlation: 0.0152
  kl_divergence: -1413.9572
  ssim: 0.0509
  iou: 0.1447
Layer 2 metrics:
  pearson_correlation: 0.0152
  kl_divergence: -1413.9572
  ssim: 0.0509
  iou: 0.1447

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.48844, std: 0.13499

Metrics for layer 3:
  pearson_correlation: 0.0011
  kl_divergence: -1426.2437
  ssim: 0.0417
  iou: 0.1381
Layer 3 metrics:
  pearson_correlation: 0.0011
  kl_divergence: -1426.2437
  ssim: 0.0417
  iou: 0.1381

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.51472, std: 0.15161

Metrics for layer 4:
  pearson_correlation: 0.0120
  kl_divergence: -414.3873
  ssim: 0.0479
  iou: 0.1338
Layer 4 metrics:
  pearson_correlation: 0.0120
  kl_divergence: -414.3873
  ssim: 0.0479
  iou: 0.1338

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48007, std: 0.15519

Metrics for layer 5:
  pearson_correlation: 0.0021
  kl_divergence: -383.4637
  ssim: 0.0453
  iou: 0.1479
Layer 5 metrics:
  pearson_correlation: 0.0021
  kl_divergence: -383.4637
  ssim: 0.0453
  iou: 0.1479

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48237, std: 0.13537

Metrics for layer 6:
  pearson_correlation: 0.0275
  kl_divergence: -395.0555
  ssim: 0.0685
  iou: 0.1555
Layer 6 metrics:
  pearson_correlation: 0.0275
  kl_divergence: -395.0555
  ssim: 0.0685
  iou: 0.1555

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.39530, std: 0.14181

Metrics for layer 7:
  pearson_correlation: -0.0635
  kl_divergence: -73.0916
  ssim: 0.0162
  iou: 0.1232
Layer 7 metrics:
  pearson_correlation: -0.0635
  kl_divergence: -73.0916
  ssim: 0.0162
  iou: 0.1232

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.49537, std: 0.17193

Metrics for layer 8:
  pearson_correlation: -0.0303
  kl_divergence: -86.7350
  ssim: 0.0159
  iou: 0.1264
Layer 8 metrics:
  pearson_correlation: -0.0303
  kl_divergence: -86.7350
  ssim: 0.0159
  iou: 0.1264

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.47916, std: 0.16415

Metrics for layer 9:
  pearson_correlation: 0.0281
  kl_divergence: -86.0851
  ssim: 0.0453
  iou: 0.1563
Layer 9 metrics:
  pearson_correlation: 0.0281
  kl_divergence: -86.0851
  ssim: 0.0453
  iou: 0.1563

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.46605, std: 0.18246

Metrics for layer 10:
  pearson_correlation: 0.1748
  kl_divergence: -17.2769
  ssim: 0.1260
  iou: 0.1951
Layer 10 metrics:
  pearson_correlation: 0.1748
  kl_divergence: -17.2769
  ssim: 0.1260
  iou: 0.1951

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.49615, std: 0.21334

Metrics for layer 11:
  pearson_correlation: -0.0709
  kl_divergence: -1.6699
  ssim: -0.1076
  iou: 0.1667
Layer 11 metrics:
  pearson_correlation: -0.0709
  kl_divergence: -1.6699
  ssim: -0.1076
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.33901, std: 0.18204

Metrics for layer 12:
  pearson_correlation: -0.0767
  kl_divergence: 2.0969
  ssim: 0.0514
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: -0.0767
  kl_divergence: 2.0969
  ssim: 0.0514
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer10/batch_1_strength_0.0_results.npy

Processing attention strength 0.4
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.4 0.  0. ]

Processing batch 1/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.44723, std: 0.12916

Metrics for layer 0:
  pearson_correlation: 0.0084
  kl_divergence: -4725.3447
  ssim: 0.0442
  iou: 0.1439
Layer 0 metrics:
  pearson_correlation: 0.0084
  kl_divergence: -4725.3447
  ssim: 0.0442
  iou: 0.1439

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.40690, std: 0.11175

Metrics for layer 1:
  pearson_correlation: -0.0002
  kl_divergence: -4442.3828
  ssim: 0.0568
  iou: 0.1397
Layer 1 metrics:
  pearson_correlation: -0.0002
  kl_divergence: -4442.3828
  ssim: 0.0568
  iou: 0.1397

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.47169, std: 0.12797

Metrics for layer 2:
  pearson_correlation: -0.0024
  kl_divergence: -1424.7529
  ssim: 0.0586
  iou: 0.1439
Layer 2 metrics:
  pearson_correlation: -0.0024
  kl_divergence: -1424.7529
  ssim: 0.0586
  iou: 0.1439

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.48957, std: 0.13157

Metrics for layer 3:
  pearson_correlation: 0.0126
  kl_divergence: -1468.2496
  ssim: 0.0513
  iou: 0.1437
Layer 3 metrics:
  pearson_correlation: 0.0126
  kl_divergence: -1468.2496
  ssim: 0.0513
  iou: 0.1437

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50849, std: 0.13910

Metrics for layer 4:
  pearson_correlation: -0.0202
  kl_divergence: -398.2860
  ssim: 0.0432
  iou: 0.1462
Layer 4 metrics:
  pearson_correlation: -0.0202
  kl_divergence: -398.2860
  ssim: 0.0432
  iou: 0.1462

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50489, std: 0.15189

Metrics for layer 5:
  pearson_correlation: 0.0479
  kl_divergence: -398.3188
  ssim: 0.0565
  iou: 0.1387
Layer 5 metrics:
  pearson_correlation: 0.0479
  kl_divergence: -398.3188
  ssim: 0.0565
  iou: 0.1387

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.42440, std: 0.13866

Metrics for layer 6:
  pearson_correlation: -0.0105
  kl_divergence: -328.7013
  ssim: 0.0577
  iou: 0.1454
Layer 6 metrics:
  pearson_correlation: -0.0105
  kl_divergence: -328.7013
  ssim: 0.0577
  iou: 0.1454

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.53243, std: 0.15529

Metrics for layer 7:
  pearson_correlation: -0.0318
  kl_divergence: -101.6063
  ssim: 0.0265
  iou: 0.1105
Layer 7 metrics:
  pearson_correlation: -0.0318
  kl_divergence: -101.6063
  ssim: 0.0265
  iou: 0.1105

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.51044, std: 0.15980

Metrics for layer 8:
  pearson_correlation: 0.0355
  kl_divergence: -94.7663
  ssim: 0.0494
  iou: 0.1667
Layer 8 metrics:
  pearson_correlation: 0.0355
  kl_divergence: -94.7663
  ssim: 0.0494
  iou: 0.1667

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.49900, std: 0.14679

Metrics for layer 9:
  pearson_correlation: 0.0239
  kl_divergence: -93.9100
  ssim: 0.0630
  iou: 0.1563
Layer 9 metrics:
  pearson_correlation: 0.0239
  kl_divergence: -93.9100
  ssim: 0.0630
  iou: 0.1563

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.39081, std: 0.17701

Metrics for layer 10:
  pearson_correlation: 0.0217
  kl_divergence: -8.8958
  ssim: 0.0604
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: 0.0217
  kl_divergence: -8.8958
  ssim: 0.0604
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.54689, std: 0.16613

Metrics for layer 11:
  pearson_correlation: -0.0016
  kl_divergence: -22.5250
  ssim: 0.0395
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: -0.0016
  kl_divergence: -22.5250
  ssim: 0.0395
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.52582, std: 0.18029

Metrics for layer 12:
  pearson_correlation: -0.0264
  kl_divergence: -24.1022
  ssim: 0.0652
  iou: 0.1264
Layer 12 metrics:
  pearson_correlation: -0.0264
  kl_divergence: -24.1022
  ssim: 0.0652
  iou: 0.1264
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer10/batch_0_strength_0.4_results.npy

Processing batch 2/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.41118, std: 0.12180

Metrics for layer 0:
  pearson_correlation: 0.0065
  kl_divergence: -3706.2190
  ssim: 0.0352
  iou: 0.1426
Layer 0 metrics:
  pearson_correlation: 0.0065
  kl_divergence: -3706.2190
  ssim: 0.0352
  iou: 0.1426

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.44578, std: 0.13043

Metrics for layer 1:
  pearson_correlation: 0.0037
  kl_divergence: -3851.6348
  ssim: 0.0292
  iou: 0.1423
Layer 1 metrics:
  pearson_correlation: 0.0037
  kl_divergence: -3851.6348
  ssim: 0.0292
  iou: 0.1423

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.41955, std: 0.12833

Metrics for layer 2:
  pearson_correlation: 0.0033
  kl_divergence: -1281.5342
  ssim: 0.0533
  iou: 0.1433
Layer 2 metrics:
  pearson_correlation: 0.0033
  kl_divergence: -1281.5342
  ssim: 0.0533
  iou: 0.1433

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.42379, std: 0.12689

Metrics for layer 3:
  pearson_correlation: -0.0101
  kl_divergence: -1290.7260
  ssim: 0.0516
  iou: 0.1393
Layer 3 metrics:
  pearson_correlation: -0.0101
  kl_divergence: -1290.7260
  ssim: 0.0516
  iou: 0.1393

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.45456, std: 0.15105

Metrics for layer 4:
  pearson_correlation: 0.0020
  kl_divergence: -361.9321
  ssim: 0.0525
  iou: 0.1404
Layer 4 metrics:
  pearson_correlation: 0.0020
  kl_divergence: -361.9321
  ssim: 0.0525
  iou: 0.1404

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.50785, std: 0.12705

Metrics for layer 5:
  pearson_correlation: -0.0058
  kl_divergence: -409.7623
  ssim: 0.0661
  iou: 0.1395
Layer 5 metrics:
  pearson_correlation: -0.0058
  kl_divergence: -409.7623
  ssim: 0.0661
  iou: 0.1395

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48744, std: 0.14757

Metrics for layer 6:
  pearson_correlation: -0.0073
  kl_divergence: -393.0870
  ssim: 0.0521
  iou: 0.1504
Layer 6 metrics:
  pearson_correlation: -0.0073
  kl_divergence: -393.0870
  ssim: 0.0521
  iou: 0.1504

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.44707, std: 0.15672

Metrics for layer 7:
  pearson_correlation: 0.0088
  kl_divergence: -81.3425
  ssim: 0.0248
  iou: 0.1329
Layer 7 metrics:
  pearson_correlation: 0.0088
  kl_divergence: -81.3425
  ssim: 0.0248
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.53733, std: 0.14718

Metrics for layer 8:
  pearson_correlation: -0.0003
  kl_divergence: -95.3990
  ssim: 0.0383
  iou: 0.1529
Layer 8 metrics:
  pearson_correlation: -0.0003
  kl_divergence: -95.3990
  ssim: 0.0383
  iou: 0.1529

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.47688, std: 0.16108

Metrics for layer 9:
  pearson_correlation: -0.0173
  kl_divergence: -86.1645
  ssim: 0.0285
  iou: 0.1329
Layer 9 metrics:
  pearson_correlation: -0.0173
  kl_divergence: -86.1645
  ssim: 0.0285
  iou: 0.1329

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.54140, std: 0.17745

Metrics for layer 10:
  pearson_correlation: -0.0609
  kl_divergence: -16.1246
  ssim: -0.0301
  iou: 0.1395
Layer 10 metrics:
  pearson_correlation: -0.0609
  kl_divergence: -16.1246
  ssim: -0.0301
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.55324, std: 0.19089

Metrics for layer 11:
  pearson_correlation: 0.0069
  kl_divergence: -20.4147
  ssim: 0.0804
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: 0.0069
  kl_divergence: -20.4147
  ssim: 0.0804
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.53624, std: 0.19022

Metrics for layer 12:
  pearson_correlation: 0.0858
  kl_divergence: -18.0756
  ssim: 0.1299
  iou: 0.2250
Layer 12 metrics:
  pearson_correlation: 0.0858
  kl_divergence: -18.0756
  ssim: 0.1299
  iou: 0.2250
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer10/batch_1_strength_0.4_results.npy

Processing attention strength 0.8
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.8 0.  0. ]

Processing batch 1/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42494, std: 0.11682

Metrics for layer 0:
  pearson_correlation: -0.0037
  kl_divergence: -4570.0151
  ssim: 0.0509
  iou: 0.1427
Layer 0 metrics:
  pearson_correlation: -0.0037
  kl_divergence: -4570.0151
  ssim: 0.0509
  iou: 0.1427

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42688, std: 0.12919

Metrics for layer 1:
  pearson_correlation: -0.0004
  kl_divergence: -4557.7979
  ssim: 0.0450
  iou: 0.1391
Layer 1 metrics:
  pearson_correlation: -0.0004
  kl_divergence: -4557.7979
  ssim: 0.0450
  iou: 0.1391

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.45178, std: 0.12845

Metrics for layer 2:
  pearson_correlation: 0.0087
  kl_divergence: -1381.9406
  ssim: 0.0601
  iou: 0.1439
Layer 2 metrics:
  pearson_correlation: 0.0087
  kl_divergence: -1381.9406
  ssim: 0.0601
  iou: 0.1439

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.47566, std: 0.11808

Metrics for layer 3:
  pearson_correlation: 0.0004
  kl_divergence: -1439.7705
  ssim: 0.0613
  iou: 0.1368
Layer 3 metrics:
  pearson_correlation: 0.0004
  kl_divergence: -1439.7705
  ssim: 0.0613
  iou: 0.1368

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.44341, std: 0.13177

Metrics for layer 4:
  pearson_correlation: 0.0193
  kl_divergence: -350.5238
  ssim: 0.0767
  iou: 0.1470
Layer 4 metrics:
  pearson_correlation: 0.0193
  kl_divergence: -350.5238
  ssim: 0.0767
  iou: 0.1470

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.48351, std: 0.15481

Metrics for layer 5:
  pearson_correlation: 0.0182
  kl_divergence: -372.8409
  ssim: 0.0520
  iou: 0.1445
Layer 5 metrics:
  pearson_correlation: 0.0182
  kl_divergence: -372.8409
  ssim: 0.0520
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.39290, std: 0.13856

Metrics for layer 6:
  pearson_correlation: 0.0043
  kl_divergence: -297.9919
  ssim: 0.0607
  iou: 0.1563
Layer 6 metrics:
  pearson_correlation: 0.0043
  kl_divergence: -297.9919
  ssim: 0.0607
  iou: 0.1563

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.49075, std: 0.15266

Metrics for layer 7:
  pearson_correlation: 0.0006
  kl_divergence: -95.0956
  ssim: 0.0596
  iou: 0.1297
Layer 7 metrics:
  pearson_correlation: 0.0006
  kl_divergence: -95.0956
  ssim: 0.0596
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.51801, std: 0.16175

Metrics for layer 8:
  pearson_correlation: 0.0519
  kl_divergence: -98.1723
  ssim: 0.0876
  iou: 0.1297
Layer 8 metrics:
  pearson_correlation: 0.0519
  kl_divergence: -98.1723
  ssim: 0.0876
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.54447, std: 0.16801

Metrics for layer 9:
  pearson_correlation: 0.0419
  kl_divergence: -103.8461
  ssim: 0.0616
  iou: 0.1496
Layer 9 metrics:
  pearson_correlation: 0.0419
  kl_divergence: -103.8461
  ssim: 0.0616
  iou: 0.1496

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.50681, std: 0.21033

Metrics for layer 10:
  pearson_correlation: 0.1111
  kl_divergence: -23.3892
  ssim: 0.1931
  iou: 0.1395
Layer 10 metrics:
  pearson_correlation: 0.1111
  kl_divergence: -23.3892
  ssim: 0.1931
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.56415, std: 0.17205

Metrics for layer 11:
  pearson_correlation: -0.1194
  kl_divergence: -21.3718
  ssim: -0.0474
  iou: 0.0889
Layer 11 metrics:
  pearson_correlation: -0.1194
  kl_divergence: -21.3718
  ssim: -0.0474
  iou: 0.0889

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.44126, std: 0.20039

Metrics for layer 12:
  pearson_correlation: 0.0791
  kl_divergence: -18.9715
  ssim: -0.0034
  iou: 0.1136
Layer 12 metrics:
  pearson_correlation: 0.0791
  kl_divergence: -18.9715
  ssim: -0.0034
  iou: 0.1136
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer10/batch_0_strength_0.8_results.npy

Processing batch 2/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.46870, std: 0.12162

Metrics for layer 0:
  pearson_correlation: -0.0037
  kl_divergence: -3965.0320
  ssim: 0.0300
  iou: 0.1414
Layer 0 metrics:
  pearson_correlation: -0.0037
  kl_divergence: -3965.0320
  ssim: 0.0300
  iou: 0.1414

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.41871, std: 0.11552

Metrics for layer 1:
  pearson_correlation: 0.0051
  kl_divergence: -3748.8203
  ssim: 0.0367
  iou: 0.1481
Layer 1 metrics:
  pearson_correlation: 0.0051
  kl_divergence: -3748.8203
  ssim: 0.0367
  iou: 0.1481

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.47228, std: 0.12290

Metrics for layer 2:
  pearson_correlation: 0.0211
  kl_divergence: -1406.2197
  ssim: 0.0556
  iou: 0.1458
Layer 2 metrics:
  pearson_correlation: 0.0211
  kl_divergence: -1406.2197
  ssim: 0.0556
  iou: 0.1458

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.47482, std: 0.13714

Metrics for layer 3:
  pearson_correlation: -0.0107
  kl_divergence: -1396.1064
  ssim: 0.0407
  iou: 0.1391
Layer 3 metrics:
  pearson_correlation: -0.0107
  kl_divergence: -1396.1064
  ssim: 0.0407
  iou: 0.1391

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.45100, std: 0.15685

Metrics for layer 4:
  pearson_correlation: 0.0014
  kl_divergence: -357.0385
  ssim: 0.0534
  iou: 0.1420
Layer 4 metrics:
  pearson_correlation: 0.0014
  kl_divergence: -357.0385
  ssim: 0.0534
  iou: 0.1420

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47365, std: 0.15239

Metrics for layer 5:
  pearson_correlation: 0.0179
  kl_divergence: -381.5999
  ssim: 0.0558
  iou: 0.1470
Layer 5 metrics:
  pearson_correlation: 0.0179
  kl_divergence: -381.5999
  ssim: 0.0558
  iou: 0.1470

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.52105, std: 0.14953

Metrics for layer 6:
  pearson_correlation: -0.0094
  kl_divergence: -416.8953
  ssim: 0.0378
  iou: 0.1521
Layer 6 metrics:
  pearson_correlation: -0.0094
  kl_divergence: -416.8953
  ssim: 0.0378
  iou: 0.1521

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.52242, std: 0.15405

Metrics for layer 7:
  pearson_correlation: -0.0304
  kl_divergence: -90.3677
  ssim: 0.0393
  iou: 0.1329
Layer 7 metrics:
  pearson_correlation: -0.0304
  kl_divergence: -90.3677
  ssim: 0.0393
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.51018, std: 0.15732

Metrics for layer 8:
  pearson_correlation: -0.0138
  kl_divergence: -88.4162
  ssim: 0.0318
  iou: 0.1105
Layer 8 metrics:
  pearson_correlation: -0.0138
  kl_divergence: -88.4162
  ssim: 0.0318
  iou: 0.1105

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.49917, std: 0.14801

Metrics for layer 9:
  pearson_correlation: 0.0076
  kl_divergence: -89.2090
  ssim: 0.0472
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: 0.0076
  kl_divergence: -89.2090
  ssim: 0.0472
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.52246, std: 0.18741

Metrics for layer 10:
  pearson_correlation: 0.0499
  kl_divergence: -20.0408
  ssim: 0.0773
  iou: 0.1136
Layer 10 metrics:
  pearson_correlation: 0.0499
  kl_divergence: -20.0408
  ssim: 0.0773
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.52808, std: 0.19537

Metrics for layer 11:
  pearson_correlation: -0.0594
  kl_divergence: -16.6332
  ssim: -0.0253
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: -0.0594
  kl_divergence: -16.6332
  ssim: -0.0253
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.54275, std: 0.15239

Metrics for layer 12:
  pearson_correlation: 0.0164
  kl_divergence: -20.0174
  ssim: 0.0555
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: 0.0164
  kl_divergence: -20.0174
  ssim: 0.0555
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer10/batch_1_strength_0.8_results.npy

Processing attention strength 1.2
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.2 0.  0. ]

Processing batch 1/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.43630, std: 0.12444

Metrics for layer 0:
  pearson_correlation: 0.0021
  kl_divergence: -4646.5547
  ssim: 0.0473
  iou: 0.1442
Layer 0 metrics:
  pearson_correlation: 0.0021
  kl_divergence: -4646.5547
  ssim: 0.0473
  iou: 0.1442

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42470, std: 0.12188

Metrics for layer 1:
  pearson_correlation: -0.0086
  kl_divergence: -4551.2153
  ssim: 0.0474
  iou: 0.1442
Layer 1 metrics:
  pearson_correlation: -0.0086
  kl_divergence: -4551.2153
  ssim: 0.0474
  iou: 0.1442

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.47572, std: 0.11937

Metrics for layer 2:
  pearson_correlation: -0.0036
  kl_divergence: -1439.6138
  ssim: 0.0546
  iou: 0.1466
Layer 2 metrics:
  pearson_correlation: -0.0036
  kl_divergence: -1439.6138
  ssim: 0.0546
  iou: 0.1466

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.45984, std: 0.12806

Metrics for layer 3:
  pearson_correlation: -0.0050
  kl_divergence: -1394.1733
  ssim: 0.0532
  iou: 0.1454
Layer 3 metrics:
  pearson_correlation: -0.0050
  kl_divergence: -1394.1733
  ssim: 0.0532
  iou: 0.1454

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.42830, std: 0.14368

Metrics for layer 4:
  pearson_correlation: -0.0243
  kl_divergence: -327.9468
  ssim: 0.0613
  iou: 0.1362
Layer 4 metrics:
  pearson_correlation: -0.0243
  kl_divergence: -327.9468
  ssim: 0.0613
  iou: 0.1362

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.48283, std: 0.15121

Metrics for layer 5:
  pearson_correlation: 0.0380
  kl_divergence: -379.5892
  ssim: 0.0723
  iou: 0.1487
Layer 5 metrics:
  pearson_correlation: 0.0380
  kl_divergence: -379.5892
  ssim: 0.0723
  iou: 0.1487

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.42888, std: 0.15549

Metrics for layer 6:
  pearson_correlation: 0.0231
  kl_divergence: -328.7891
  ssim: 0.0669
  iou: 0.1470
Layer 6 metrics:
  pearson_correlation: 0.0231
  kl_divergence: -328.7891
  ssim: 0.0669
  iou: 0.1470

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.47114, std: 0.16874

Metrics for layer 7:
  pearson_correlation: 0.0363
  kl_divergence: -86.7950
  ssim: 0.0588
  iou: 0.1362
Layer 7 metrics:
  pearson_correlation: 0.0363
  kl_divergence: -86.7950
  ssim: 0.0588
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.41218, std: 0.14852

Metrics for layer 8:
  pearson_correlation: -0.0422
  kl_divergence: -72.6649
  ssim: 0.0194
  iou: 0.1462
Layer 8 metrics:
  pearson_correlation: -0.0422
  kl_divergence: -72.6649
  ssim: 0.0194
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.43475, std: 0.16044

Metrics for layer 9:
  pearson_correlation: 0.0082
  kl_divergence: -78.5853
  ssim: 0.0421
  iou: 0.1496
Layer 9 metrics:
  pearson_correlation: 0.0082
  kl_divergence: -78.5853
  ssim: 0.0421
  iou: 0.1496

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.56747, std: 0.19893

Metrics for layer 10:
  pearson_correlation: 0.0014
  kl_divergence: -25.6646
  ssim: 0.0573
  iou: 0.1667
Layer 10 metrics:
  pearson_correlation: 0.0014
  kl_divergence: -25.6646
  ssim: 0.0573
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.53906, std: 0.17512

Metrics for layer 11:
  pearson_correlation: 0.0038
  kl_divergence: -25.3859
  ssim: 0.0910
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: 0.0038
  kl_divergence: -25.3859
  ssim: 0.0910
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.47661, std: 0.14716

Metrics for layer 12:
  pearson_correlation: 0.0258
  kl_divergence: -17.6179
  ssim: 0.0642
  iou: 0.1807
Layer 12 metrics:
  pearson_correlation: 0.0258
  kl_divergence: -17.6179
  ssim: 0.0642
  iou: 0.1807
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer10/batch_0_strength_1.2_results.npy

Processing batch 2/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.40908, std: 0.11044

Metrics for layer 0:
  pearson_correlation: 0.0122
  kl_divergence: -3714.2100
  ssim: 0.0413
  iou: 0.1494
Layer 0 metrics:
  pearson_correlation: 0.0122
  kl_divergence: -3714.2100
  ssim: 0.0413
  iou: 0.1494

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.40172, std: 0.11809

Metrics for layer 1:
  pearson_correlation: 0.0057
  kl_divergence: -3659.6497
  ssim: 0.0379
  iou: 0.1468
Layer 1 metrics:
  pearson_correlation: 0.0057
  kl_divergence: -3659.6497
  ssim: 0.0379
  iou: 0.1468

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.47748, std: 0.14138

Metrics for layer 2:
  pearson_correlation: 0.0074
  kl_divergence: -1400.9028
  ssim: 0.0424
  iou: 0.1485
Layer 2 metrics:
  pearson_correlation: 0.0074
  kl_divergence: -1400.9028
  ssim: 0.0424
  iou: 0.1485

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.46370, std: 0.13886

Metrics for layer 3:
  pearson_correlation: -0.0104
  kl_divergence: -1369.6426
  ssim: 0.0424
  iou: 0.1399
Layer 3 metrics:
  pearson_correlation: -0.0104
  kl_divergence: -1369.6426
  ssim: 0.0424
  iou: 0.1399

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.53212, std: 0.13838

Metrics for layer 4:
  pearson_correlation: -0.0227
  kl_divergence: -426.7766
  ssim: 0.0501
  iou: 0.1362
Layer 4 metrics:
  pearson_correlation: -0.0227
  kl_divergence: -426.7766
  ssim: 0.0501
  iou: 0.1362

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48164, std: 0.14844

Metrics for layer 5:
  pearson_correlation: -0.0122
  kl_divergence: -386.0465
  ssim: 0.0483
  iou: 0.1462
Layer 5 metrics:
  pearson_correlation: -0.0122
  kl_divergence: -386.0465
  ssim: 0.0483
  iou: 0.1462

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47217, std: 0.13328

Metrics for layer 6:
  pearson_correlation: 0.0095
  kl_divergence: -387.2224
  ssim: 0.0620
  iou: 0.1429
Layer 6 metrics:
  pearson_correlation: 0.0095
  kl_divergence: -387.2224
  ssim: 0.0620
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.48776, std: 0.17574

Metrics for layer 7:
  pearson_correlation: 0.0019
  kl_divergence: -85.2669
  ssim: 0.0266
  iou: 0.1529
Layer 7 metrics:
  pearson_correlation: 0.0019
  kl_divergence: -85.2669
  ssim: 0.0266
  iou: 0.1529

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.54752, std: 0.15062

Metrics for layer 8:
  pearson_correlation: -0.0075
  kl_divergence: -95.2010
  ssim: 0.0280
  iou: 0.1395
Layer 8 metrics:
  pearson_correlation: -0.0075
  kl_divergence: -95.2010
  ssim: 0.0280
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.56041, std: 0.15668

Metrics for layer 9:
  pearson_correlation: -0.0349
  kl_divergence: -95.9663
  ssim: 0.0262
  iou: 0.1462
Layer 9 metrics:
  pearson_correlation: -0.0349
  kl_divergence: -95.9663
  ssim: 0.0262
  iou: 0.1462

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.55040, std: 0.20036

Metrics for layer 10:
  pearson_correlation: -0.0013
  kl_divergence: -23.6086
  ssim: 0.0110
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: -0.0013
  kl_divergence: -23.6086
  ssim: 0.0110
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.49368, std: 0.18639

Metrics for layer 11:
  pearson_correlation: 0.1743
  kl_divergence: -21.1570
  ssim: 0.0767
  iou: 0.2727
Layer 11 metrics:
  pearson_correlation: 0.1743
  kl_divergence: -21.1570
  ssim: 0.0767
  iou: 0.2727

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.49660, std: 0.18240

Metrics for layer 12:
  pearson_correlation: 0.0308
  kl_divergence: -19.2758
  ssim: 0.1065
  iou: 0.1136
Layer 12 metrics:
  pearson_correlation: 0.0308
  kl_divergence: -19.2758
  ssim: 0.1065
  iou: 0.1136
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer10/batch_1_strength_1.2_results.npy

Analysis complete! Results saved to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer10
Completed experiment for category 5, layer 10
----------------------------------------
Running experiment for category 5, layer 11
===================================================
Starting experiment:
Category: 5
Layer: 11
Logs will be saved to: /scratch/hy2611/CNN_attention/logs/attention_analysis_20241216_104146/category5/layer11
===================================================
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-12-16 11:12:42.997169: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-16 11:12:43.016509: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2024-12-16 11:12:43.016909: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4e4d5c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:12:43.016920: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-16 11:12:43.019677: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-16 11:12:43.147729: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4e41290 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:12:43.147745: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-12-16 11:12:43.148294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:2f:00.0
2024-12-16 11:12:43.149533: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:12:43.150649: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:12:43.151736: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:12:43.152808: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:12:43.153895: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:12:43.154968: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:12:43.156033: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:12:43.156045: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-12-16 11:12:43.156061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-16 11:12:43.156066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-16 11:12:43.156069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:61: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:87: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:15: sigmoid_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.sigmoid_cross_entropy instead. Note that the order of the predictions and labels arguments has been changed.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:322: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:82: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.


Verifying paths:
tc_path: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs exists
weight_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists
image_path: /scratch/hy2611/CNN_attention/Data/VGG16/images exists
save_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists

Initializing model...
('c11', [1, 224, 224, 64])
('c12', [1, 224, 224, 64])
('c21', [1, 112, 112, 128])
('c22', [1, 112, 112, 128])
('c31', [1, 56, 56, 256])
('c32', [1, 56, 56, 256])
('c33', [1, 56, 56, 256])
('c41', [1, 28, 28, 512])
('c42', [1, 28, 28, 512])
('c43', [1, 28, 28, 512])
('c51', [1, 14, 14, 512])
('c52', [1, 14, 14, 512])
('c53', [1, 14, 14, 512])
(0, 'conv1_1_W', (3, 3, 3, 64))
(1, 'conv1_1_b', (64,))
(2, 'conv1_2_W', (3, 3, 64, 64))
(3, 'conv1_2_b', (64,))
(4, 'conv2_1_W', (3, 3, 64, 128))
(5, 'conv2_1_b', (128,))
(6, 'conv2_2_W', (3, 3, 128, 128))
(7, 'conv2_2_b', (128,))
(8, 'conv3_1_W', (3, 3, 128, 256))
(9, 'conv3_1_b', (256,))
(10, 'conv3_2_W', (3, 3, 256, 256))
(11, 'conv3_2_b', (256,))
(12, 'conv3_3_W', (3, 3, 256, 256))
(13, 'conv3_3_b', (256,))
(14, 'conv4_1_W', (3, 3, 256, 512))
(15, 'conv4_1_b', (512,))
(16, 'conv4_2_W', (3, 3, 512, 512))
(17, 'conv4_2_b', (512,))
(18, 'conv4_3_W', (3, 3, 512, 512))
(19, 'conv4_3_b', (512,))
(20, 'conv5_1_W', (3, 3, 512, 512))
(21, 'conv5_1_b', (512,))
(22, 'conv5_2_W', (3, 3, 512, 512))
(23, 'conv5_2_b', (512,))
(24, 'conv5_3_W', (3, 3, 512, 512))
(25, 'conv5_3_b', (512,))
(26, 'fc6_W', (25088, 4096))
(27, 'fc6_b', (4096,))
(28, 'fc7_W', (4096, 4096))
(29, 'fc7_b', (4096,))
Checking checkpoint files:
Data file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.data-00000-of-00001 - Found
Index file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.index - Found
Loading checkpoint from: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt
Checkpoint loaded successfully

Initializing components...
Found tuning curves file: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs/featvecs20_train35_c.txt

Loading category 5 data...
Original positive images shape: (2, 224, 224, 3)

Processing data...

Processing attention strength 0.0
Attention vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

Processing batch 1/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.41771, std: 0.12181

Metrics for layer 0:
  pearson_correlation: -0.0026
  kl_divergence: -4502.5986
  ssim: 0.0478
  iou: 0.1428
Layer 0 metrics:
  pearson_correlation: -0.0026
  kl_divergence: -4502.5986
  ssim: 0.0478
  iou: 0.1428

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.39614, std: 0.10076

Metrics for layer 1:
  pearson_correlation: 0.0042
  kl_divergence: -4385.4741
  ssim: 0.0676
  iou: 0.1433
Layer 1 metrics:
  pearson_correlation: 0.0042
  kl_divergence: -4385.4741
  ssim: 0.0676
  iou: 0.1433

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.44771, std: 0.12646

Metrics for layer 2:
  pearson_correlation: -0.0105
  kl_divergence: -1369.0618
  ssim: 0.0569
  iou: 0.1399
Layer 2 metrics:
  pearson_correlation: -0.0105
  kl_divergence: -1369.0618
  ssim: 0.0569
  iou: 0.1399

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.45333, std: 0.12823

Metrics for layer 3:
  pearson_correlation: 0.0062
  kl_divergence: -1383.8644
  ssim: 0.0599
  iou: 0.1364
Layer 3 metrics:
  pearson_correlation: 0.0062
  kl_divergence: -1383.8644
  ssim: 0.0599
  iou: 0.1364

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.48038, std: 0.14182

Metrics for layer 4:
  pearson_correlation: 0.0084
  kl_divergence: -373.6163
  ssim: 0.0597
  iou: 0.1487
Layer 4 metrics:
  pearson_correlation: 0.0084
  kl_divergence: -373.6163
  ssim: 0.0597
  iou: 0.1487

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.44919, std: 0.13384

Metrics for layer 5:
  pearson_correlation: -0.0157
  kl_divergence: -350.2109
  ssim: 0.0610
  iou: 0.1338
Layer 5 metrics:
  pearson_correlation: -0.0157
  kl_divergence: -350.2109
  ssim: 0.0610
  iou: 0.1338

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.49180, std: 0.15132

Metrics for layer 6:
  pearson_correlation: -0.0039
  kl_divergence: -375.5438
  ssim: 0.0495
  iou: 0.1429
Layer 6 metrics:
  pearson_correlation: -0.0039
  kl_divergence: -375.5438
  ssim: 0.0495
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.46532, std: 0.14315

Metrics for layer 7:
  pearson_correlation: 0.0199
  kl_divergence: -86.3265
  ssim: 0.0847
  iou: 0.1168
Layer 7 metrics:
  pearson_correlation: 0.0199
  kl_divergence: -86.3265
  ssim: 0.0847
  iou: 0.1168

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.46806, std: 0.14784

Metrics for layer 8:
  pearson_correlation: -0.0177
  kl_divergence: -81.9514
  ssim: 0.0435
  iou: 0.1362
Layer 8 metrics:
  pearson_correlation: -0.0177
  kl_divergence: -81.9514
  ssim: 0.0435
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.46133, std: 0.14907

Metrics for layer 9:
  pearson_correlation: -0.0706
  kl_divergence: -78.6832
  ssim: 0.0298
  iou: 0.1329
Layer 9 metrics:
  pearson_correlation: -0.0706
  kl_divergence: -78.6832
  ssim: 0.0298
  iou: 0.1329

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.51149, std: 0.17448

Metrics for layer 10:
  pearson_correlation: 0.0113
  kl_divergence: -18.7844
  ssim: 0.0970
  iou: 0.1395
Layer 10 metrics:
  pearson_correlation: 0.0113
  kl_divergence: -18.7844
  ssim: 0.0970
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.40990, std: 0.17653

Metrics for layer 11:
  pearson_correlation: 0.0012
  kl_divergence: -10.3982
  ssim: 0.0433
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: 0.0012
  kl_divergence: -10.3982
  ssim: 0.0433
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.44534, std: 0.17430

Metrics for layer 12:
  pearson_correlation: 0.1011
  kl_divergence: -18.8711
  ssim: 0.1979
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: 0.1011
  kl_divergence: -18.8711
  ssim: 0.1979
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer11/batch_0_strength_0.0_results.npy

Processing batch 2/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.45082, std: 0.11649

Metrics for layer 0:
  pearson_correlation: 0.0079
  kl_divergence: -3899.0405
  ssim: 0.0346
  iou: 0.1458
Layer 0 metrics:
  pearson_correlation: 0.0079
  kl_divergence: -3899.0405
  ssim: 0.0346
  iou: 0.1458

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.42201, std: 0.11817

Metrics for layer 1:
  pearson_correlation: -0.0056
  kl_divergence: -3754.1333
  ssim: 0.0346
  iou: 0.1418
Layer 1 metrics:
  pearson_correlation: -0.0056
  kl_divergence: -3754.1333
  ssim: 0.0346
  iou: 0.1418

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.45952, std: 0.13260

Metrics for layer 2:
  pearson_correlation: -0.0230
  kl_divergence: -1362.1147
  ssim: 0.0458
  iou: 0.1346
Layer 2 metrics:
  pearson_correlation: -0.0230
  kl_divergence: -1362.1147
  ssim: 0.0458
  iou: 0.1346

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.39945, std: 0.10547

Metrics for layer 3:
  pearson_correlation: 0.0086
  kl_divergence: -1253.7180
  ssim: 0.0787
  iou: 0.1477
Layer 3 metrics:
  pearson_correlation: 0.0086
  kl_divergence: -1253.7180
  ssim: 0.0787
  iou: 0.1477

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.44770, std: 0.14224

Metrics for layer 4:
  pearson_correlation: 0.0385
  kl_divergence: -361.1701
  ssim: 0.0651
  iou: 0.1563
Layer 4 metrics:
  pearson_correlation: 0.0385
  kl_divergence: -361.1701
  ssim: 0.0651
  iou: 0.1563

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.44610, std: 0.14331

Metrics for layer 5:
  pearson_correlation: 0.0258
  kl_divergence: -363.2619
  ssim: 0.0550
  iou: 0.1371
Layer 5 metrics:
  pearson_correlation: 0.0258
  kl_divergence: -363.2619
  ssim: 0.0550
  iou: 0.1371

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.42244, std: 0.13753

Metrics for layer 6:
  pearson_correlation: 0.0116
  kl_divergence: -336.5865
  ssim: 0.0655
  iou: 0.1454
Layer 6 metrics:
  pearson_correlation: 0.0116
  kl_divergence: -336.5865
  ssim: 0.0655
  iou: 0.1454

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.46105, std: 0.16592

Metrics for layer 7:
  pearson_correlation: -0.0161
  kl_divergence: -80.7661
  ssim: 0.0282
  iou: 0.1462
Layer 7 metrics:
  pearson_correlation: -0.0161
  kl_divergence: -80.7661
  ssim: 0.0282
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.50679, std: 0.16761

Metrics for layer 8:
  pearson_correlation: -0.0642
  kl_divergence: -88.6122
  ssim: 0.0084
  iou: 0.1011
Layer 8 metrics:
  pearson_correlation: -0.0642
  kl_divergence: -88.6122
  ssim: 0.0084
  iou: 0.1011

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.49196, std: 0.16616

Metrics for layer 9:
  pearson_correlation: 0.0092
  kl_divergence: -87.8240
  ssim: 0.0390
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: 0.0092
  kl_divergence: -87.8240
  ssim: 0.0390
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.44969, std: 0.18572

Metrics for layer 10:
  pearson_correlation: 0.0057
  kl_divergence: -8.8609
  ssim: 0.0445
  iou: 0.1264
Layer 10 metrics:
  pearson_correlation: 0.0057
  kl_divergence: -8.8609
  ssim: 0.0445
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.54587, std: 0.16800

Metrics for layer 11:
  pearson_correlation: 0.0492
  kl_divergence: -24.9759
  ssim: 0.0707
  iou: 0.1667
Layer 11 metrics:
  pearson_correlation: 0.0492
  kl_divergence: -24.9759
  ssim: 0.0707
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.49118, std: 0.18605

Metrics for layer 12:
  pearson_correlation: 0.0307
  kl_divergence: -14.7997
  ssim: 0.1161
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: 0.0307
  kl_divergence: -14.7997
  ssim: 0.1161
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer11/batch_1_strength_0.0_results.npy

Processing attention strength 0.4
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.4 0. ]

Processing batch 1/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42241, std: 0.11751

Metrics for layer 0:
  pearson_correlation: -0.0043
  kl_divergence: -4548.5234
  ssim: 0.0511
  iou: 0.1413
Layer 0 metrics:
  pearson_correlation: -0.0043
  kl_divergence: -4548.5234
  ssim: 0.0511
  iou: 0.1413

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42960, std: 0.11802

Metrics for layer 1:
  pearson_correlation: 0.0054
  kl_divergence: -4613.2617
  ssim: 0.0490
  iou: 0.1453
Layer 1 metrics:
  pearson_correlation: 0.0054
  kl_divergence: -4613.2617
  ssim: 0.0490
  iou: 0.1453

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.49661, std: 0.13008

Metrics for layer 2:
  pearson_correlation: -0.0054
  kl_divergence: -1480.9441
  ssim: 0.0505
  iou: 0.1404
Layer 2 metrics:
  pearson_correlation: -0.0054
  kl_divergence: -1480.9441
  ssim: 0.0505
  iou: 0.1404

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.47996, std: 0.12799

Metrics for layer 3:
  pearson_correlation: 0.0041
  kl_divergence: -1445.2842
  ssim: 0.0529
  iou: 0.1445
Layer 3 metrics:
  pearson_correlation: 0.0041
  kl_divergence: -1445.2842
  ssim: 0.0529
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.48598, std: 0.14326

Metrics for layer 4:
  pearson_correlation: 0.0221
  kl_divergence: -382.2145
  ssim: 0.0641
  iou: 0.1470
Layer 4 metrics:
  pearson_correlation: 0.0221
  kl_divergence: -382.2145
  ssim: 0.0641
  iou: 0.1470

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47339, std: 0.14693

Metrics for layer 5:
  pearson_correlation: -0.0102
  kl_divergence: -367.1360
  ssim: 0.0592
  iou: 0.1454
Layer 5 metrics:
  pearson_correlation: -0.0102
  kl_divergence: -367.1360
  ssim: 0.0592
  iou: 0.1454

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47927, std: 0.15844

Metrics for layer 6:
  pearson_correlation: -0.0160
  kl_divergence: -369.2016
  ssim: 0.0524
  iou: 0.1371
Layer 6 metrics:
  pearson_correlation: -0.0160
  kl_divergence: -369.2016
  ssim: 0.0524
  iou: 0.1371

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.45798, std: 0.14968

Metrics for layer 7:
  pearson_correlation: -0.0407
  kl_divergence: -83.7796
  ssim: 0.0344
  iou: 0.1042
Layer 7 metrics:
  pearson_correlation: -0.0407
  kl_divergence: -83.7796
  ssim: 0.0344
  iou: 0.1042

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.47030, std: 0.17685

Metrics for layer 8:
  pearson_correlation: 0.0195
  kl_divergence: -86.7621
  ssim: 0.0435
  iou: 0.1395
Layer 8 metrics:
  pearson_correlation: 0.0195
  kl_divergence: -86.7621
  ssim: 0.0435
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.43691, std: 0.17540

Metrics for layer 9:
  pearson_correlation: -0.0301
  kl_divergence: -73.5004
  ssim: 0.0479
  iou: 0.1632
Layer 9 metrics:
  pearson_correlation: -0.0301
  kl_divergence: -73.5004
  ssim: 0.0479
  iou: 0.1632

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.43779, std: 0.19260

Metrics for layer 10:
  pearson_correlation: 0.0919
  kl_divergence: -17.8542
  ssim: 0.1551
  iou: 0.2099
Layer 10 metrics:
  pearson_correlation: 0.0919
  kl_divergence: -17.8542
  ssim: 0.1551
  iou: 0.2099

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.46480, std: 0.18484

Metrics for layer 11:
  pearson_correlation: 0.0446
  kl_divergence: -20.1416
  ssim: 0.1033
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: 0.0446
  kl_divergence: -20.1416
  ssim: 0.1033
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.42446, std: 0.20071

Metrics for layer 12:
  pearson_correlation: 0.0278
  kl_divergence: -15.7842
  ssim: 0.0294
  iou: 0.1264
Layer 12 metrics:
  pearson_correlation: 0.0278
  kl_divergence: -15.7842
  ssim: 0.0294
  iou: 0.1264
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer11/batch_0_strength_0.4_results.npy

Processing batch 2/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.40637, std: 0.11756

Metrics for layer 0:
  pearson_correlation: -0.0020
  kl_divergence: -3681.4727
  ssim: 0.0368
  iou: 0.1409
Layer 0 metrics:
  pearson_correlation: -0.0020
  kl_divergence: -3681.4727
  ssim: 0.0368
  iou: 0.1409

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.44629, std: 0.12857

Metrics for layer 1:
  pearson_correlation: -0.0088
  kl_divergence: -3852.5789
  ssim: 0.0290
  iou: 0.1431
Layer 1 metrics:
  pearson_correlation: -0.0088
  kl_divergence: -3852.5789
  ssim: 0.0290
  iou: 0.1431

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.48342, std: 0.12517

Metrics for layer 2:
  pearson_correlation: -0.0054
  kl_divergence: -1421.3080
  ssim: 0.0469
  iou: 0.1389
Layer 2 metrics:
  pearson_correlation: -0.0054
  kl_divergence: -1421.3080
  ssim: 0.0469
  iou: 0.1389

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.44333, std: 0.12728

Metrics for layer 3:
  pearson_correlation: -0.0007
  kl_divergence: -1335.8066
  ssim: 0.0523
  iou: 0.1443
Layer 3 metrics:
  pearson_correlation: -0.0007
  kl_divergence: -1335.8066
  ssim: 0.0523
  iou: 0.1443

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.44668, std: 0.14852

Metrics for layer 4:
  pearson_correlation: 0.0083
  kl_divergence: -354.1469
  ssim: 0.0580
  iou: 0.1371
Layer 4 metrics:
  pearson_correlation: 0.0083
  kl_divergence: -354.1469
  ssim: 0.0580
  iou: 0.1371

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.44145, std: 0.12559

Metrics for layer 5:
  pearson_correlation: -0.0135
  kl_divergence: -360.3211
  ssim: 0.0496
  iou: 0.1462
Layer 5 metrics:
  pearson_correlation: -0.0135
  kl_divergence: -360.3211
  ssim: 0.0496
  iou: 0.1462

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.50876, std: 0.13187

Metrics for layer 6:
  pearson_correlation: 0.0002
  kl_divergence: -411.6065
  ssim: 0.0535
  iou: 0.1387
Layer 6 metrics:
  pearson_correlation: 0.0002
  kl_divergence: -411.6065
  ssim: 0.0535
  iou: 0.1387

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.56029, std: 0.15135

Metrics for layer 7:
  pearson_correlation: -0.0259
  kl_divergence: -94.2101
  ssim: 0.0265
  iou: 0.1395
Layer 7 metrics:
  pearson_correlation: -0.0259
  kl_divergence: -94.2101
  ssim: 0.0265
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.55266, std: 0.16871

Metrics for layer 8:
  pearson_correlation: 0.0036
  kl_divergence: -93.7456
  ssim: 0.0275
  iou: 0.1264
Layer 8 metrics:
  pearson_correlation: 0.0036
  kl_divergence: -93.7456
  ssim: 0.0275
  iou: 0.1264

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.50206, std: 0.16280

Metrics for layer 9:
  pearson_correlation: -0.0246
  kl_divergence: -89.4816
  ssim: 0.0263
  iou: 0.1362
Layer 9 metrics:
  pearson_correlation: -0.0246
  kl_divergence: -89.4816
  ssim: 0.0263
  iou: 0.1362

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.42953, std: 0.16534

Metrics for layer 10:
  pearson_correlation: 0.0401
  kl_divergence: -12.5363
  ssim: 0.1012
  iou: 0.1951
Layer 10 metrics:
  pearson_correlation: 0.0401
  kl_divergence: -12.5363
  ssim: 0.1012
  iou: 0.1951

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.51831, std: 0.19917

Metrics for layer 11:
  pearson_correlation: 0.0725
  kl_divergence: -21.0382
  ssim: 0.0518
  iou: 0.2099
Layer 11 metrics:
  pearson_correlation: 0.0725
  kl_divergence: -21.0382
  ssim: 0.0518
  iou: 0.2099

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.42313, std: 0.19232

Metrics for layer 12:
  pearson_correlation: -0.0227
  kl_divergence: -10.9851
  ssim: -0.0310
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: -0.0227
  kl_divergence: -10.9851
  ssim: -0.0310
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer11/batch_1_strength_0.4_results.npy

Processing attention strength 0.8
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.8 0. ]

Processing batch 1/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42581, std: 0.12113

Metrics for layer 0:
  pearson_correlation: 0.0037
  kl_divergence: -4575.2983
  ssim: 0.0500
  iou: 0.1445
Layer 0 metrics:
  pearson_correlation: 0.0037
  kl_divergence: -4575.2983
  ssim: 0.0500
  iou: 0.1445

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42320, std: 0.12408

Metrics for layer 1:
  pearson_correlation: 0.0028
  kl_divergence: -4545.0645
  ssim: 0.0470
  iou: 0.1427
Layer 1 metrics:
  pearson_correlation: 0.0028
  kl_divergence: -4545.0645
  ssim: 0.0470
  iou: 0.1427

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.43873, std: 0.13101

Metrics for layer 2:
  pearson_correlation: -0.0243
  kl_divergence: -1337.9082
  ssim: 0.0513
  iou: 0.1408
Layer 2 metrics:
  pearson_correlation: -0.0243
  kl_divergence: -1337.9082
  ssim: 0.0513
  iou: 0.1408

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.43330, std: 0.13841

Metrics for layer 3:
  pearson_correlation: 0.0062
  kl_divergence: -1324.6272
  ssim: 0.0544
  iou: 0.1391
Layer 3 metrics:
  pearson_correlation: 0.0062
  kl_divergence: -1324.6272
  ssim: 0.0544
  iou: 0.1391

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.45953, std: 0.14866

Metrics for layer 4:
  pearson_correlation: 0.0262
  kl_divergence: -357.9483
  ssim: 0.0634
  iou: 0.1521
Layer 4 metrics:
  pearson_correlation: 0.0262
  kl_divergence: -357.9483
  ssim: 0.0634
  iou: 0.1521

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46994, std: 0.14673

Metrics for layer 5:
  pearson_correlation: -0.0265
  kl_divergence: -360.0011
  ssim: 0.0413
  iou: 0.1329
Layer 5 metrics:
  pearson_correlation: -0.0265
  kl_divergence: -360.0011
  ssim: 0.0413
  iou: 0.1329

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46015, std: 0.14444

Metrics for layer 6:
  pearson_correlation: 0.0118
  kl_divergence: -358.5350
  ssim: 0.0582
  iou: 0.1496
Layer 6 metrics:
  pearson_correlation: 0.0118
  kl_divergence: -358.5350
  ssim: 0.0582
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.46519, std: 0.18263

Metrics for layer 7:
  pearson_correlation: -0.0376
  kl_divergence: -72.5100
  ssim: 0.0044
  iou: 0.1297
Layer 7 metrics:
  pearson_correlation: -0.0376
  kl_divergence: -72.5100
  ssim: 0.0044
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.57469, std: 0.15108

Metrics for layer 8:
  pearson_correlation: -0.0582
  kl_divergence: -108.0797
  ssim: 0.0330
  iou: 0.1362
Layer 8 metrics:
  pearson_correlation: -0.0582
  kl_divergence: -108.0797
  ssim: 0.0330
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.47392, std: 0.15400

Metrics for layer 9:
  pearson_correlation: 0.0050
  kl_divergence: -82.1334
  ssim: 0.0416
  iou: 0.1598
Layer 9 metrics:
  pearson_correlation: 0.0050
  kl_divergence: -82.1334
  ssim: 0.0416
  iou: 0.1598

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49325, std: 0.22188

Metrics for layer 10:
  pearson_correlation: -0.0789
  kl_divergence: -19.7936
  ssim: -0.0055
  iou: 0.1011
Layer 10 metrics:
  pearson_correlation: -0.0789
  kl_divergence: -19.7936
  ssim: -0.0055
  iou: 0.1011

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.52479, std: 0.19386

Metrics for layer 11:
  pearson_correlation: -0.1140
  kl_divergence: -17.4261
  ssim: -0.0039
  iou: 0.0889
Layer 11 metrics:
  pearson_correlation: -0.1140
  kl_divergence: -17.4261
  ssim: -0.0039
  iou: 0.0889

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49608, std: 0.19783

Metrics for layer 12:
  pearson_correlation: 0.1526
  kl_divergence: -23.1806
  ssim: 0.1786
  iou: 0.1807
Layer 12 metrics:
  pearson_correlation: 0.1526
  kl_divergence: -23.1806
  ssim: 0.1786
  iou: 0.1807
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer11/batch_0_strength_0.8_results.npy

Processing batch 2/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.41988, std: 0.11407

Metrics for layer 0:
  pearson_correlation: 0.0022
  kl_divergence: -3756.6157
  ssim: 0.0372
  iou: 0.1432
Layer 0 metrics:
  pearson_correlation: 0.0022
  kl_divergence: -3756.6157
  ssim: 0.0372
  iou: 0.1432

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.41803, std: 0.11536

Metrics for layer 1:
  pearson_correlation: 0.0063
  kl_divergence: -3748.5471
  ssim: 0.0369
  iou: 0.1417
Layer 1 metrics:
  pearson_correlation: 0.0063
  kl_divergence: -3748.5471
  ssim: 0.0369
  iou: 0.1417

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.42993, std: 0.11341

Metrics for layer 2:
  pearson_correlation: 0.0167
  kl_divergence: -1317.9290
  ssim: 0.0635
  iou: 0.1424
Layer 2 metrics:
  pearson_correlation: 0.0167
  kl_divergence: -1317.9290
  ssim: 0.0635
  iou: 0.1424

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.47169, std: 0.12745

Metrics for layer 3:
  pearson_correlation: -0.0153
  kl_divergence: -1392.0796
  ssim: 0.0453
  iou: 0.1422
Layer 3 metrics:
  pearson_correlation: -0.0153
  kl_divergence: -1392.0796
  ssim: 0.0453
  iou: 0.1422

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.50696, std: 0.14591

Metrics for layer 4:
  pearson_correlation: 0.0298
  kl_divergence: -410.6175
  ssim: 0.0511
  iou: 0.1563
Layer 4 metrics:
  pearson_correlation: 0.0298
  kl_divergence: -410.6175
  ssim: 0.0511
  iou: 0.1563

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48204, std: 0.14160

Metrics for layer 5:
  pearson_correlation: 0.0256
  kl_divergence: -391.5033
  ssim: 0.0519
  iou: 0.1512
Layer 5 metrics:
  pearson_correlation: 0.0256
  kl_divergence: -391.5033
  ssim: 0.0519
  iou: 0.1512

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.45391, std: 0.15424

Metrics for layer 6:
  pearson_correlation: -0.0204
  kl_divergence: -359.0289
  ssim: 0.0527
  iou: 0.1429
Layer 6 metrics:
  pearson_correlation: -0.0204
  kl_divergence: -359.0289
  ssim: 0.0527
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.41329, std: 0.13230

Metrics for layer 7:
  pearson_correlation: -0.0529
  kl_divergence: -76.8206
  ssim: 0.0331
  iou: 0.1362
Layer 7 metrics:
  pearson_correlation: -0.0529
  kl_divergence: -76.8206
  ssim: 0.0331
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.48794, std: 0.15494

Metrics for layer 8:
  pearson_correlation: -0.0218
  kl_divergence: -87.0727
  ssim: 0.0261
  iou: 0.1429
Layer 8 metrics:
  pearson_correlation: -0.0218
  kl_divergence: -87.0727
  ssim: 0.0261
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.46873, std: 0.15889

Metrics for layer 9:
  pearson_correlation: -0.0284
  kl_divergence: -83.9173
  ssim: 0.0357
  iou: 0.1329
Layer 9 metrics:
  pearson_correlation: -0.0284
  kl_divergence: -83.9173
  ssim: 0.0357
  iou: 0.1329

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.53446, std: 0.18833

Metrics for layer 10:
  pearson_correlation: -0.0402
  kl_divergence: -14.3772
  ssim: 0.0341
  iou: 0.1667
Layer 10 metrics:
  pearson_correlation: -0.0402
  kl_divergence: -14.3772
  ssim: 0.0341
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.46368, std: 0.17656

Metrics for layer 11:
  pearson_correlation: 0.1097
  kl_divergence: -17.6582
  ssim: 0.0798
  iou: 0.1951
Layer 11 metrics:
  pearson_correlation: 0.1097
  kl_divergence: -17.6582
  ssim: 0.0798
  iou: 0.1951

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.48366, std: 0.17069

Metrics for layer 12:
  pearson_correlation: -0.0457
  kl_divergence: -16.0541
  ssim: -0.0158
  iou: 0.0889
Layer 12 metrics:
  pearson_correlation: -0.0457
  kl_divergence: -16.0541
  ssim: -0.0158
  iou: 0.0889
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer11/batch_1_strength_0.8_results.npy

Processing attention strength 1.2
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.2 0. ]

Processing batch 1/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.43723, std: 0.12626

Metrics for layer 0:
  pearson_correlation: -0.0046
  kl_divergence: -4640.4263
  ssim: 0.0435
  iou: 0.1447
Layer 0 metrics:
  pearson_correlation: -0.0046
  kl_divergence: -4640.4263
  ssim: 0.0435
  iou: 0.1447

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.44557, std: 0.12377

Metrics for layer 1:
  pearson_correlation: -0.0005
  kl_divergence: -4716.8828
  ssim: 0.0459
  iou: 0.1425
Layer 1 metrics:
  pearson_correlation: -0.0005
  kl_divergence: -4716.8828
  ssim: 0.0459
  iou: 0.1425

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.47925, std: 0.12905

Metrics for layer 2:
  pearson_correlation: -0.0146
  kl_divergence: -1438.8242
  ssim: 0.0477
  iou: 0.1381
Layer 2 metrics:
  pearson_correlation: -0.0146
  kl_divergence: -1438.8242
  ssim: 0.0477
  iou: 0.1381

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.41680, std: 0.13538

Metrics for layer 3:
  pearson_correlation: -0.0109
  kl_divergence: -1276.9163
  ssim: 0.0535
  iou: 0.1385
Layer 3 metrics:
  pearson_correlation: -0.0109
  kl_divergence: -1276.9163
  ssim: 0.0535
  iou: 0.1385

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.45684, std: 0.13678

Metrics for layer 4:
  pearson_correlation: 0.0253
  kl_divergence: -358.4784
  ssim: 0.0681
  iou: 0.1555
Layer 4 metrics:
  pearson_correlation: 0.0253
  kl_divergence: -358.4784
  ssim: 0.0681
  iou: 0.1555

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.45530, std: 0.15181

Metrics for layer 5:
  pearson_correlation: -0.0443
  kl_divergence: -345.6220
  ssim: 0.0439
  iou: 0.1313
Layer 5 metrics:
  pearson_correlation: -0.0443
  kl_divergence: -345.6220
  ssim: 0.0439
  iou: 0.1313

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.53954, std: 0.13071

Metrics for layer 6:
  pearson_correlation: 0.0194
  kl_divergence: -422.7677
  ssim: 0.0561
  iou: 0.1462
Layer 6 metrics:
  pearson_correlation: 0.0194
  kl_divergence: -422.7677
  ssim: 0.0561
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.44428, std: 0.13718

Metrics for layer 7:
  pearson_correlation: 0.0357
  kl_divergence: -84.8601
  ssim: 0.0743
  iou: 0.1362
Layer 7 metrics:
  pearson_correlation: 0.0357
  kl_divergence: -84.8601
  ssim: 0.0743
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.40938, std: 0.14871

Metrics for layer 8:
  pearson_correlation: 0.0294
  kl_divergence: -73.9341
  ssim: 0.0918
  iou: 0.1462
Layer 8 metrics:
  pearson_correlation: 0.0294
  kl_divergence: -73.9341
  ssim: 0.0918
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.47254, std: 0.16499

Metrics for layer 9:
  pearson_correlation: -0.0007
  kl_divergence: -85.4265
  ssim: 0.0610
  iou: 0.1598
Layer 9 metrics:
  pearson_correlation: -0.0007
  kl_divergence: -85.4265
  ssim: 0.0610
  iou: 0.1598

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.46204, std: 0.16649

Metrics for layer 10:
  pearson_correlation: 0.1226
  kl_divergence: -21.9215
  ssim: 0.1628
  iou: 0.1667
Layer 10 metrics:
  pearson_correlation: 0.1226
  kl_divergence: -21.9215
  ssim: 0.1628
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.35954, std: 0.16686

Metrics for layer 11:
  pearson_correlation: -0.0192
  kl_divergence: -0.2840
  ssim: 0.0855
  iou: 0.1667
Layer 11 metrics:
  pearson_correlation: -0.0192
  kl_divergence: -0.2840
  ssim: 0.0855
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.48010, std: 0.19637

Metrics for layer 12:
  pearson_correlation: 0.1283
  kl_divergence: -20.9221
  ssim: 0.0781
  iou: 0.1264
Layer 12 metrics:
  pearson_correlation: 0.1283
  kl_divergence: -20.9221
  ssim: 0.0781
  iou: 0.1264
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer11/batch_0_strength_1.2_results.npy

Processing batch 2/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.46524, std: 0.12082

Metrics for layer 0:
  pearson_correlation: -0.0005
  kl_divergence: -3953.0161
  ssim: 0.0305
  iou: 0.1425
Layer 0 metrics:
  pearson_correlation: -0.0005
  kl_divergence: -3953.0161
  ssim: 0.0305
  iou: 0.1425

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.40808, std: 0.11816

Metrics for layer 1:
  pearson_correlation: -0.0020
  kl_divergence: -3690.3599
  ssim: 0.0363
  iou: 0.1407
Layer 1 metrics:
  pearson_correlation: -0.0020
  kl_divergence: -3690.3599
  ssim: 0.0363
  iou: 0.1407

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.47051, std: 0.13535

Metrics for layer 2:
  pearson_correlation: 0.0013
  kl_divergence: -1391.4611
  ssim: 0.0457
  iou: 0.1485
Layer 2 metrics:
  pearson_correlation: 0.0013
  kl_divergence: -1391.4611
  ssim: 0.0457
  iou: 0.1485

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.45943, std: 0.13724

Metrics for layer 3:
  pearson_correlation: -0.0149
  kl_divergence: -1360.0811
  ssim: 0.0417
  iou: 0.1313
Layer 3 metrics:
  pearson_correlation: -0.0149
  kl_divergence: -1360.0811
  ssim: 0.0417
  iou: 0.1313

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.46809, std: 0.14499

Metrics for layer 4:
  pearson_correlation: -0.0558
  kl_divergence: -368.8853
  ssim: 0.0410
  iou: 0.1305
Layer 4 metrics:
  pearson_correlation: -0.0558
  kl_divergence: -368.8853
  ssim: 0.0410
  iou: 0.1305

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.50660, std: 0.14646

Metrics for layer 5:
  pearson_correlation: -0.0051
  kl_divergence: -404.9931
  ssim: 0.0487
  iou: 0.1487
Layer 5 metrics:
  pearson_correlation: -0.0051
  kl_divergence: -404.9931
  ssim: 0.0487
  iou: 0.1487

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.41893, std: 0.14356

Metrics for layer 6:
  pearson_correlation: 0.0113
  kl_divergence: -333.0086
  ssim: 0.0691
  iou: 0.1487
Layer 6 metrics:
  pearson_correlation: 0.0113
  kl_divergence: -333.0086
  ssim: 0.0691
  iou: 0.1487

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.46581, std: 0.18314

Metrics for layer 7:
  pearson_correlation: 0.0223
  kl_divergence: -83.3336
  ssim: 0.0329
  iou: 0.1329
Layer 7 metrics:
  pearson_correlation: 0.0223
  kl_divergence: -83.3336
  ssim: 0.0329
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.41857, std: 0.15691

Metrics for layer 8:
  pearson_correlation: 0.0281
  kl_divergence: -77.6527
  ssim: 0.0443
  iou: 0.1598
Layer 8 metrics:
  pearson_correlation: 0.0281
  kl_divergence: -77.6527
  ssim: 0.0443
  iou: 0.1598

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.43557, std: 0.15694

Metrics for layer 9:
  pearson_correlation: -0.0196
  kl_divergence: -78.7017
  ssim: 0.0342
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: -0.0196
  kl_divergence: -78.7017
  ssim: 0.0342
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.48922, std: 0.19249

Metrics for layer 10:
  pearson_correlation: -0.1119
  kl_divergence: -15.0636
  ssim: -0.0710
  iou: 0.1011
Layer 10 metrics:
  pearson_correlation: -0.1119
  kl_divergence: -15.0636
  ssim: -0.0710
  iou: 0.1011

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.52954, std: 0.18361

Metrics for layer 11:
  pearson_correlation: 0.0716
  kl_divergence: -8.3749
  ssim: 0.1327
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: 0.0716
  kl_divergence: -8.3749
  ssim: 0.1327
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.51004, std: 0.17421

Metrics for layer 12:
  pearson_correlation: -0.0465
  kl_divergence: -17.2229
  ssim: -0.0103
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: -0.0465
  kl_divergence: -17.2229
  ssim: -0.0103
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer11/batch_1_strength_1.2_results.npy

Analysis complete! Results saved to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer11
Completed experiment for category 5, layer 11
----------------------------------------
Running experiment for category 5, layer 12
===================================================
Starting experiment:
Category: 5
Layer: 12
Logs will be saved to: /scratch/hy2611/CNN_attention/logs/attention_analysis_20241216_104146/category5/layer12
===================================================
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-12-16 11:15:38.270842: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-16 11:15:38.289637: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2024-12-16 11:15:38.290281: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4217a20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:15:38.290297: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-16 11:15:38.293025: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-16 11:15:38.421980: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x42004d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:15:38.421998: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-12-16 11:15:38.422560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:2f:00.0
2024-12-16 11:15:38.423853: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:15:38.425003: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:15:38.426105: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:15:38.427185: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:15:38.428279: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:15:38.429363: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:15:38.430437: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:15:38.430448: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-12-16 11:15:38.430466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-16 11:15:38.430471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-16 11:15:38.430475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:61: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:87: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:15: sigmoid_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.sigmoid_cross_entropy instead. Note that the order of the predictions and labels arguments has been changed.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:322: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:82: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.


Verifying paths:
tc_path: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs exists
weight_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists
image_path: /scratch/hy2611/CNN_attention/Data/VGG16/images exists
save_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists

Initializing model...
('c11', [1, 224, 224, 64])
('c12', [1, 224, 224, 64])
('c21', [1, 112, 112, 128])
('c22', [1, 112, 112, 128])
('c31', [1, 56, 56, 256])
('c32', [1, 56, 56, 256])
('c33', [1, 56, 56, 256])
('c41', [1, 28, 28, 512])
('c42', [1, 28, 28, 512])
('c43', [1, 28, 28, 512])
('c51', [1, 14, 14, 512])
('c52', [1, 14, 14, 512])
('c53', [1, 14, 14, 512])
(0, 'conv1_1_W', (3, 3, 3, 64))
(1, 'conv1_1_b', (64,))
(2, 'conv1_2_W', (3, 3, 64, 64))
(3, 'conv1_2_b', (64,))
(4, 'conv2_1_W', (3, 3, 64, 128))
(5, 'conv2_1_b', (128,))
(6, 'conv2_2_W', (3, 3, 128, 128))
(7, 'conv2_2_b', (128,))
(8, 'conv3_1_W', (3, 3, 128, 256))
(9, 'conv3_1_b', (256,))
(10, 'conv3_2_W', (3, 3, 256, 256))
(11, 'conv3_2_b', (256,))
(12, 'conv3_3_W', (3, 3, 256, 256))
(13, 'conv3_3_b', (256,))
(14, 'conv4_1_W', (3, 3, 256, 512))
(15, 'conv4_1_b', (512,))
(16, 'conv4_2_W', (3, 3, 512, 512))
(17, 'conv4_2_b', (512,))
(18, 'conv4_3_W', (3, 3, 512, 512))
(19, 'conv4_3_b', (512,))
(20, 'conv5_1_W', (3, 3, 512, 512))
(21, 'conv5_1_b', (512,))
(22, 'conv5_2_W', (3, 3, 512, 512))
(23, 'conv5_2_b', (512,))
(24, 'conv5_3_W', (3, 3, 512, 512))
(25, 'conv5_3_b', (512,))
(26, 'fc6_W', (25088, 4096))
(27, 'fc6_b', (4096,))
(28, 'fc7_W', (4096, 4096))
(29, 'fc7_b', (4096,))
Checking checkpoint files:
Data file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.data-00000-of-00001 - Found
Index file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.index - Found
Loading checkpoint from: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt
Checkpoint loaded successfully

Initializing components...
Found tuning curves file: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs/featvecs20_train35_c.txt

Loading category 5 data...
Original positive images shape: (2, 224, 224, 3)

Processing data...

Processing attention strength 0.0
Attention vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

Processing batch 1/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.40561, std: 0.12137

Metrics for layer 0:
  pearson_correlation: -0.0016
  kl_divergence: -4406.5522
  ssim: 0.0518
  iou: 0.1413
Layer 0 metrics:
  pearson_correlation: -0.0016
  kl_divergence: -4406.5522
  ssim: 0.0518
  iou: 0.1413

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.40976, std: 0.11858

Metrics for layer 1:
  pearson_correlation: -0.0023
  kl_divergence: -4445.1045
  ssim: 0.0513
  iou: 0.1413
Layer 1 metrics:
  pearson_correlation: -0.0023
  kl_divergence: -4445.1045
  ssim: 0.0513
  iou: 0.1413

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.44564, std: 0.12008

Metrics for layer 2:
  pearson_correlation: 0.0017
  kl_divergence: -1370.3236
  ssim: 0.0632
  iou: 0.1456
Layer 2 metrics:
  pearson_correlation: 0.0017
  kl_divergence: -1370.3236
  ssim: 0.0632
  iou: 0.1456

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.45191, std: 0.13084

Metrics for layer 3:
  pearson_correlation: 0.0173
  kl_divergence: -1378.1528
  ssim: 0.0582
  iou: 0.1515
Layer 3 metrics:
  pearson_correlation: 0.0173
  kl_divergence: -1378.1528
  ssim: 0.0582
  iou: 0.1515

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.51756, std: 0.14132

Metrics for layer 4:
  pearson_correlation: 0.0190
  kl_divergence: -405.7701
  ssim: 0.0618
  iou: 0.1412
Layer 4 metrics:
  pearson_correlation: 0.0190
  kl_divergence: -405.7701
  ssim: 0.0618
  iou: 0.1412

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47397, std: 0.14171

Metrics for layer 5:
  pearson_correlation: -0.0109
  kl_divergence: -366.8965
  ssim: 0.0544
  iou: 0.1512
Layer 5 metrics:
  pearson_correlation: -0.0109
  kl_divergence: -366.8965
  ssim: 0.0544
  iou: 0.1512

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47970, std: 0.15637

Metrics for layer 6:
  pearson_correlation: -0.0126
  kl_divergence: -369.4372
  ssim: 0.0491
  iou: 0.1313
Layer 6 metrics:
  pearson_correlation: -0.0126
  kl_divergence: -369.4372
  ssim: 0.0491
  iou: 0.1313

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.51533, std: 0.14662

Metrics for layer 7:
  pearson_correlation: 0.0228
  kl_divergence: -98.9514
  ssim: 0.0617
  iou: 0.1496
Layer 7 metrics:
  pearson_correlation: 0.0228
  kl_divergence: -98.9514
  ssim: 0.0617
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.52685, std: 0.16415

Metrics for layer 8:
  pearson_correlation: 0.0008
  kl_divergence: -97.0147
  ssim: 0.0376
  iou: 0.1264
Layer 8 metrics:
  pearson_correlation: 0.0008
  kl_divergence: -97.0147
  ssim: 0.0376
  iou: 0.1264

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.50179, std: 0.16084

Metrics for layer 9:
  pearson_correlation: 0.0031
  kl_divergence: -93.6199
  ssim: 0.0517
  iou: 0.1264
Layer 9 metrics:
  pearson_correlation: 0.0031
  kl_divergence: -93.6199
  ssim: 0.0517
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.52009, std: 0.19787

Metrics for layer 10:
  pearson_correlation: 0.0633
  kl_divergence: -24.1636
  ssim: 0.1594
  iou: 0.1807
Layer 10 metrics:
  pearson_correlation: 0.0633
  kl_divergence: -24.1636
  ssim: 0.1594
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49870, std: 0.17878

Metrics for layer 11:
  pearson_correlation: -0.0380
  kl_divergence: -22.3406
  ssim: 0.0428
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: -0.0380
  kl_divergence: -22.3406
  ssim: 0.0428
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.50835, std: 0.17480

Metrics for layer 12:
  pearson_correlation: -0.0376
  kl_divergence: -22.3013
  ssim: 0.1450
  iou: 0.1264
Layer 12 metrics:
  pearson_correlation: -0.0376
  kl_divergence: -22.3013
  ssim: 0.1450
  iou: 0.1264
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer12/batch_0_strength_0.0_results.npy

Processing batch 2/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.40062, std: 0.11003

Metrics for layer 0:
  pearson_correlation: 0.0057
  kl_divergence: -3667.9189
  ssim: 0.0418
  iou: 0.1447
Layer 0 metrics:
  pearson_correlation: 0.0057
  kl_divergence: -3667.9189
  ssim: 0.0418
  iou: 0.1447

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.44174, std: 0.12252

Metrics for layer 1:
  pearson_correlation: 0.0007
  kl_divergence: -3845.1450
  ssim: 0.0326
  iou: 0.1418
Layer 1 metrics:
  pearson_correlation: 0.0007
  kl_divergence: -3845.1450
  ssim: 0.0326
  iou: 0.1418

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.47909, std: 0.12918

Metrics for layer 2:
  pearson_correlation: 0.0171
  kl_divergence: -1416.7609
  ssim: 0.0489
  iou: 0.1458
Layer 2 metrics:
  pearson_correlation: 0.0171
  kl_divergence: -1416.7609
  ssim: 0.0489
  iou: 0.1458

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.42004, std: 0.14185

Metrics for layer 3:
  pearson_correlation: 0.0016
  kl_divergence: -1268.4258
  ssim: 0.0444
  iou: 0.1475
Layer 3 metrics:
  pearson_correlation: 0.0016
  kl_divergence: -1268.4258
  ssim: 0.0444
  iou: 0.1475

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.43912, std: 0.13747

Metrics for layer 4:
  pearson_correlation: 0.0115
  kl_divergence: -355.8444
  ssim: 0.0639
  iou: 0.1437
Layer 4 metrics:
  pearson_correlation: 0.0115
  kl_divergence: -355.8444
  ssim: 0.0639
  iou: 0.1437

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.50865, std: 0.12676

Metrics for layer 5:
  pearson_correlation: 0.0161
  kl_divergence: -414.1596
  ssim: 0.0652
  iou: 0.1563
Layer 5 metrics:
  pearson_correlation: 0.0161
  kl_divergence: -414.1596
  ssim: 0.0652
  iou: 0.1563

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48331, std: 0.14641

Metrics for layer 6:
  pearson_correlation: 0.0004
  kl_divergence: -389.7745
  ssim: 0.0496
  iou: 0.1512
Layer 6 metrics:
  pearson_correlation: 0.0004
  kl_divergence: -389.7745
  ssim: 0.0496
  iou: 0.1512

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.44625, std: 0.15756

Metrics for layer 7:
  pearson_correlation: -0.0277
  kl_divergence: -81.1728
  ssim: 0.0319
  iou: 0.1496
Layer 7 metrics:
  pearson_correlation: -0.0277
  kl_divergence: -81.1728
  ssim: 0.0319
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.48858, std: 0.15678

Metrics for layer 8:
  pearson_correlation: 0.0016
  kl_divergence: -88.7242
  ssim: 0.0309
  iou: 0.1362
Layer 8 metrics:
  pearson_correlation: 0.0016
  kl_divergence: -88.7242
  ssim: 0.0309
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.51731, std: 0.13886

Metrics for layer 9:
  pearson_correlation: -0.0343
  kl_divergence: -87.8887
  ssim: 0.0365
  iou: 0.1200
Layer 9 metrics:
  pearson_correlation: -0.0343
  kl_divergence: -87.8887
  ssim: 0.0365
  iou: 0.1200

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.31954, std: 0.15201

Metrics for layer 10:
  pearson_correlation: 0.0079
  kl_divergence: 2.6800
  ssim: 0.0197
  iou: 0.1807
Layer 10 metrics:
  pearson_correlation: 0.0079
  kl_divergence: 2.6800
  ssim: 0.0197
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.49760, std: 0.17474

Metrics for layer 11:
  pearson_correlation: -0.0774
  kl_divergence: -17.8327
  ssim: -0.0698
  iou: 0.1667
Layer 11 metrics:
  pearson_correlation: -0.0774
  kl_divergence: -17.8327
  ssim: -0.0698
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.57122, std: 0.19060

Metrics for layer 12:
  pearson_correlation: 0.0632
  kl_divergence: -25.2495
  ssim: 0.0938
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: 0.0632
  kl_divergence: -25.2495
  ssim: 0.0938
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer12/batch_1_strength_0.0_results.npy

Processing attention strength 0.4
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.4]

Processing batch 1/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42657, std: 0.12229

Metrics for layer 0:
  pearson_correlation: 0.0015
  kl_divergence: -4574.6191
  ssim: 0.0483
  iou: 0.1440
Layer 0 metrics:
  pearson_correlation: 0.0015
  kl_divergence: -4574.6191
  ssim: 0.0483
  iou: 0.1440

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.45036, std: 0.13091

Metrics for layer 1:
  pearson_correlation: -0.0028
  kl_divergence: -4729.6577
  ssim: 0.0414
  iou: 0.1426
Layer 1 metrics:
  pearson_correlation: -0.0028
  kl_divergence: -4729.6577
  ssim: 0.0414
  iou: 0.1426

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.46340, std: 0.14184

Metrics for layer 2:
  pearson_correlation: 0.0007
  kl_divergence: -1396.7537
  ssim: 0.0512
  iou: 0.1420
Layer 2 metrics:
  pearson_correlation: 0.0007
  kl_divergence: -1396.7537
  ssim: 0.0512
  iou: 0.1420

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.47280, std: 0.13982

Metrics for layer 3:
  pearson_correlation: 0.0107
  kl_divergence: -1422.0192
  ssim: 0.0517
  iou: 0.1424
Layer 3 metrics:
  pearson_correlation: 0.0107
  kl_divergence: -1422.0192
  ssim: 0.0517
  iou: 0.1424

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46489, std: 0.14165

Metrics for layer 4:
  pearson_correlation: 0.0145
  kl_divergence: -365.7336
  ssim: 0.0673
  iou: 0.1487
Layer 4 metrics:
  pearson_correlation: 0.0145
  kl_divergence: -365.7336
  ssim: 0.0673
  iou: 0.1487

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50876, std: 0.14582

Metrics for layer 5:
  pearson_correlation: -0.0167
  kl_divergence: -392.1266
  ssim: 0.0401
  iou: 0.1412
Layer 5 metrics:
  pearson_correlation: -0.0167
  kl_divergence: -392.1266
  ssim: 0.0401
  iou: 0.1412

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.52911, std: 0.13522

Metrics for layer 6:
  pearson_correlation: -0.0110
  kl_divergence: -413.3851
  ssim: 0.0514
  iou: 0.1470
Layer 6 metrics:
  pearson_correlation: -0.0110
  kl_divergence: -413.3851
  ssim: 0.0514
  iou: 0.1470

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.47713, std: 0.15177

Metrics for layer 7:
  pearson_correlation: 0.0848
  kl_divergence: -86.4271
  ssim: 0.0882
  iou: 0.1951
Layer 7 metrics:
  pearson_correlation: 0.0848
  kl_divergence: -86.4271
  ssim: 0.0882
  iou: 0.1951

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.42930, std: 0.16385

Metrics for layer 8:
  pearson_correlation: -0.0004
  kl_divergence: -78.3959
  ssim: 0.0530
  iou: 0.1232
Layer 8 metrics:
  pearson_correlation: -0.0004
  kl_divergence: -78.3959
  ssim: 0.0530
  iou: 0.1232

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.47618, std: 0.17236

Metrics for layer 9:
  pearson_correlation: 0.0636
  kl_divergence: -92.0344
  ssim: 0.0612
  iou: 0.1529
Layer 9 metrics:
  pearson_correlation: 0.0636
  kl_divergence: -92.0344
  ssim: 0.0612
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.40081, std: 0.18531

Metrics for layer 10:
  pearson_correlation: -0.0039
  kl_divergence: -12.9752
  ssim: 0.0368
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: -0.0039
  kl_divergence: -12.9752
  ssim: 0.0368
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.52834, std: 0.20236

Metrics for layer 11:
  pearson_correlation: 0.0878
  kl_divergence: -23.0774
  ssim: 0.1253
  iou: 0.2099
Layer 11 metrics:
  pearson_correlation: 0.0878
  kl_divergence: -23.0774
  ssim: 0.1253
  iou: 0.2099

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.40840, std: 0.16557

Metrics for layer 12:
  pearson_correlation: 0.0128
  kl_divergence: -16.4096
  ssim: -0.0320
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: 0.0128
  kl_divergence: -16.4096
  ssim: -0.0320
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer12/batch_0_strength_0.4_results.npy

Processing batch 2/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43480, std: 0.12402

Metrics for layer 0:
  pearson_correlation: 0.0138
  kl_divergence: -3814.2683
  ssim: 0.0321
  iou: 0.1463
Layer 0 metrics:
  pearson_correlation: 0.0138
  kl_divergence: -3814.2683
  ssim: 0.0321
  iou: 0.1463

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.37075, std: 0.10744

Metrics for layer 1:
  pearson_correlation: -0.0047
  kl_divergence: -3510.0405
  ssim: 0.0461
  iou: 0.1417
Layer 1 metrics:
  pearson_correlation: -0.0047
  kl_divergence: -3510.0405
  ssim: 0.0461
  iou: 0.1417

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.47255, std: 0.12504

Metrics for layer 2:
  pearson_correlation: -0.0040
  kl_divergence: -1399.3251
  ssim: 0.0481
  iou: 0.1416
Layer 2 metrics:
  pearson_correlation: -0.0040
  kl_divergence: -1399.3251
  ssim: 0.0481
  iou: 0.1416

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.40399, std: 0.12597

Metrics for layer 3:
  pearson_correlation: 0.0036
  kl_divergence: -1246.2795
  ssim: 0.0569
  iou: 0.1416
Layer 3 metrics:
  pearson_correlation: 0.0036
  kl_divergence: -1246.2795
  ssim: 0.0569
  iou: 0.1416

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.45138, std: 0.14320

Metrics for layer 4:
  pearson_correlation: -0.0214
  kl_divergence: -360.6965
  ssim: 0.0527
  iou: 0.1362
Layer 4 metrics:
  pearson_correlation: -0.0214
  kl_divergence: -360.6965
  ssim: 0.0527
  iou: 0.1362

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.45256, std: 0.14284

Metrics for layer 5:
  pearson_correlation: -0.0012
  kl_divergence: -361.7422
  ssim: 0.0603
  iou: 0.1563
Layer 5 metrics:
  pearson_correlation: -0.0012
  kl_divergence: -361.7422
  ssim: 0.0603
  iou: 0.1563

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.46535, std: 0.13656

Metrics for layer 6:
  pearson_correlation: -0.0273
  kl_divergence: -375.0994
  ssim: 0.0508
  iou: 0.1281
Layer 6 metrics:
  pearson_correlation: -0.0273
  kl_divergence: -375.0994
  ssim: 0.0508
  iou: 0.1281

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.51028, std: 0.15418

Metrics for layer 7:
  pearson_correlation: -0.0690
  kl_divergence: -88.5448
  ssim: 0.0158
  iou: 0.1232
Layer 7 metrics:
  pearson_correlation: -0.0690
  kl_divergence: -88.5448
  ssim: 0.0158
  iou: 0.1232

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.51704, std: 0.15398

Metrics for layer 8:
  pearson_correlation: -0.0713
  kl_divergence: -88.2283
  ssim: 0.0198
  iou: 0.1329
Layer 8 metrics:
  pearson_correlation: -0.0713
  kl_divergence: -88.2283
  ssim: 0.0198
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.53933, std: 0.16121

Metrics for layer 9:
  pearson_correlation: -0.0105
  kl_divergence: -92.1972
  ssim: 0.0247
  iou: 0.1462
Layer 9 metrics:
  pearson_correlation: -0.0105
  kl_divergence: -92.1972
  ssim: 0.0247
  iou: 0.1462

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.44539, std: 0.17765

Metrics for layer 10:
  pearson_correlation: 0.1071
  kl_divergence: -13.9942
  ssim: 0.1340
  iou: 0.1807
Layer 10 metrics:
  pearson_correlation: 0.1071
  kl_divergence: -13.9942
  ssim: 0.1340
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.45321, std: 0.20452

Metrics for layer 11:
  pearson_correlation: 0.1206
  kl_divergence: -5.0999
  ssim: 0.1542
  iou: 0.1951
Layer 11 metrics:
  pearson_correlation: 0.1206
  kl_divergence: -5.0999
  ssim: 0.1542
  iou: 0.1951

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.48218, std: 0.15673

Metrics for layer 12:
  pearson_correlation: 0.0330
  kl_divergence: -19.3146
  ssim: 0.0274
  iou: 0.2099
Layer 12 metrics:
  pearson_correlation: 0.0330
  kl_divergence: -19.3146
  ssim: 0.0274
  iou: 0.2099
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer12/batch_1_strength_0.4_results.npy

Processing attention strength 0.8
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.8]

Processing batch 1/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.40785, std: 0.11965

Metrics for layer 0:
  pearson_correlation: 0.0035
  kl_divergence: -4434.7437
  ssim: 0.0516
  iou: 0.1451
Layer 0 metrics:
  pearson_correlation: 0.0035
  kl_divergence: -4434.7437
  ssim: 0.0516
  iou: 0.1451

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.41302, std: 0.11821

Metrics for layer 1:
  pearson_correlation: -0.0011
  kl_divergence: -4473.4463
  ssim: 0.0519
  iou: 0.1422
Layer 1 metrics:
  pearson_correlation: -0.0011
  kl_divergence: -4473.4463
  ssim: 0.0519
  iou: 0.1422

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.43889, std: 0.13408

Metrics for layer 2:
  pearson_correlation: 0.0081
  kl_divergence: -1343.3478
  ssim: 0.0544
  iou: 0.1437
Layer 2 metrics:
  pearson_correlation: 0.0081
  kl_divergence: -1343.3478
  ssim: 0.0544
  iou: 0.1437

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.46135, std: 0.13300

Metrics for layer 3:
  pearson_correlation: -0.0002
  kl_divergence: -1397.2589
  ssim: 0.0527
  iou: 0.1412
Layer 3 metrics:
  pearson_correlation: -0.0002
  kl_divergence: -1397.2589
  ssim: 0.0527
  iou: 0.1412

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.48932, std: 0.16155

Metrics for layer 4:
  pearson_correlation: 0.0045
  kl_divergence: -377.7235
  ssim: 0.0491
  iou: 0.1445
Layer 4 metrics:
  pearson_correlation: 0.0045
  kl_divergence: -377.7235
  ssim: 0.0491
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.41196, std: 0.13544

Metrics for layer 5:
  pearson_correlation: 0.0065
  kl_divergence: -318.7222
  ssim: 0.0725
  iou: 0.1581
Layer 5 metrics:
  pearson_correlation: 0.0065
  kl_divergence: -318.7222
  ssim: 0.0725
  iou: 0.1581

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46456, std: 0.14432

Metrics for layer 6:
  pearson_correlation: -0.0300
  kl_divergence: -359.1121
  ssim: 0.0385
  iou: 0.1395
Layer 6 metrics:
  pearson_correlation: -0.0300
  kl_divergence: -359.1121
  ssim: 0.0385
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.53794, std: 0.17344

Metrics for layer 7:
  pearson_correlation: -0.0353
  kl_divergence: -100.9108
  ssim: 0.0496
  iou: 0.1297
Layer 7 metrics:
  pearson_correlation: -0.0353
  kl_divergence: -100.9108
  ssim: 0.0496
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.48121, std: 0.13251

Metrics for layer 8:
  pearson_correlation: -0.0121
  kl_divergence: -90.2680
  ssim: 0.0628
  iou: 0.1462
Layer 8 metrics:
  pearson_correlation: -0.0121
  kl_divergence: -90.2680
  ssim: 0.0628
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.45436, std: 0.15973

Metrics for layer 9:
  pearson_correlation: 0.0038
  kl_divergence: -85.6252
  ssim: 0.0492
  iou: 0.1496
Layer 9 metrics:
  pearson_correlation: 0.0038
  kl_divergence: -85.6252
  ssim: 0.0492
  iou: 0.1496

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.50862, std: 0.21625

Metrics for layer 10:
  pearson_correlation: -0.0217
  kl_divergence: -21.3025
  ssim: -0.0578
  iou: 0.1136
Layer 10 metrics:
  pearson_correlation: -0.0217
  kl_divergence: -21.3025
  ssim: -0.0578
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.55089, std: 0.18911

Metrics for layer 11:
  pearson_correlation: -0.0571
  kl_divergence: -23.0647
  ssim: 0.1161
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: -0.0571
  kl_divergence: -23.0647
  ssim: 0.1161
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.44790, std: 0.19322

Metrics for layer 12:
  pearson_correlation: -0.0029
  kl_divergence: -13.1192
  ssim: 0.0320
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: -0.0029
  kl_divergence: -13.1192
  ssim: 0.0320
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer12/batch_0_strength_0.8_results.npy

Processing batch 2/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.42955, std: 0.12046

Metrics for layer 0:
  pearson_correlation: 0.0011
  kl_divergence: -3792.3613
  ssim: 0.0340
  iou: 0.1438
Layer 0 metrics:
  pearson_correlation: 0.0011
  kl_divergence: -3792.3613
  ssim: 0.0340
  iou: 0.1438

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43098, std: 0.12858

Metrics for layer 1:
  pearson_correlation: 0.0071
  kl_divergence: -3790.1746
  ssim: 0.0311
  iou: 0.1450
Layer 1 metrics:
  pearson_correlation: 0.0071
  kl_divergence: -3790.1746
  ssim: 0.0311
  iou: 0.1450

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.39984, std: 0.10895

Metrics for layer 2:
  pearson_correlation: -0.0044
  kl_divergence: -1248.9587
  ssim: 0.0708
  iou: 0.1391
Layer 2 metrics:
  pearson_correlation: -0.0044
  kl_divergence: -1248.9587
  ssim: 0.0708
  iou: 0.1391

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.43912, std: 0.11891

Metrics for layer 3:
  pearson_correlation: 0.0168
  kl_divergence: -1336.4124
  ssim: 0.0613
  iou: 0.1475
Layer 3 metrics:
  pearson_correlation: 0.0168
  kl_divergence: -1336.4124
  ssim: 0.0613
  iou: 0.1475

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48411, std: 0.13798

Metrics for layer 4:
  pearson_correlation: -0.0154
  kl_divergence: -392.3972
  ssim: 0.0551
  iou: 0.1445
Layer 4 metrics:
  pearson_correlation: -0.0154
  kl_divergence: -392.3972
  ssim: 0.0551
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.51936, std: 0.14129

Metrics for layer 5:
  pearson_correlation: 0.0318
  kl_divergence: -422.5919
  ssim: 0.0518
  iou: 0.1479
Layer 5 metrics:
  pearson_correlation: 0.0318
  kl_divergence: -422.5919
  ssim: 0.0518
  iou: 0.1479

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.45170, std: 0.12996

Metrics for layer 6:
  pearson_correlation: -0.0165
  kl_divergence: -366.9095
  ssim: 0.0587
  iou: 0.1379
Layer 6 metrics:
  pearson_correlation: -0.0165
  kl_divergence: -366.9095
  ssim: 0.0587
  iou: 0.1379

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.46311, std: 0.15636

Metrics for layer 7:
  pearson_correlation: -0.0513
  kl_divergence: -82.6893
  ssim: 0.0126
  iou: 0.1395
Layer 7 metrics:
  pearson_correlation: -0.0513
  kl_divergence: -82.6893
  ssim: 0.0126
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.45642, std: 0.12313

Metrics for layer 8:
  pearson_correlation: 0.0206
  kl_divergence: -82.6104
  ssim: 0.0646
  iou: 0.1737
Layer 8 metrics:
  pearson_correlation: 0.0206
  kl_divergence: -82.6104
  ssim: 0.0646
  iou: 0.1737

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.50362, std: 0.15448

Metrics for layer 9:
  pearson_correlation: -0.0413
  kl_divergence: -86.6385
  ssim: 0.0340
  iou: 0.1429
Layer 9 metrics:
  pearson_correlation: -0.0413
  kl_divergence: -86.6385
  ssim: 0.0340
  iou: 0.1429

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.59280, std: 0.17751

Metrics for layer 10:
  pearson_correlation: 0.0622
  kl_divergence: -24.1011
  ssim: 0.0808
  iou: 0.1667
Layer 10 metrics:
  pearson_correlation: 0.0622
  kl_divergence: -24.1011
  ssim: 0.0808
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.52534, std: 0.17153

Metrics for layer 11:
  pearson_correlation: 0.0943
  kl_divergence: -23.0567
  ssim: 0.0837
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: 0.0943
  kl_divergence: -23.0567
  ssim: 0.0837
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.46304, std: 0.18818

Metrics for layer 12:
  pearson_correlation: 0.0932
  kl_divergence: -14.0950
  ssim: 0.1178
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: 0.0932
  kl_divergence: -14.0950
  ssim: 0.1178
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer12/batch_1_strength_0.8_results.npy

Processing attention strength 1.2
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.2]

Processing batch 1/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.44731, std: 0.11961

Metrics for layer 0:
  pearson_correlation: -0.0013
  kl_divergence: -4738.4448
  ssim: 0.0468
  iou: 0.1420
Layer 0 metrics:
  pearson_correlation: -0.0013
  kl_divergence: -4738.4448
  ssim: 0.0468
  iou: 0.1420

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42656, std: 0.11613

Metrics for layer 1:
  pearson_correlation: -0.0013
  kl_divergence: -4589.4194
  ssim: 0.0524
  iou: 0.1415
Layer 1 metrics:
  pearson_correlation: -0.0013
  kl_divergence: -4589.4194
  ssim: 0.0524
  iou: 0.1415

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.43101, std: 0.12183

Metrics for layer 2:
  pearson_correlation: -0.0011
  kl_divergence: -1328.9626
  ssim: 0.0644
  iou: 0.1460
Layer 2 metrics:
  pearson_correlation: -0.0011
  kl_divergence: -1328.9626
  ssim: 0.0644
  iou: 0.1460

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.42217, std: 0.12654

Metrics for layer 3:
  pearson_correlation: 0.0052
  kl_divergence: -1308.0168
  ssim: 0.0635
  iou: 0.1416
Layer 3 metrics:
  pearson_correlation: 0.0052
  kl_divergence: -1308.0168
  ssim: 0.0635
  iou: 0.1416

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47359, std: 0.11967

Metrics for layer 4:
  pearson_correlation: -0.0044
  kl_divergence: -373.9181
  ssim: 0.0738
  iou: 0.1445
Layer 4 metrics:
  pearson_correlation: -0.0044
  kl_divergence: -373.9181
  ssim: 0.0738
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47282, std: 0.14130

Metrics for layer 5:
  pearson_correlation: -0.0089
  kl_divergence: -369.9108
  ssim: 0.0512
  iou: 0.1379
Layer 5 metrics:
  pearson_correlation: -0.0089
  kl_divergence: -369.9108
  ssim: 0.0512
  iou: 0.1379

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.45663, std: 0.15128

Metrics for layer 6:
  pearson_correlation: -0.0173
  kl_divergence: -348.7358
  ssim: 0.0478
  iou: 0.1281
Layer 6 metrics:
  pearson_correlation: -0.0173
  kl_divergence: -348.7358
  ssim: 0.0478
  iou: 0.1281

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.53468, std: 0.16915

Metrics for layer 7:
  pearson_correlation: 0.0362
  kl_divergence: -102.2369
  ssim: 0.0803
  iou: 0.1772
Layer 7 metrics:
  pearson_correlation: 0.0362
  kl_divergence: -102.2369
  ssim: 0.0803
  iou: 0.1772

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.48635, std: 0.15050

Metrics for layer 8:
  pearson_correlation: 0.0288
  kl_divergence: -93.0952
  ssim: 0.0569
  iou: 0.1362
Layer 8 metrics:
  pearson_correlation: 0.0288
  kl_divergence: -93.0952
  ssim: 0.0569
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.49448, std: 0.16418

Metrics for layer 9:
  pearson_correlation: -0.0034
  kl_divergence: -92.8782
  ssim: 0.0561
  iou: 0.1362
Layer 9 metrics:
  pearson_correlation: -0.0034
  kl_divergence: -92.8782
  ssim: 0.0561
  iou: 0.1362

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.50007, std: 0.21279

Metrics for layer 10:
  pearson_correlation: -0.0115
  kl_divergence: -21.4430
  ssim: 0.0227
  iou: 0.1264
Layer 10 metrics:
  pearson_correlation: -0.0115
  kl_divergence: -21.4430
  ssim: 0.0227
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.41826, std: 0.19347

Metrics for layer 11:
  pearson_correlation: -0.0583
  kl_divergence: -15.0728
  ssim: 0.0273
  iou: 0.1011
Layer 11 metrics:
  pearson_correlation: -0.0583
  kl_divergence: -15.0728
  ssim: 0.0273
  iou: 0.1011

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.48019, std: 0.20263

Metrics for layer 12:
  pearson_correlation: 0.0475
  kl_divergence: -20.2807
  ssim: -0.0052
  iou: 0.2099
Layer 12 metrics:
  pearson_correlation: 0.0475
  kl_divergence: -20.2807
  ssim: -0.0052
  iou: 0.2099
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer12/batch_0_strength_1.2_results.npy

Processing batch 2/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.45763, std: 0.12025

Metrics for layer 0:
  pearson_correlation: 0.0059
  kl_divergence: -3923.4536
  ssim: 0.0319
  iou: 0.1455
Layer 0 metrics:
  pearson_correlation: 0.0059
  kl_divergence: -3923.4536
  ssim: 0.0319
  iou: 0.1455

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.38282, std: 0.11181

Metrics for layer 1:
  pearson_correlation: 0.0005
  kl_divergence: -3571.1895
  ssim: 0.0416
  iou: 0.1411
Layer 1 metrics:
  pearson_correlation: 0.0005
  kl_divergence: -3571.1895
  ssim: 0.0416
  iou: 0.1411

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.43652, std: 0.13527

Metrics for layer 2:
  pearson_correlation: 0.0082
  kl_divergence: -1315.8462
  ssim: 0.0510
  iou: 0.1475
Layer 2 metrics:
  pearson_correlation: 0.0082
  kl_divergence: -1315.8462
  ssim: 0.0510
  iou: 0.1475

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.48351, std: 0.11153

Metrics for layer 3:
  pearson_correlation: -0.0074
  kl_divergence: -1427.5142
  ssim: 0.0571
  iou: 0.1412
Layer 3 metrics:
  pearson_correlation: -0.0074
  kl_divergence: -1427.5142
  ssim: 0.0571
  iou: 0.1412

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47130, std: 0.15457

Metrics for layer 4:
  pearson_correlation: -0.0010
  kl_divergence: -377.2362
  ssim: 0.0500
  iou: 0.1462
Layer 4 metrics:
  pearson_correlation: -0.0010
  kl_divergence: -377.2362
  ssim: 0.0500
  iou: 0.1462

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.46166, std: 0.14198

Metrics for layer 5:
  pearson_correlation: -0.0034
  kl_divergence: -372.0511
  ssim: 0.0553
  iou: 0.1437
Layer 5 metrics:
  pearson_correlation: -0.0034
  kl_divergence: -372.0511
  ssim: 0.0553
  iou: 0.1437

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.52028, std: 0.15378

Metrics for layer 6:
  pearson_correlation: 0.0149
  kl_divergence: -419.6925
  ssim: 0.0445
  iou: 0.1546
Layer 6 metrics:
  pearson_correlation: 0.0149
  kl_divergence: -419.6925
  ssim: 0.0445
  iou: 0.1546

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.52148, std: 0.15514

Metrics for layer 7:
  pearson_correlation: -0.0057
  kl_divergence: -91.3262
  ssim: 0.0284
  iou: 0.1362
Layer 7 metrics:
  pearson_correlation: -0.0057
  kl_divergence: -91.3262
  ssim: 0.0284
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.47110, std: 0.16535

Metrics for layer 8:
  pearson_correlation: 0.0040
  kl_divergence: -85.1545
  ssim: 0.0444
  iou: 0.1168
Layer 8 metrics:
  pearson_correlation: 0.0040
  kl_divergence: -85.1545
  ssim: 0.0444
  iou: 0.1168

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.56573, std: 0.12913

Metrics for layer 9:
  pearson_correlation: 0.0118
  kl_divergence: -93.1269
  ssim: 0.0443
  iou: 0.1496
Layer 9 metrics:
  pearson_correlation: 0.0118
  kl_divergence: -93.1269
  ssim: 0.0443
  iou: 0.1496

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.47579, std: 0.17754

Metrics for layer 10:
  pearson_correlation: 0.0396
  kl_divergence: -7.8857
  ssim: 0.0815
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: 0.0396
  kl_divergence: -7.8857
  ssim: 0.0815
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.54260, std: 0.18960

Metrics for layer 11:
  pearson_correlation: -0.0462
  kl_divergence: -20.6192
  ssim: -0.0149
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: -0.0462
  kl_divergence: -20.6192
  ssim: -0.0149
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.51588, std: 0.22296

Metrics for layer 12:
  pearson_correlation: 0.1273
  kl_divergence: -20.8948
  ssim: 0.1568
  iou: 0.1264
Layer 12 metrics:
  pearson_correlation: 0.1273
  kl_divergence: -20.8948
  ssim: 0.1568
  iou: 0.1264
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer12/batch_1_strength_1.2_results.npy

Analysis complete! Results saved to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer12
Completed experiment for category 5, layer 12
----------------------------------------
Completed all layer experiments for category 5
===========================================
Starting experiments for category 13
Running experiment for category 13, layer 0
===================================================
Starting experiment:
Category: 13
Layer: 0
Logs will be saved to: /scratch/hy2611/CNN_attention/logs/attention_analysis_20241216_104146/category13/layer0
===================================================
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-12-16 11:18:29.147850: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-16 11:18:29.155682: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2024-12-16 11:18:29.155992: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4a32590 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:18:29.156006: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-16 11:18:29.159082: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-16 11:18:29.290712: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4a29f30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:18:29.290730: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-12-16 11:18:29.291289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:2f:00.0
2024-12-16 11:18:29.292548: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:18:29.293696: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:18:29.294801: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:18:29.295887: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:18:29.296989: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:18:29.298077: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:18:29.299153: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:18:29.299168: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-12-16 11:18:29.299187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-16 11:18:29.299192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-16 11:18:29.299195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:61: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:87: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:15: sigmoid_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.sigmoid_cross_entropy instead. Note that the order of the predictions and labels arguments has been changed.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:322: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:82: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.


Verifying paths:
tc_path: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs exists
weight_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists
image_path: /scratch/hy2611/CNN_attention/Data/VGG16/images exists
save_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists

Initializing model...
('c11', [1, 224, 224, 64])
('c12', [1, 224, 224, 64])
('c21', [1, 112, 112, 128])
('c22', [1, 112, 112, 128])
('c31', [1, 56, 56, 256])
('c32', [1, 56, 56, 256])
('c33', [1, 56, 56, 256])
('c41', [1, 28, 28, 512])
('c42', [1, 28, 28, 512])
('c43', [1, 28, 28, 512])
('c51', [1, 14, 14, 512])
('c52', [1, 14, 14, 512])
('c53', [1, 14, 14, 512])
(0, 'conv1_1_W', (3, 3, 3, 64))
(1, 'conv1_1_b', (64,))
(2, 'conv1_2_W', (3, 3, 64, 64))
(3, 'conv1_2_b', (64,))
(4, 'conv2_1_W', (3, 3, 64, 128))
(5, 'conv2_1_b', (128,))
(6, 'conv2_2_W', (3, 3, 128, 128))
(7, 'conv2_2_b', (128,))
(8, 'conv3_1_W', (3, 3, 128, 256))
(9, 'conv3_1_b', (256,))
(10, 'conv3_2_W', (3, 3, 256, 256))
(11, 'conv3_2_b', (256,))
(12, 'conv3_3_W', (3, 3, 256, 256))
(13, 'conv3_3_b', (256,))
(14, 'conv4_1_W', (3, 3, 256, 512))
(15, 'conv4_1_b', (512,))
(16, 'conv4_2_W', (3, 3, 512, 512))
(17, 'conv4_2_b', (512,))
(18, 'conv4_3_W', (3, 3, 512, 512))
(19, 'conv4_3_b', (512,))
(20, 'conv5_1_W', (3, 3, 512, 512))
(21, 'conv5_1_b', (512,))
(22, 'conv5_2_W', (3, 3, 512, 512))
(23, 'conv5_2_b', (512,))
(24, 'conv5_3_W', (3, 3, 512, 512))
(25, 'conv5_3_b', (512,))
(26, 'fc6_W', (25088, 4096))
(27, 'fc6_b', (4096,))
(28, 'fc7_W', (4096, 4096))
(29, 'fc7_b', (4096,))
Checking checkpoint files:
Data file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_13.ckpt.data-00000-of-00001 - Found
Index file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_13.ckpt.index - Found
Loading checkpoint from: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_13.ckpt
Checkpoint loaded successfully

Initializing components...
Found tuning curves file: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs/featvecs20_train35_c.txt

Loading category 13 data...
Original positive images shape: (2, 224, 224, 3)

Processing data...

Processing attention strength 0.0
Attention vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

Processing batch 1/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.46344, std: 0.11890

Metrics for layer 0:
  pearson_correlation: -0.0051
  kl_divergence: -5001.0063
  ssim: 0.0484
  iou: 0.1415
Layer 0 metrics:
  pearson_correlation: -0.0051
  kl_divergence: -5001.0063
  ssim: 0.0484
  iou: 0.1415

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.44510, std: 0.12141

Metrics for layer 1:
  pearson_correlation: -0.0027
  kl_divergence: -4858.1538
  ssim: 0.0485
  iou: 0.1420
Layer 1 metrics:
  pearson_correlation: -0.0027
  kl_divergence: -4858.1538
  ssim: 0.0485
  iou: 0.1420

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.49440, std: 0.13440

Metrics for layer 2:
  pearson_correlation: 0.0087
  kl_divergence: -1588.9346
  ssim: 0.0572
  iou: 0.1408
Layer 2 metrics:
  pearson_correlation: 0.0087
  kl_divergence: -1588.9346
  ssim: 0.0572
  iou: 0.1408

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.45321, std: 0.12603

Metrics for layer 3:
  pearson_correlation: 0.0122
  kl_divergence: -1485.6576
  ssim: 0.0645
  iou: 0.1431
Layer 3 metrics:
  pearson_correlation: 0.0122
  kl_divergence: -1485.6576
  ssim: 0.0645
  iou: 0.1431

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.44002, std: 0.13125

Metrics for layer 4:
  pearson_correlation: 0.0248
  kl_divergence: -364.6985
  ssim: 0.0810
  iou: 0.1429
Layer 4 metrics:
  pearson_correlation: 0.0248
  kl_divergence: -364.6985
  ssim: 0.0810
  iou: 0.1429

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.48748, std: 0.14843

Metrics for layer 5:
  pearson_correlation: 0.0140
  kl_divergence: -401.5890
  ssim: 0.0653
  iou: 0.1496
Layer 5 metrics:
  pearson_correlation: 0.0140
  kl_divergence: -401.5890
  ssim: 0.0653
  iou: 0.1496

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.48190, std: 0.13177

Metrics for layer 6:
  pearson_correlation: 0.0009
  kl_divergence: -393.8937
  ssim: 0.0659
  iou: 0.1387
Layer 6 metrics:
  pearson_correlation: 0.0009
  kl_divergence: -393.8937
  ssim: 0.0659
  iou: 0.1387

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.50902, std: 0.17002

Metrics for layer 7:
  pearson_correlation: 0.0071
  kl_divergence: -99.5990
  ssim: 0.0499
  iou: 0.1264
Layer 7 metrics:
  pearson_correlation: 0.0071
  kl_divergence: -99.5990
  ssim: 0.0499
  iou: 0.1264

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.53300, std: 0.16035

Metrics for layer 8:
  pearson_correlation: 0.0540
  kl_divergence: -106.2828
  ssim: 0.0785
  iou: 0.1772
Layer 8 metrics:
  pearson_correlation: 0.0540
  kl_divergence: -106.2828
  ssim: 0.0785
  iou: 0.1772

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.50707, std: 0.17380

Metrics for layer 9:
  pearson_correlation: 0.0417
  kl_divergence: -98.1844
  ssim: 0.0502
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: 0.0417
  kl_divergence: -98.1844
  ssim: 0.0502
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.41217, std: 0.21023

Metrics for layer 10:
  pearson_correlation: -0.0358
  kl_divergence: -10.4008
  ssim: 0.0037
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: -0.0358
  kl_divergence: -10.4008
  ssim: 0.0037
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.51194, std: 0.18928

Metrics for layer 11:
  pearson_correlation: -0.0531
  kl_divergence: -14.7588
  ssim: 0.0357
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: -0.0531
  kl_divergence: -14.7588
  ssim: 0.0357
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.43706, std: 0.20898

Metrics for layer 12:
  pearson_correlation: -0.1110
  kl_divergence: -10.3734
  ssim: -0.0895
  iou: 0.0889
Layer 12 metrics:
  pearson_correlation: -0.1110
  kl_divergence: -10.3734
  ssim: -0.0895
  iou: 0.0889
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer0/batch_0_strength_0.0_results.npy

Processing batch 2/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.44547, std: 0.11784

Metrics for layer 0:
  pearson_correlation: -0.0023
  kl_divergence: -5627.1499
  ssim: 0.0652
  iou: 0.1426
Layer 0 metrics:
  pearson_correlation: -0.0023
  kl_divergence: -5627.1499
  ssim: 0.0652
  iou: 0.1426

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.46034, std: 0.12589

Metrics for layer 1:
  pearson_correlation: 0.0009
  kl_divergence: -5772.5474
  ssim: 0.0591
  iou: 0.1439
Layer 1 metrics:
  pearson_correlation: 0.0009
  kl_divergence: -5772.5474
  ssim: 0.0591
  iou: 0.1439

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.47470, std: 0.12724

Metrics for layer 2:
  pearson_correlation: 0.0005
  kl_divergence: -1665.3481
  ssim: 0.0684
  iou: 0.1410
Layer 2 metrics:
  pearson_correlation: 0.0005
  kl_divergence: -1665.3481
  ssim: 0.0684
  iou: 0.1410

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.47267, std: 0.12248

Metrics for layer 3:
  pearson_correlation: -0.0010
  kl_divergence: -1660.2510
  ssim: 0.0737
  iou: 0.1437
Layer 3 metrics:
  pearson_correlation: -0.0010
  kl_divergence: -1660.2510
  ssim: 0.0737
  iou: 0.1437

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.46676, std: 0.14963

Metrics for layer 4:
  pearson_correlation: 0.0065
  kl_divergence: -397.3639
  ssim: 0.0646
  iou: 0.1521
Layer 4 metrics:
  pearson_correlation: 0.0065
  kl_divergence: -397.3639
  ssim: 0.0646
  iou: 0.1521

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.47383, std: 0.14427

Metrics for layer 5:
  pearson_correlation: -0.0151
  kl_divergence: -407.5546
  ssim: 0.0519
  iou: 0.1445
Layer 5 metrics:
  pearson_correlation: -0.0151
  kl_divergence: -407.5546
  ssim: 0.0519
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.46039, std: 0.14569

Metrics for layer 6:
  pearson_correlation: 0.0294
  kl_divergence: -397.9958
  ssim: 0.0671
  iou: 0.1504
Layer 6 metrics:
  pearson_correlation: 0.0294
  kl_divergence: -397.9958
  ssim: 0.0671
  iou: 0.1504

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.49900, std: 0.16155

Metrics for layer 7:
  pearson_correlation: 0.0280
  kl_divergence: -95.9543
  ssim: 0.0377
  iou: 0.1496
Layer 7 metrics:
  pearson_correlation: 0.0280
  kl_divergence: -95.9543
  ssim: 0.0377
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.50596, std: 0.15618

Metrics for layer 8:
  pearson_correlation: 0.0106
  kl_divergence: -97.5827
  ssim: 0.0694
  iou: 0.1496
Layer 8 metrics:
  pearson_correlation: 0.0106
  kl_divergence: -97.5827
  ssim: 0.0694
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.46861, std: 0.16233

Metrics for layer 9:
  pearson_correlation: -0.0646
  kl_divergence: -76.3442
  ssim: 0.0209
  iou: 0.1232
Layer 9 metrics:
  pearson_correlation: -0.0646
  kl_divergence: -76.3442
  ssim: 0.0209
  iou: 0.1232

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.46030, std: 0.18236

Metrics for layer 10:
  pearson_correlation: -0.1177
  kl_divergence: -13.3713
  ssim: -0.0243
  iou: 0.1807
Layer 10 metrics:
  pearson_correlation: -0.1177
  kl_divergence: -13.3713
  ssim: -0.0243
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.51668, std: 0.16849

Metrics for layer 11:
  pearson_correlation: 0.0591
  kl_divergence: -16.2436
  ssim: 0.0287
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: 0.0591
  kl_divergence: -16.2436
  ssim: 0.0287
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.40715, std: 0.15750

Metrics for layer 12:
  pearson_correlation: 0.1545
  kl_divergence: -18.0910
  ssim: 0.1673
  iou: 0.2405
Layer 12 metrics:
  pearson_correlation: 0.1545
  kl_divergence: -18.0910
  ssim: 0.1673
  iou: 0.2405
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer0/batch_1_strength_0.0_results.npy

Processing attention strength 0.4
Attention vector: [0.4 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.50211, std: 0.12348

Metrics for layer 0:
  pearson_correlation: 0.0043
  kl_divergence: -5266.2578
  ssim: 0.0423
  iou: 0.1454
Layer 0 metrics:
  pearson_correlation: 0.0043
  kl_divergence: -5266.2578
  ssim: 0.0423
  iou: 0.1454

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.40534, std: 0.12253

Metrics for layer 1:
  pearson_correlation: -0.0021
  kl_divergence: -4527.7515
  ssim: 0.0524
  iou: 0.1388
Layer 1 metrics:
  pearson_correlation: -0.0021
  kl_divergence: -4527.7515
  ssim: 0.0524
  iou: 0.1388

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.46736, std: 0.12907

Metrics for layer 2:
  pearson_correlation: -0.0098
  kl_divergence: -1516.9576
  ssim: 0.0590
  iou: 0.1443
Layer 2 metrics:
  pearson_correlation: -0.0098
  kl_divergence: -1516.9576
  ssim: 0.0590
  iou: 0.1443

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.42643, std: 0.13615

Metrics for layer 3:
  pearson_correlation: -0.0143
  kl_divergence: -1381.3127
  ssim: 0.0589
  iou: 0.1381
Layer 3 metrics:
  pearson_correlation: -0.0143
  kl_divergence: -1381.3127
  ssim: 0.0589
  iou: 0.1381

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.44465, std: 0.14348

Metrics for layer 4:
  pearson_correlation: 0.0080
  kl_divergence: -364.7590
  ssim: 0.0555
  iou: 0.1387
Layer 4 metrics:
  pearson_correlation: 0.0080
  kl_divergence: -364.7590
  ssim: 0.0555
  iou: 0.1387

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.49549, std: 0.14568

Metrics for layer 5:
  pearson_correlation: -0.0118
  kl_divergence: -402.1114
  ssim: 0.0521
  iou: 0.1420
Layer 5 metrics:
  pearson_correlation: -0.0118
  kl_divergence: -402.1114
  ssim: 0.0521
  iou: 0.1420

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.40502, std: 0.13479

Metrics for layer 6:
  pearson_correlation: 0.0025
  kl_divergence: -328.0614
  ssim: 0.0634
  iou: 0.1496
Layer 6 metrics:
  pearson_correlation: 0.0025
  kl_divergence: -328.0614
  ssim: 0.0634
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.47103, std: 0.17640

Metrics for layer 7:
  pearson_correlation: -0.0024
  kl_divergence: -89.1452
  ssim: 0.0552
  iou: 0.1395
Layer 7 metrics:
  pearson_correlation: -0.0024
  kl_divergence: -89.1452
  ssim: 0.0552
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.50767, std: 0.16041

Metrics for layer 8:
  pearson_correlation: -0.0536
  kl_divergence: -98.6810
  ssim: 0.0238
  iou: 0.1429
Layer 8 metrics:
  pearson_correlation: -0.0536
  kl_divergence: -98.6810
  ssim: 0.0238
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.48798, std: 0.16843

Metrics for layer 9:
  pearson_correlation: 0.0263
  kl_divergence: -96.6108
  ssim: 0.0542
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: 0.0263
  kl_divergence: -96.6108
  ssim: 0.0542
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.55741, std: 0.17345

Metrics for layer 10:
  pearson_correlation: 0.0320
  kl_divergence: -25.7402
  ssim: 0.1122
  iou: 0.1395
Layer 10 metrics:
  pearson_correlation: 0.0320
  kl_divergence: -25.7402
  ssim: 0.1122
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.51398, std: 0.18620

Metrics for layer 11:
  pearson_correlation: -0.0466
  kl_divergence: -17.4470
  ssim: 0.0778
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: -0.0466
  kl_divergence: -17.4470
  ssim: 0.0778
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.49887, std: 0.18283

Metrics for layer 12:
  pearson_correlation: -0.0157
  kl_divergence: -20.1162
  ssim: 0.0835
  iou: 0.0769
Layer 12 metrics:
  pearson_correlation: -0.0157
  kl_divergence: -20.1162
  ssim: 0.0835
  iou: 0.0769
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer0/batch_0_strength_0.4_results.npy

Processing batch 2/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.50463, std: 0.12277

Metrics for layer 0:
  pearson_correlation: -0.0025
  kl_divergence: -6231.8721
  ssim: 0.0534
  iou: 0.1442
Layer 0 metrics:
  pearson_correlation: -0.0025
  kl_divergence: -6231.8721
  ssim: 0.0534
  iou: 0.1442

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.45862, std: 0.11525

Metrics for layer 1:
  pearson_correlation: 0.0066
  kl_divergence: -5796.8369
  ssim: 0.0655
  iou: 0.1439
Layer 1 metrics:
  pearson_correlation: 0.0066
  kl_divergence: -5796.8369
  ssim: 0.0655
  iou: 0.1439

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.45031, std: 0.13863

Metrics for layer 2:
  pearson_correlation: 0.0022
  kl_divergence: -1554.2483
  ssim: 0.0659
  iou: 0.1441
Layer 2 metrics:
  pearson_correlation: 0.0022
  kl_divergence: -1554.2483
  ssim: 0.0659
  iou: 0.1441

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.52864, std: 0.12017

Metrics for layer 3:
  pearson_correlation: 0.0109
  kl_divergence: -1861.6599
  ssim: 0.0722
  iou: 0.1431
Layer 3 metrics:
  pearson_correlation: 0.0109
  kl_divergence: -1861.6599
  ssim: 0.0722
  iou: 0.1431

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.47543, std: 0.14242

Metrics for layer 4:
  pearson_correlation: 0.0154
  kl_divergence: -409.1622
  ssim: 0.0681
  iou: 0.1563
Layer 4 metrics:
  pearson_correlation: 0.0154
  kl_divergence: -409.1622
  ssim: 0.0681
  iou: 0.1563

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.50681, std: 0.13783

Metrics for layer 5:
  pearson_correlation: -0.0225
  kl_divergence: -440.1441
  ssim: 0.0509
  iou: 0.1321
Layer 5 metrics:
  pearson_correlation: -0.0225
  kl_divergence: -440.1441
  ssim: 0.0509
  iou: 0.1321

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.50515, std: 0.14208

Metrics for layer 6:
  pearson_correlation: 0.0150
  kl_divergence: -442.6345
  ssim: 0.0722
  iou: 0.1412
Layer 6 metrics:
  pearson_correlation: 0.0150
  kl_divergence: -442.6345
  ssim: 0.0722
  iou: 0.1412

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.52629, std: 0.17168

Metrics for layer 7:
  pearson_correlation: 0.0213
  kl_divergence: -103.5569
  ssim: 0.0461
  iou: 0.1462
Layer 7 metrics:
  pearson_correlation: 0.0213
  kl_divergence: -103.5569
  ssim: 0.0461
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.43586, std: 0.14915

Metrics for layer 8:
  pearson_correlation: -0.0117
  kl_divergence: -73.4014
  ssim: 0.0502
  iou: 0.1563
Layer 8 metrics:
  pearson_correlation: -0.0117
  kl_divergence: -73.4014
  ssim: 0.0502
  iou: 0.1563

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.52975, std: 0.16114

Metrics for layer 9:
  pearson_correlation: -0.0238
  kl_divergence: -104.3612
  ssim: 0.0443
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: -0.0238
  kl_divergence: -104.3612
  ssim: 0.0443
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.44617, std: 0.20108

Metrics for layer 10:
  pearson_correlation: 0.0366
  kl_divergence: -15.5097
  ssim: 0.0282
  iou: 0.1136
Layer 10 metrics:
  pearson_correlation: 0.0366
  kl_divergence: -15.5097
  ssim: 0.0282
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.37960, std: 0.21181

Metrics for layer 11:
  pearson_correlation: 0.0435
  kl_divergence: -8.1940
  ssim: 0.0089
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: 0.0435
  kl_divergence: -8.1940
  ssim: 0.0089
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.41702, std: 0.18229

Metrics for layer 12:
  pearson_correlation: 0.0369
  kl_divergence: -17.4365
  ssim: 0.0536
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: 0.0369
  kl_divergence: -17.4365
  ssim: 0.0536
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer0/batch_1_strength_0.4_results.npy

Processing attention strength 0.8
Attention vector: [0.8 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.46130, std: 0.10888

Metrics for layer 0:
  pearson_correlation: 0.0002
  kl_divergence: -5007.0527
  ssim: 0.0544
  iou: 0.1438
Layer 0 metrics:
  pearson_correlation: 0.0002
  kl_divergence: -5007.0527
  ssim: 0.0544
  iou: 0.1438

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.44614, std: 0.11969

Metrics for layer 1:
  pearson_correlation: -0.0049
  kl_divergence: -4869.1064
  ssim: 0.0487
  iou: 0.1403
Layer 1 metrics:
  pearson_correlation: -0.0049
  kl_divergence: -4869.1064
  ssim: 0.0487
  iou: 0.1403

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.44901, std: 0.14083

Metrics for layer 2:
  pearson_correlation: 0.0109
  kl_divergence: -1456.8383
  ssim: 0.0582
  iou: 0.1491
Layer 2 metrics:
  pearson_correlation: 0.0109
  kl_divergence: -1456.8383
  ssim: 0.0582
  iou: 0.1491

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.46228, std: 0.12580

Metrics for layer 3:
  pearson_correlation: -0.0200
  kl_divergence: -1504.0461
  ssim: 0.0623
  iou: 0.1311
Layer 3 metrics:
  pearson_correlation: -0.0200
  kl_divergence: -1504.0461
  ssim: 0.0623
  iou: 0.1311

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.44582, std: 0.13164

Metrics for layer 4:
  pearson_correlation: 0.0044
  kl_divergence: -369.3849
  ssim: 0.0764
  iou: 0.1479
Layer 4 metrics:
  pearson_correlation: 0.0044
  kl_divergence: -369.3849
  ssim: 0.0764
  iou: 0.1479

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.50781, std: 0.14161

Metrics for layer 5:
  pearson_correlation: -0.0072
  kl_divergence: -418.4441
  ssim: 0.0516
  iou: 0.1546
Layer 5 metrics:
  pearson_correlation: -0.0072
  kl_divergence: -418.4441
  ssim: 0.0516
  iou: 0.1546

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.47930, std: 0.13028

Metrics for layer 6:
  pearson_correlation: -0.0017
  kl_divergence: -390.9581
  ssim: 0.0672
  iou: 0.1346
Layer 6 metrics:
  pearson_correlation: -0.0017
  kl_divergence: -390.9581
  ssim: 0.0672
  iou: 0.1346

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.50543, std: 0.15650

Metrics for layer 7:
  pearson_correlation: 0.0471
  kl_divergence: -102.5746
  ssim: 0.0718
  iou: 0.1264
Layer 7 metrics:
  pearson_correlation: 0.0471
  kl_divergence: -102.5746
  ssim: 0.0718
  iou: 0.1264

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.48934, std: 0.14976

Metrics for layer 8:
  pearson_correlation: -0.0506
  kl_divergence: -97.1103
  ssim: 0.0381
  iou: 0.1264
Layer 8 metrics:
  pearson_correlation: -0.0506
  kl_divergence: -97.1103
  ssim: 0.0381
  iou: 0.1264

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.48745, std: 0.16387

Metrics for layer 9:
  pearson_correlation: 0.0271
  kl_divergence: -96.1656
  ssim: 0.0627
  iou: 0.1737
Layer 9 metrics:
  pearson_correlation: 0.0271
  kl_divergence: -96.1656
  ssim: 0.0627
  iou: 0.1737

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.51995, std: 0.18029

Metrics for layer 10:
  pearson_correlation: 0.1137
  kl_divergence: -23.5526
  ssim: 0.1541
  iou: 0.1667
Layer 10 metrics:
  pearson_correlation: 0.1137
  kl_divergence: -23.5526
  ssim: 0.1541
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.53175, std: 0.21779

Metrics for layer 11:
  pearson_correlation: -0.1656
  kl_divergence: 0.2660
  ssim: -0.0994
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: -0.1656
  kl_divergence: 0.2660
  ssim: -0.0994
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.42994, std: 0.18749

Metrics for layer 12:
  pearson_correlation: -0.0407
  kl_divergence: -14.4751
  ssim: 0.0489
  iou: 0.1264
Layer 12 metrics:
  pearson_correlation: -0.0407
  kl_divergence: -14.4751
  ssim: 0.0489
  iou: 0.1264
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer0/batch_0_strength_0.8_results.npy

Processing batch 2/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.51963, std: 0.11354

Metrics for layer 0:
  pearson_correlation: 0.0037
  kl_divergence: -6420.1611
  ssim: 0.0604
  iou: 0.1432
Layer 0 metrics:
  pearson_correlation: 0.0037
  kl_divergence: -6420.1611
  ssim: 0.0604
  iou: 0.1432

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.40130, std: 0.12331

Metrics for layer 1:
  pearson_correlation: 0.0026
  kl_divergence: -5064.7412
  ssim: 0.0672
  iou: 0.1421
Layer 1 metrics:
  pearson_correlation: 0.0026
  kl_divergence: -5064.7412
  ssim: 0.0672
  iou: 0.1421

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.45560, std: 0.12362

Metrics for layer 2:
  pearson_correlation: 0.0099
  kl_divergence: -1601.2607
  ssim: 0.0784
  iou: 0.1498
Layer 2 metrics:
  pearson_correlation: 0.0099
  kl_divergence: -1601.2607
  ssim: 0.0784
  iou: 0.1498

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.42162, std: 0.13570

Metrics for layer 3:
  pearson_correlation: -0.0011
  kl_divergence: -1441.6074
  ssim: 0.0681
  iou: 0.1452
Layer 3 metrics:
  pearson_correlation: -0.0011
  kl_divergence: -1441.6074
  ssim: 0.0681
  iou: 0.1452

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.45924, std: 0.15001

Metrics for layer 4:
  pearson_correlation: 0.0220
  kl_divergence: -394.8352
  ssim: 0.0751
  iou: 0.1615
Layer 4 metrics:
  pearson_correlation: 0.0220
  kl_divergence: -394.8352
  ssim: 0.0751
  iou: 0.1615

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.45305, std: 0.15173

Metrics for layer 5:
  pearson_correlation: 0.0159
  kl_divergence: -381.7905
  ssim: 0.0614
  iou: 0.1538
Layer 5 metrics:
  pearson_correlation: 0.0159
  kl_divergence: -381.7905
  ssim: 0.0614
  iou: 0.1538

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.47762, std: 0.13661

Metrics for layer 6:
  pearson_correlation: -0.0098
  kl_divergence: -412.7470
  ssim: 0.0692
  iou: 0.1281
Layer 6 metrics:
  pearson_correlation: -0.0098
  kl_divergence: -412.7470
  ssim: 0.0692
  iou: 0.1281

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.54814, std: 0.17666

Metrics for layer 7:
  pearson_correlation: -0.0702
  kl_divergence: -104.1537
  ssim: 0.0044
  iou: 0.1042
Layer 7 metrics:
  pearson_correlation: -0.0702
  kl_divergence: -104.1537
  ssim: 0.0044
  iou: 0.1042

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.47848, std: 0.15624

Metrics for layer 8:
  pearson_correlation: -0.0465
  kl_divergence: -84.3219
  ssim: 0.0121
  iou: 0.1329
Layer 8 metrics:
  pearson_correlation: -0.0465
  kl_divergence: -84.3219
  ssim: 0.0121
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.44355, std: 0.14220

Metrics for layer 9:
  pearson_correlation: 0.0304
  kl_divergence: -79.5043
  ssim: 0.0596
  iou: 0.1563
Layer 9 metrics:
  pearson_correlation: 0.0304
  kl_divergence: -79.5043
  ssim: 0.0596
  iou: 0.1563

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.45799, std: 0.18319

Metrics for layer 10:
  pearson_correlation: 0.0510
  kl_divergence: -17.1928
  ssim: 0.1237
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: 0.0510
  kl_divergence: -17.1928
  ssim: 0.1237
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.53251, std: 0.20886

Metrics for layer 11:
  pearson_correlation: 0.1608
  kl_divergence: -23.9878
  ssim: 0.0404
  iou: 0.1807
Layer 11 metrics:
  pearson_correlation: 0.1608
  kl_divergence: -23.9878
  ssim: 0.0404
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.59218, std: 0.18773

Metrics for layer 12:
  pearson_correlation: 0.0658
  kl_divergence: -30.7420
  ssim: 0.1047
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: 0.0658
  kl_divergence: -30.7420
  ssim: 0.1047
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer0/batch_1_strength_0.8_results.npy

Processing attention strength 1.2
Attention vector: [1.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.47361, std: 0.12365

Metrics for layer 0:
  pearson_correlation: 0.0013
  kl_divergence: -5066.2529
  ssim: 0.0445
  iou: 0.1415
Layer 0 metrics:
  pearson_correlation: 0.0013
  kl_divergence: -5066.2529
  ssim: 0.0445
  iou: 0.1415

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.39637, std: 0.11132

Metrics for layer 1:
  pearson_correlation: -0.0072
  kl_divergence: -4475.2583
  ssim: 0.0583
  iou: 0.1395
Layer 1 metrics:
  pearson_correlation: -0.0072
  kl_divergence: -4475.2583
  ssim: 0.0583
  iou: 0.1395

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.42287, std: 0.13528

Metrics for layer 2:
  pearson_correlation: 0.0104
  kl_divergence: -1378.5856
  ssim: 0.0667
  iou: 0.1431
Layer 2 metrics:
  pearson_correlation: 0.0104
  kl_divergence: -1378.5856
  ssim: 0.0667
  iou: 0.1431

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.45469, std: 0.12905

Metrics for layer 3:
  pearson_correlation: 0.0052
  kl_divergence: -1485.4458
  ssim: 0.0634
  iou: 0.1449
Layer 3 metrics:
  pearson_correlation: 0.0052
  kl_divergence: -1485.4458
  ssim: 0.0634
  iou: 0.1449

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.44423, std: 0.14868

Metrics for layer 4:
  pearson_correlation: 0.0278
  kl_divergence: -363.5390
  ssim: 0.0671
  iou: 0.1496
Layer 4 metrics:
  pearson_correlation: 0.0278
  kl_divergence: -363.5390
  ssim: 0.0671
  iou: 0.1496

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.40883, std: 0.13418

Metrics for layer 5:
  pearson_correlation: -0.0175
  kl_divergence: -328.4001
  ssim: 0.0640
  iou: 0.1371
Layer 5 metrics:
  pearson_correlation: -0.0175
  kl_divergence: -328.4001
  ssim: 0.0640
  iou: 0.1371

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.49185, std: 0.15019

Metrics for layer 6:
  pearson_correlation: -0.0079
  kl_divergence: -399.3003
  ssim: 0.0427
  iou: 0.1362
Layer 6 metrics:
  pearson_correlation: -0.0079
  kl_divergence: -399.3003
  ssim: 0.0427
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.46034, std: 0.16896

Metrics for layer 7:
  pearson_correlation: 0.0360
  kl_divergence: -86.7162
  ssim: 0.0594
  iou: 0.1297
Layer 7 metrics:
  pearson_correlation: 0.0360
  kl_divergence: -86.7162
  ssim: 0.0594
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.45089, std: 0.14288

Metrics for layer 8:
  pearson_correlation: -0.0157
  kl_divergence: -87.5897
  ssim: 0.0460
  iou: 0.1362
Layer 8 metrics:
  pearson_correlation: -0.0157
  kl_divergence: -87.5897
  ssim: 0.0460
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.40649, std: 0.16136

Metrics for layer 9:
  pearson_correlation: 0.0021
  kl_divergence: -74.8863
  ssim: 0.0382
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: 0.0021
  kl_divergence: -74.8863
  ssim: 0.0382
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.47921, std: 0.17927

Metrics for layer 10:
  pearson_correlation: 0.0404
  kl_divergence: -20.9337
  ssim: 0.0347
  iou: 0.0889
Layer 10 metrics:
  pearson_correlation: 0.0404
  kl_divergence: -20.9337
  ssim: 0.0347
  iou: 0.0889

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.47102, std: 0.19355

Metrics for layer 11:
  pearson_correlation: 0.1075
  kl_divergence: -19.6399
  ssim: 0.1936
  iou: 0.2099
Layer 11 metrics:
  pearson_correlation: 0.1075
  kl_divergence: -19.6399
  ssim: 0.1936
  iou: 0.2099

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.47112, std: 0.18267

Metrics for layer 12:
  pearson_correlation: -0.0299
  kl_divergence: -15.2360
  ssim: 0.0233
  iou: 0.1807
Layer 12 metrics:
  pearson_correlation: -0.0299
  kl_divergence: -15.2360
  ssim: 0.0233
  iou: 0.1807
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer0/batch_0_strength_1.2_results.npy

Processing batch 2/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.50807, std: 0.12798

Metrics for layer 0:
  pearson_correlation: -0.0016
  kl_divergence: -6258.8706
  ssim: 0.0505
  iou: 0.1422
Layer 0 metrics:
  pearson_correlation: -0.0016
  kl_divergence: -6258.8706
  ssim: 0.0505
  iou: 0.1422

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.43394, std: 0.11549

Metrics for layer 1:
  pearson_correlation: 0.0029
  kl_divergence: -5506.6079
  ssim: 0.0669
  iou: 0.1474
Layer 1 metrics:
  pearson_correlation: 0.0029
  kl_divergence: -5506.6079
  ssim: 0.0669
  iou: 0.1474

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.48919, std: 0.12888

Metrics for layer 2:
  pearson_correlation: 0.0069
  kl_divergence: -1718.5659
  ssim: 0.0730
  iou: 0.1447
Layer 2 metrics:
  pearson_correlation: 0.0069
  kl_divergence: -1718.5659
  ssim: 0.0730
  iou: 0.1447

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.47541, std: 0.13209

Metrics for layer 3:
  pearson_correlation: -0.0017
  kl_divergence: -1656.7874
  ssim: 0.0682
  iou: 0.1414
Layer 3 metrics:
  pearson_correlation: -0.0017
  kl_divergence: -1656.7874
  ssim: 0.0682
  iou: 0.1414

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.47431, std: 0.14558

Metrics for layer 4:
  pearson_correlation: -0.0245
  kl_divergence: -406.4086
  ssim: 0.0630
  iou: 0.1297
Layer 4 metrics:
  pearson_correlation: -0.0245
  kl_divergence: -406.4086
  ssim: 0.0630
  iou: 0.1297

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.43042, std: 0.13369

Metrics for layer 5:
  pearson_correlation: 0.0102
  kl_divergence: -363.8805
  ssim: 0.0793
  iou: 0.1412
Layer 5 metrics:
  pearson_correlation: 0.0102
  kl_divergence: -363.8805
  ssim: 0.0793
  iou: 0.1412

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.48671, std: 0.15530

Metrics for layer 6:
  pearson_correlation: -0.0168
  kl_divergence: -413.1700
  ssim: 0.0456
  iou: 0.1437
Layer 6 metrics:
  pearson_correlation: -0.0168
  kl_divergence: -413.1700
  ssim: 0.0456
  iou: 0.1437

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.51702, std: 0.15562

Metrics for layer 7:
  pearson_correlation: -0.0557
  kl_divergence: -99.3053
  ssim: 0.0044
  iou: 0.1362
Layer 7 metrics:
  pearson_correlation: -0.0557
  kl_divergence: -99.3053
  ssim: 0.0044
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.50528, std: 0.15470

Metrics for layer 8:
  pearson_correlation: 0.0357
  kl_divergence: -98.7074
  ssim: 0.0665
  iou: 0.1667
Layer 8 metrics:
  pearson_correlation: 0.0357
  kl_divergence: -98.7074
  ssim: 0.0665
  iou: 0.1667

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.48870, std: 0.15368

Metrics for layer 9:
  pearson_correlation: 0.0726
  kl_divergence: -96.3446
  ssim: 0.0775
  iou: 0.1667
Layer 9 metrics:
  pearson_correlation: 0.0726
  kl_divergence: -96.3446
  ssim: 0.0775
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.47316, std: 0.14668

Metrics for layer 10:
  pearson_correlation: -0.1463
  kl_divergence: -19.5536
  ssim: 0.0025
  iou: 0.1395
Layer 10 metrics:
  pearson_correlation: -0.1463
  kl_divergence: -19.5536
  ssim: 0.0025
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.45835, std: 0.19155

Metrics for layer 11:
  pearson_correlation: 0.0379
  kl_divergence: -20.4000
  ssim: 0.0776
  iou: 0.1011
Layer 11 metrics:
  pearson_correlation: 0.0379
  kl_divergence: -20.4000
  ssim: 0.0776
  iou: 0.1011

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.54612, std: 0.18946

Metrics for layer 12:
  pearson_correlation: -0.1705
  kl_divergence: -25.0201
  ssim: -0.0061
  iou: 0.0889
Layer 12 metrics:
  pearson_correlation: -0.1705
  kl_divergence: -25.0201
  ssim: -0.0061
  iou: 0.0889
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer0/batch_1_strength_1.2_results.npy

Analysis complete! Results saved to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer0
Completed experiment for category 13, layer 0
----------------------------------------
Running experiment for category 13, layer 1
===================================================
Starting experiment:
Category: 13
Layer: 1
Logs will be saved to: /scratch/hy2611/CNN_attention/logs/attention_analysis_20241216_104146/category13/layer1
===================================================
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-12-16 11:21:30.335834: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-16 11:21:30.354507: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2024-12-16 11:21:30.354948: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4b3add0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:21:30.354965: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-16 11:21:30.357715: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-16 11:21:30.500646: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4b33e60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:21:30.500665: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-12-16 11:21:30.501184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:2f:00.0
2024-12-16 11:21:30.502412: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:21:30.503537: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:21:30.504582: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:21:30.505622: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:21:30.506650: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:21:30.507687: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:21:30.508726: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:21:30.508737: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-12-16 11:21:30.508757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-16 11:21:30.508762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-16 11:21:30.508765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:61: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:87: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:15: sigmoid_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.sigmoid_cross_entropy instead. Note that the order of the predictions and labels arguments has been changed.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:322: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:82: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.


Verifying paths:
tc_path: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs exists
weight_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists
image_path: /scratch/hy2611/CNN_attention/Data/VGG16/images exists
save_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists

Initializing model...
('c11', [1, 224, 224, 64])
('c12', [1, 224, 224, 64])
('c21', [1, 112, 112, 128])
('c22', [1, 112, 112, 128])
('c31', [1, 56, 56, 256])
('c32', [1, 56, 56, 256])
('c33', [1, 56, 56, 256])
('c41', [1, 28, 28, 512])
('c42', [1, 28, 28, 512])
('c43', [1, 28, 28, 512])
('c51', [1, 14, 14, 512])
('c52', [1, 14, 14, 512])
('c53', [1, 14, 14, 512])
(0, 'conv1_1_W', (3, 3, 3, 64))
(1, 'conv1_1_b', (64,))
(2, 'conv1_2_W', (3, 3, 64, 64))
(3, 'conv1_2_b', (64,))
(4, 'conv2_1_W', (3, 3, 64, 128))
(5, 'conv2_1_b', (128,))
(6, 'conv2_2_W', (3, 3, 128, 128))
(7, 'conv2_2_b', (128,))
(8, 'conv3_1_W', (3, 3, 128, 256))
(9, 'conv3_1_b', (256,))
(10, 'conv3_2_W', (3, 3, 256, 256))
(11, 'conv3_2_b', (256,))
(12, 'conv3_3_W', (3, 3, 256, 256))
(13, 'conv3_3_b', (256,))
(14, 'conv4_1_W', (3, 3, 256, 512))
(15, 'conv4_1_b', (512,))
(16, 'conv4_2_W', (3, 3, 512, 512))
(17, 'conv4_2_b', (512,))
(18, 'conv4_3_W', (3, 3, 512, 512))
(19, 'conv4_3_b', (512,))
(20, 'conv5_1_W', (3, 3, 512, 512))
(21, 'conv5_1_b', (512,))
(22, 'conv5_2_W', (3, 3, 512, 512))
(23, 'conv5_2_b', (512,))
(24, 'conv5_3_W', (3, 3, 512, 512))
(25, 'conv5_3_b', (512,))
(26, 'fc6_W', (25088, 4096))
(27, 'fc6_b', (4096,))
(28, 'fc7_W', (4096, 4096))
(29, 'fc7_b', (4096,))
Checking checkpoint files:
Data file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_13.ckpt.data-00000-of-00001 - Found
Index file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_13.ckpt.index - Found
Loading checkpoint from: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_13.ckpt
Checkpoint loaded successfully

Initializing components...
Found tuning curves file: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs/featvecs20_train35_c.txt

Loading category 13 data...
Original positive images shape: (2, 224, 224, 3)

Processing data...

Processing attention strength 0.0
Attention vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

Processing batch 1/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.44481, std: 0.11396

Metrics for layer 0:
  pearson_correlation: 0.0026
  kl_divergence: -4876.7109
  ssim: 0.0526
  iou: 0.1450
Layer 0 metrics:
  pearson_correlation: 0.0026
  kl_divergence: -4876.7109
  ssim: 0.0526
  iou: 0.1450

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.44766, std: 0.12027

Metrics for layer 1:
  pearson_correlation: -0.0028
  kl_divergence: -4881.2812
  ssim: 0.0487
  iou: 0.1436
Layer 1 metrics:
  pearson_correlation: -0.0028
  kl_divergence: -4881.2812
  ssim: 0.0487
  iou: 0.1436

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.46128, std: 0.13649

Metrics for layer 2:
  pearson_correlation: -0.0025
  kl_divergence: -1491.0229
  ssim: 0.0585
  iou: 0.1472
Layer 2 metrics:
  pearson_correlation: -0.0025
  kl_divergence: -1491.0229
  ssim: 0.0585
  iou: 0.1472

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.43671, std: 0.13339

Metrics for layer 3:
  pearson_correlation: -0.0054
  kl_divergence: -1419.8213
  ssim: 0.0600
  iou: 0.1389
Layer 3 metrics:
  pearson_correlation: -0.0054
  kl_divergence: -1419.8213
  ssim: 0.0600
  iou: 0.1389

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.47075, std: 0.15063

Metrics for layer 4:
  pearson_correlation: 0.0057
  kl_divergence: -385.5251
  ssim: 0.0561
  iou: 0.1437
Layer 4 metrics:
  pearson_correlation: 0.0057
  kl_divergence: -385.5251
  ssim: 0.0561
  iou: 0.1437

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.44266, std: 0.13699

Metrics for layer 5:
  pearson_correlation: -0.0212
  kl_divergence: -362.5101
  ssim: 0.0549
  iou: 0.1395
Layer 5 metrics:
  pearson_correlation: -0.0212
  kl_divergence: -362.5101
  ssim: 0.0549
  iou: 0.1395

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.45183, std: 0.14171

Metrics for layer 6:
  pearson_correlation: -0.0208
  kl_divergence: -366.6567
  ssim: 0.0488
  iou: 0.1479
Layer 6 metrics:
  pearson_correlation: -0.0208
  kl_divergence: -366.6567
  ssim: 0.0488
  iou: 0.1479

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.48851, std: 0.17732

Metrics for layer 7:
  pearson_correlation: 0.0768
  kl_divergence: -97.9567
  ssim: 0.0709
  iou: 0.1667
Layer 7 metrics:
  pearson_correlation: 0.0768
  kl_divergence: -97.9567
  ssim: 0.0709
  iou: 0.1667

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.48355, std: 0.15891

Metrics for layer 8:
  pearson_correlation: -0.0044
  kl_divergence: -93.2207
  ssim: 0.0393
  iou: 0.1701
Layer 8 metrics:
  pearson_correlation: -0.0044
  kl_divergence: -93.2207
  ssim: 0.0393
  iou: 0.1701

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.45775, std: 0.14353

Metrics for layer 9:
  pearson_correlation: 0.0434
  kl_divergence: -91.8592
  ssim: 0.0874
  iou: 0.1496
Layer 9 metrics:
  pearson_correlation: 0.0434
  kl_divergence: -91.8592
  ssim: 0.0874
  iou: 0.1496

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.45377, std: 0.20491

Metrics for layer 10:
  pearson_correlation: 0.0165
  kl_divergence: -13.9664
  ssim: 0.1155
  iou: 0.1667
Layer 10 metrics:
  pearson_correlation: 0.0165
  kl_divergence: -13.9664
  ssim: 0.1155
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.44045, std: 0.21170

Metrics for layer 11:
  pearson_correlation: 0.0955
  kl_divergence: -15.6105
  ssim: 0.1391
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: 0.0955
  kl_divergence: -15.6105
  ssim: 0.1391
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.61563, std: 0.16419

Metrics for layer 12:
  pearson_correlation: -0.0055
  kl_divergence: -24.1015
  ssim: 0.0807
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: -0.0055
  kl_divergence: -24.1015
  ssim: 0.0807
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer1/batch_0_strength_0.0_results.npy

Processing batch 2/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.40991, std: 0.11898

Metrics for layer 0:
  pearson_correlation: -0.0042
  kl_divergence: -5186.6470
  ssim: 0.0676
  iou: 0.1434
Layer 0 metrics:
  pearson_correlation: -0.0042
  kl_divergence: -5186.6470
  ssim: 0.0676
  iou: 0.1434

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.41539, std: 0.11675

Metrics for layer 1:
  pearson_correlation: 0.0015
  kl_divergence: -5277.9756
  ssim: 0.0695
  iou: 0.1462
Layer 1 metrics:
  pearson_correlation: 0.0015
  kl_divergence: -5277.9756
  ssim: 0.0695
  iou: 0.1462

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.46395, std: 0.13617

Metrics for layer 2:
  pearson_correlation: 0.0174
  kl_divergence: -1622.0712
  ssim: 0.0714
  iou: 0.1449
Layer 2 metrics:
  pearson_correlation: 0.0174
  kl_divergence: -1622.0712
  ssim: 0.0714
  iou: 0.1449

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.43926, std: 0.13002

Metrics for layer 3:
  pearson_correlation: 0.0189
  kl_divergence: -1533.6112
  ssim: 0.0813
  iou: 0.1498
Layer 3 metrics:
  pearson_correlation: 0.0189
  kl_divergence: -1533.6112
  ssim: 0.0813
  iou: 0.1498

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.46439, std: 0.14085

Metrics for layer 4:
  pearson_correlation: -0.0063
  kl_divergence: -400.3980
  ssim: 0.0602
  iou: 0.1437
Layer 4 metrics:
  pearson_correlation: -0.0063
  kl_divergence: -400.3980
  ssim: 0.0602
  iou: 0.1437

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.50129, std: 0.14036

Metrics for layer 5:
  pearson_correlation: 0.0056
  kl_divergence: -439.2166
  ssim: 0.0653
  iou: 0.1420
Layer 5 metrics:
  pearson_correlation: 0.0056
  kl_divergence: -439.2166
  ssim: 0.0653
  iou: 0.1420

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.47458, std: 0.14542

Metrics for layer 6:
  pearson_correlation: -0.0092
  kl_divergence: -408.9731
  ssim: 0.0525
  iou: 0.1321
Layer 6 metrics:
  pearson_correlation: -0.0092
  kl_divergence: -408.9731
  ssim: 0.0525
  iou: 0.1321

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.47244, std: 0.13760

Metrics for layer 7:
  pearson_correlation: -0.0422
  kl_divergence: -86.8642
  ssim: 0.0438
  iou: 0.1329
Layer 7 metrics:
  pearson_correlation: -0.0422
  kl_divergence: -86.8642
  ssim: 0.0438
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.49286, std: 0.14643

Metrics for layer 8:
  pearson_correlation: -0.0521
  kl_divergence: -86.9174
  ssim: 0.0286
  iou: 0.1264
Layer 8 metrics:
  pearson_correlation: -0.0521
  kl_divergence: -86.9174
  ssim: 0.0286
  iou: 0.1264

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.52051, std: 0.18213

Metrics for layer 9:
  pearson_correlation: 0.0479
  kl_divergence: -98.3270
  ssim: 0.0666
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: 0.0479
  kl_divergence: -98.3270
  ssim: 0.0666
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.55705, std: 0.18253

Metrics for layer 10:
  pearson_correlation: 0.0625
  kl_divergence: -26.8123
  ssim: 0.1023
  iou: 0.1667
Layer 10 metrics:
  pearson_correlation: 0.0625
  kl_divergence: -26.8123
  ssim: 0.1023
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.51217, std: 0.21151

Metrics for layer 11:
  pearson_correlation: -0.0148
  kl_divergence: -21.2858
  ssim: 0.0210
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: -0.0148
  kl_divergence: -21.2858
  ssim: 0.0210
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.43433, std: 0.15518

Metrics for layer 12:
  pearson_correlation: -0.0609
  kl_divergence: -17.5214
  ssim: 0.0373
  iou: 0.0769
Layer 12 metrics:
  pearson_correlation: -0.0609
  kl_divergence: -17.5214
  ssim: 0.0373
  iou: 0.0769
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer1/batch_1_strength_0.0_results.npy

Processing attention strength 0.4
Attention vector: [0.  0.4 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.45292, std: 0.12708

Metrics for layer 0:
  pearson_correlation: -0.0054
  kl_divergence: -4905.5166
  ssim: 0.0447
  iou: 0.1388
Layer 0 metrics:
  pearson_correlation: -0.0054
  kl_divergence: -4905.5166
  ssim: 0.0447
  iou: 0.1388

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.48810, std: 0.11936

Metrics for layer 1:
  pearson_correlation: 0.0018
  kl_divergence: -5177.7471
  ssim: 0.0457
  iou: 0.1433
Layer 1 metrics:
  pearson_correlation: 0.0018
  kl_divergence: -5177.7471
  ssim: 0.0457
  iou: 0.1433

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.46093, std: 0.12024

Metrics for layer 2:
  pearson_correlation: 0.0040
  kl_divergence: -1510.7178
  ssim: 0.0703
  iou: 0.1452
Layer 2 metrics:
  pearson_correlation: 0.0040
  kl_divergence: -1510.7178
  ssim: 0.0703
  iou: 0.1452

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.43213, std: 0.12213

Metrics for layer 3:
  pearson_correlation: -0.0034
  kl_divergence: -1420.7815
  ssim: 0.0676
  iou: 0.1437
Layer 3 metrics:
  pearson_correlation: -0.0034
  kl_divergence: -1420.7815
  ssim: 0.0676
  iou: 0.1437

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.48165, std: 0.15532

Metrics for layer 4:
  pearson_correlation: 0.0059
  kl_divergence: -392.1155
  ssim: 0.0543
  iou: 0.1454
Layer 4 metrics:
  pearson_correlation: 0.0059
  kl_divergence: -392.1155
  ssim: 0.0543
  iou: 0.1454

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.46960, std: 0.14223

Metrics for layer 5:
  pearson_correlation: 0.0079
  kl_divergence: -381.6010
  ssim: 0.0702
  iou: 0.1429
Layer 5 metrics:
  pearson_correlation: 0.0079
  kl_divergence: -381.6010
  ssim: 0.0702
  iou: 0.1429

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.48339, std: 0.15477

Metrics for layer 6:
  pearson_correlation: -0.0339
  kl_divergence: -388.7792
  ssim: 0.0448
  iou: 0.1429
Layer 6 metrics:
  pearson_correlation: -0.0339
  kl_divergence: -388.7792
  ssim: 0.0448
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.51314, std: 0.16845

Metrics for layer 7:
  pearson_correlation: -0.0310
  kl_divergence: -97.4890
  ssim: 0.0281
  iou: 0.1232
Layer 7 metrics:
  pearson_correlation: -0.0310
  kl_divergence: -97.4890
  ssim: 0.0281
  iou: 0.1232

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.46658, std: 0.15097

Metrics for layer 8:
  pearson_correlation: -0.0448
  kl_divergence: -90.9381
  ssim: 0.0459
  iou: 0.1329
Layer 8 metrics:
  pearson_correlation: -0.0448
  kl_divergence: -90.9381
  ssim: 0.0459
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.49276, std: 0.15935

Metrics for layer 9:
  pearson_correlation: -0.0166
  kl_divergence: -96.3115
  ssim: 0.0642
  iou: 0.1264
Layer 9 metrics:
  pearson_correlation: -0.0166
  kl_divergence: -96.3115
  ssim: 0.0642
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.46256, std: 0.20587

Metrics for layer 10:
  pearson_correlation: -0.0721
  kl_divergence: -3.4653
  ssim: -0.0713
  iou: 0.1011
Layer 10 metrics:
  pearson_correlation: -0.0721
  kl_divergence: -3.4653
  ssim: -0.0713
  iou: 0.1011

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.42748, std: 0.19661

Metrics for layer 11:
  pearson_correlation: -0.0971
  kl_divergence: -11.2907
  ssim: -0.0237
  iou: 0.1011
Layer 11 metrics:
  pearson_correlation: -0.0971
  kl_divergence: -11.2907
  ssim: -0.0237
  iou: 0.1011

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.40474, std: 0.17182

Metrics for layer 12:
  pearson_correlation: 0.1017
  kl_divergence: -13.7990
  ssim: 0.1843
  iou: 0.1951
Layer 12 metrics:
  pearson_correlation: 0.1017
  kl_divergence: -13.7990
  ssim: 0.1843
  iou: 0.1951
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer1/batch_0_strength_0.4_results.npy

Processing batch 2/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.39966, std: 0.11577

Metrics for layer 0:
  pearson_correlation: -0.0078
  kl_divergence: -5061.2358
  ssim: 0.0699
  iou: 0.1410
Layer 0 metrics:
  pearson_correlation: -0.0078
  kl_divergence: -5061.2358
  ssim: 0.0699
  iou: 0.1410

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.50319, std: 0.12016

Metrics for layer 1:
  pearson_correlation: -0.0006
  kl_divergence: -6239.3779
  ssim: 0.0552
  iou: 0.1429
Layer 1 metrics:
  pearson_correlation: -0.0006
  kl_divergence: -6239.3779
  ssim: 0.0552
  iou: 0.1429

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.44575, std: 0.12647

Metrics for layer 2:
  pearson_correlation: -0.0152
  kl_divergence: -1543.8452
  ssim: 0.0704
  iou: 0.1399
Layer 2 metrics:
  pearson_correlation: -0.0152
  kl_divergence: -1543.8452
  ssim: 0.0704
  iou: 0.1399

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.49427, std: 0.13093

Metrics for layer 3:
  pearson_correlation: 0.0014
  kl_divergence: -1727.8799
  ssim: 0.0670
  iou: 0.1412
Layer 3 metrics:
  pearson_correlation: 0.0014
  kl_divergence: -1727.8799
  ssim: 0.0670
  iou: 0.1412

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.43474, std: 0.14536

Metrics for layer 4:
  pearson_correlation: -0.0102
  kl_divergence: -363.8637
  ssim: 0.0684
  iou: 0.1404
Layer 4 metrics:
  pearson_correlation: -0.0102
  kl_divergence: -363.8637
  ssim: 0.0684
  iou: 0.1404

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.41687, std: 0.13032

Metrics for layer 5:
  pearson_correlation: 0.0273
  kl_divergence: -355.2542
  ssim: 0.0729
  iou: 0.1496
Layer 5 metrics:
  pearson_correlation: 0.0273
  kl_divergence: -355.2542
  ssim: 0.0729
  iou: 0.1496

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.43166, std: 0.14016

Metrics for layer 6:
  pearson_correlation: -0.0242
  kl_divergence: -358.9758
  ssim: 0.0635
  iou: 0.1321
Layer 6 metrics:
  pearson_correlation: -0.0242
  kl_divergence: -358.9758
  ssim: 0.0635
  iou: 0.1321

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.48745, std: 0.16905

Metrics for layer 7:
  pearson_correlation: -0.0582
  kl_divergence: -86.8639
  ssim: 0.0366
  iou: 0.1395
Layer 7 metrics:
  pearson_correlation: -0.0582
  kl_divergence: -86.8639
  ssim: 0.0366
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.48406, std: 0.14739

Metrics for layer 8:
  pearson_correlation: -0.0323
  kl_divergence: -84.8991
  ssim: 0.0305
  iou: 0.1264
Layer 8 metrics:
  pearson_correlation: -0.0323
  kl_divergence: -84.8991
  ssim: 0.0305
  iou: 0.1264

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.43698, std: 0.15737

Metrics for layer 9:
  pearson_correlation: 0.0761
  kl_divergence: -76.1688
  ssim: 0.1158
  iou: 0.1632
Layer 9 metrics:
  pearson_correlation: 0.0761
  kl_divergence: -76.1688
  ssim: 0.1158
  iou: 0.1632

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.46782, std: 0.17249

Metrics for layer 10:
  pearson_correlation: 0.1157
  kl_divergence: -21.1841
  ssim: 0.0980
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: 0.1157
  kl_divergence: -21.1841
  ssim: 0.0980
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.48990, std: 0.19645

Metrics for layer 11:
  pearson_correlation: -0.0439
  kl_divergence: -13.0341
  ssim: 0.0136
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: -0.0439
  kl_divergence: -13.0341
  ssim: 0.0136
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.52350, std: 0.17550

Metrics for layer 12:
  pearson_correlation: 0.0121
  kl_divergence: -24.2010
  ssim: 0.0950
  iou: 0.1951
Layer 12 metrics:
  pearson_correlation: 0.0121
  kl_divergence: -24.2010
  ssim: 0.0950
  iou: 0.1951
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer1/batch_1_strength_0.4_results.npy

Processing attention strength 0.8
Attention vector: [0.  0.8 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.42493, std: 0.12710

Metrics for layer 0:
  pearson_correlation: -0.0003
  kl_divergence: -4682.4961
  ssim: 0.0480
  iou: 0.1441
Layer 0 metrics:
  pearson_correlation: -0.0003
  kl_divergence: -4682.4961
  ssim: 0.0480
  iou: 0.1441

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.46413, std: 0.11396

Metrics for layer 1:
  pearson_correlation: -0.0008
  kl_divergence: -5018.8784
  ssim: 0.0512
  iou: 0.1417
Layer 1 metrics:
  pearson_correlation: -0.0008
  kl_divergence: -5018.8784
  ssim: 0.0512
  iou: 0.1417

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.41198, std: 0.12502

Metrics for layer 2:
  pearson_correlation: 0.0162
  kl_divergence: -1357.3525
  ssim: 0.0786
  iou: 0.1540
Layer 2 metrics:
  pearson_correlation: 0.0162
  kl_divergence: -1357.3525
  ssim: 0.0786
  iou: 0.1540

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.49876, std: 0.13119

Metrics for layer 3:
  pearson_correlation: 0.0003
  kl_divergence: -1603.5691
  ssim: 0.0579
  iou: 0.1445
Layer 3 metrics:
  pearson_correlation: 0.0003
  kl_divergence: -1603.5691
  ssim: 0.0579
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.43894, std: 0.14620

Metrics for layer 4:
  pearson_correlation: -0.0036
  kl_divergence: -352.9396
  ssim: 0.0548
  iou: 0.1429
Layer 4 metrics:
  pearson_correlation: -0.0036
  kl_divergence: -352.9396
  ssim: 0.0548
  iou: 0.1429

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.45657, std: 0.12844

Metrics for layer 5:
  pearson_correlation: -0.0111
  kl_divergence: -379.4358
  ssim: 0.0575
  iou: 0.1462
Layer 5 metrics:
  pearson_correlation: -0.0111
  kl_divergence: -379.4358
  ssim: 0.0575
  iou: 0.1462

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.45589, std: 0.14692

Metrics for layer 6:
  pearson_correlation: 0.0164
  kl_divergence: -374.4540
  ssim: 0.0686
  iou: 0.1563
Layer 6 metrics:
  pearson_correlation: 0.0164
  kl_divergence: -374.4540
  ssim: 0.0686
  iou: 0.1563

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.47570, std: 0.15405

Metrics for layer 7:
  pearson_correlation: 0.0044
  kl_divergence: -93.1490
  ssim: 0.0513
  iou: 0.1496
Layer 7 metrics:
  pearson_correlation: 0.0044
  kl_divergence: -93.1490
  ssim: 0.0513
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.49889, std: 0.14686

Metrics for layer 8:
  pearson_correlation: -0.0537
  kl_divergence: -98.7264
  ssim: 0.0139
  iou: 0.1362
Layer 8 metrics:
  pearson_correlation: -0.0537
  kl_divergence: -98.7264
  ssim: 0.0139
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.44693, std: 0.14891

Metrics for layer 9:
  pearson_correlation: -0.0268
  kl_divergence: -86.8230
  ssim: 0.0525
  iou: 0.1232
Layer 9 metrics:
  pearson_correlation: -0.0268
  kl_divergence: -86.8230
  ssim: 0.0525
  iou: 0.1232

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.54015, std: 0.16954

Metrics for layer 10:
  pearson_correlation: -0.0166
  kl_divergence: -21.8485
  ssim: 0.0172
  iou: 0.1395
Layer 10 metrics:
  pearson_correlation: -0.0166
  kl_divergence: -21.8485
  ssim: 0.0172
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.51332, std: 0.18901

Metrics for layer 11:
  pearson_correlation: 0.0829
  kl_divergence: -23.4742
  ssim: 0.0933
  iou: 0.1667
Layer 11 metrics:
  pearson_correlation: 0.0829
  kl_divergence: -23.4742
  ssim: 0.0933
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.54699, std: 0.20514

Metrics for layer 12:
  pearson_correlation: -0.1191
  kl_divergence: -22.6895
  ssim: -0.0536
  iou: 0.0769
Layer 12 metrics:
  pearson_correlation: -0.1191
  kl_divergence: -22.6895
  ssim: -0.0536
  iou: 0.0769
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer1/batch_0_strength_0.8_results.npy

Processing batch 2/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.43090, std: 0.12635

Metrics for layer 0:
  pearson_correlation: -0.0009
  kl_divergence: -5422.3237
  ssim: 0.0621
  iou: 0.1444
Layer 0 metrics:
  pearson_correlation: -0.0009
  kl_divergence: -5422.3237
  ssim: 0.0621
  iou: 0.1444

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.51222, std: 0.12091

Metrics for layer 1:
  pearson_correlation: 0.0006
  kl_divergence: -6328.5996
  ssim: 0.0562
  iou: 0.1406
Layer 1 metrics:
  pearson_correlation: 0.0006
  kl_divergence: -6328.5996
  ssim: 0.0562
  iou: 0.1406

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.47450, std: 0.12544

Metrics for layer 2:
  pearson_correlation: -0.0046
  kl_divergence: -1665.1956
  ssim: 0.0718
  iou: 0.1412
Layer 2 metrics:
  pearson_correlation: -0.0046
  kl_divergence: -1665.1956
  ssim: 0.0718
  iou: 0.1412

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.44233, std: 0.13683

Metrics for layer 3:
  pearson_correlation: -0.0011
  kl_divergence: -1522.2023
  ssim: 0.0687
  iou: 0.1447
Layer 3 metrics:
  pearson_correlation: -0.0011
  kl_divergence: -1522.2023
  ssim: 0.0687
  iou: 0.1447

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.46190, std: 0.14922

Metrics for layer 4:
  pearson_correlation: 0.0219
  kl_divergence: -395.0162
  ssim: 0.0661
  iou: 0.1346
Layer 4 metrics:
  pearson_correlation: 0.0219
  kl_divergence: -395.0162
  ssim: 0.0661
  iou: 0.1346

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.43966, std: 0.14431

Metrics for layer 5:
  pearson_correlation: 0.0024
  kl_divergence: -366.5506
  ssim: 0.0579
  iou: 0.1462
Layer 5 metrics:
  pearson_correlation: 0.0024
  kl_divergence: -366.5506
  ssim: 0.0579
  iou: 0.1462

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.46110, std: 0.14703

Metrics for layer 6:
  pearson_correlation: -0.0146
  kl_divergence: -392.4298
  ssim: 0.0557
  iou: 0.1289
Layer 6 metrics:
  pearson_correlation: -0.0146
  kl_divergence: -392.4298
  ssim: 0.0557
  iou: 0.1289

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.48740, std: 0.16581

Metrics for layer 7:
  pearson_correlation: 0.0071
  kl_divergence: -87.5920
  ssim: 0.0388
  iou: 0.1429
Layer 7 metrics:
  pearson_correlation: 0.0071
  kl_divergence: -87.5920
  ssim: 0.0388
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.50830, std: 0.17427

Metrics for layer 8:
  pearson_correlation: 0.0446
  kl_divergence: -96.6094
  ssim: 0.0654
  iou: 0.1563
Layer 8 metrics:
  pearson_correlation: 0.0446
  kl_divergence: -96.6094
  ssim: 0.0654
  iou: 0.1563

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.44044, std: 0.15631

Metrics for layer 9:
  pearson_correlation: 0.0309
  kl_divergence: -78.9931
  ssim: 0.0609
  iou: 0.1105
Layer 9 metrics:
  pearson_correlation: 0.0309
  kl_divergence: -78.9931
  ssim: 0.0609
  iou: 0.1105

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.43691, std: 0.15664

Metrics for layer 10:
  pearson_correlation: -0.0662
  kl_divergence: -19.5460
  ssim: 0.0486
  iou: 0.1667
Layer 10 metrics:
  pearson_correlation: -0.0662
  kl_divergence: -19.5460
  ssim: 0.0486
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.42382, std: 0.18068

Metrics for layer 11:
  pearson_correlation: 0.0494
  kl_divergence: -12.0414
  ssim: 0.0521
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: 0.0494
  kl_divergence: -12.0414
  ssim: 0.0521
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.47740, std: 0.18834

Metrics for layer 12:
  pearson_correlation: 0.0294
  kl_divergence: -22.4260
  ssim: 0.0799
  iou: 0.1264
Layer 12 metrics:
  pearson_correlation: 0.0294
  kl_divergence: -22.4260
  ssim: 0.0799
  iou: 0.1264
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer1/batch_1_strength_0.8_results.npy

Processing attention strength 1.2
Attention vector: [0.  1.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.42580, std: 0.11776

Metrics for layer 0:
  pearson_correlation: -0.0004
  kl_divergence: -4715.9702
  ssim: 0.0528
  iou: 0.1421
Layer 0 metrics:
  pearson_correlation: -0.0004
  kl_divergence: -4715.9702
  ssim: 0.0528
  iou: 0.1421

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.49465, std: 0.11650

Metrics for layer 1:
  pearson_correlation: 0.0054
  kl_divergence: -5232.1680
  ssim: 0.0473
  iou: 0.1431
Layer 1 metrics:
  pearson_correlation: 0.0054
  kl_divergence: -5232.1680
  ssim: 0.0473
  iou: 0.1431

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.44070, std: 0.12689

Metrics for layer 2:
  pearson_correlation: 0.0056
  kl_divergence: -1443.2089
  ssim: 0.0662
  iou: 0.1496
Layer 2 metrics:
  pearson_correlation: 0.0056
  kl_divergence: -1443.2089
  ssim: 0.0662
  iou: 0.1496

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.44852, std: 0.13569

Metrics for layer 3:
  pearson_correlation: -0.0017
  kl_divergence: -1457.0190
  ssim: 0.0616
  iou: 0.1477
Layer 3 metrics:
  pearson_correlation: -0.0017
  kl_divergence: -1457.0190
  ssim: 0.0616
  iou: 0.1477

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.50044, std: 0.14911

Metrics for layer 4:
  pearson_correlation: -0.0049
  kl_divergence: -408.4257
  ssim: 0.0502
  iou: 0.1264
Layer 4 metrics:
  pearson_correlation: -0.0049
  kl_divergence: -408.4257
  ssim: 0.0502
  iou: 0.1264

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.49007, std: 0.15283

Metrics for layer 5:
  pearson_correlation: 0.0069
  kl_divergence: -398.6925
  ssim: 0.0603
  iou: 0.1412
Layer 5 metrics:
  pearson_correlation: 0.0069
  kl_divergence: -398.6925
  ssim: 0.0603
  iou: 0.1412

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.48736, std: 0.14083

Metrics for layer 6:
  pearson_correlation: 0.0289
  kl_divergence: -402.3777
  ssim: 0.0644
  iou: 0.1606
Layer 6 metrics:
  pearson_correlation: 0.0289
  kl_divergence: -402.3777
  ssim: 0.0644
  iou: 0.1606

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.49058, std: 0.14108

Metrics for layer 7:
  pearson_correlation: 0.0168
  kl_divergence: -100.2071
  ssim: 0.0766
  iou: 0.1667
Layer 7 metrics:
  pearson_correlation: 0.0168
  kl_divergence: -100.2071
  ssim: 0.0766
  iou: 0.1667

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.41996, std: 0.14495

Metrics for layer 8:
  pearson_correlation: -0.0016
  kl_divergence: -78.6690
  ssim: 0.0430
  iou: 0.1329
Layer 8 metrics:
  pearson_correlation: -0.0016
  kl_divergence: -78.6690
  ssim: 0.0430
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.44788, std: 0.15141

Metrics for layer 9:
  pearson_correlation: -0.0169
  kl_divergence: -84.0888
  ssim: 0.0587
  iou: 0.1200
Layer 9 metrics:
  pearson_correlation: -0.0169
  kl_divergence: -84.0888
  ssim: 0.0587
  iou: 0.1200

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.56639, std: 0.20938

Metrics for layer 10:
  pearson_correlation: -0.1170
  kl_divergence: -20.7580
  ssim: -0.0536
  iou: 0.0889
Layer 10 metrics:
  pearson_correlation: -0.1170
  kl_divergence: -20.7580
  ssim: -0.0536
  iou: 0.0889

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.44025, std: 0.18551

Metrics for layer 11:
  pearson_correlation: 0.0629
  kl_divergence: -15.6547
  ssim: 0.0481
  iou: 0.1667
Layer 11 metrics:
  pearson_correlation: 0.0629
  kl_divergence: -15.6547
  ssim: 0.0481
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.45814, std: 0.21071

Metrics for layer 12:
  pearson_correlation: 0.0661
  kl_divergence: -16.5670
  ssim: 0.1453
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: 0.0661
  kl_divergence: -16.5670
  ssim: 0.1453
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer1/batch_0_strength_1.2_results.npy

Processing batch 2/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.46097, std: 0.11274

Metrics for layer 0:
  pearson_correlation: -0.0043
  kl_divergence: -5816.8335
  ssim: 0.0652
  iou: 0.1434
Layer 0 metrics:
  pearson_correlation: -0.0043
  kl_divergence: -5816.8335
  ssim: 0.0652
  iou: 0.1434

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.49021, std: 0.12253

Metrics for layer 1:
  pearson_correlation: -0.0050
  kl_divergence: -6090.6802
  ssim: 0.0540
  iou: 0.1429
Layer 1 metrics:
  pearson_correlation: -0.0050
  kl_divergence: -6090.6802
  ssim: 0.0540
  iou: 0.1429

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.45988, std: 0.12331

Metrics for layer 2:
  pearson_correlation: -0.0093
  kl_divergence: -1611.0730
  ssim: 0.0724
  iou: 0.1393
Layer 2 metrics:
  pearson_correlation: -0.0093
  kl_divergence: -1611.0730
  ssim: 0.0724
  iou: 0.1393

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.45697, std: 0.11995

Metrics for layer 3:
  pearson_correlation: -0.0018
  kl_divergence: -1606.1594
  ssim: 0.0777
  iou: 0.1435
Layer 3 metrics:
  pearson_correlation: -0.0018
  kl_divergence: -1606.1594
  ssim: 0.0777
  iou: 0.1435

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.51926, std: 0.14998

Metrics for layer 4:
  pearson_correlation: -0.0074
  kl_divergence: -450.6590
  ssim: 0.0559
  iou: 0.1305
Layer 4 metrics:
  pearson_correlation: -0.0074
  kl_divergence: -450.6590
  ssim: 0.0559
  iou: 0.1305

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.46461, std: 0.14073

Metrics for layer 5:
  pearson_correlation: 0.0076
  kl_divergence: -400.7510
  ssim: 0.0724
  iou: 0.1437
Layer 5 metrics:
  pearson_correlation: 0.0076
  kl_divergence: -400.7510
  ssim: 0.0724
  iou: 0.1437

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.45884, std: 0.14744

Metrics for layer 6:
  pearson_correlation: 0.0038
  kl_divergence: -390.9926
  ssim: 0.0600
  iou: 0.1487
Layer 6 metrics:
  pearson_correlation: 0.0038
  kl_divergence: -390.9926
  ssim: 0.0600
  iou: 0.1487

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.55752, std: 0.14942

Metrics for layer 7:
  pearson_correlation: -0.0416
  kl_divergence: -107.8272
  ssim: 0.0560
  iou: 0.1563
Layer 7 metrics:
  pearson_correlation: -0.0416
  kl_divergence: -107.8272
  ssim: 0.0560
  iou: 0.1563

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.42976, std: 0.14438

Metrics for layer 8:
  pearson_correlation: -0.0101
  kl_divergence: -72.1775
  ssim: 0.0486
  iou: 0.1297
Layer 8 metrics:
  pearson_correlation: -0.0101
  kl_divergence: -72.1775
  ssim: 0.0486
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.52859, std: 0.14760

Metrics for layer 9:
  pearson_correlation: -0.0298
  kl_divergence: -105.4975
  ssim: 0.0229
  iou: 0.1701
Layer 9 metrics:
  pearson_correlation: -0.0298
  kl_divergence: -105.4975
  ssim: 0.0229
  iou: 0.1701

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.49233, std: 0.17133

Metrics for layer 10:
  pearson_correlation: -0.1076
  kl_divergence: -19.5633
  ssim: -0.0219
  iou: 0.0769
Layer 10 metrics:
  pearson_correlation: -0.1076
  kl_divergence: -19.5633
  ssim: -0.0219
  iou: 0.0769

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.47144, std: 0.18822

Metrics for layer 11:
  pearson_correlation: -0.0202
  kl_divergence: -17.8966
  ssim: 0.0220
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: -0.0202
  kl_divergence: -17.8966
  ssim: 0.0220
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.49031, std: 0.18903

Metrics for layer 12:
  pearson_correlation: 0.0083
  kl_divergence: -20.4111
  ssim: 0.0738
  iou: 0.1136
Layer 12 metrics:
  pearson_correlation: 0.0083
  kl_divergence: -20.4111
  ssim: 0.0738
  iou: 0.1136
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer1/batch_1_strength_1.2_results.npy

Analysis complete! Results saved to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer1
Completed experiment for category 13, layer 1
----------------------------------------
Running experiment for category 13, layer 2
===================================================
Starting experiment:
Category: 13
Layer: 2
Logs will be saved to: /scratch/hy2611/CNN_attention/logs/attention_analysis_20241216_104146/category13/layer2
===================================================
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-12-16 11:24:27.392243: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-16 11:24:27.423511: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2024-12-16 11:24:27.423919: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4016fc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:24:27.423934: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-16 11:24:27.426804: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-16 11:24:27.571444: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4015f60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:24:27.571464: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-12-16 11:24:27.571986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:2f:00.0
2024-12-16 11:24:27.573342: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:24:27.574459: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:24:27.575537: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:24:27.576591: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:24:27.577633: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:24:27.578697: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:24:27.579777: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:24:27.579790: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-12-16 11:24:27.579809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-16 11:24:27.579814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-16 11:24:27.579817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:61: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:87: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:15: sigmoid_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.sigmoid_cross_entropy instead. Note that the order of the predictions and labels arguments has been changed.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:322: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:82: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.


Verifying paths:
tc_path: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs exists
weight_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists
image_path: /scratch/hy2611/CNN_attention/Data/VGG16/images exists
save_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists

Initializing model...
('c11', [1, 224, 224, 64])
('c12', [1, 224, 224, 64])
('c21', [1, 112, 112, 128])
('c22', [1, 112, 112, 128])
('c31', [1, 56, 56, 256])
('c32', [1, 56, 56, 256])
('c33', [1, 56, 56, 256])
('c41', [1, 28, 28, 512])
('c42', [1, 28, 28, 512])
('c43', [1, 28, 28, 512])
('c51', [1, 14, 14, 512])
('c52', [1, 14, 14, 512])
('c53', [1, 14, 14, 512])
(0, 'conv1_1_W', (3, 3, 3, 64))
(1, 'conv1_1_b', (64,))
(2, 'conv1_2_W', (3, 3, 64, 64))
(3, 'conv1_2_b', (64,))
(4, 'conv2_1_W', (3, 3, 64, 128))
(5, 'conv2_1_b', (128,))
(6, 'conv2_2_W', (3, 3, 128, 128))
(7, 'conv2_2_b', (128,))
(8, 'conv3_1_W', (3, 3, 128, 256))
(9, 'conv3_1_b', (256,))
(10, 'conv3_2_W', (3, 3, 256, 256))
(11, 'conv3_2_b', (256,))
(12, 'conv3_3_W', (3, 3, 256, 256))
(13, 'conv3_3_b', (256,))
(14, 'conv4_1_W', (3, 3, 256, 512))
(15, 'conv4_1_b', (512,))
(16, 'conv4_2_W', (3, 3, 512, 512))
(17, 'conv4_2_b', (512,))
(18, 'conv4_3_W', (3, 3, 512, 512))
(19, 'conv4_3_b', (512,))
(20, 'conv5_1_W', (3, 3, 512, 512))
(21, 'conv5_1_b', (512,))
(22, 'conv5_2_W', (3, 3, 512, 512))
(23, 'conv5_2_b', (512,))
(24, 'conv5_3_W', (3, 3, 512, 512))
(25, 'conv5_3_b', (512,))
(26, 'fc6_W', (25088, 4096))
(27, 'fc6_b', (4096,))
(28, 'fc7_W', (4096, 4096))
(29, 'fc7_b', (4096,))
Checking checkpoint files:
Data file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_13.ckpt.data-00000-of-00001 - Found
Index file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_13.ckpt.index - Found
Loading checkpoint from: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_13.ckpt
Checkpoint loaded successfully

Initializing components...
Found tuning curves file: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs/featvecs20_train35_c.txt

Loading category 13 data...
Original positive images shape: (2, 224, 224, 3)

Processing data...

Processing attention strength 0.0
Attention vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

Processing batch 1/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.40553, std: 0.12657

Metrics for layer 0:
  pearson_correlation: -0.0090
  kl_divergence: -4505.9614
  ssim: 0.0480
  iou: 0.1428
Layer 0 metrics:
  pearson_correlation: -0.0090
  kl_divergence: -4505.9614
  ssim: 0.0480
  iou: 0.1428

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.42008, std: 0.12149

Metrics for layer 1:
  pearson_correlation: 0.0031
  kl_divergence: -4661.5830
  ssim: 0.0505
  iou: 0.1420
Layer 1 metrics:
  pearson_correlation: 0.0031
  kl_divergence: -4661.5830
  ssim: 0.0505
  iou: 0.1420

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.45277, std: 0.12237

Metrics for layer 2:
  pearson_correlation: -0.0134
  kl_divergence: -1479.3005
  ssim: 0.0651
  iou: 0.1356
Layer 2 metrics:
  pearson_correlation: -0.0134
  kl_divergence: -1479.3005
  ssim: 0.0651
  iou: 0.1356

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.45145, std: 0.13652

Metrics for layer 3:
  pearson_correlation: 0.0167
  kl_divergence: -1470.8278
  ssim: 0.0613
  iou: 0.1483
Layer 3 metrics:
  pearson_correlation: 0.0167
  kl_divergence: -1470.8278
  ssim: 0.0613
  iou: 0.1483

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.47363, std: 0.14754

Metrics for layer 4:
  pearson_correlation: 0.0317
  kl_divergence: -390.4789
  ssim: 0.0739
  iou: 0.1487
Layer 4 metrics:
  pearson_correlation: 0.0317
  kl_divergence: -390.4789
  ssim: 0.0739
  iou: 0.1487

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.51600, std: 0.15153

Metrics for layer 5:
  pearson_correlation: 0.0087
  kl_divergence: -421.9788
  ssim: 0.0505
  iou: 0.1512
Layer 5 metrics:
  pearson_correlation: 0.0087
  kl_divergence: -421.9788
  ssim: 0.0505
  iou: 0.1512

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.49036, std: 0.14389

Metrics for layer 6:
  pearson_correlation: 0.0169
  kl_divergence: -404.9390
  ssim: 0.0691
  iou: 0.1470
Layer 6 metrics:
  pearson_correlation: 0.0169
  kl_divergence: -404.9390
  ssim: 0.0691
  iou: 0.1470

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.52370, std: 0.15263

Metrics for layer 7:
  pearson_correlation: 0.0424
  kl_divergence: -102.1807
  ssim: 0.0698
  iou: 0.1462
Layer 7 metrics:
  pearson_correlation: 0.0424
  kl_divergence: -102.1807
  ssim: 0.0698
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.53411, std: 0.15956

Metrics for layer 8:
  pearson_correlation: 0.0332
  kl_divergence: -107.5147
  ssim: 0.0833
  iou: 0.1598
Layer 8 metrics:
  pearson_correlation: 0.0332
  kl_divergence: -107.5147
  ssim: 0.0833
  iou: 0.1598

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.44145, std: 0.15987

Metrics for layer 9:
  pearson_correlation: -0.0273
  kl_divergence: -85.0231
  ssim: 0.0364
  iou: 0.1563
Layer 9 metrics:
  pearson_correlation: -0.0273
  kl_divergence: -85.0231
  ssim: 0.0364
  iou: 0.1563

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.42187, std: 0.18147

Metrics for layer 10:
  pearson_correlation: 0.1125
  kl_divergence: -15.7735
  ssim: 0.1743
  iou: 0.2250
Layer 10 metrics:
  pearson_correlation: 0.1125
  kl_divergence: -15.7735
  ssim: 0.1743
  iou: 0.2250

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.48484, std: 0.17768

Metrics for layer 11:
  pearson_correlation: -0.0065
  kl_divergence: -19.5591
  ssim: -0.0049
  iou: 0.0889
Layer 11 metrics:
  pearson_correlation: -0.0065
  kl_divergence: -19.5591
  ssim: -0.0049
  iou: 0.0889

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.47859, std: 0.18725

Metrics for layer 12:
  pearson_correlation: 0.1326
  kl_divergence: -21.7523
  ssim: 0.1549
  iou: 0.2250
Layer 12 metrics:
  pearson_correlation: 0.1326
  kl_divergence: -21.7523
  ssim: 0.1549
  iou: 0.2250
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer2/batch_0_strength_0.0_results.npy

Processing batch 2/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.44693, std: 0.12718

Metrics for layer 0:
  pearson_correlation: 0.0041
  kl_divergence: -5617.9712
  ssim: 0.0609
  iou: 0.1457
Layer 0 metrics:
  pearson_correlation: 0.0041
  kl_divergence: -5617.9712
  ssim: 0.0609
  iou: 0.1457

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.44015, std: 0.11569

Metrics for layer 1:
  pearson_correlation: -0.0003
  kl_divergence: -5572.5337
  ssim: 0.0671
  iou: 0.1396
Layer 1 metrics:
  pearson_correlation: -0.0003
  kl_divergence: -5572.5337
  ssim: 0.0671
  iou: 0.1396

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.48644, std: 0.13189

Metrics for layer 2:
  pearson_correlation: 0.0093
  kl_divergence: -1704.5027
  ssim: 0.0652
  iou: 0.1454
Layer 2 metrics:
  pearson_correlation: 0.0093
  kl_divergence: -1704.5027
  ssim: 0.0652
  iou: 0.1454

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.47101, std: 0.12658

Metrics for layer 3:
  pearson_correlation: 0.0017
  kl_divergence: -1654.8579
  ssim: 0.0706
  iou: 0.1358
Layer 3 metrics:
  pearson_correlation: 0.0017
  kl_divergence: -1654.8579
  ssim: 0.0706
  iou: 0.1358

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.45000, std: 0.13835

Metrics for layer 4:
  pearson_correlation: 0.0219
  kl_divergence: -389.9452
  ssim: 0.0655
  iou: 0.1479
Layer 4 metrics:
  pearson_correlation: 0.0219
  kl_divergence: -389.9452
  ssim: 0.0655
  iou: 0.1479

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.46473, std: 0.12926

Metrics for layer 5:
  pearson_correlation: 0.0387
  kl_divergence: -408.9408
  ssim: 0.0755
  iou: 0.1420
Layer 5 metrics:
  pearson_correlation: 0.0387
  kl_divergence: -408.9408
  ssim: 0.0755
  iou: 0.1420

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.47149, std: 0.13961

Metrics for layer 6:
  pearson_correlation: -0.0054
  kl_divergence: -407.2434
  ssim: 0.0591
  iou: 0.1529
Layer 6 metrics:
  pearson_correlation: -0.0054
  kl_divergence: -407.2434
  ssim: 0.0591
  iou: 0.1529

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.54831, std: 0.15413

Metrics for layer 7:
  pearson_correlation: -0.0004
  kl_divergence: -111.3380
  ssim: 0.0468
  iou: 0.1362
Layer 7 metrics:
  pearson_correlation: -0.0004
  kl_divergence: -111.3380
  ssim: 0.0468
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.50295, std: 0.18641

Metrics for layer 8:
  pearson_correlation: -0.0365
  kl_divergence: -89.6304
  ssim: 0.0300
  iou: 0.1496
Layer 8 metrics:
  pearson_correlation: -0.0365
  kl_divergence: -89.6304
  ssim: 0.0300
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.45351, std: 0.17081

Metrics for layer 9:
  pearson_correlation: -0.0088
  kl_divergence: -77.2227
  ssim: 0.0722
  iou: 0.1496
Layer 9 metrics:
  pearson_correlation: -0.0088
  kl_divergence: -77.2227
  ssim: 0.0722
  iou: 0.1496

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.56525, std: 0.16962

Metrics for layer 10:
  pearson_correlation: -0.0523
  kl_divergence: -28.3605
  ssim: 0.0154
  iou: 0.1136
Layer 10 metrics:
  pearson_correlation: -0.0523
  kl_divergence: -28.3605
  ssim: 0.0154
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.47184, std: 0.17595

Metrics for layer 11:
  pearson_correlation: -0.0017
  kl_divergence: -21.7507
  ssim: 0.0309
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: -0.0017
  kl_divergence: -21.7507
  ssim: 0.0309
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.46074, std: 0.19839

Metrics for layer 12:
  pearson_correlation: -0.1104
  kl_divergence: -15.5967
  ssim: -0.0052
  iou: 0.0769
Layer 12 metrics:
  pearson_correlation: -0.1104
  kl_divergence: -15.5967
  ssim: -0.0052
  iou: 0.0769
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer2/batch_1_strength_0.0_results.npy

Processing attention strength 0.4
Attention vector: [0.  0.  0.4 0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.41280, std: 0.12361

Metrics for layer 0:
  pearson_correlation: 0.0019
  kl_divergence: -4589.9766
  ssim: 0.0510
  iou: 0.1434
Layer 0 metrics:
  pearson_correlation: 0.0019
  kl_divergence: -4589.9766
  ssim: 0.0510
  iou: 0.1434

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.42575, std: 0.11559

Metrics for layer 1:
  pearson_correlation: 0.0033
  kl_divergence: -4725.7661
  ssim: 0.0547
  iou: 0.1430
Layer 1 metrics:
  pearson_correlation: 0.0033
  kl_divergence: -4725.7661
  ssim: 0.0547
  iou: 0.1430

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.48979, std: 0.13788

Metrics for layer 2:
  pearson_correlation: -0.0064
  kl_divergence: -1570.7755
  ssim: 0.0534
  iou: 0.1414
Layer 2 metrics:
  pearson_correlation: -0.0064
  kl_divergence: -1570.7755
  ssim: 0.0534
  iou: 0.1414

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.45095, std: 0.13340

Metrics for layer 3:
  pearson_correlation: -0.0005
  kl_divergence: -1462.9694
  ssim: 0.0590
  iou: 0.1445
Layer 3 metrics:
  pearson_correlation: -0.0005
  kl_divergence: -1462.9694
  ssim: 0.0590
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.47828, std: 0.13501

Metrics for layer 4:
  pearson_correlation: -0.0056
  kl_divergence: -397.1263
  ssim: 0.0572
  iou: 0.1412
Layer 4 metrics:
  pearson_correlation: -0.0056
  kl_divergence: -397.1263
  ssim: 0.0572
  iou: 0.1412

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.53081, std: 0.15504

Metrics for layer 5:
  pearson_correlation: -0.0019
  kl_divergence: -432.0726
  ssim: 0.0469
  iou: 0.1354
Layer 5 metrics:
  pearson_correlation: -0.0019
  kl_divergence: -432.0726
  ssim: 0.0469
  iou: 0.1354

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.43615, std: 0.15012

Metrics for layer 6:
  pearson_correlation: 0.0207
  kl_divergence: -352.1193
  ssim: 0.0688
  iou: 0.1529
Layer 6 metrics:
  pearson_correlation: 0.0207
  kl_divergence: -352.1193
  ssim: 0.0688
  iou: 0.1529

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.49606, std: 0.15301

Metrics for layer 7:
  pearson_correlation: 0.0117
  kl_divergence: -97.4863
  ssim: 0.0608
  iou: 0.1297
Layer 7 metrics:
  pearson_correlation: 0.0117
  kl_divergence: -97.4863
  ssim: 0.0608
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.47296, std: 0.15784

Metrics for layer 8:
  pearson_correlation: 0.0352
  kl_divergence: -93.3532
  ssim: 0.0786
  iou: 0.1462
Layer 8 metrics:
  pearson_correlation: 0.0352
  kl_divergence: -93.3532
  ssim: 0.0786
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.44030, std: 0.15303

Metrics for layer 9:
  pearson_correlation: 0.0142
  kl_divergence: -86.2334
  ssim: 0.0621
  iou: 0.1737
Layer 9 metrics:
  pearson_correlation: 0.0142
  kl_divergence: -86.2334
  ssim: 0.0621
  iou: 0.1737

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.42013, std: 0.18232

Metrics for layer 10:
  pearson_correlation: -0.0974
  kl_divergence: -7.1022
  ssim: -0.0731
  iou: 0.1667
Layer 10 metrics:
  pearson_correlation: -0.0974
  kl_divergence: -7.1022
  ssim: -0.0731
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.49184, std: 0.18315

Metrics for layer 11:
  pearson_correlation: 0.0023
  kl_divergence: -20.7769
  ssim: 0.0675
  iou: 0.0889
Layer 11 metrics:
  pearson_correlation: 0.0023
  kl_divergence: -20.7769
  ssim: 0.0675
  iou: 0.0889

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.50323, std: 0.21306

Metrics for layer 12:
  pearson_correlation: 0.0443
  kl_divergence: -18.3010
  ssim: 0.0473
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: 0.0443
  kl_divergence: -18.3010
  ssim: 0.0473
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer2/batch_0_strength_0.4_results.npy

Processing batch 2/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.46524, std: 0.11950

Metrics for layer 0:
  pearson_correlation: -0.0006
  kl_divergence: -5847.9995
  ssim: 0.0618
  iou: 0.1440
Layer 0 metrics:
  pearson_correlation: -0.0006
  kl_divergence: -5847.9995
  ssim: 0.0618
  iou: 0.1440

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.42994, std: 0.12709

Metrics for layer 1:
  pearson_correlation: 0.0018
  kl_divergence: -5415.1816
  ssim: 0.0624
  iou: 0.1428
Layer 1 metrics:
  pearson_correlation: 0.0018
  kl_divergence: -5415.1816
  ssim: 0.0624
  iou: 0.1428

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.51818, std: 0.13051

Metrics for layer 2:
  pearson_correlation: 0.0058
  kl_divergence: -1812.6658
  ssim: 0.0631
  iou: 0.1479
Layer 2 metrics:
  pearson_correlation: 0.0058
  kl_divergence: -1812.6658
  ssim: 0.0631
  iou: 0.1479

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.45329, std: 0.12704

Metrics for layer 3:
  pearson_correlation: -0.0011
  kl_divergence: -1581.4751
  ssim: 0.0711
  iou: 0.1443
Layer 3 metrics:
  pearson_correlation: -0.0011
  kl_divergence: -1581.4751
  ssim: 0.0711
  iou: 0.1443

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.49895, std: 0.15182

Metrics for layer 4:
  pearson_correlation: -0.0326
  kl_divergence: -427.7401
  ssim: 0.0481
  iou: 0.1232
Layer 4 metrics:
  pearson_correlation: -0.0326
  kl_divergence: -427.7401
  ssim: 0.0481
  iou: 0.1232

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.42239, std: 0.14819

Metrics for layer 5:
  pearson_correlation: 0.0096
  kl_divergence: -346.4182
  ssim: 0.0723
  iou: 0.1429
Layer 5 metrics:
  pearson_correlation: 0.0096
  kl_divergence: -346.4182
  ssim: 0.0723
  iou: 0.1429

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.44471, std: 0.15265

Metrics for layer 6:
  pearson_correlation: 0.0069
  kl_divergence: -371.1013
  ssim: 0.0560
  iou: 0.1445
Layer 6 metrics:
  pearson_correlation: 0.0069
  kl_divergence: -371.1013
  ssim: 0.0560
  iou: 0.1445

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.44340, std: 0.16472

Metrics for layer 7:
  pearson_correlation: -0.0111
  kl_divergence: -74.0862
  ssim: 0.0679
  iou: 0.1264
Layer 7 metrics:
  pearson_correlation: -0.0111
  kl_divergence: -74.0862
  ssim: 0.0679
  iou: 0.1264

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.45821, std: 0.15991

Metrics for layer 8:
  pearson_correlation: 0.0056
  kl_divergence: -82.3774
  ssim: 0.0507
  iou: 0.1395
Layer 8 metrics:
  pearson_correlation: 0.0056
  kl_divergence: -82.3774
  ssim: 0.0507
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.45069, std: 0.15388

Metrics for layer 9:
  pearson_correlation: -0.0191
  kl_divergence: -77.6292
  ssim: 0.0590
  iou: 0.1136
Layer 9 metrics:
  pearson_correlation: -0.0191
  kl_divergence: -77.6292
  ssim: 0.0590
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.39566, std: 0.16021

Metrics for layer 10:
  pearson_correlation: -0.0104
  kl_divergence: -8.9599
  ssim: 0.0964
  iou: 0.1807
Layer 10 metrics:
  pearson_correlation: -0.0104
  kl_divergence: -8.9599
  ssim: 0.0964
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.48933, std: 0.19097

Metrics for layer 11:
  pearson_correlation: 0.0187
  kl_divergence: -13.1215
  ssim: 0.0311
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: 0.0187
  kl_divergence: -13.1215
  ssim: 0.0311
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.49666, std: 0.17231

Metrics for layer 12:
  pearson_correlation: -0.0274
  kl_divergence: -22.5957
  ssim: 0.0226
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: -0.0274
  kl_divergence: -22.5957
  ssim: 0.0226
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer2/batch_1_strength_0.4_results.npy

Processing attention strength 0.8
Attention vector: [0.  0.  0.8 0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.41539, std: 0.12014

Metrics for layer 0:
  pearson_correlation: -0.0011
  kl_divergence: -4616.4580
  ssim: 0.0541
  iou: 0.1376
Layer 0 metrics:
  pearson_correlation: -0.0011
  kl_divergence: -4616.4580
  ssim: 0.0541
  iou: 0.1376

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.42745, std: 0.12346

Metrics for layer 1:
  pearson_correlation: 0.0078
  kl_divergence: -4719.0020
  ssim: 0.0507
  iou: 0.1442
Layer 1 metrics:
  pearson_correlation: 0.0078
  kl_divergence: -4719.0020
  ssim: 0.0507
  iou: 0.1442

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.48376, std: 0.11539

Metrics for layer 2:
  pearson_correlation: 0.0037
  kl_divergence: -1578.2396
  ssim: 0.0698
  iou: 0.1429
Layer 2 metrics:
  pearson_correlation: 0.0037
  kl_divergence: -1578.2396
  ssim: 0.0698
  iou: 0.1429

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.42464, std: 0.12199

Metrics for layer 3:
  pearson_correlation: -0.0018
  kl_divergence: -1395.8696
  ssim: 0.0699
  iou: 0.1493
Layer 3 metrics:
  pearson_correlation: -0.0018
  kl_divergence: -1395.8696
  ssim: 0.0699
  iou: 0.1493

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.47675, std: 0.14641

Metrics for layer 4:
  pearson_correlation: 0.0326
  kl_divergence: -394.3150
  ssim: 0.0628
  iou: 0.1379
Layer 4 metrics:
  pearson_correlation: 0.0326
  kl_divergence: -394.3150
  ssim: 0.0628
  iou: 0.1379

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.51172, std: 0.14625

Metrics for layer 5:
  pearson_correlation: -0.0013
  kl_divergence: -414.2975
  ssim: 0.0419
  iou: 0.1354
Layer 5 metrics:
  pearson_correlation: -0.0013
  kl_divergence: -414.2975
  ssim: 0.0419
  iou: 0.1354

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.45355, std: 0.13743

Metrics for layer 6:
  pearson_correlation: 0.0004
  kl_divergence: -375.5622
  ssim: 0.0615
  iou: 0.1512
Layer 6 metrics:
  pearson_correlation: 0.0004
  kl_divergence: -375.5622
  ssim: 0.0615
  iou: 0.1512

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.48860, std: 0.14746

Metrics for layer 7:
  pearson_correlation: 0.0096
  kl_divergence: -98.2366
  ssim: 0.0564
  iou: 0.1462
Layer 7 metrics:
  pearson_correlation: 0.0096
  kl_divergence: -98.2366
  ssim: 0.0564
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.51485, std: 0.14925

Metrics for layer 8:
  pearson_correlation: -0.0223
  kl_divergence: -99.5757
  ssim: 0.0480
  iou: 0.1264
Layer 8 metrics:
  pearson_correlation: -0.0223
  kl_divergence: -99.5757
  ssim: 0.0480
  iou: 0.1264

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.50238, std: 0.16358

Metrics for layer 9:
  pearson_correlation: 0.0727
  kl_divergence: -101.9580
  ssim: 0.0640
  iou: 0.1772
Layer 9 metrics:
  pearson_correlation: 0.0727
  kl_divergence: -101.9580
  ssim: 0.0640
  iou: 0.1772

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.52521, std: 0.21190

Metrics for layer 10:
  pearson_correlation: -0.0374
  kl_divergence: -17.9369
  ssim: -0.0314
  iou: 0.1264
Layer 10 metrics:
  pearson_correlation: -0.0374
  kl_divergence: -17.9369
  ssim: -0.0314
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.52143, std: 0.18453

Metrics for layer 11:
  pearson_correlation: 0.0230
  kl_divergence: -17.5816
  ssim: 0.0868
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: 0.0230
  kl_divergence: -17.5816
  ssim: 0.0868
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.49810, std: 0.18532

Metrics for layer 12:
  pearson_correlation: 0.0511
  kl_divergence: -20.2529
  ssim: 0.1645
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: 0.0511
  kl_divergence: -20.2529
  ssim: 0.1645
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer2/batch_0_strength_0.8_results.npy

Processing batch 2/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.44007, std: 0.12664

Metrics for layer 0:
  pearson_correlation: 0.0051
  kl_divergence: -5538.3921
  ssim: 0.0603
  iou: 0.1441
Layer 0 metrics:
  pearson_correlation: 0.0051
  kl_divergence: -5538.3921
  ssim: 0.0603
  iou: 0.1441

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.42232, std: 0.12519

Metrics for layer 1:
  pearson_correlation: -0.0019
  kl_divergence: -5324.3071
  ssim: 0.0623
  iou: 0.1413
Layer 1 metrics:
  pearson_correlation: -0.0019
  kl_divergence: -5324.3071
  ssim: 0.0623
  iou: 0.1413

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.53428, std: 0.12375

Metrics for layer 2:
  pearson_correlation: -0.0053
  kl_divergence: -1869.4847
  ssim: 0.0629
  iou: 0.1404
Layer 2 metrics:
  pearson_correlation: -0.0053
  kl_divergence: -1869.4847
  ssim: 0.0629
  iou: 0.1404

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.46545, std: 0.12604

Metrics for layer 3:
  pearson_correlation: 0.0067
  kl_divergence: -1629.0566
  ssim: 0.0724
  iou: 0.1485
Layer 3 metrics:
  pearson_correlation: 0.0067
  kl_divergence: -1629.0566
  ssim: 0.0724
  iou: 0.1485

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.44707, std: 0.13589

Metrics for layer 4:
  pearson_correlation: 0.0010
  kl_divergence: -383.8073
  ssim: 0.0685
  iou: 0.1338
Layer 4 metrics:
  pearson_correlation: 0.0010
  kl_divergence: -383.8073
  ssim: 0.0685
  iou: 0.1338

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.44823, std: 0.14072

Metrics for layer 5:
  pearson_correlation: -0.0036
  kl_divergence: -382.4647
  ssim: 0.0575
  iou: 0.1329
Layer 5 metrics:
  pearson_correlation: -0.0036
  kl_divergence: -382.4647
  ssim: 0.0575
  iou: 0.1329

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.45239, std: 0.12934

Metrics for layer 6:
  pearson_correlation: -0.0340
  kl_divergence: -389.9616
  ssim: 0.0627
  iou: 0.1248
Layer 6 metrics:
  pearson_correlation: -0.0340
  kl_divergence: -389.9616
  ssim: 0.0627
  iou: 0.1248

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.50102, std: 0.14550

Metrics for layer 7:
  pearson_correlation: 0.0072
  kl_divergence: -89.4827
  ssim: 0.0616
  iou: 0.1329
Layer 7 metrics:
  pearson_correlation: 0.0072
  kl_divergence: -89.4827
  ssim: 0.0616
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.48798, std: 0.17250

Metrics for layer 8:
  pearson_correlation: 0.0326
  kl_divergence: -90.1358
  ssim: 0.0628
  iou: 0.1563
Layer 8 metrics:
  pearson_correlation: 0.0326
  kl_divergence: -90.1358
  ssim: 0.0628
  iou: 0.1563

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.50409, std: 0.16444

Metrics for layer 9:
  pearson_correlation: 0.0015
  kl_divergence: -98.1795
  ssim: 0.0795
  iou: 0.1496
Layer 9 metrics:
  pearson_correlation: 0.0015
  kl_divergence: -98.1795
  ssim: 0.0795
  iou: 0.1496

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.44213, std: 0.19885

Metrics for layer 10:
  pearson_correlation: 0.0183
  kl_divergence: -16.5972
  ssim: 0.0877
  iou: 0.1667
Layer 10 metrics:
  pearson_correlation: 0.0183
  kl_divergence: -16.5972
  ssim: 0.0877
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.47889, std: 0.16964

Metrics for layer 11:
  pearson_correlation: -0.1147
  kl_divergence: -18.9946
  ssim: 0.0230
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: -0.1147
  kl_divergence: -18.9946
  ssim: 0.0230
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.53805, std: 0.22762

Metrics for layer 12:
  pearson_correlation: -0.0017
  kl_divergence: -24.0676
  ssim: 0.0481
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: -0.0017
  kl_divergence: -24.0676
  ssim: 0.0481
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer2/batch_1_strength_0.8_results.npy

Processing attention strength 1.2
Attention vector: [0.  0.  1.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.46491, std: 0.11695

Metrics for layer 0:
  pearson_correlation: 0.0017
  kl_divergence: -5022.7461
  ssim: 0.0483
  iou: 0.1441
Layer 0 metrics:
  pearson_correlation: 0.0017
  kl_divergence: -5022.7461
  ssim: 0.0483
  iou: 0.1441

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.45805, std: 0.11878

Metrics for layer 1:
  pearson_correlation: -0.0033
  kl_divergence: -4959.0093
  ssim: 0.0471
  iou: 0.1425
Layer 1 metrics:
  pearson_correlation: -0.0033
  kl_divergence: -4959.0093
  ssim: 0.0471
  iou: 0.1425

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.51560, std: 0.12975

Metrics for layer 2:
  pearson_correlation: 0.0081
  kl_divergence: -1653.0405
  ssim: 0.0583
  iou: 0.1470
Layer 2 metrics:
  pearson_correlation: 0.0081
  kl_divergence: -1653.0405
  ssim: 0.0583
  iou: 0.1470

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.46326, std: 0.12616

Metrics for layer 3:
  pearson_correlation: -0.0164
  kl_divergence: -1508.6062
  ssim: 0.0560
  iou: 0.1364
Layer 3 metrics:
  pearson_correlation: -0.0164
  kl_divergence: -1508.6062
  ssim: 0.0560
  iou: 0.1364

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.54537, std: 0.14114

Metrics for layer 4:
  pearson_correlation: 0.0035
  kl_divergence: -448.7126
  ssim: 0.0494
  iou: 0.1412
Layer 4 metrics:
  pearson_correlation: 0.0035
  kl_divergence: -448.7126
  ssim: 0.0494
  iou: 0.1412

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.47026, std: 0.16201

Metrics for layer 5:
  pearson_correlation: -0.0012
  kl_divergence: -370.4474
  ssim: 0.0516
  iou: 0.1429
Layer 5 metrics:
  pearson_correlation: -0.0012
  kl_divergence: -370.4474
  ssim: 0.0516
  iou: 0.1429

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.53117, std: 0.14084

Metrics for layer 6:
  pearson_correlation: -0.0156
  kl_divergence: -435.6082
  ssim: 0.0525
  iou: 0.1546
Layer 6 metrics:
  pearson_correlation: -0.0156
  kl_divergence: -435.6082
  ssim: 0.0525
  iou: 0.1546

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.50680, std: 0.15742

Metrics for layer 7:
  pearson_correlation: -0.0084
  kl_divergence: -99.5761
  ssim: 0.0222
  iou: 0.1395
Layer 7 metrics:
  pearson_correlation: -0.0084
  kl_divergence: -99.5761
  ssim: 0.0222
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.45204, std: 0.16746

Metrics for layer 8:
  pearson_correlation: 0.0171
  kl_divergence: -87.1534
  ssim: 0.0510
  iou: 0.1632
Layer 8 metrics:
  pearson_correlation: 0.0171
  kl_divergence: -87.1534
  ssim: 0.0510
  iou: 0.1632

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.47225, std: 0.15154

Metrics for layer 9:
  pearson_correlation: 0.0252
  kl_divergence: -94.9962
  ssim: 0.0792
  iou: 0.1529
Layer 9 metrics:
  pearson_correlation: 0.0252
  kl_divergence: -94.9962
  ssim: 0.0792
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.39514, std: 0.15641

Metrics for layer 10:
  pearson_correlation: -0.0580
  kl_divergence: -11.6553
  ssim: -0.0017
  iou: 0.1395
Layer 10 metrics:
  pearson_correlation: -0.0580
  kl_divergence: -11.6553
  ssim: -0.0017
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.56048, std: 0.18475

Metrics for layer 11:
  pearson_correlation: -0.0403
  kl_divergence: -23.7122
  ssim: 0.0224
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: -0.0403
  kl_divergence: -23.7122
  ssim: 0.0224
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.47003, std: 0.16331

Metrics for layer 12:
  pearson_correlation: 0.0652
  kl_divergence: -18.3823
  ssim: 0.0938
  iou: 0.1264
Layer 12 metrics:
  pearson_correlation: 0.0652
  kl_divergence: -18.3823
  ssim: 0.0938
  iou: 0.1264
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer2/batch_0_strength_1.2_results.npy

Processing batch 2/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.43499, std: 0.12667

Metrics for layer 0:
  pearson_correlation: -0.0020
  kl_divergence: -5473.4238
  ssim: 0.0584
  iou: 0.1427
Layer 0 metrics:
  pearson_correlation: -0.0020
  kl_divergence: -5473.4238
  ssim: 0.0584
  iou: 0.1427

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.45844, std: 0.12539

Metrics for layer 1:
  pearson_correlation: -0.0019
  kl_divergence: -5754.7690
  ssim: 0.0567
  iou: 0.1416
Layer 1 metrics:
  pearson_correlation: -0.0019
  kl_divergence: -5754.7690
  ssim: 0.0567
  iou: 0.1416

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.52034, std: 0.12721

Metrics for layer 2:
  pearson_correlation: 0.0003
  kl_divergence: -1822.2625
  ssim: 0.0682
  iou: 0.1435
Layer 2 metrics:
  pearson_correlation: 0.0003
  kl_divergence: -1822.2625
  ssim: 0.0682
  iou: 0.1435

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.46508, std: 0.12940

Metrics for layer 3:
  pearson_correlation: 0.0198
  kl_divergence: -1635.4590
  ssim: 0.0730
  iou: 0.1431
Layer 3 metrics:
  pearson_correlation: 0.0198
  kl_divergence: -1635.4590
  ssim: 0.0730
  iou: 0.1431

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.47757, std: 0.16134

Metrics for layer 4:
  pearson_correlation: 0.0203
  kl_divergence: -407.9443
  ssim: 0.0577
  iou: 0.1572
Layer 4 metrics:
  pearson_correlation: 0.0203
  kl_divergence: -407.9443
  ssim: 0.0577
  iou: 0.1572

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.45511, std: 0.15097

Metrics for layer 5:
  pearson_correlation: -0.0145
  kl_divergence: -384.2756
  ssim: 0.0543
  iou: 0.1297
Layer 5 metrics:
  pearson_correlation: -0.0145
  kl_divergence: -384.2756
  ssim: 0.0543
  iou: 0.1297

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.47262, std: 0.14013

Metrics for layer 6:
  pearson_correlation: 0.0139
  kl_divergence: -410.4532
  ssim: 0.0744
  iou: 0.1487
Layer 6 metrics:
  pearson_correlation: 0.0139
  kl_divergence: -410.4532
  ssim: 0.0744
  iou: 0.1487

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.46513, std: 0.15921

Metrics for layer 7:
  pearson_correlation: 0.0004
  kl_divergence: -82.8221
  ssim: 0.0565
  iou: 0.1329
Layer 7 metrics:
  pearson_correlation: 0.0004
  kl_divergence: -82.8221
  ssim: 0.0565
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.44664, std: 0.14777

Metrics for layer 8:
  pearson_correlation: -0.0399
  kl_divergence: -77.2449
  ssim: 0.0324
  iou: 0.1200
Layer 8 metrics:
  pearson_correlation: -0.0399
  kl_divergence: -77.2449
  ssim: 0.0324
  iou: 0.1200

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.49725, std: 0.15788

Metrics for layer 9:
  pearson_correlation: -0.0062
  kl_divergence: -96.3360
  ssim: 0.0498
  iou: 0.1297
Layer 9 metrics:
  pearson_correlation: -0.0062
  kl_divergence: -96.3360
  ssim: 0.0498
  iou: 0.1297

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.47681, std: 0.17206

Metrics for layer 10:
  pearson_correlation: 0.0152
  kl_divergence: -19.6339
  ssim: 0.0456
  iou: 0.1951
Layer 10 metrics:
  pearson_correlation: 0.0152
  kl_divergence: -19.6339
  ssim: 0.0456
  iou: 0.1951

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.51959, std: 0.16708

Metrics for layer 11:
  pearson_correlation: -0.0490
  kl_divergence: -24.6123
  ssim: 0.0459
  iou: 0.1807
Layer 11 metrics:
  pearson_correlation: -0.0490
  kl_divergence: -24.6123
  ssim: 0.0459
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.46515, std: 0.17927

Metrics for layer 12:
  pearson_correlation: 0.0271
  kl_divergence: -20.1136
  ssim: 0.0880
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: 0.0271
  kl_divergence: -20.1136
  ssim: 0.0880
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer2/batch_1_strength_1.2_results.npy

Analysis complete! Results saved to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer2
Completed experiment for category 13, layer 2
----------------------------------------
Running experiment for category 13, layer 3
===================================================
Starting experiment:
Category: 13
Layer: 3
Logs will be saved to: /scratch/hy2611/CNN_attention/logs/attention_analysis_20241216_104146/category13/layer3
===================================================
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-12-16 11:27:12.301877: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-16 11:27:12.320514: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2024-12-16 11:27:12.320978: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4dd0d90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:27:12.320993: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-16 11:27:12.323955: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-16 11:27:12.465558: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4dcb1c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:27:12.465576: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-12-16 11:27:12.466104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:2f:00.0
2024-12-16 11:27:12.467349: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:27:12.468338: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:27:12.469280: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:27:12.470224: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:27:12.471167: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:27:12.472115: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:27:12.473042: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:27:12.473054: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-12-16 11:27:12.473073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-16 11:27:12.473077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-16 11:27:12.473080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:61: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:87: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:15: sigmoid_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.sigmoid_cross_entropy instead. Note that the order of the predictions and labels arguments has been changed.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:322: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:82: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.


Verifying paths:
tc_path: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs exists
weight_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists
image_path: /scratch/hy2611/CNN_attention/Data/VGG16/images exists
save_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists

Initializing model...
('c11', [1, 224, 224, 64])
('c12', [1, 224, 224, 64])
('c21', [1, 112, 112, 128])
('c22', [1, 112, 112, 128])
('c31', [1, 56, 56, 256])
('c32', [1, 56, 56, 256])
('c33', [1, 56, 56, 256])
('c41', [1, 28, 28, 512])
('c42', [1, 28, 28, 512])
('c43', [1, 28, 28, 512])
('c51', [1, 14, 14, 512])
('c52', [1, 14, 14, 512])
('c53', [1, 14, 14, 512])
(0, 'conv1_1_W', (3, 3, 3, 64))
(1, 'conv1_1_b', (64,))
(2, 'conv1_2_W', (3, 3, 64, 64))
(3, 'conv1_2_b', (64,))
(4, 'conv2_1_W', (3, 3, 64, 128))
(5, 'conv2_1_b', (128,))
(6, 'conv2_2_W', (3, 3, 128, 128))
(7, 'conv2_2_b', (128,))
(8, 'conv3_1_W', (3, 3, 128, 256))
(9, 'conv3_1_b', (256,))
(10, 'conv3_2_W', (3, 3, 256, 256))
(11, 'conv3_2_b', (256,))
(12, 'conv3_3_W', (3, 3, 256, 256))
(13, 'conv3_3_b', (256,))
(14, 'conv4_1_W', (3, 3, 256, 512))
(15, 'conv4_1_b', (512,))
(16, 'conv4_2_W', (3, 3, 512, 512))
(17, 'conv4_2_b', (512,))
(18, 'conv4_3_W', (3, 3, 512, 512))
(19, 'conv4_3_b', (512,))
(20, 'conv5_1_W', (3, 3, 512, 512))
(21, 'conv5_1_b', (512,))
(22, 'conv5_2_W', (3, 3, 512, 512))
(23, 'conv5_2_b', (512,))
(24, 'conv5_3_W', (3, 3, 512, 512))
(25, 'conv5_3_b', (512,))
(26, 'fc6_W', (25088, 4096))
(27, 'fc6_b', (4096,))
(28, 'fc7_W', (4096, 4096))
(29, 'fc7_b', (4096,))
Checking checkpoint files:
Data file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_13.ckpt.data-00000-of-00001 - Found
Index file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_13.ckpt.index - Found
Loading checkpoint from: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_13.ckpt
Checkpoint loaded successfully

Initializing components...
Found tuning curves file: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs/featvecs20_train35_c.txt

Loading category 13 data...
Original positive images shape: (2, 224, 224, 3)

Processing data...

Processing attention strength 0.0
Attention vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

Processing batch 1/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.45047, std: 0.13159

Metrics for layer 0:
  pearson_correlation: -0.0042
  kl_divergence: -4872.6484
  ssim: 0.0421
  iou: 0.1410
Layer 0 metrics:
  pearson_correlation: -0.0042
  kl_divergence: -4872.6484
  ssim: 0.0421
  iou: 0.1410

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.40722, std: 0.12142

Metrics for layer 1:
  pearson_correlation: -0.0058
  kl_divergence: -4542.5903
  ssim: 0.0517
  iou: 0.1367
Layer 1 metrics:
  pearson_correlation: -0.0058
  kl_divergence: -4542.5903
  ssim: 0.0517
  iou: 0.1367

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.49870, std: 0.13890

Metrics for layer 2:
  pearson_correlation: -0.0155
  kl_divergence: -1594.5461
  ssim: 0.0491
  iou: 0.1332
Layer 2 metrics:
  pearson_correlation: -0.0155
  kl_divergence: -1594.5461
  ssim: 0.0491
  iou: 0.1332

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.44729, std: 0.13038

Metrics for layer 3:
  pearson_correlation: -0.0071
  kl_divergence: -1456.7982
  ssim: 0.0604
  iou: 0.1420
Layer 3 metrics:
  pearson_correlation: -0.0071
  kl_divergence: -1456.7982
  ssim: 0.0604
  iou: 0.1420

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.43717, std: 0.13177

Metrics for layer 4:
  pearson_correlation: -0.0003
  kl_divergence: -354.9752
  ssim: 0.0790
  iou: 0.1248
Layer 4 metrics:
  pearson_correlation: -0.0003
  kl_divergence: -354.9752
  ssim: 0.0790
  iou: 0.1248

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.47396, std: 0.15527

Metrics for layer 5:
  pearson_correlation: 0.0065
  kl_divergence: -388.0604
  ssim: 0.0561
  iou: 0.1454
Layer 5 metrics:
  pearson_correlation: 0.0065
  kl_divergence: -388.0604
  ssim: 0.0561
  iou: 0.1454

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.47676, std: 0.14948

Metrics for layer 6:
  pearson_correlation: 0.0124
  kl_divergence: -392.0480
  ssim: 0.0506
  iou: 0.1504
Layer 6 metrics:
  pearson_correlation: 0.0124
  kl_divergence: -392.0480
  ssim: 0.0506
  iou: 0.1504

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.46476, std: 0.15935

Metrics for layer 7:
  pearson_correlation: 0.0173
  kl_divergence: -86.2632
  ssim: 0.0693
  iou: 0.1329
Layer 7 metrics:
  pearson_correlation: 0.0173
  kl_divergence: -86.2632
  ssim: 0.0693
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.48726, std: 0.15737

Metrics for layer 8:
  pearson_correlation: -0.0115
  kl_divergence: -92.9776
  ssim: 0.0363
  iou: 0.1362
Layer 8 metrics:
  pearson_correlation: -0.0115
  kl_divergence: -92.9776
  ssim: 0.0363
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.50836, std: 0.16264

Metrics for layer 9:
  pearson_correlation: 0.0348
  kl_divergence: -101.5533
  ssim: 0.0683
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: 0.0348
  kl_divergence: -101.5533
  ssim: 0.0683
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.48038, std: 0.16443

Metrics for layer 10:
  pearson_correlation: 0.0485
  kl_divergence: -18.6954
  ssim: 0.0450
  iou: 0.1011
Layer 10 metrics:
  pearson_correlation: 0.0485
  kl_divergence: -18.6954
  ssim: 0.0450
  iou: 0.1011

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.48068, std: 0.19089

Metrics for layer 11:
  pearson_correlation: 0.0867
  kl_divergence: -19.4603
  ssim: 0.0564
  iou: 0.1951
Layer 11 metrics:
  pearson_correlation: 0.0867
  kl_divergence: -19.4603
  ssim: 0.0564
  iou: 0.1951

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.48819, std: 0.17187

Metrics for layer 12:
  pearson_correlation: -0.1200
  kl_divergence: -16.6162
  ssim: 0.0045
  iou: 0.0769
Layer 12 metrics:
  pearson_correlation: -0.1200
  kl_divergence: -16.6162
  ssim: 0.0045
  iou: 0.0769
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer3/batch_0_strength_0.0_results.npy

Processing batch 2/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.41397, std: 0.11532

Metrics for layer 0:
  pearson_correlation: 0.0060
  kl_divergence: -5270.1470
  ssim: 0.0732
  iou: 0.1427
Layer 0 metrics:
  pearson_correlation: 0.0060
  kl_divergence: -5270.1470
  ssim: 0.0732
  iou: 0.1427

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.40656, std: 0.10878

Metrics for layer 1:
  pearson_correlation: 0.0099
  kl_divergence: -5206.1558
  ssim: 0.0776
  iou: 0.1463
Layer 1 metrics:
  pearson_correlation: 0.0099
  kl_divergence: -5206.1558
  ssim: 0.0776
  iou: 0.1463

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.51554, std: 0.13327

Metrics for layer 2:
  pearson_correlation: 0.0095
  kl_divergence: -1804.5900
  ssim: 0.0638
  iou: 0.1454
Layer 2 metrics:
  pearson_correlation: 0.0095
  kl_divergence: -1804.5900
  ssim: 0.0638
  iou: 0.1454

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.43533, std: 0.12984

Metrics for layer 3:
  pearson_correlation: -0.0008
  kl_divergence: -1499.5013
  ssim: 0.0785
  iou: 0.1472
Layer 3 metrics:
  pearson_correlation: -0.0008
  kl_divergence: -1499.5013
  ssim: 0.0785
  iou: 0.1472

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.45936, std: 0.15232

Metrics for layer 4:
  pearson_correlation: 0.0095
  kl_divergence: -392.1391
  ssim: 0.0569
  iou: 0.1521
Layer 4 metrics:
  pearson_correlation: 0.0095
  kl_divergence: -392.1391
  ssim: 0.0569
  iou: 0.1521

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.46237, std: 0.14941

Metrics for layer 5:
  pearson_correlation: -0.0129
  kl_divergence: -390.1935
  ssim: 0.0630
  iou: 0.1437
Layer 5 metrics:
  pearson_correlation: -0.0129
  kl_divergence: -390.1935
  ssim: 0.0630
  iou: 0.1437

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.39489, std: 0.12426

Metrics for layer 6:
  pearson_correlation: 0.0085
  kl_divergence: -328.1820
  ssim: 0.0929
  iou: 0.1420
Layer 6 metrics:
  pearson_correlation: 0.0085
  kl_divergence: -328.1820
  ssim: 0.0929
  iou: 0.1420

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.46547, std: 0.15710

Metrics for layer 7:
  pearson_correlation: 0.0122
  kl_divergence: -85.2131
  ssim: 0.0508
  iou: 0.1362
Layer 7 metrics:
  pearson_correlation: 0.0122
  kl_divergence: -85.2131
  ssim: 0.0508
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.48143, std: 0.14568

Metrics for layer 8:
  pearson_correlation: 0.0067
  kl_divergence: -91.4681
  ssim: 0.0561
  iou: 0.1362
Layer 8 metrics:
  pearson_correlation: 0.0067
  kl_divergence: -91.4681
  ssim: 0.0561
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.52230, std: 0.14835

Metrics for layer 9:
  pearson_correlation: -0.0517
  kl_divergence: -104.1640
  ssim: -0.0002
  iou: 0.1232
Layer 9 metrics:
  pearson_correlation: -0.0517
  kl_divergence: -104.1640
  ssim: -0.0002
  iou: 0.1232

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.35828, std: 0.18113

Metrics for layer 10:
  pearson_correlation: 0.0000
  kl_divergence: -8.9772
  ssim: -0.0256
  iou: 0.1395
Layer 10 metrics:
  pearson_correlation: 0.0000
  kl_divergence: -8.9772
  ssim: -0.0256
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.49942, std: 0.21138

Metrics for layer 11:
  pearson_correlation: -0.0134
  kl_divergence: -20.4160
  ssim: -0.0216
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: -0.0134
  kl_divergence: -20.4160
  ssim: -0.0216
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.41830, std: 0.18604

Metrics for layer 12:
  pearson_correlation: 0.0149
  kl_divergence: -16.4096
  ssim: 0.0323
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: 0.0149
  kl_divergence: -16.4096
  ssim: 0.0323
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer3/batch_1_strength_0.0_results.npy

Processing attention strength 0.4
Attention vector: [0.  0.  0.  0.4 0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.42408, std: 0.12244

Metrics for layer 0:
  pearson_correlation: -0.0071
  kl_divergence: -4682.5811
  ssim: 0.0492
  iou: 0.1427
Layer 0 metrics:
  pearson_correlation: -0.0071
  kl_divergence: -4682.5811
  ssim: 0.0492
  iou: 0.1427

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.43219, std: 0.12327

Metrics for layer 1:
  pearson_correlation: 0.0036
  kl_divergence: -4756.1206
  ssim: 0.0500
  iou: 0.1454
Layer 1 metrics:
  pearson_correlation: 0.0036
  kl_divergence: -4756.1206
  ssim: 0.0500
  iou: 0.1454

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.46983, std: 0.13758

Metrics for layer 2:
  pearson_correlation: -0.0103
  kl_divergence: -1516.8600
  ssim: 0.0534
  iou: 0.1383
Layer 2 metrics:
  pearson_correlation: -0.0103
  kl_divergence: -1516.8600
  ssim: 0.0534
  iou: 0.1383

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.50319, std: 0.14224

Metrics for layer 3:
  pearson_correlation: -0.0057
  kl_divergence: -1604.9562
  ssim: 0.0496
  iou: 0.1431
Layer 3 metrics:
  pearson_correlation: -0.0057
  kl_divergence: -1604.9562
  ssim: 0.0496
  iou: 0.1431

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.51149, std: 0.12510

Metrics for layer 4:
  pearson_correlation: -0.0140
  kl_divergence: -421.5685
  ssim: 0.0616
  iou: 0.1445
Layer 4 metrics:
  pearson_correlation: -0.0140
  kl_divergence: -421.5685
  ssim: 0.0616
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.42700, std: 0.14735

Metrics for layer 5:
  pearson_correlation: -0.0127
  kl_divergence: -338.0987
  ssim: 0.0532
  iou: 0.1462
Layer 5 metrics:
  pearson_correlation: -0.0127
  kl_divergence: -338.0987
  ssim: 0.0532
  iou: 0.1462

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.48807, std: 0.13737

Metrics for layer 6:
  pearson_correlation: 0.0035
  kl_divergence: -404.7466
  ssim: 0.0623
  iou: 0.1437
Layer 6 metrics:
  pearson_correlation: 0.0035
  kl_divergence: -404.7466
  ssim: 0.0623
  iou: 0.1437

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.52020, std: 0.16746

Metrics for layer 7:
  pearson_correlation: 0.0330
  kl_divergence: -102.9914
  ssim: 0.0385
  iou: 0.1429
Layer 7 metrics:
  pearson_correlation: 0.0330
  kl_divergence: -102.9914
  ssim: 0.0385
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.56218, std: 0.16233

Metrics for layer 8:
  pearson_correlation: 0.0149
  kl_divergence: -110.6132
  ssim: 0.0429
  iou: 0.1462
Layer 8 metrics:
  pearson_correlation: 0.0149
  kl_divergence: -110.6132
  ssim: 0.0429
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.49354, std: 0.14447

Metrics for layer 9:
  pearson_correlation: -0.0077
  kl_divergence: -98.7650
  ssim: 0.0552
  iou: 0.1529
Layer 9 metrics:
  pearson_correlation: -0.0077
  kl_divergence: -98.7650
  ssim: 0.0552
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.51913, std: 0.16423

Metrics for layer 10:
  pearson_correlation: 0.1048
  kl_divergence: -22.4806
  ssim: 0.0224
  iou: 0.1807
Layer 10 metrics:
  pearson_correlation: 0.1048
  kl_divergence: -22.4806
  ssim: 0.0224
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.48104, std: 0.17792

Metrics for layer 11:
  pearson_correlation: -0.0648
  kl_divergence: -18.3446
  ssim: -0.0364
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: -0.0648
  kl_divergence: -18.3446
  ssim: -0.0364
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.47909, std: 0.20346

Metrics for layer 12:
  pearson_correlation: -0.1565
  kl_divergence: -13.8241
  ssim: -0.0666
  iou: 0.1136
Layer 12 metrics:
  pearson_correlation: -0.1565
  kl_divergence: -13.8241
  ssim: -0.0666
  iou: 0.1136
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer3/batch_0_strength_0.4_results.npy

Processing batch 2/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.43133, std: 0.11985

Metrics for layer 0:
  pearson_correlation: 0.0000
  kl_divergence: -5456.0894
  ssim: 0.0642
  iou: 0.1436
Layer 0 metrics:
  pearson_correlation: 0.0000
  kl_divergence: -5456.0894
  ssim: 0.0642
  iou: 0.1436

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.42931, std: 0.11675

Metrics for layer 1:
  pearson_correlation: 0.0038
  kl_divergence: -5447.6382
  ssim: 0.0682
  iou: 0.1452
Layer 1 metrics:
  pearson_correlation: 0.0038
  kl_divergence: -5447.6382
  ssim: 0.0682
  iou: 0.1452

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.46403, std: 0.12787

Metrics for layer 2:
  pearson_correlation: 0.0033
  kl_divergence: -1626.4360
  ssim: 0.0762
  iou: 0.1464
Layer 2 metrics:
  pearson_correlation: 0.0033
  kl_divergence: -1626.4360
  ssim: 0.0762
  iou: 0.1464

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.51868, std: 0.13462

Metrics for layer 3:
  pearson_correlation: 0.0024
  kl_divergence: -1809.8257
  ssim: 0.0634
  iou: 0.1431
Layer 3 metrics:
  pearson_correlation: 0.0024
  kl_divergence: -1809.8257
  ssim: 0.0634
  iou: 0.1431

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.44754, std: 0.13755

Metrics for layer 4:
  pearson_correlation: -0.0064
  kl_divergence: -382.2575
  ssim: 0.0614
  iou: 0.1297
Layer 4 metrics:
  pearson_correlation: -0.0064
  kl_divergence: -382.2575
  ssim: 0.0614
  iou: 0.1297

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.47755, std: 0.14870

Metrics for layer 5:
  pearson_correlation: -0.0135
  kl_divergence: -408.5250
  ssim: 0.0448
  iou: 0.1338
Layer 5 metrics:
  pearson_correlation: -0.0135
  kl_divergence: -408.5250
  ssim: 0.0448
  iou: 0.1338

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.50962, std: 0.14427

Metrics for layer 6:
  pearson_correlation: -0.0092
  kl_divergence: -441.6056
  ssim: 0.0633
  iou: 0.1313
Layer 6 metrics:
  pearson_correlation: -0.0092
  kl_divergence: -441.6056
  ssim: 0.0633
  iou: 0.1313

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.47969, std: 0.16863

Metrics for layer 7:
  pearson_correlation: -0.0463
  kl_divergence: -82.6422
  ssim: 0.0013
  iou: 0.1297
Layer 7 metrics:
  pearson_correlation: -0.0463
  kl_divergence: -82.6422
  ssim: 0.0013
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.50482, std: 0.17813

Metrics for layer 8:
  pearson_correlation: -0.0541
  kl_divergence: -87.2813
  ssim: 0.0159
  iou: 0.1362
Layer 8 metrics:
  pearson_correlation: -0.0541
  kl_divergence: -87.2813
  ssim: 0.0159
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.52704, std: 0.17352

Metrics for layer 9:
  pearson_correlation: 0.0035
  kl_divergence: -104.2922
  ssim: 0.0358
  iou: 0.1462
Layer 9 metrics:
  pearson_correlation: 0.0035
  kl_divergence: -104.2922
  ssim: 0.0358
  iou: 0.1462

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.39491, std: 0.17785

Metrics for layer 10:
  pearson_correlation: -0.0005
  kl_divergence: -15.9422
  ssim: 0.0999
  iou: 0.0889
Layer 10 metrics:
  pearson_correlation: -0.0005
  kl_divergence: -15.9422
  ssim: 0.0999
  iou: 0.0889

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.48404, std: 0.16522

Metrics for layer 11:
  pearson_correlation: 0.0152
  kl_divergence: -22.1877
  ssim: -0.0034
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: 0.0152
  kl_divergence: -22.1877
  ssim: -0.0034
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.49479, std: 0.19026

Metrics for layer 12:
  pearson_correlation: -0.0563
  kl_divergence: -13.2361
  ssim: -0.0510
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: -0.0563
  kl_divergence: -13.2361
  ssim: -0.0510
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer3/batch_1_strength_0.4_results.npy

Processing attention strength 0.8
Attention vector: [0.  0.  0.  0.8 0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.41065, std: 0.12145

Metrics for layer 0:
  pearson_correlation: 0.0023
  kl_divergence: -4576.2114
  ssim: 0.0519
  iou: 0.1429
Layer 0 metrics:
  pearson_correlation: 0.0023
  kl_divergence: -4576.2114
  ssim: 0.0519
  iou: 0.1429

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.45798, std: 0.12451

Metrics for layer 1:
  pearson_correlation: -0.0060
  kl_divergence: -4948.1455
  ssim: 0.0454
  iou: 0.1380
Layer 1 metrics:
  pearson_correlation: -0.0060
  kl_divergence: -4948.1455
  ssim: 0.0454
  iou: 0.1380

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.50441, std: 0.12817

Metrics for layer 2:
  pearson_correlation: -0.0046
  kl_divergence: -1622.5649
  ssim: 0.0574
  iou: 0.1424
Layer 2 metrics:
  pearson_correlation: -0.0046
  kl_divergence: -1622.5649
  ssim: 0.0574
  iou: 0.1424

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.50960, std: 0.13062

Metrics for layer 3:
  pearson_correlation: -0.0151
  kl_divergence: -1629.4613
  ssim: 0.0498
  iou: 0.1410
Layer 3 metrics:
  pearson_correlation: -0.0151
  kl_divergence: -1629.4613
  ssim: 0.0498
  iou: 0.1410

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.51275, std: 0.14652

Metrics for layer 4:
  pearson_correlation: 0.0112
  kl_divergence: -422.5323
  ssim: 0.0603
  iou: 0.1338
Layer 4 metrics:
  pearson_correlation: 0.0112
  kl_divergence: -422.5323
  ssim: 0.0603
  iou: 0.1338

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.46617, std: 0.14849

Metrics for layer 5:
  pearson_correlation: -0.0012
  kl_divergence: -379.8347
  ssim: 0.0495
  iou: 0.1470
Layer 5 metrics:
  pearson_correlation: -0.0012
  kl_divergence: -379.8347
  ssim: 0.0495
  iou: 0.1470

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.46172, std: 0.13592

Metrics for layer 6:
  pearson_correlation: 0.0221
  kl_divergence: -382.2304
  ssim: 0.0698
  iou: 0.1479
Layer 6 metrics:
  pearson_correlation: 0.0221
  kl_divergence: -382.2304
  ssim: 0.0698
  iou: 0.1479

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.45576, std: 0.14672

Metrics for layer 7:
  pearson_correlation: -0.0269
  kl_divergence: -84.0118
  ssim: 0.0551
  iou: 0.1496
Layer 7 metrics:
  pearson_correlation: -0.0269
  kl_divergence: -84.0118
  ssim: 0.0551
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.45002, std: 0.14730

Metrics for layer 8:
  pearson_correlation: 0.0725
  kl_divergence: -89.3538
  ssim: 0.1023
  iou: 0.1879
Layer 8 metrics:
  pearson_correlation: 0.0725
  kl_divergence: -89.3538
  ssim: 0.1023
  iou: 0.1879

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.41750, std: 0.14916

Metrics for layer 9:
  pearson_correlation: -0.0211
  kl_divergence: -77.2835
  ssim: 0.0529
  iou: 0.1563
Layer 9 metrics:
  pearson_correlation: -0.0211
  kl_divergence: -77.2835
  ssim: 0.0529
  iou: 0.1563

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.44619, std: 0.17598

Metrics for layer 10:
  pearson_correlation: 0.0571
  kl_divergence: -18.3015
  ssim: 0.0535
  iou: 0.1011
Layer 10 metrics:
  pearson_correlation: 0.0571
  kl_divergence: -18.3015
  ssim: 0.0535
  iou: 0.1011

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.46139, std: 0.18165

Metrics for layer 11:
  pearson_correlation: -0.0194
  kl_divergence: -16.2304
  ssim: -0.0050
  iou: 0.0652
Layer 11 metrics:
  pearson_correlation: -0.0194
  kl_divergence: -16.2304
  ssim: -0.0050
  iou: 0.0652

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.52706, std: 0.16874

Metrics for layer 12:
  pearson_correlation: -0.0213
  kl_divergence: -20.8794
  ssim: 0.0310
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: -0.0213
  kl_divergence: -20.8794
  ssim: 0.0310
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer3/batch_0_strength_0.8_results.npy

Processing batch 2/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.42473, std: 0.12282

Metrics for layer 0:
  pearson_correlation: -0.0011
  kl_divergence: -5364.1025
  ssim: 0.0622
  iou: 0.1399
Layer 0 metrics:
  pearson_correlation: -0.0011
  kl_divergence: -5364.1025
  ssim: 0.0622
  iou: 0.1399

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.43675, std: 0.11934

Metrics for layer 1:
  pearson_correlation: 0.0006
  kl_divergence: -5523.9160
  ssim: 0.0658
  iou: 0.1381
Layer 1 metrics:
  pearson_correlation: 0.0006
  kl_divergence: -5523.9160
  ssim: 0.0658
  iou: 0.1381

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.42263, std: 0.13313

Metrics for layer 2:
  pearson_correlation: -0.0074
  kl_divergence: -1442.6516
  ssim: 0.0707
  iou: 0.1399
Layer 2 metrics:
  pearson_correlation: -0.0074
  kl_divergence: -1442.6516
  ssim: 0.0707
  iou: 0.1399

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.53032, std: 0.13164

Metrics for layer 3:
  pearson_correlation: 0.0096
  kl_divergence: -1853.9187
  ssim: 0.0653
  iou: 0.1472
Layer 3 metrics:
  pearson_correlation: 0.0096
  kl_divergence: -1853.9187
  ssim: 0.0653
  iou: 0.1472

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.48801, std: 0.14524

Metrics for layer 4:
  pearson_correlation: -0.0045
  kl_divergence: -418.8694
  ssim: 0.0606
  iou: 0.1454
Layer 4 metrics:
  pearson_correlation: -0.0045
  kl_divergence: -418.8694
  ssim: 0.0606
  iou: 0.1454

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.44342, std: 0.13791

Metrics for layer 5:
  pearson_correlation: -0.0153
  kl_divergence: -373.7817
  ssim: 0.0670
  iou: 0.1479
Layer 5 metrics:
  pearson_correlation: -0.0153
  kl_divergence: -373.7817
  ssim: 0.0670
  iou: 0.1479

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.49073, std: 0.15833

Metrics for layer 6:
  pearson_correlation: -0.0146
  kl_divergence: -418.8746
  ssim: 0.0480
  iou: 0.1297
Layer 6 metrics:
  pearson_correlation: -0.0146
  kl_divergence: -418.8746
  ssim: 0.0480
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.51017, std: 0.14381

Metrics for layer 7:
  pearson_correlation: -0.0133
  kl_divergence: -86.8900
  ssim: 0.0415
  iou: 0.1632
Layer 7 metrics:
  pearson_correlation: -0.0133
  kl_divergence: -86.8900
  ssim: 0.0415
  iou: 0.1632

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.53152, std: 0.16227

Metrics for layer 8:
  pearson_correlation: 0.0474
  kl_divergence: -107.5059
  ssim: 0.0636
  iou: 0.1362
Layer 8 metrics:
  pearson_correlation: 0.0474
  kl_divergence: -107.5059
  ssim: 0.0636
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.44235, std: 0.14413

Metrics for layer 9:
  pearson_correlation: 0.0045
  kl_divergence: -75.3762
  ssim: 0.0637
  iou: 0.1462
Layer 9 metrics:
  pearson_correlation: 0.0045
  kl_divergence: -75.3762
  ssim: 0.0637
  iou: 0.1462

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.46093, std: 0.22373

Metrics for layer 10:
  pearson_correlation: 0.0630
  kl_divergence: -17.1039
  ssim: 0.0789
  iou: 0.2099
Layer 10 metrics:
  pearson_correlation: 0.0630
  kl_divergence: -17.1039
  ssim: 0.0789
  iou: 0.2099

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.47349, std: 0.21387

Metrics for layer 11:
  pearson_correlation: 0.0385
  kl_divergence: -16.2064
  ssim: 0.0830
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: 0.0385
  kl_divergence: -16.2064
  ssim: 0.0830
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.45401, std: 0.18255

Metrics for layer 12:
  pearson_correlation: -0.0742
  kl_divergence: -15.2734
  ssim: 0.0011
  iou: 0.1136
Layer 12 metrics:
  pearson_correlation: -0.0742
  kl_divergence: -15.2734
  ssim: 0.0011
  iou: 0.1136
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer3/batch_1_strength_0.8_results.npy

Processing attention strength 1.2
Attention vector: [0.  0.  0.  1.2 0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.44075, std: 0.12549

Metrics for layer 0:
  pearson_correlation: 0.0014
  kl_divergence: -4811.5088
  ssim: 0.0475
  iou: 0.1424
Layer 0 metrics:
  pearson_correlation: 0.0014
  kl_divergence: -4811.5088
  ssim: 0.0475
  iou: 0.1424

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.42403, std: 0.12414

Metrics for layer 1:
  pearson_correlation: 0.0034
  kl_divergence: -4688.5806
  ssim: 0.0505
  iou: 0.1443
Layer 1 metrics:
  pearson_correlation: 0.0034
  kl_divergence: -4688.5806
  ssim: 0.0505
  iou: 0.1443

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.45237, std: 0.12895

Metrics for layer 2:
  pearson_correlation: -0.0083
  kl_divergence: -1472.9558
  ssim: 0.0593
  iou: 0.1383
Layer 2 metrics:
  pearson_correlation: -0.0083
  kl_divergence: -1472.9558
  ssim: 0.0593
  iou: 0.1383

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.48386, std: 0.10857

Metrics for layer 3:
  pearson_correlation: 0.0051
  kl_divergence: -1581.4954
  ssim: 0.0755
  iou: 0.1448
Layer 3 metrics:
  pearson_correlation: 0.0051
  kl_divergence: -1581.4954
  ssim: 0.0755
  iou: 0.1448

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.47966, std: 0.15621

Metrics for layer 4:
  pearson_correlation: -0.0228
  kl_divergence: -390.0179
  ssim: 0.0446
  iou: 0.1454
Layer 4 metrics:
  pearson_correlation: -0.0228
  kl_divergence: -390.0179
  ssim: 0.0446
  iou: 0.1454

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.46200, std: 0.13979

Metrics for layer 5:
  pearson_correlation: -0.0061
  kl_divergence: -376.9642
  ssim: 0.0616
  iou: 0.1354
Layer 5 metrics:
  pearson_correlation: -0.0061
  kl_divergence: -376.9642
  ssim: 0.0616
  iou: 0.1354

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.48852, std: 0.13989

Metrics for layer 6:
  pearson_correlation: -0.0007
  kl_divergence: -403.1431
  ssim: 0.0626
  iou: 0.1362
Layer 6 metrics:
  pearson_correlation: -0.0007
  kl_divergence: -403.1431
  ssim: 0.0626
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.57273, std: 0.15330

Metrics for layer 7:
  pearson_correlation: 0.0234
  kl_divergence: -116.1810
  ssim: 0.0418
  iou: 0.1429
Layer 7 metrics:
  pearson_correlation: 0.0234
  kl_divergence: -116.1810
  ssim: 0.0418
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.49687, std: 0.16136

Metrics for layer 8:
  pearson_correlation: 0.0194
  kl_divergence: -98.5070
  ssim: 0.0392
  iou: 0.1297
Layer 8 metrics:
  pearson_correlation: 0.0194
  kl_divergence: -98.5070
  ssim: 0.0392
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.47024, std: 0.15545

Metrics for layer 9:
  pearson_correlation: -0.0637
  kl_divergence: -89.7037
  ssim: 0.0406
  iou: 0.1011
Layer 9 metrics:
  pearson_correlation: -0.0637
  kl_divergence: -89.7037
  ssim: 0.0406
  iou: 0.1011

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.53435, std: 0.16446

Metrics for layer 10:
  pearson_correlation: -0.0344
  kl_divergence: -20.9965
  ssim: 0.0116
  iou: 0.1264
Layer 10 metrics:
  pearson_correlation: -0.0344
  kl_divergence: -20.9965
  ssim: 0.0116
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.50685, std: 0.18263

Metrics for layer 11:
  pearson_correlation: 0.0135
  kl_divergence: -19.3053
  ssim: 0.0484
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: 0.0135
  kl_divergence: -19.3053
  ssim: 0.0484
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.50805, std: 0.20147

Metrics for layer 12:
  pearson_correlation: 0.0457
  kl_divergence: -21.5971
  ssim: 0.0585
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: 0.0457
  kl_divergence: -21.5971
  ssim: 0.0585
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer3/batch_0_strength_1.2_results.npy

Processing batch 2/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.42917, std: 0.11888

Metrics for layer 0:
  pearson_correlation: 0.0117
  kl_divergence: -5451.1191
  ssim: 0.0687
  iou: 0.1461
Layer 0 metrics:
  pearson_correlation: 0.0117
  kl_divergence: -5451.1191
  ssim: 0.0687
  iou: 0.1461

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.41986, std: 0.11396

Metrics for layer 1:
  pearson_correlation: -0.0024
  kl_divergence: -5339.3408
  ssim: 0.0699
  iou: 0.1410
Layer 1 metrics:
  pearson_correlation: -0.0024
  kl_divergence: -5339.3408
  ssim: 0.0699
  iou: 0.1410

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.46408, std: 0.13790

Metrics for layer 2:
  pearson_correlation: 0.0101
  kl_divergence: -1613.4478
  ssim: 0.0728
  iou: 0.1483
Layer 2 metrics:
  pearson_correlation: 0.0101
  kl_divergence: -1613.4478
  ssim: 0.0728
  iou: 0.1483

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.47283, std: 0.12944

Metrics for layer 3:
  pearson_correlation: -0.0095
  kl_divergence: -1644.3303
  ssim: 0.0685
  iou: 0.1437
Layer 3 metrics:
  pearson_correlation: -0.0095
  kl_divergence: -1644.3303
  ssim: 0.0685
  iou: 0.1437

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.45702, std: 0.14908

Metrics for layer 4:
  pearson_correlation: -0.0040
  kl_divergence: -388.0919
  ssim: 0.0571
  iou: 0.1529
Layer 4 metrics:
  pearson_correlation: -0.0040
  kl_divergence: -388.0919
  ssim: 0.0571
  iou: 0.1529

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.47612, std: 0.14896

Metrics for layer 5:
  pearson_correlation: 0.0243
  kl_divergence: -405.6977
  ssim: 0.0637
  iou: 0.1563
Layer 5 metrics:
  pearson_correlation: 0.0243
  kl_divergence: -405.6977
  ssim: 0.0637
  iou: 0.1563

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.46548, std: 0.14806

Metrics for layer 6:
  pearson_correlation: -0.0131
  kl_divergence: -393.9143
  ssim: 0.0514
  iou: 0.1395
Layer 6 metrics:
  pearson_correlation: -0.0131
  kl_divergence: -393.9143
  ssim: 0.0514
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.53631, std: 0.13804

Metrics for layer 7:
  pearson_correlation: 0.0133
  kl_divergence: -105.2028
  ssim: 0.0530
  iou: 0.1329
Layer 7 metrics:
  pearson_correlation: 0.0133
  kl_divergence: -105.2028
  ssim: 0.0530
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.45853, std: 0.16377

Metrics for layer 8:
  pearson_correlation: 0.0429
  kl_divergence: -82.8917
  ssim: 0.0685
  iou: 0.1395
Layer 8 metrics:
  pearson_correlation: 0.0429
  kl_divergence: -82.8917
  ssim: 0.0685
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.48546, std: 0.14395

Metrics for layer 9:
  pearson_correlation: -0.0405
  kl_divergence: -91.5618
  ssim: 0.0538
  iou: 0.1529
Layer 9 metrics:
  pearson_correlation: -0.0405
  kl_divergence: -91.5618
  ssim: 0.0538
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.40419, std: 0.17334

Metrics for layer 10:
  pearson_correlation: -0.0208
  kl_divergence: -13.4530
  ssim: 0.0484
  iou: 0.1136
Layer 10 metrics:
  pearson_correlation: -0.0208
  kl_divergence: -13.4530
  ssim: 0.0484
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.43592, std: 0.19250

Metrics for layer 11:
  pearson_correlation: 0.0895
  kl_divergence: -16.8063
  ssim: 0.1263
  iou: 0.1807
Layer 11 metrics:
  pearson_correlation: 0.0895
  kl_divergence: -16.8063
  ssim: 0.1263
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.51892, std: 0.17685

Metrics for layer 12:
  pearson_correlation: -0.0717
  kl_divergence: -4.7016
  ssim: 0.0450
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: -0.0717
  kl_divergence: -4.7016
  ssim: 0.0450
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer3/batch_1_strength_1.2_results.npy

Analysis complete! Results saved to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer3
