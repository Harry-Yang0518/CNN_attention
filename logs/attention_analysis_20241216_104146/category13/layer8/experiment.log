WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-12-16 11:41:32.988657: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-16 11:41:33.007506: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2024-12-16 11:41:33.007915: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4328b10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:41:33.007933: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-16 11:41:33.010703: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-16 11:41:33.156753: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4322f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:41:33.156771: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-12-16 11:41:33.157305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:2f:00.0
2024-12-16 11:41:33.158505: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:41:33.159568: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:41:33.160591: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:41:33.161609: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:41:33.162628: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:41:33.163650: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:41:33.164654: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:41:33.164665: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-12-16 11:41:33.164683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-16 11:41:33.164688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-16 11:41:33.164691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:61: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:87: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:15: sigmoid_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.sigmoid_cross_entropy instead. Note that the order of the predictions and labels arguments has been changed.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:322: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:82: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.


Verifying paths:
tc_path: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs exists
weight_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists
image_path: /scratch/hy2611/CNN_attention/Data/VGG16/images exists
save_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists

Initializing model...
('c11', [1, 224, 224, 64])
('c12', [1, 224, 224, 64])
('c21', [1, 112, 112, 128])
('c22', [1, 112, 112, 128])
('c31', [1, 56, 56, 256])
('c32', [1, 56, 56, 256])
('c33', [1, 56, 56, 256])
('c41', [1, 28, 28, 512])
('c42', [1, 28, 28, 512])
('c43', [1, 28, 28, 512])
('c51', [1, 14, 14, 512])
('c52', [1, 14, 14, 512])
('c53', [1, 14, 14, 512])
(0, 'conv1_1_W', (3, 3, 3, 64))
(1, 'conv1_1_b', (64,))
(2, 'conv1_2_W', (3, 3, 64, 64))
(3, 'conv1_2_b', (64,))
(4, 'conv2_1_W', (3, 3, 64, 128))
(5, 'conv2_1_b', (128,))
(6, 'conv2_2_W', (3, 3, 128, 128))
(7, 'conv2_2_b', (128,))
(8, 'conv3_1_W', (3, 3, 128, 256))
(9, 'conv3_1_b', (256,))
(10, 'conv3_2_W', (3, 3, 256, 256))
(11, 'conv3_2_b', (256,))
(12, 'conv3_3_W', (3, 3, 256, 256))
(13, 'conv3_3_b', (256,))
(14, 'conv4_1_W', (3, 3, 256, 512))
(15, 'conv4_1_b', (512,))
(16, 'conv4_2_W', (3, 3, 512, 512))
(17, 'conv4_2_b', (512,))
(18, 'conv4_3_W', (3, 3, 512, 512))
(19, 'conv4_3_b', (512,))
(20, 'conv5_1_W', (3, 3, 512, 512))
(21, 'conv5_1_b', (512,))
(22, 'conv5_2_W', (3, 3, 512, 512))
(23, 'conv5_2_b', (512,))
(24, 'conv5_3_W', (3, 3, 512, 512))
(25, 'conv5_3_b', (512,))
(26, 'fc6_W', (25088, 4096))
(27, 'fc6_b', (4096,))
(28, 'fc7_W', (4096, 4096))
(29, 'fc7_b', (4096,))
Checking checkpoint files:
Data file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_13.ckpt.data-00000-of-00001 - Found
Index file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_13.ckpt.index - Found
Loading checkpoint from: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_13.ckpt
Checkpoint loaded successfully

Initializing components...
Found tuning curves file: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs/featvecs20_train35_c.txt

Loading category 13 data...
Original positive images shape: (2, 224, 224, 3)

Processing data...

Processing attention strength 0.0
Attention vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

Processing batch 1/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.42758, std: 0.11258

Metrics for layer 0:
  pearson_correlation: -0.0085
  kl_divergence: -4736.7456
  ssim: 0.0543
  iou: 0.1389
Layer 0 metrics:
  pearson_correlation: -0.0085
  kl_divergence: -4736.7456
  ssim: 0.0543
  iou: 0.1389

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.41870, std: 0.12049

Metrics for layer 1:
  pearson_correlation: -0.0030
  kl_divergence: -4647.7358
  ssim: 0.0509
  iou: 0.1409
Layer 1 metrics:
  pearson_correlation: -0.0030
  kl_divergence: -4647.7358
  ssim: 0.0509
  iou: 0.1409

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.42361, std: 0.13052

Metrics for layer 2:
  pearson_correlation: -0.0050
  kl_divergence: -1378.5349
  ssim: 0.0607
  iou: 0.1393
Layer 2 metrics:
  pearson_correlation: -0.0050
  kl_divergence: -1378.5349
  ssim: 0.0607
  iou: 0.1393

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.42407, std: 0.13995

Metrics for layer 3:
  pearson_correlation: -0.0133
  kl_divergence: -1367.8917
  ssim: 0.0587
  iou: 0.1404
Layer 3 metrics:
  pearson_correlation: -0.0133
  kl_divergence: -1367.8917
  ssim: 0.0587
  iou: 0.1404

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.49090, std: 0.14752

Metrics for layer 4:
  pearson_correlation: -0.0155
  kl_divergence: -403.4520
  ssim: 0.0495
  iou: 0.1371
Layer 4 metrics:
  pearson_correlation: -0.0155
  kl_divergence: -403.4520
  ssim: 0.0495
  iou: 0.1371

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.51531, std: 0.14998

Metrics for layer 5:
  pearson_correlation: -0.0219
  kl_divergence: -418.4208
  ssim: 0.0444
  iou: 0.1305
Layer 5 metrics:
  pearson_correlation: -0.0219
  kl_divergence: -418.4208
  ssim: 0.0444
  iou: 0.1305

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.50072, std: 0.13223

Metrics for layer 6:
  pearson_correlation: 0.0226
  kl_divergence: -418.0122
  ssim: 0.0693
  iou: 0.1529
Layer 6 metrics:
  pearson_correlation: 0.0226
  kl_divergence: -418.0122
  ssim: 0.0693
  iou: 0.1529

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.48473, std: 0.19473

Metrics for layer 7:
  pearson_correlation: 0.0519
  kl_divergence: -91.5968
  ssim: 0.0422
  iou: 0.1632
Layer 7 metrics:
  pearson_correlation: 0.0519
  kl_divergence: -91.5968
  ssim: 0.0422
  iou: 0.1632

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.43894, std: 0.16022

Metrics for layer 8:
  pearson_correlation: -0.0204
  kl_divergence: -79.2581
  ssim: 0.0353
  iou: 0.1395
Layer 8 metrics:
  pearson_correlation: -0.0204
  kl_divergence: -79.2581
  ssim: 0.0353
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.46470, std: 0.14473

Metrics for layer 9:
  pearson_correlation: 0.0086
  kl_divergence: -92.5371
  ssim: 0.0518
  iou: 0.1329
Layer 9 metrics:
  pearson_correlation: 0.0086
  kl_divergence: -92.5371
  ssim: 0.0518
  iou: 0.1329

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.55238, std: 0.16588

Metrics for layer 10:
  pearson_correlation: -0.0614
  kl_divergence: -22.9494
  ssim: -0.0075
  iou: 0.1136
Layer 10 metrics:
  pearson_correlation: -0.0614
  kl_divergence: -22.9494
  ssim: -0.0075
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.47056, std: 0.17199

Metrics for layer 11:
  pearson_correlation: 0.0790
  kl_divergence: -19.1480
  ssim: 0.0936
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: 0.0790
  kl_divergence: -19.1480
  ssim: 0.0936
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.46945, std: 0.21764

Metrics for layer 12:
  pearson_correlation: -0.0928
  kl_divergence: -15.5392
  ssim: -0.0525
  iou: 0.1011
Layer 12 metrics:
  pearson_correlation: -0.0928
  kl_divergence: -15.5392
  ssim: -0.0525
  iou: 0.1011
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer8/batch_0_strength_0.0_results.npy

Processing batch 2/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.44302, std: 0.12567

Metrics for layer 0:
  pearson_correlation: -0.0000
  kl_divergence: -5575.2314
  ssim: 0.0589
  iou: 0.1409
Layer 0 metrics:
  pearson_correlation: -0.0000
  kl_divergence: -5575.2314
  ssim: 0.0589
  iou: 0.1409

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.42946, std: 0.12392

Metrics for layer 1:
  pearson_correlation: 0.0076
  kl_divergence: -5428.9658
  ssim: 0.0634
  iou: 0.1430
Layer 1 metrics:
  pearson_correlation: 0.0076
  kl_divergence: -5428.9658
  ssim: 0.0634
  iou: 0.1430

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.45912, std: 0.12440

Metrics for layer 2:
  pearson_correlation: 0.0087
  kl_divergence: -1612.5220
  ssim: 0.0804
  iou: 0.1462
Layer 2 metrics:
  pearson_correlation: 0.0087
  kl_divergence: -1612.5220
  ssim: 0.0804
  iou: 0.1462

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.42194, std: 0.12738

Metrics for layer 3:
  pearson_correlation: 0.0093
  kl_divergence: -1457.9421
  ssim: 0.0812
  iou: 0.1381
Layer 3 metrics:
  pearson_correlation: 0.0093
  kl_divergence: -1457.9421
  ssim: 0.0812
  iou: 0.1381

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.49787, std: 0.13473

Metrics for layer 4:
  pearson_correlation: -0.0098
  kl_divergence: -435.6323
  ssim: 0.0574
  iou: 0.1313
Layer 4 metrics:
  pearson_correlation: -0.0098
  kl_divergence: -435.6323
  ssim: 0.0574
  iou: 0.1313

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.48196, std: 0.13737

Metrics for layer 5:
  pearson_correlation: -0.0115
  kl_divergence: -417.2292
  ssim: 0.0668
  iou: 0.1412
Layer 5 metrics:
  pearson_correlation: -0.0115
  kl_divergence: -417.2292
  ssim: 0.0668
  iou: 0.1412

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.44833, std: 0.15199

Metrics for layer 6:
  pearson_correlation: -0.0199
  kl_divergence: -374.0928
  ssim: 0.0582
  iou: 0.1387
Layer 6 metrics:
  pearson_correlation: -0.0199
  kl_divergence: -374.0928
  ssim: 0.0582
  iou: 0.1387

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.50262, std: 0.17533

Metrics for layer 7:
  pearson_correlation: 0.0073
  kl_divergence: -95.7506
  ssim: 0.0318
  iou: 0.1563
Layer 7 metrics:
  pearson_correlation: 0.0073
  kl_divergence: -95.7506
  ssim: 0.0318
  iou: 0.1563

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.52151, std: 0.17348

Metrics for layer 8:
  pearson_correlation: -0.0180
  kl_divergence: -94.9352
  ssim: 0.0372
  iou: 0.1395
Layer 8 metrics:
  pearson_correlation: -0.0180
  kl_divergence: -94.9352
  ssim: 0.0372
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.48624, std: 0.17238

Metrics for layer 9:
  pearson_correlation: 0.0220
  kl_divergence: -86.2702
  ssim: 0.0353
  iou: 0.1496
Layer 9 metrics:
  pearson_correlation: 0.0220
  kl_divergence: -86.2702
  ssim: 0.0353
  iou: 0.1496

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.55721, std: 0.19776

Metrics for layer 10:
  pearson_correlation: 0.0669
  kl_divergence: -27.3099
  ssim: 0.0530
  iou: 0.1807
Layer 10 metrics:
  pearson_correlation: 0.0669
  kl_divergence: -27.3099
  ssim: 0.0530
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.40803, std: 0.18489

Metrics for layer 11:
  pearson_correlation: 0.0399
  kl_divergence: -15.6064
  ssim: -0.0118
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: 0.0399
  kl_divergence: -15.6064
  ssim: -0.0118
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.51127, std: 0.17287

Metrics for layer 12:
  pearson_correlation: -0.0290
  kl_divergence: -23.5267
  ssim: -0.0600
  iou: 0.1264
Layer 12 metrics:
  pearson_correlation: -0.0290
  kl_divergence: -23.5267
  ssim: -0.0600
  iou: 0.1264
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer8/batch_1_strength_0.0_results.npy

Processing attention strength 0.4
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.  0.4 0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.44863, std: 0.12228

Metrics for layer 0:
  pearson_correlation: 0.0062
  kl_divergence: -4892.3809
  ssim: 0.0485
  iou: 0.1449
Layer 0 metrics:
  pearson_correlation: 0.0062
  kl_divergence: -4892.3809
  ssim: 0.0485
  iou: 0.1449

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.38977, std: 0.11966

Metrics for layer 1:
  pearson_correlation: 0.0007
  kl_divergence: -4397.6597
  ssim: 0.0550
  iou: 0.1445
Layer 1 metrics:
  pearson_correlation: 0.0007
  kl_divergence: -4397.6597
  ssim: 0.0550
  iou: 0.1445

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.45305, std: 0.12867

Metrics for layer 2:
  pearson_correlation: 0.0068
  kl_divergence: -1478.6851
  ssim: 0.0664
  iou: 0.1404
Layer 2 metrics:
  pearson_correlation: 0.0068
  kl_divergence: -1478.6851
  ssim: 0.0664
  iou: 0.1404

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.44814, std: 0.13783

Metrics for layer 3:
  pearson_correlation: 0.0005
  kl_divergence: -1451.8250
  ssim: 0.0582
  iou: 0.1458
Layer 3 metrics:
  pearson_correlation: 0.0005
  kl_divergence: -1451.8250
  ssim: 0.0582
  iou: 0.1458

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.50210, std: 0.15291

Metrics for layer 4:
  pearson_correlation: -0.0210
  kl_divergence: -404.6634
  ssim: 0.0442
  iou: 0.1346
Layer 4 metrics:
  pearson_correlation: -0.0210
  kl_divergence: -404.6634
  ssim: 0.0442
  iou: 0.1346

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.49061, std: 0.12596

Metrics for layer 5:
  pearson_correlation: 0.0198
  kl_divergence: -410.0405
  ssim: 0.0696
  iou: 0.1496
Layer 5 metrics:
  pearson_correlation: 0.0198
  kl_divergence: -410.0405
  ssim: 0.0696
  iou: 0.1496

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.46141, std: 0.13927

Metrics for layer 6:
  pearson_correlation: 0.0190
  kl_divergence: -381.6584
  ssim: 0.0701
  iou: 0.1572
Layer 6 metrics:
  pearson_correlation: 0.0190
  kl_divergence: -381.6584
  ssim: 0.0701
  iou: 0.1572

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.47389, std: 0.13796

Metrics for layer 7:
  pearson_correlation: 0.0069
  kl_divergence: -87.1971
  ssim: 0.0506
  iou: 0.1598
Layer 7 metrics:
  pearson_correlation: 0.0069
  kl_divergence: -87.1971
  ssim: 0.0506
  iou: 0.1598

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.50365, std: 0.16812

Metrics for layer 8:
  pearson_correlation: 0.0364
  kl_divergence: -98.7074
  ssim: 0.0680
  iou: 0.1563
Layer 8 metrics:
  pearson_correlation: 0.0364
  kl_divergence: -98.7074
  ssim: 0.0680
  iou: 0.1563

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.45761, std: 0.15923

Metrics for layer 9:
  pearson_correlation: -0.0182
  kl_divergence: -88.6438
  ssim: 0.0597
  iou: 0.1329
Layer 9 metrics:
  pearson_correlation: -0.0182
  kl_divergence: -88.6438
  ssim: 0.0597
  iou: 0.1329

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.49753, std: 0.18170

Metrics for layer 10:
  pearson_correlation: 0.1335
  kl_divergence: -20.8342
  ssim: 0.1110
  iou: 0.1667
Layer 10 metrics:
  pearson_correlation: 0.1335
  kl_divergence: -20.8342
  ssim: 0.1110
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.47802, std: 0.16804

Metrics for layer 11:
  pearson_correlation: 0.0134
  kl_divergence: -18.7636
  ssim: 0.0703
  iou: 0.2099
Layer 11 metrics:
  pearson_correlation: 0.0134
  kl_divergence: -18.7636
  ssim: 0.0703
  iou: 0.2099

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.49712, std: 0.16378

Metrics for layer 12:
  pearson_correlation: -0.0233
  kl_divergence: -19.4283
  ssim: -0.0414
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: -0.0233
  kl_divergence: -19.4283
  ssim: -0.0414
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer8/batch_0_strength_0.4_results.npy

Processing batch 2/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.42159, std: 0.12629

Metrics for layer 0:
  pearson_correlation: -0.0083
  kl_divergence: -5300.2856
  ssim: 0.0605
  iou: 0.1381
Layer 0 metrics:
  pearson_correlation: -0.0083
  kl_divergence: -5300.2856
  ssim: 0.0605
  iou: 0.1381

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.40589, std: 0.11522

Metrics for layer 1:
  pearson_correlation: 0.0000
  kl_divergence: -5160.7471
  ssim: 0.0713
  iou: 0.1441
Layer 1 metrics:
  pearson_correlation: 0.0000
  kl_divergence: -5160.7471
  ssim: 0.0713
  iou: 0.1441

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.39670, std: 0.13087

Metrics for layer 2:
  pearson_correlation: -0.0076
  kl_divergence: -1331.4165
  ssim: 0.0763
  iou: 0.1387
Layer 2 metrics:
  pearson_correlation: -0.0076
  kl_divergence: -1331.4165
  ssim: 0.0763
  iou: 0.1387

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.46323, std: 0.13839

Metrics for layer 3:
  pearson_correlation: 0.0038
  kl_divergence: -1604.6707
  ssim: 0.0647
  iou: 0.1481
Layer 3 metrics:
  pearson_correlation: 0.0038
  kl_divergence: -1604.6707
  ssim: 0.0647
  iou: 0.1481

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.51109, std: 0.14449

Metrics for layer 4:
  pearson_correlation: -0.0451
  kl_divergence: -441.7985
  ssim: 0.0367
  iou: 0.1329
Layer 4 metrics:
  pearson_correlation: -0.0451
  kl_divergence: -441.7985
  ssim: 0.0367
  iou: 0.1329

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.50640, std: 0.14795

Metrics for layer 5:
  pearson_correlation: 0.0003
  kl_divergence: -440.3452
  ssim: 0.0527
  iou: 0.1395
Layer 5 metrics:
  pearson_correlation: 0.0003
  kl_divergence: -440.3452
  ssim: 0.0527
  iou: 0.1395

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.44196, std: 0.14753

Metrics for layer 6:
  pearson_correlation: -0.0147
  kl_divergence: -368.6739
  ssim: 0.0478
  iou: 0.1379
Layer 6 metrics:
  pearson_correlation: -0.0147
  kl_divergence: -368.6739
  ssim: 0.0478
  iou: 0.1379

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.46136, std: 0.16477

Metrics for layer 7:
  pearson_correlation: 0.0639
  kl_divergence: -85.1979
  ssim: 0.0703
  iou: 0.1529
Layer 7 metrics:
  pearson_correlation: 0.0639
  kl_divergence: -85.1979
  ssim: 0.0703
  iou: 0.1529

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.47468, std: 0.16912

Metrics for layer 8:
  pearson_correlation: 0.0004
  kl_divergence: -82.8605
  ssim: 0.0408
  iou: 0.1395
Layer 8 metrics:
  pearson_correlation: 0.0004
  kl_divergence: -82.8605
  ssim: 0.0408
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.50312, std: 0.17587

Metrics for layer 9:
  pearson_correlation: 0.0178
  kl_divergence: -95.2770
  ssim: 0.0389
  iou: 0.1563
Layer 9 metrics:
  pearson_correlation: 0.0178
  kl_divergence: -95.2770
  ssim: 0.0389
  iou: 0.1563

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.55129, std: 0.18996

Metrics for layer 10:
  pearson_correlation: 0.0011
  kl_divergence: -26.8822
  ssim: 0.0339
  iou: 0.1807
Layer 10 metrics:
  pearson_correlation: 0.0011
  kl_divergence: -26.8822
  ssim: 0.0339
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.52271, std: 0.19752

Metrics for layer 11:
  pearson_correlation: -0.0169
  kl_divergence: -20.5658
  ssim: 0.0441
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: -0.0169
  kl_divergence: -20.5658
  ssim: 0.0441
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.51634, std: 0.17490

Metrics for layer 12:
  pearson_correlation: 0.0090
  kl_divergence: -22.0785
  ssim: 0.0801
  iou: 0.1264
Layer 12 metrics:
  pearson_correlation: 0.0090
  kl_divergence: -22.0785
  ssim: 0.0801
  iou: 0.1264
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer8/batch_1_strength_0.4_results.npy

Processing attention strength 0.8
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.  0.8 0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.43648, std: 0.12042

Metrics for layer 0:
  pearson_correlation: -0.0033
  kl_divergence: -4792.5181
  ssim: 0.0507
  iou: 0.1435
Layer 0 metrics:
  pearson_correlation: -0.0033
  kl_divergence: -4792.5181
  ssim: 0.0507
  iou: 0.1435

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.42236, std: 0.11309

Metrics for layer 1:
  pearson_correlation: 0.0106
  kl_divergence: -4706.6733
  ssim: 0.0571
  iou: 0.1455
Layer 1 metrics:
  pearson_correlation: 0.0106
  kl_divergence: -4706.6733
  ssim: 0.0571
  iou: 0.1455

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.47278, std: 0.13453

Metrics for layer 2:
  pearson_correlation: 0.0002
  kl_divergence: -1530.7888
  ssim: 0.0539
  iou: 0.1402
Layer 2 metrics:
  pearson_correlation: 0.0002
  kl_divergence: -1530.7888
  ssim: 0.0539
  iou: 0.1402

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.42217, std: 0.12603

Metrics for layer 3:
  pearson_correlation: -0.0102
  kl_divergence: -1380.2897
  ssim: 0.0666
  iou: 0.1420
Layer 3 metrics:
  pearson_correlation: -0.0102
  kl_divergence: -1380.2897
  ssim: 0.0666
  iou: 0.1420

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.48603, std: 0.14290

Metrics for layer 4:
  pearson_correlation: -0.0142
  kl_divergence: -399.4293
  ssim: 0.0425
  iou: 0.1470
Layer 4 metrics:
  pearson_correlation: -0.0142
  kl_divergence: -399.4293
  ssim: 0.0425
  iou: 0.1470

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.48929, std: 0.15901

Metrics for layer 5:
  pearson_correlation: 0.0333
  kl_divergence: -402.6522
  ssim: 0.0627
  iou: 0.1496
Layer 5 metrics:
  pearson_correlation: 0.0333
  kl_divergence: -402.6522
  ssim: 0.0627
  iou: 0.1496

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.44754, std: 0.14391

Metrics for layer 6:
  pearson_correlation: 0.0401
  kl_divergence: -371.6240
  ssim: 0.0764
  iou: 0.1589
Layer 6 metrics:
  pearson_correlation: 0.0401
  kl_divergence: -371.6240
  ssim: 0.0764
  iou: 0.1589

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.50788, std: 0.15349

Metrics for layer 7:
  pearson_correlation: -0.0208
  kl_divergence: -100.8379
  ssim: 0.0401
  iou: 0.1168
Layer 7 metrics:
  pearson_correlation: -0.0208
  kl_divergence: -100.8379
  ssim: 0.0401
  iou: 0.1168

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.49237, std: 0.15598

Metrics for layer 8:
  pearson_correlation: -0.0239
  kl_divergence: -90.4625
  ssim: 0.0450
  iou: 0.1632
Layer 8 metrics:
  pearson_correlation: -0.0239
  kl_divergence: -90.4625
  ssim: 0.0450
  iou: 0.1632

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.50198, std: 0.16396

Metrics for layer 9:
  pearson_correlation: -0.0295
  kl_divergence: -96.1740
  ssim: 0.0364
  iou: 0.1168
Layer 9 metrics:
  pearson_correlation: -0.0295
  kl_divergence: -96.1740
  ssim: 0.0364
  iou: 0.1168

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.43841, std: 0.14350

Metrics for layer 10:
  pearson_correlation: 0.0337
  kl_divergence: -18.3425
  ssim: 0.1203
  iou: 0.1395
Layer 10 metrics:
  pearson_correlation: 0.0337
  kl_divergence: -18.3425
  ssim: 0.1203
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.38650, std: 0.19071

Metrics for layer 11:
  pearson_correlation: 0.1099
  kl_divergence: -12.0959
  ssim: 0.0991
  iou: 0.1807
Layer 11 metrics:
  pearson_correlation: 0.1099
  kl_divergence: -12.0959
  ssim: 0.0991
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.43924, std: 0.19976

Metrics for layer 12:
  pearson_correlation: -0.0280
  kl_divergence: -11.3645
  ssim: 0.0427
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: -0.0280
  kl_divergence: -11.3645
  ssim: 0.0427
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer8/batch_0_strength_0.8_results.npy

Processing batch 2/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.42227, std: 0.11611

Metrics for layer 0:
  pearson_correlation: -0.0022
  kl_divergence: -5357.8447
  ssim: 0.0705
  iou: 0.1428
Layer 0 metrics:
  pearson_correlation: -0.0022
  kl_divergence: -5357.8447
  ssim: 0.0705
  iou: 0.1428

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.43714, std: 0.11901

Metrics for layer 1:
  pearson_correlation: 0.0011
  kl_divergence: -5529.8667
  ssim: 0.0653
  iou: 0.1465
Layer 1 metrics:
  pearson_correlation: 0.0011
  kl_divergence: -5529.8667
  ssim: 0.0653
  iou: 0.1465

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.45292, std: 0.12736

Metrics for layer 2:
  pearson_correlation: 0.0026
  kl_divergence: -1584.1675
  ssim: 0.0761
  iou: 0.1433
Layer 2 metrics:
  pearson_correlation: 0.0026
  kl_divergence: -1584.1675
  ssim: 0.0761
  iou: 0.1433

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.45935, std: 0.13205

Metrics for layer 3:
  pearson_correlation: -0.0142
  kl_divergence: -1593.2795
  ssim: 0.0673
  iou: 0.1416
Layer 3 metrics:
  pearson_correlation: -0.0142
  kl_divergence: -1593.2795
  ssim: 0.0673
  iou: 0.1416

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.45952, std: 0.14580

Metrics for layer 4:
  pearson_correlation: 0.0265
  kl_divergence: -396.7433
  ssim: 0.0732
  iou: 0.1362
Layer 4 metrics:
  pearson_correlation: 0.0265
  kl_divergence: -396.7433
  ssim: 0.0732
  iou: 0.1362

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.45513, std: 0.13070

Metrics for layer 5:
  pearson_correlation: 0.0015
  kl_divergence: -391.7901
  ssim: 0.0760
  iou: 0.1538
Layer 5 metrics:
  pearson_correlation: 0.0015
  kl_divergence: -391.7901
  ssim: 0.0760
  iou: 0.1538

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.45433, std: 0.13987

Metrics for layer 6:
  pearson_correlation: 0.0011
  kl_divergence: -387.3382
  ssim: 0.0741
  iou: 0.1437
Layer 6 metrics:
  pearson_correlation: 0.0011
  kl_divergence: -387.3382
  ssim: 0.0741
  iou: 0.1437

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.52710, std: 0.17567

Metrics for layer 7:
  pearson_correlation: 0.0299
  kl_divergence: -101.1342
  ssim: 0.0613
  iou: 0.1667
Layer 7 metrics:
  pearson_correlation: 0.0299
  kl_divergence: -101.1342
  ssim: 0.0613
  iou: 0.1667

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.46544, std: 0.14419

Metrics for layer 8:
  pearson_correlation: 0.0258
  kl_divergence: -87.4126
  ssim: 0.0750
  iou: 0.1496
Layer 8 metrics:
  pearson_correlation: 0.0258
  kl_divergence: -87.4126
  ssim: 0.0750
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.45340, std: 0.16790

Metrics for layer 9:
  pearson_correlation: -0.0901
  kl_divergence: -67.7820
  ssim: -0.0184
  iou: 0.1232
Layer 9 metrics:
  pearson_correlation: -0.0901
  kl_divergence: -67.7820
  ssim: -0.0184
  iou: 0.1232

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.48778, std: 0.21719

Metrics for layer 10:
  pearson_correlation: -0.0113
  kl_divergence: -21.1639
  ssim: -0.0366
  iou: 0.1264
Layer 10 metrics:
  pearson_correlation: -0.0113
  kl_divergence: -21.1639
  ssim: -0.0366
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.51918, std: 0.18135

Metrics for layer 11:
  pearson_correlation: -0.0464
  kl_divergence: -24.4536
  ssim: 0.0185
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: -0.0464
  kl_divergence: -24.4536
  ssim: 0.0185
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.50074, std: 0.15532

Metrics for layer 12:
  pearson_correlation: 0.0680
  kl_divergence: -23.2024
  ssim: 0.1111
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: 0.0680
  kl_divergence: -23.2024
  ssim: 0.1111
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer8/batch_1_strength_0.8_results.npy

Processing attention strength 1.2
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.  1.2 0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.43398, std: 0.12734

Metrics for layer 0:
  pearson_correlation: -0.0009
  kl_divergence: -4756.0957
  ssim: 0.0467
  iou: 0.1405
Layer 0 metrics:
  pearson_correlation: -0.0009
  kl_divergence: -4756.0957
  ssim: 0.0467
  iou: 0.1405

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06354, std: 0.06310
Attention - min: 0.00000, max: 1.00000, mean: 0.42446, std: 0.11917

Metrics for layer 1:
  pearson_correlation: -0.0021
  kl_divergence: -4699.3286
  ssim: 0.0520
  iou: 0.1415
Layer 1 metrics:
  pearson_correlation: -0.0021
  kl_divergence: -4699.3286
  ssim: 0.0520
  iou: 0.1415

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.45671, std: 0.13261

Metrics for layer 2:
  pearson_correlation: 0.0032
  kl_divergence: -1486.8888
  ssim: 0.0595
  iou: 0.1468
Layer 2 metrics:
  pearson_correlation: 0.0032
  kl_divergence: -1486.8888
  ssim: 0.0595
  iou: 0.1468

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09857, std: 0.08197
Attention - min: 0.00000, max: 1.00000, mean: 0.40607, std: 0.13393

Metrics for layer 3:
  pearson_correlation: -0.0124
  kl_divergence: -1308.9868
  ssim: 0.0612
  iou: 0.1439
Layer 3 metrics:
  pearson_correlation: -0.0124
  kl_divergence: -1308.9868
  ssim: 0.0612
  iou: 0.1439

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.47668, std: 0.15077

Metrics for layer 4:
  pearson_correlation: -0.0353
  kl_divergence: -386.3362
  ssim: 0.0382
  iou: 0.1346
Layer 4 metrics:
  pearson_correlation: -0.0353
  kl_divergence: -386.3362
  ssim: 0.0382
  iou: 0.1346

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.45699, std: 0.16262

Metrics for layer 5:
  pearson_correlation: 0.0258
  kl_divergence: -370.4654
  ssim: 0.0569
  iou: 0.1529
Layer 5 metrics:
  pearson_correlation: 0.0258
  kl_divergence: -370.4654
  ssim: 0.0569
  iou: 0.1529

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11688, std: 0.09763
Attention - min: 0.00000, max: 1.00000, mean: 0.44572, std: 0.14026

Metrics for layer 6:
  pearson_correlation: 0.0041
  kl_divergence: -366.9612
  ssim: 0.0590
  iou: 0.1281
Layer 6 metrics:
  pearson_correlation: 0.0041
  kl_divergence: -366.9612
  ssim: 0.0590
  iou: 0.1281

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.45384, std: 0.14248

Metrics for layer 7:
  pearson_correlation: 0.0289
  kl_divergence: -89.4948
  ssim: 0.0886
  iou: 0.1429
Layer 7 metrics:
  pearson_correlation: 0.0289
  kl_divergence: -89.4948
  ssim: 0.0886
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.51644, std: 0.16100

Metrics for layer 8:
  pearson_correlation: -0.0323
  kl_divergence: -102.0261
  ssim: 0.0283
  iou: 0.1362
Layer 8 metrics:
  pearson_correlation: -0.0323
  kl_divergence: -102.0261
  ssim: 0.0283
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12664, std: 0.10895
Attention - min: 0.00000, max: 1.00000, mean: 0.44085, std: 0.16034

Metrics for layer 9:
  pearson_correlation: -0.0362
  kl_divergence: -82.1559
  ssim: 0.0467
  iou: 0.1200
Layer 9 metrics:
  pearson_correlation: -0.0362
  kl_divergence: -82.1559
  ssim: 0.0467
  iou: 0.1200

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.48638, std: 0.22672

Metrics for layer 10:
  pearson_correlation: -0.0030
  kl_divergence: -13.9931
  ssim: 0.0192
  iou: 0.1264
Layer 10 metrics:
  pearson_correlation: -0.0030
  kl_divergence: -13.9931
  ssim: 0.0192
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.47936, std: 0.17387

Metrics for layer 11:
  pearson_correlation: 0.0516
  kl_divergence: -19.6018
  ssim: 0.0927
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: 0.0516
  kl_divergence: -19.6018
  ssim: 0.0927
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.14846, std: 0.15154
Attention - min: 0.00000, max: 1.00000, mean: 0.54078, std: 0.20708

Metrics for layer 12:
  pearson_correlation: -0.0746
  kl_divergence: -20.4011
  ssim: -0.0344
  iou: 0.1264
Layer 12 metrics:
  pearson_correlation: -0.0746
  kl_divergence: -20.4011
  ssim: -0.0344
  iou: 0.1264
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06354, std=0.06310
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer8/batch_0_strength_1.2_results.npy

Processing batch 2/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.41962, std: 0.10687

Metrics for layer 0:
  pearson_correlation: 0.0043
  kl_divergence: -5367.2109
  ssim: 0.0781
  iou: 0.1474
Layer 0 metrics:
  pearson_correlation: 0.0043
  kl_divergence: -5367.2109
  ssim: 0.0781
  iou: 0.1474

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.09433, std: 0.08576
Attention - min: 0.00000, max: 1.00000, mean: 0.41303, std: 0.12214

Metrics for layer 1:
  pearson_correlation: -0.0067
  kl_divergence: -5214.2744
  ssim: 0.0646
  iou: 0.1410
Layer 1 metrics:
  pearson_correlation: -0.0067
  kl_divergence: -5214.2744
  ssim: 0.0646
  iou: 0.1410

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.46883, std: 0.14401

Metrics for layer 2:
  pearson_correlation: -0.0123
  kl_divergence: -1616.3379
  ssim: 0.0559
  iou: 0.1362
Layer 2 metrics:
  pearson_correlation: -0.0123
  kl_divergence: -1616.3379
  ssim: 0.0559
  iou: 0.1362

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12810, std: 0.09580
Attention - min: 0.00000, max: 1.00000, mean: 0.48170, std: 0.13270

Metrics for layer 3:
  pearson_correlation: 0.0054
  kl_divergence: -1683.5270
  ssim: 0.0639
  iou: 0.1454
Layer 3 metrics:
  pearson_correlation: 0.0054
  kl_divergence: -1683.5270
  ssim: 0.0639
  iou: 0.1454

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.44735, std: 0.15006

Metrics for layer 4:
  pearson_correlation: 0.0088
  kl_divergence: -377.6119
  ssim: 0.0716
  iou: 0.1437
Layer 4 metrics:
  pearson_correlation: 0.0088
  kl_divergence: -377.6119
  ssim: 0.0716
  iou: 0.1437

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.55309, std: 0.13036

Metrics for layer 5:
  pearson_correlation: -0.0228
  kl_divergence: -486.3753
  ssim: 0.0549
  iou: 0.1420
Layer 5 metrics:
  pearson_correlation: -0.0228
  kl_divergence: -486.3753
  ssim: 0.0549
  iou: 0.1420

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.13945, std: 0.10371
Attention - min: 0.00000, max: 1.00000, mean: 0.51007, std: 0.14100

Metrics for layer 6:
  pearson_correlation: 0.0238
  kl_divergence: -448.1375
  ssim: 0.0669
  iou: 0.1437
Layer 6 metrics:
  pearson_correlation: 0.0238
  kl_divergence: -448.1375
  ssim: 0.0669
  iou: 0.1437

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.44264, std: 0.14172

Metrics for layer 7:
  pearson_correlation: -0.0032
  kl_divergence: -79.4962
  ssim: 0.0526
  iou: 0.1667
Layer 7 metrics:
  pearson_correlation: -0.0032
  kl_divergence: -79.4962
  ssim: 0.0526
  iou: 0.1667

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.53999, std: 0.14376

Metrics for layer 8:
  pearson_correlation: -0.0216
  kl_divergence: -110.2978
  ssim: 0.0452
  iou: 0.1362
Layer 8 metrics:
  pearson_correlation: -0.0216
  kl_divergence: -110.2978
  ssim: 0.0452
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.17714, std: 0.14250
Attention - min: 0.00000, max: 1.00000, mean: 0.52406, std: 0.16675

Metrics for layer 9:
  pearson_correlation: 0.0348
  kl_divergence: -103.2535
  ssim: 0.0680
  iou: 0.1297
Layer 9 metrics:
  pearson_correlation: 0.0348
  kl_divergence: -103.2535
  ssim: 0.0680
  iou: 0.1297

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.40644, std: 0.18046

Metrics for layer 10:
  pearson_correlation: 0.0674
  kl_divergence: -14.1197
  ssim: 0.1228
  iou: 0.1951
Layer 10 metrics:
  pearson_correlation: 0.0674
  kl_divergence: -14.1197
  ssim: 0.1228
  iou: 0.1951

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.51885, std: 0.21156

Metrics for layer 11:
  pearson_correlation: -0.0468
  kl_divergence: -24.0375
  ssim: -0.0004
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: -0.0468
  kl_divergence: -24.0375
  ssim: -0.0004
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16192, std: 0.12504
Attention - min: 0.00000, max: 1.00000, mean: 0.41888, std: 0.18553

Metrics for layer 12:
  pearson_correlation: 0.0740
  kl_divergence: -16.3406
  ssim: 0.1221
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: 0.0740
  kl_divergence: -16.3406
  ssim: 0.1221
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.09433, std=0.08576
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer8/batch_1_strength_1.2_results.npy

Analysis complete! Results saved to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat13_layer8
