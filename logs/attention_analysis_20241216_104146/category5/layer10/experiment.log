WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-12-16 11:09:50.853513: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-16 11:09:50.872501: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2024-12-16 11:09:50.872953: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3f3f0f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:09:50.872971: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-16 11:09:50.875991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-16 11:09:51.010911: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3f120e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:09:51.010931: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-12-16 11:09:51.011455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:2f:00.0
2024-12-16 11:09:51.012541: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:09:51.013535: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:09:51.014491: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:09:51.015441: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:09:51.016366: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:09:51.017347: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:09:51.018312: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:09:51.018325: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-12-16 11:09:51.018344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-16 11:09:51.018349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-16 11:09:51.018352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:61: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:87: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:15: sigmoid_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.sigmoid_cross_entropy instead. Note that the order of the predictions and labels arguments has been changed.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:322: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:82: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.


Verifying paths:
tc_path: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs exists
weight_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists
image_path: /scratch/hy2611/CNN_attention/Data/VGG16/images exists
save_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists

Initializing model...
('c11', [1, 224, 224, 64])
('c12', [1, 224, 224, 64])
('c21', [1, 112, 112, 128])
('c22', [1, 112, 112, 128])
('c31', [1, 56, 56, 256])
('c32', [1, 56, 56, 256])
('c33', [1, 56, 56, 256])
('c41', [1, 28, 28, 512])
('c42', [1, 28, 28, 512])
('c43', [1, 28, 28, 512])
('c51', [1, 14, 14, 512])
('c52', [1, 14, 14, 512])
('c53', [1, 14, 14, 512])
(0, 'conv1_1_W', (3, 3, 3, 64))
(1, 'conv1_1_b', (64,))
(2, 'conv1_2_W', (3, 3, 64, 64))
(3, 'conv1_2_b', (64,))
(4, 'conv2_1_W', (3, 3, 64, 128))
(5, 'conv2_1_b', (128,))
(6, 'conv2_2_W', (3, 3, 128, 128))
(7, 'conv2_2_b', (128,))
(8, 'conv3_1_W', (3, 3, 128, 256))
(9, 'conv3_1_b', (256,))
(10, 'conv3_2_W', (3, 3, 256, 256))
(11, 'conv3_2_b', (256,))
(12, 'conv3_3_W', (3, 3, 256, 256))
(13, 'conv3_3_b', (256,))
(14, 'conv4_1_W', (3, 3, 256, 512))
(15, 'conv4_1_b', (512,))
(16, 'conv4_2_W', (3, 3, 512, 512))
(17, 'conv4_2_b', (512,))
(18, 'conv4_3_W', (3, 3, 512, 512))
(19, 'conv4_3_b', (512,))
(20, 'conv5_1_W', (3, 3, 512, 512))
(21, 'conv5_1_b', (512,))
(22, 'conv5_2_W', (3, 3, 512, 512))
(23, 'conv5_2_b', (512,))
(24, 'conv5_3_W', (3, 3, 512, 512))
(25, 'conv5_3_b', (512,))
(26, 'fc6_W', (25088, 4096))
(27, 'fc6_b', (4096,))
(28, 'fc7_W', (4096, 4096))
(29, 'fc7_b', (4096,))
Checking checkpoint files:
Data file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.data-00000-of-00001 - Found
Index file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.index - Found
Loading checkpoint from: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt
Checkpoint loaded successfully

Initializing components...
Found tuning curves file: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs/featvecs20_train35_c.txt

Loading category 5 data...
Original positive images shape: (2, 224, 224, 3)

Processing data...

Processing attention strength 0.0
Attention vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

Processing batch 1/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42458, std: 0.12126

Metrics for layer 0:
  pearson_correlation: -0.0034
  kl_divergence: -4557.7329
  ssim: 0.0484
  iou: 0.1376
Layer 0 metrics:
  pearson_correlation: -0.0034
  kl_divergence: -4557.7329
  ssim: 0.0484
  iou: 0.1376

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.40447, std: 0.11710

Metrics for layer 1:
  pearson_correlation: -0.0004
  kl_divergence: -4405.6060
  ssim: 0.0515
  iou: 0.1425
Layer 1 metrics:
  pearson_correlation: -0.0004
  kl_divergence: -4405.6060
  ssim: 0.0515
  iou: 0.1425

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.47142, std: 0.13125

Metrics for layer 2:
  pearson_correlation: -0.0141
  kl_divergence: -1421.2747
  ssim: 0.0465
  iou: 0.1350
Layer 2 metrics:
  pearson_correlation: -0.0141
  kl_divergence: -1421.2747
  ssim: 0.0465
  iou: 0.1350

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.46040, std: 0.13115

Metrics for layer 3:
  pearson_correlation: -0.0057
  kl_divergence: -1393.4181
  ssim: 0.0517
  iou: 0.1414
Layer 3 metrics:
  pearson_correlation: -0.0057
  kl_divergence: -1393.4181
  ssim: 0.0517
  iou: 0.1414

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47833, std: 0.14049

Metrics for layer 4:
  pearson_correlation: -0.0080
  kl_divergence: -372.5096
  ssim: 0.0566
  iou: 0.1538
Layer 4 metrics:
  pearson_correlation: -0.0080
  kl_divergence: -372.5096
  ssim: 0.0566
  iou: 0.1538

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.49203, std: 0.14953

Metrics for layer 5:
  pearson_correlation: -0.0347
  kl_divergence: -378.1055
  ssim: 0.0302
  iou: 0.1354
Layer 5 metrics:
  pearson_correlation: -0.0347
  kl_divergence: -378.1055
  ssim: 0.0302
  iou: 0.1354

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47374, std: 0.14198

Metrics for layer 6:
  pearson_correlation: 0.0044
  kl_divergence: -365.3451
  ssim: 0.0567
  iou: 0.1445
Layer 6 metrics:
  pearson_correlation: 0.0044
  kl_divergence: -365.3451
  ssim: 0.0567
  iou: 0.1445

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.47712, std: 0.17069

Metrics for layer 7:
  pearson_correlation: -0.0068
  kl_divergence: -88.2862
  ssim: 0.0480
  iou: 0.1105
Layer 7 metrics:
  pearson_correlation: -0.0068
  kl_divergence: -88.2862
  ssim: 0.0480
  iou: 0.1105

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.45631, std: 0.14302

Metrics for layer 8:
  pearson_correlation: -0.0122
  kl_divergence: -85.8203
  ssim: 0.0786
  iou: 0.1667
Layer 8 metrics:
  pearson_correlation: -0.0122
  kl_divergence: -85.8203
  ssim: 0.0786
  iou: 0.1667

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.51600, std: 0.16114

Metrics for layer 9:
  pearson_correlation: -0.0328
  kl_divergence: -92.9317
  ssim: 0.0261
  iou: 0.1200
Layer 9 metrics:
  pearson_correlation: -0.0328
  kl_divergence: -92.9317
  ssim: 0.0261
  iou: 0.1200

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.53151, std: 0.19295

Metrics for layer 10:
  pearson_correlation: -0.0136
  kl_divergence: -24.5699
  ssim: 0.0489
  iou: 0.1264
Layer 10 metrics:
  pearson_correlation: -0.0136
  kl_divergence: -24.5699
  ssim: 0.0489
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.46690, std: 0.17995

Metrics for layer 11:
  pearson_correlation: -0.0127
  kl_divergence: -19.0178
  ssim: 0.0126
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: -0.0127
  kl_divergence: -19.0178
  ssim: 0.0126
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49817, std: 0.19675

Metrics for layer 12:
  pearson_correlation: -0.0949
  kl_divergence: -20.5129
  ssim: 0.0601
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: -0.0949
  kl_divergence: -20.5129
  ssim: 0.0601
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer10/batch_0_strength_0.0_results.npy

Processing batch 2/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43197, std: 0.12463

Metrics for layer 0:
  pearson_correlation: 0.0035
  kl_divergence: -3797.5173
  ssim: 0.0320
  iou: 0.1448
Layer 0 metrics:
  pearson_correlation: 0.0035
  kl_divergence: -3797.5173
  ssim: 0.0320
  iou: 0.1448

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43632, std: 0.12164

Metrics for layer 1:
  pearson_correlation: -0.0018
  kl_divergence: -3821.4858
  ssim: 0.0327
  iou: 0.1404
Layer 1 metrics:
  pearson_correlation: -0.0018
  kl_divergence: -3821.4858
  ssim: 0.0327
  iou: 0.1404

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.47752, std: 0.12753

Metrics for layer 2:
  pearson_correlation: 0.0152
  kl_divergence: -1413.9572
  ssim: 0.0509
  iou: 0.1447
Layer 2 metrics:
  pearson_correlation: 0.0152
  kl_divergence: -1413.9572
  ssim: 0.0509
  iou: 0.1447

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.48844, std: 0.13499

Metrics for layer 3:
  pearson_correlation: 0.0011
  kl_divergence: -1426.2437
  ssim: 0.0417
  iou: 0.1381
Layer 3 metrics:
  pearson_correlation: 0.0011
  kl_divergence: -1426.2437
  ssim: 0.0417
  iou: 0.1381

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.51472, std: 0.15161

Metrics for layer 4:
  pearson_correlation: 0.0120
  kl_divergence: -414.3873
  ssim: 0.0479
  iou: 0.1338
Layer 4 metrics:
  pearson_correlation: 0.0120
  kl_divergence: -414.3873
  ssim: 0.0479
  iou: 0.1338

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48007, std: 0.15519

Metrics for layer 5:
  pearson_correlation: 0.0021
  kl_divergence: -383.4637
  ssim: 0.0453
  iou: 0.1479
Layer 5 metrics:
  pearson_correlation: 0.0021
  kl_divergence: -383.4637
  ssim: 0.0453
  iou: 0.1479

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48237, std: 0.13537

Metrics for layer 6:
  pearson_correlation: 0.0275
  kl_divergence: -395.0555
  ssim: 0.0685
  iou: 0.1555
Layer 6 metrics:
  pearson_correlation: 0.0275
  kl_divergence: -395.0555
  ssim: 0.0685
  iou: 0.1555

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.39530, std: 0.14181

Metrics for layer 7:
  pearson_correlation: -0.0635
  kl_divergence: -73.0916
  ssim: 0.0162
  iou: 0.1232
Layer 7 metrics:
  pearson_correlation: -0.0635
  kl_divergence: -73.0916
  ssim: 0.0162
  iou: 0.1232

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.49537, std: 0.17193

Metrics for layer 8:
  pearson_correlation: -0.0303
  kl_divergence: -86.7350
  ssim: 0.0159
  iou: 0.1264
Layer 8 metrics:
  pearson_correlation: -0.0303
  kl_divergence: -86.7350
  ssim: 0.0159
  iou: 0.1264

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.47916, std: 0.16415

Metrics for layer 9:
  pearson_correlation: 0.0281
  kl_divergence: -86.0851
  ssim: 0.0453
  iou: 0.1563
Layer 9 metrics:
  pearson_correlation: 0.0281
  kl_divergence: -86.0851
  ssim: 0.0453
  iou: 0.1563

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.46605, std: 0.18246

Metrics for layer 10:
  pearson_correlation: 0.1748
  kl_divergence: -17.2769
  ssim: 0.1260
  iou: 0.1951
Layer 10 metrics:
  pearson_correlation: 0.1748
  kl_divergence: -17.2769
  ssim: 0.1260
  iou: 0.1951

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.49615, std: 0.21334

Metrics for layer 11:
  pearson_correlation: -0.0709
  kl_divergence: -1.6699
  ssim: -0.1076
  iou: 0.1667
Layer 11 metrics:
  pearson_correlation: -0.0709
  kl_divergence: -1.6699
  ssim: -0.1076
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.33901, std: 0.18204

Metrics for layer 12:
  pearson_correlation: -0.0767
  kl_divergence: 2.0969
  ssim: 0.0514
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: -0.0767
  kl_divergence: 2.0969
  ssim: 0.0514
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer10/batch_1_strength_0.0_results.npy

Processing attention strength 0.4
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.4 0.  0. ]

Processing batch 1/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.44723, std: 0.12916

Metrics for layer 0:
  pearson_correlation: 0.0084
  kl_divergence: -4725.3447
  ssim: 0.0442
  iou: 0.1439
Layer 0 metrics:
  pearson_correlation: 0.0084
  kl_divergence: -4725.3447
  ssim: 0.0442
  iou: 0.1439

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.40690, std: 0.11175

Metrics for layer 1:
  pearson_correlation: -0.0002
  kl_divergence: -4442.3828
  ssim: 0.0568
  iou: 0.1397
Layer 1 metrics:
  pearson_correlation: -0.0002
  kl_divergence: -4442.3828
  ssim: 0.0568
  iou: 0.1397

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.47169, std: 0.12797

Metrics for layer 2:
  pearson_correlation: -0.0024
  kl_divergence: -1424.7529
  ssim: 0.0586
  iou: 0.1439
Layer 2 metrics:
  pearson_correlation: -0.0024
  kl_divergence: -1424.7529
  ssim: 0.0586
  iou: 0.1439

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.48957, std: 0.13157

Metrics for layer 3:
  pearson_correlation: 0.0126
  kl_divergence: -1468.2496
  ssim: 0.0513
  iou: 0.1437
Layer 3 metrics:
  pearson_correlation: 0.0126
  kl_divergence: -1468.2496
  ssim: 0.0513
  iou: 0.1437

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50849, std: 0.13910

Metrics for layer 4:
  pearson_correlation: -0.0202
  kl_divergence: -398.2860
  ssim: 0.0432
  iou: 0.1462
Layer 4 metrics:
  pearson_correlation: -0.0202
  kl_divergence: -398.2860
  ssim: 0.0432
  iou: 0.1462

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50489, std: 0.15189

Metrics for layer 5:
  pearson_correlation: 0.0479
  kl_divergence: -398.3188
  ssim: 0.0565
  iou: 0.1387
Layer 5 metrics:
  pearson_correlation: 0.0479
  kl_divergence: -398.3188
  ssim: 0.0565
  iou: 0.1387

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.42440, std: 0.13866

Metrics for layer 6:
  pearson_correlation: -0.0105
  kl_divergence: -328.7013
  ssim: 0.0577
  iou: 0.1454
Layer 6 metrics:
  pearson_correlation: -0.0105
  kl_divergence: -328.7013
  ssim: 0.0577
  iou: 0.1454

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.53243, std: 0.15529

Metrics for layer 7:
  pearson_correlation: -0.0318
  kl_divergence: -101.6063
  ssim: 0.0265
  iou: 0.1105
Layer 7 metrics:
  pearson_correlation: -0.0318
  kl_divergence: -101.6063
  ssim: 0.0265
  iou: 0.1105

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.51044, std: 0.15980

Metrics for layer 8:
  pearson_correlation: 0.0355
  kl_divergence: -94.7663
  ssim: 0.0494
  iou: 0.1667
Layer 8 metrics:
  pearson_correlation: 0.0355
  kl_divergence: -94.7663
  ssim: 0.0494
  iou: 0.1667

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.49900, std: 0.14679

Metrics for layer 9:
  pearson_correlation: 0.0239
  kl_divergence: -93.9100
  ssim: 0.0630
  iou: 0.1563
Layer 9 metrics:
  pearson_correlation: 0.0239
  kl_divergence: -93.9100
  ssim: 0.0630
  iou: 0.1563

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.39081, std: 0.17701

Metrics for layer 10:
  pearson_correlation: 0.0217
  kl_divergence: -8.8958
  ssim: 0.0604
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: 0.0217
  kl_divergence: -8.8958
  ssim: 0.0604
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.54689, std: 0.16613

Metrics for layer 11:
  pearson_correlation: -0.0016
  kl_divergence: -22.5250
  ssim: 0.0395
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: -0.0016
  kl_divergence: -22.5250
  ssim: 0.0395
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.52582, std: 0.18029

Metrics for layer 12:
  pearson_correlation: -0.0264
  kl_divergence: -24.1022
  ssim: 0.0652
  iou: 0.1264
Layer 12 metrics:
  pearson_correlation: -0.0264
  kl_divergence: -24.1022
  ssim: 0.0652
  iou: 0.1264
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer10/batch_0_strength_0.4_results.npy

Processing batch 2/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.41118, std: 0.12180

Metrics for layer 0:
  pearson_correlation: 0.0065
  kl_divergence: -3706.2190
  ssim: 0.0352
  iou: 0.1426
Layer 0 metrics:
  pearson_correlation: 0.0065
  kl_divergence: -3706.2190
  ssim: 0.0352
  iou: 0.1426

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.44578, std: 0.13043

Metrics for layer 1:
  pearson_correlation: 0.0037
  kl_divergence: -3851.6348
  ssim: 0.0292
  iou: 0.1423
Layer 1 metrics:
  pearson_correlation: 0.0037
  kl_divergence: -3851.6348
  ssim: 0.0292
  iou: 0.1423

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.41955, std: 0.12833

Metrics for layer 2:
  pearson_correlation: 0.0033
  kl_divergence: -1281.5342
  ssim: 0.0533
  iou: 0.1433
Layer 2 metrics:
  pearson_correlation: 0.0033
  kl_divergence: -1281.5342
  ssim: 0.0533
  iou: 0.1433

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.42379, std: 0.12689

Metrics for layer 3:
  pearson_correlation: -0.0101
  kl_divergence: -1290.7260
  ssim: 0.0516
  iou: 0.1393
Layer 3 metrics:
  pearson_correlation: -0.0101
  kl_divergence: -1290.7260
  ssim: 0.0516
  iou: 0.1393

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.45456, std: 0.15105

Metrics for layer 4:
  pearson_correlation: 0.0020
  kl_divergence: -361.9321
  ssim: 0.0525
  iou: 0.1404
Layer 4 metrics:
  pearson_correlation: 0.0020
  kl_divergence: -361.9321
  ssim: 0.0525
  iou: 0.1404

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.50785, std: 0.12705

Metrics for layer 5:
  pearson_correlation: -0.0058
  kl_divergence: -409.7623
  ssim: 0.0661
  iou: 0.1395
Layer 5 metrics:
  pearson_correlation: -0.0058
  kl_divergence: -409.7623
  ssim: 0.0661
  iou: 0.1395

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48744, std: 0.14757

Metrics for layer 6:
  pearson_correlation: -0.0073
  kl_divergence: -393.0870
  ssim: 0.0521
  iou: 0.1504
Layer 6 metrics:
  pearson_correlation: -0.0073
  kl_divergence: -393.0870
  ssim: 0.0521
  iou: 0.1504

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.44707, std: 0.15672

Metrics for layer 7:
  pearson_correlation: 0.0088
  kl_divergence: -81.3425
  ssim: 0.0248
  iou: 0.1329
Layer 7 metrics:
  pearson_correlation: 0.0088
  kl_divergence: -81.3425
  ssim: 0.0248
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.53733, std: 0.14718

Metrics for layer 8:
  pearson_correlation: -0.0003
  kl_divergence: -95.3990
  ssim: 0.0383
  iou: 0.1529
Layer 8 metrics:
  pearson_correlation: -0.0003
  kl_divergence: -95.3990
  ssim: 0.0383
  iou: 0.1529

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.47688, std: 0.16108

Metrics for layer 9:
  pearson_correlation: -0.0173
  kl_divergence: -86.1645
  ssim: 0.0285
  iou: 0.1329
Layer 9 metrics:
  pearson_correlation: -0.0173
  kl_divergence: -86.1645
  ssim: 0.0285
  iou: 0.1329

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.54140, std: 0.17745

Metrics for layer 10:
  pearson_correlation: -0.0609
  kl_divergence: -16.1246
  ssim: -0.0301
  iou: 0.1395
Layer 10 metrics:
  pearson_correlation: -0.0609
  kl_divergence: -16.1246
  ssim: -0.0301
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.55324, std: 0.19089

Metrics for layer 11:
  pearson_correlation: 0.0069
  kl_divergence: -20.4147
  ssim: 0.0804
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: 0.0069
  kl_divergence: -20.4147
  ssim: 0.0804
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.53624, std: 0.19022

Metrics for layer 12:
  pearson_correlation: 0.0858
  kl_divergence: -18.0756
  ssim: 0.1299
  iou: 0.2250
Layer 12 metrics:
  pearson_correlation: 0.0858
  kl_divergence: -18.0756
  ssim: 0.1299
  iou: 0.2250
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer10/batch_1_strength_0.4_results.npy

Processing attention strength 0.8
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.8 0.  0. ]

Processing batch 1/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42494, std: 0.11682

Metrics for layer 0:
  pearson_correlation: -0.0037
  kl_divergence: -4570.0151
  ssim: 0.0509
  iou: 0.1427
Layer 0 metrics:
  pearson_correlation: -0.0037
  kl_divergence: -4570.0151
  ssim: 0.0509
  iou: 0.1427

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42688, std: 0.12919

Metrics for layer 1:
  pearson_correlation: -0.0004
  kl_divergence: -4557.7979
  ssim: 0.0450
  iou: 0.1391
Layer 1 metrics:
  pearson_correlation: -0.0004
  kl_divergence: -4557.7979
  ssim: 0.0450
  iou: 0.1391

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.45178, std: 0.12845

Metrics for layer 2:
  pearson_correlation: 0.0087
  kl_divergence: -1381.9406
  ssim: 0.0601
  iou: 0.1439
Layer 2 metrics:
  pearson_correlation: 0.0087
  kl_divergence: -1381.9406
  ssim: 0.0601
  iou: 0.1439

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.47566, std: 0.11808

Metrics for layer 3:
  pearson_correlation: 0.0004
  kl_divergence: -1439.7705
  ssim: 0.0613
  iou: 0.1368
Layer 3 metrics:
  pearson_correlation: 0.0004
  kl_divergence: -1439.7705
  ssim: 0.0613
  iou: 0.1368

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.44341, std: 0.13177

Metrics for layer 4:
  pearson_correlation: 0.0193
  kl_divergence: -350.5238
  ssim: 0.0767
  iou: 0.1470
Layer 4 metrics:
  pearson_correlation: 0.0193
  kl_divergence: -350.5238
  ssim: 0.0767
  iou: 0.1470

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.48351, std: 0.15481

Metrics for layer 5:
  pearson_correlation: 0.0182
  kl_divergence: -372.8409
  ssim: 0.0520
  iou: 0.1445
Layer 5 metrics:
  pearson_correlation: 0.0182
  kl_divergence: -372.8409
  ssim: 0.0520
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.39290, std: 0.13856

Metrics for layer 6:
  pearson_correlation: 0.0043
  kl_divergence: -297.9919
  ssim: 0.0607
  iou: 0.1563
Layer 6 metrics:
  pearson_correlation: 0.0043
  kl_divergence: -297.9919
  ssim: 0.0607
  iou: 0.1563

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.49075, std: 0.15266

Metrics for layer 7:
  pearson_correlation: 0.0006
  kl_divergence: -95.0956
  ssim: 0.0596
  iou: 0.1297
Layer 7 metrics:
  pearson_correlation: 0.0006
  kl_divergence: -95.0956
  ssim: 0.0596
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.51801, std: 0.16175

Metrics for layer 8:
  pearson_correlation: 0.0519
  kl_divergence: -98.1723
  ssim: 0.0876
  iou: 0.1297
Layer 8 metrics:
  pearson_correlation: 0.0519
  kl_divergence: -98.1723
  ssim: 0.0876
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.54447, std: 0.16801

Metrics for layer 9:
  pearson_correlation: 0.0419
  kl_divergence: -103.8461
  ssim: 0.0616
  iou: 0.1496
Layer 9 metrics:
  pearson_correlation: 0.0419
  kl_divergence: -103.8461
  ssim: 0.0616
  iou: 0.1496

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.50681, std: 0.21033

Metrics for layer 10:
  pearson_correlation: 0.1111
  kl_divergence: -23.3892
  ssim: 0.1931
  iou: 0.1395
Layer 10 metrics:
  pearson_correlation: 0.1111
  kl_divergence: -23.3892
  ssim: 0.1931
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.56415, std: 0.17205

Metrics for layer 11:
  pearson_correlation: -0.1194
  kl_divergence: -21.3718
  ssim: -0.0474
  iou: 0.0889
Layer 11 metrics:
  pearson_correlation: -0.1194
  kl_divergence: -21.3718
  ssim: -0.0474
  iou: 0.0889

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.44126, std: 0.20039

Metrics for layer 12:
  pearson_correlation: 0.0791
  kl_divergence: -18.9715
  ssim: -0.0034
  iou: 0.1136
Layer 12 metrics:
  pearson_correlation: 0.0791
  kl_divergence: -18.9715
  ssim: -0.0034
  iou: 0.1136
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer10/batch_0_strength_0.8_results.npy

Processing batch 2/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.46870, std: 0.12162

Metrics for layer 0:
  pearson_correlation: -0.0037
  kl_divergence: -3965.0320
  ssim: 0.0300
  iou: 0.1414
Layer 0 metrics:
  pearson_correlation: -0.0037
  kl_divergence: -3965.0320
  ssim: 0.0300
  iou: 0.1414

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.41871, std: 0.11552

Metrics for layer 1:
  pearson_correlation: 0.0051
  kl_divergence: -3748.8203
  ssim: 0.0367
  iou: 0.1481
Layer 1 metrics:
  pearson_correlation: 0.0051
  kl_divergence: -3748.8203
  ssim: 0.0367
  iou: 0.1481

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.47228, std: 0.12290

Metrics for layer 2:
  pearson_correlation: 0.0211
  kl_divergence: -1406.2197
  ssim: 0.0556
  iou: 0.1458
Layer 2 metrics:
  pearson_correlation: 0.0211
  kl_divergence: -1406.2197
  ssim: 0.0556
  iou: 0.1458

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.47482, std: 0.13714

Metrics for layer 3:
  pearson_correlation: -0.0107
  kl_divergence: -1396.1064
  ssim: 0.0407
  iou: 0.1391
Layer 3 metrics:
  pearson_correlation: -0.0107
  kl_divergence: -1396.1064
  ssim: 0.0407
  iou: 0.1391

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.45100, std: 0.15685

Metrics for layer 4:
  pearson_correlation: 0.0014
  kl_divergence: -357.0385
  ssim: 0.0534
  iou: 0.1420
Layer 4 metrics:
  pearson_correlation: 0.0014
  kl_divergence: -357.0385
  ssim: 0.0534
  iou: 0.1420

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47365, std: 0.15239

Metrics for layer 5:
  pearson_correlation: 0.0179
  kl_divergence: -381.5999
  ssim: 0.0558
  iou: 0.1470
Layer 5 metrics:
  pearson_correlation: 0.0179
  kl_divergence: -381.5999
  ssim: 0.0558
  iou: 0.1470

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.52105, std: 0.14953

Metrics for layer 6:
  pearson_correlation: -0.0094
  kl_divergence: -416.8953
  ssim: 0.0378
  iou: 0.1521
Layer 6 metrics:
  pearson_correlation: -0.0094
  kl_divergence: -416.8953
  ssim: 0.0378
  iou: 0.1521

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.52242, std: 0.15405

Metrics for layer 7:
  pearson_correlation: -0.0304
  kl_divergence: -90.3677
  ssim: 0.0393
  iou: 0.1329
Layer 7 metrics:
  pearson_correlation: -0.0304
  kl_divergence: -90.3677
  ssim: 0.0393
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.51018, std: 0.15732

Metrics for layer 8:
  pearson_correlation: -0.0138
  kl_divergence: -88.4162
  ssim: 0.0318
  iou: 0.1105
Layer 8 metrics:
  pearson_correlation: -0.0138
  kl_divergence: -88.4162
  ssim: 0.0318
  iou: 0.1105

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.49917, std: 0.14801

Metrics for layer 9:
  pearson_correlation: 0.0076
  kl_divergence: -89.2090
  ssim: 0.0472
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: 0.0076
  kl_divergence: -89.2090
  ssim: 0.0472
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.52246, std: 0.18741

Metrics for layer 10:
  pearson_correlation: 0.0499
  kl_divergence: -20.0408
  ssim: 0.0773
  iou: 0.1136
Layer 10 metrics:
  pearson_correlation: 0.0499
  kl_divergence: -20.0408
  ssim: 0.0773
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.52808, std: 0.19537

Metrics for layer 11:
  pearson_correlation: -0.0594
  kl_divergence: -16.6332
  ssim: -0.0253
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: -0.0594
  kl_divergence: -16.6332
  ssim: -0.0253
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.54275, std: 0.15239

Metrics for layer 12:
  pearson_correlation: 0.0164
  kl_divergence: -20.0174
  ssim: 0.0555
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: 0.0164
  kl_divergence: -20.0174
  ssim: 0.0555
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer10/batch_1_strength_0.8_results.npy

Processing attention strength 1.2
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.2 0.  0. ]

Processing batch 1/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.43630, std: 0.12444

Metrics for layer 0:
  pearson_correlation: 0.0021
  kl_divergence: -4646.5547
  ssim: 0.0473
  iou: 0.1442
Layer 0 metrics:
  pearson_correlation: 0.0021
  kl_divergence: -4646.5547
  ssim: 0.0473
  iou: 0.1442

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42470, std: 0.12188

Metrics for layer 1:
  pearson_correlation: -0.0086
  kl_divergence: -4551.2153
  ssim: 0.0474
  iou: 0.1442
Layer 1 metrics:
  pearson_correlation: -0.0086
  kl_divergence: -4551.2153
  ssim: 0.0474
  iou: 0.1442

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.47572, std: 0.11937

Metrics for layer 2:
  pearson_correlation: -0.0036
  kl_divergence: -1439.6138
  ssim: 0.0546
  iou: 0.1466
Layer 2 metrics:
  pearson_correlation: -0.0036
  kl_divergence: -1439.6138
  ssim: 0.0546
  iou: 0.1466

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.45984, std: 0.12806

Metrics for layer 3:
  pearson_correlation: -0.0050
  kl_divergence: -1394.1733
  ssim: 0.0532
  iou: 0.1454
Layer 3 metrics:
  pearson_correlation: -0.0050
  kl_divergence: -1394.1733
  ssim: 0.0532
  iou: 0.1454

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.42830, std: 0.14368

Metrics for layer 4:
  pearson_correlation: -0.0243
  kl_divergence: -327.9468
  ssim: 0.0613
  iou: 0.1362
Layer 4 metrics:
  pearson_correlation: -0.0243
  kl_divergence: -327.9468
  ssim: 0.0613
  iou: 0.1362

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.48283, std: 0.15121

Metrics for layer 5:
  pearson_correlation: 0.0380
  kl_divergence: -379.5892
  ssim: 0.0723
  iou: 0.1487
Layer 5 metrics:
  pearson_correlation: 0.0380
  kl_divergence: -379.5892
  ssim: 0.0723
  iou: 0.1487

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.42888, std: 0.15549

Metrics for layer 6:
  pearson_correlation: 0.0231
  kl_divergence: -328.7891
  ssim: 0.0669
  iou: 0.1470
Layer 6 metrics:
  pearson_correlation: 0.0231
  kl_divergence: -328.7891
  ssim: 0.0669
  iou: 0.1470

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.47114, std: 0.16874

Metrics for layer 7:
  pearson_correlation: 0.0363
  kl_divergence: -86.7950
  ssim: 0.0588
  iou: 0.1362
Layer 7 metrics:
  pearson_correlation: 0.0363
  kl_divergence: -86.7950
  ssim: 0.0588
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.41218, std: 0.14852

Metrics for layer 8:
  pearson_correlation: -0.0422
  kl_divergence: -72.6649
  ssim: 0.0194
  iou: 0.1462
Layer 8 metrics:
  pearson_correlation: -0.0422
  kl_divergence: -72.6649
  ssim: 0.0194
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.43475, std: 0.16044

Metrics for layer 9:
  pearson_correlation: 0.0082
  kl_divergence: -78.5853
  ssim: 0.0421
  iou: 0.1496
Layer 9 metrics:
  pearson_correlation: 0.0082
  kl_divergence: -78.5853
  ssim: 0.0421
  iou: 0.1496

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.56747, std: 0.19893

Metrics for layer 10:
  pearson_correlation: 0.0014
  kl_divergence: -25.6646
  ssim: 0.0573
  iou: 0.1667
Layer 10 metrics:
  pearson_correlation: 0.0014
  kl_divergence: -25.6646
  ssim: 0.0573
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.53906, std: 0.17512

Metrics for layer 11:
  pearson_correlation: 0.0038
  kl_divergence: -25.3859
  ssim: 0.0910
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: 0.0038
  kl_divergence: -25.3859
  ssim: 0.0910
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.47661, std: 0.14716

Metrics for layer 12:
  pearson_correlation: 0.0258
  kl_divergence: -17.6179
  ssim: 0.0642
  iou: 0.1807
Layer 12 metrics:
  pearson_correlation: 0.0258
  kl_divergence: -17.6179
  ssim: 0.0642
  iou: 0.1807
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer10/batch_0_strength_1.2_results.npy

Processing batch 2/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.40908, std: 0.11044

Metrics for layer 0:
  pearson_correlation: 0.0122
  kl_divergence: -3714.2100
  ssim: 0.0413
  iou: 0.1494
Layer 0 metrics:
  pearson_correlation: 0.0122
  kl_divergence: -3714.2100
  ssim: 0.0413
  iou: 0.1494

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.40172, std: 0.11809

Metrics for layer 1:
  pearson_correlation: 0.0057
  kl_divergence: -3659.6497
  ssim: 0.0379
  iou: 0.1468
Layer 1 metrics:
  pearson_correlation: 0.0057
  kl_divergence: -3659.6497
  ssim: 0.0379
  iou: 0.1468

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.47748, std: 0.14138

Metrics for layer 2:
  pearson_correlation: 0.0074
  kl_divergence: -1400.9028
  ssim: 0.0424
  iou: 0.1485
Layer 2 metrics:
  pearson_correlation: 0.0074
  kl_divergence: -1400.9028
  ssim: 0.0424
  iou: 0.1485

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.46370, std: 0.13886

Metrics for layer 3:
  pearson_correlation: -0.0104
  kl_divergence: -1369.6426
  ssim: 0.0424
  iou: 0.1399
Layer 3 metrics:
  pearson_correlation: -0.0104
  kl_divergence: -1369.6426
  ssim: 0.0424
  iou: 0.1399

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.53212, std: 0.13838

Metrics for layer 4:
  pearson_correlation: -0.0227
  kl_divergence: -426.7766
  ssim: 0.0501
  iou: 0.1362
Layer 4 metrics:
  pearson_correlation: -0.0227
  kl_divergence: -426.7766
  ssim: 0.0501
  iou: 0.1362

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48164, std: 0.14844

Metrics for layer 5:
  pearson_correlation: -0.0122
  kl_divergence: -386.0465
  ssim: 0.0483
  iou: 0.1462
Layer 5 metrics:
  pearson_correlation: -0.0122
  kl_divergence: -386.0465
  ssim: 0.0483
  iou: 0.1462

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47217, std: 0.13328

Metrics for layer 6:
  pearson_correlation: 0.0095
  kl_divergence: -387.2224
  ssim: 0.0620
  iou: 0.1429
Layer 6 metrics:
  pearson_correlation: 0.0095
  kl_divergence: -387.2224
  ssim: 0.0620
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.48776, std: 0.17574

Metrics for layer 7:
  pearson_correlation: 0.0019
  kl_divergence: -85.2669
  ssim: 0.0266
  iou: 0.1529
Layer 7 metrics:
  pearson_correlation: 0.0019
  kl_divergence: -85.2669
  ssim: 0.0266
  iou: 0.1529

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.54752, std: 0.15062

Metrics for layer 8:
  pearson_correlation: -0.0075
  kl_divergence: -95.2010
  ssim: 0.0280
  iou: 0.1395
Layer 8 metrics:
  pearson_correlation: -0.0075
  kl_divergence: -95.2010
  ssim: 0.0280
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.56041, std: 0.15668

Metrics for layer 9:
  pearson_correlation: -0.0349
  kl_divergence: -95.9663
  ssim: 0.0262
  iou: 0.1462
Layer 9 metrics:
  pearson_correlation: -0.0349
  kl_divergence: -95.9663
  ssim: 0.0262
  iou: 0.1462

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.55040, std: 0.20036

Metrics for layer 10:
  pearson_correlation: -0.0013
  kl_divergence: -23.6086
  ssim: 0.0110
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: -0.0013
  kl_divergence: -23.6086
  ssim: 0.0110
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.49368, std: 0.18639

Metrics for layer 11:
  pearson_correlation: 0.1743
  kl_divergence: -21.1570
  ssim: 0.0767
  iou: 0.2727
Layer 11 metrics:
  pearson_correlation: 0.1743
  kl_divergence: -21.1570
  ssim: 0.0767
  iou: 0.2727

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.49660, std: 0.18240

Metrics for layer 12:
  pearson_correlation: 0.0308
  kl_divergence: -19.2758
  ssim: 0.1065
  iou: 0.1136
Layer 12 metrics:
  pearson_correlation: 0.0308
  kl_divergence: -19.2758
  ssim: 0.1065
  iou: 0.1136
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer10/batch_1_strength_1.2_results.npy

Analysis complete! Results saved to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer10
