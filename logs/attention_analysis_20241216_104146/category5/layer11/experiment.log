WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-12-16 11:12:42.997169: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-16 11:12:43.016509: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2024-12-16 11:12:43.016909: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4e4d5c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:12:43.016920: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-16 11:12:43.019677: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-16 11:12:43.147729: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4e41290 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:12:43.147745: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-12-16 11:12:43.148294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:2f:00.0
2024-12-16 11:12:43.149533: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:12:43.150649: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:12:43.151736: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:12:43.152808: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:12:43.153895: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:12:43.154968: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:12:43.156033: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:12:43.156045: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-12-16 11:12:43.156061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-16 11:12:43.156066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-16 11:12:43.156069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:61: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:87: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:15: sigmoid_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.sigmoid_cross_entropy instead. Note that the order of the predictions and labels arguments has been changed.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:322: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:82: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.


Verifying paths:
tc_path: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs exists
weight_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists
image_path: /scratch/hy2611/CNN_attention/Data/VGG16/images exists
save_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists

Initializing model...
('c11', [1, 224, 224, 64])
('c12', [1, 224, 224, 64])
('c21', [1, 112, 112, 128])
('c22', [1, 112, 112, 128])
('c31', [1, 56, 56, 256])
('c32', [1, 56, 56, 256])
('c33', [1, 56, 56, 256])
('c41', [1, 28, 28, 512])
('c42', [1, 28, 28, 512])
('c43', [1, 28, 28, 512])
('c51', [1, 14, 14, 512])
('c52', [1, 14, 14, 512])
('c53', [1, 14, 14, 512])
(0, 'conv1_1_W', (3, 3, 3, 64))
(1, 'conv1_1_b', (64,))
(2, 'conv1_2_W', (3, 3, 64, 64))
(3, 'conv1_2_b', (64,))
(4, 'conv2_1_W', (3, 3, 64, 128))
(5, 'conv2_1_b', (128,))
(6, 'conv2_2_W', (3, 3, 128, 128))
(7, 'conv2_2_b', (128,))
(8, 'conv3_1_W', (3, 3, 128, 256))
(9, 'conv3_1_b', (256,))
(10, 'conv3_2_W', (3, 3, 256, 256))
(11, 'conv3_2_b', (256,))
(12, 'conv3_3_W', (3, 3, 256, 256))
(13, 'conv3_3_b', (256,))
(14, 'conv4_1_W', (3, 3, 256, 512))
(15, 'conv4_1_b', (512,))
(16, 'conv4_2_W', (3, 3, 512, 512))
(17, 'conv4_2_b', (512,))
(18, 'conv4_3_W', (3, 3, 512, 512))
(19, 'conv4_3_b', (512,))
(20, 'conv5_1_W', (3, 3, 512, 512))
(21, 'conv5_1_b', (512,))
(22, 'conv5_2_W', (3, 3, 512, 512))
(23, 'conv5_2_b', (512,))
(24, 'conv5_3_W', (3, 3, 512, 512))
(25, 'conv5_3_b', (512,))
(26, 'fc6_W', (25088, 4096))
(27, 'fc6_b', (4096,))
(28, 'fc7_W', (4096, 4096))
(29, 'fc7_b', (4096,))
Checking checkpoint files:
Data file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.data-00000-of-00001 - Found
Index file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.index - Found
Loading checkpoint from: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt
Checkpoint loaded successfully

Initializing components...
Found tuning curves file: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs/featvecs20_train35_c.txt

Loading category 5 data...
Original positive images shape: (2, 224, 224, 3)

Processing data...

Processing attention strength 0.0
Attention vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

Processing batch 1/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.41771, std: 0.12181

Metrics for layer 0:
  pearson_correlation: -0.0026
  kl_divergence: -4502.5986
  ssim: 0.0478
  iou: 0.1428
Layer 0 metrics:
  pearson_correlation: -0.0026
  kl_divergence: -4502.5986
  ssim: 0.0478
  iou: 0.1428

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.39614, std: 0.10076

Metrics for layer 1:
  pearson_correlation: 0.0042
  kl_divergence: -4385.4741
  ssim: 0.0676
  iou: 0.1433
Layer 1 metrics:
  pearson_correlation: 0.0042
  kl_divergence: -4385.4741
  ssim: 0.0676
  iou: 0.1433

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.44771, std: 0.12646

Metrics for layer 2:
  pearson_correlation: -0.0105
  kl_divergence: -1369.0618
  ssim: 0.0569
  iou: 0.1399
Layer 2 metrics:
  pearson_correlation: -0.0105
  kl_divergence: -1369.0618
  ssim: 0.0569
  iou: 0.1399

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.45333, std: 0.12823

Metrics for layer 3:
  pearson_correlation: 0.0062
  kl_divergence: -1383.8644
  ssim: 0.0599
  iou: 0.1364
Layer 3 metrics:
  pearson_correlation: 0.0062
  kl_divergence: -1383.8644
  ssim: 0.0599
  iou: 0.1364

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.48038, std: 0.14182

Metrics for layer 4:
  pearson_correlation: 0.0084
  kl_divergence: -373.6163
  ssim: 0.0597
  iou: 0.1487
Layer 4 metrics:
  pearson_correlation: 0.0084
  kl_divergence: -373.6163
  ssim: 0.0597
  iou: 0.1487

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.44919, std: 0.13384

Metrics for layer 5:
  pearson_correlation: -0.0157
  kl_divergence: -350.2109
  ssim: 0.0610
  iou: 0.1338
Layer 5 metrics:
  pearson_correlation: -0.0157
  kl_divergence: -350.2109
  ssim: 0.0610
  iou: 0.1338

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.49180, std: 0.15132

Metrics for layer 6:
  pearson_correlation: -0.0039
  kl_divergence: -375.5438
  ssim: 0.0495
  iou: 0.1429
Layer 6 metrics:
  pearson_correlation: -0.0039
  kl_divergence: -375.5438
  ssim: 0.0495
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.46532, std: 0.14315

Metrics for layer 7:
  pearson_correlation: 0.0199
  kl_divergence: -86.3265
  ssim: 0.0847
  iou: 0.1168
Layer 7 metrics:
  pearson_correlation: 0.0199
  kl_divergence: -86.3265
  ssim: 0.0847
  iou: 0.1168

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.46806, std: 0.14784

Metrics for layer 8:
  pearson_correlation: -0.0177
  kl_divergence: -81.9514
  ssim: 0.0435
  iou: 0.1362
Layer 8 metrics:
  pearson_correlation: -0.0177
  kl_divergence: -81.9514
  ssim: 0.0435
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.46133, std: 0.14907

Metrics for layer 9:
  pearson_correlation: -0.0706
  kl_divergence: -78.6832
  ssim: 0.0298
  iou: 0.1329
Layer 9 metrics:
  pearson_correlation: -0.0706
  kl_divergence: -78.6832
  ssim: 0.0298
  iou: 0.1329

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.51149, std: 0.17448

Metrics for layer 10:
  pearson_correlation: 0.0113
  kl_divergence: -18.7844
  ssim: 0.0970
  iou: 0.1395
Layer 10 metrics:
  pearson_correlation: 0.0113
  kl_divergence: -18.7844
  ssim: 0.0970
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.40990, std: 0.17653

Metrics for layer 11:
  pearson_correlation: 0.0012
  kl_divergence: -10.3982
  ssim: 0.0433
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: 0.0012
  kl_divergence: -10.3982
  ssim: 0.0433
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.44534, std: 0.17430

Metrics for layer 12:
  pearson_correlation: 0.1011
  kl_divergence: -18.8711
  ssim: 0.1979
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: 0.1011
  kl_divergence: -18.8711
  ssim: 0.1979
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer11/batch_0_strength_0.0_results.npy

Processing batch 2/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.45082, std: 0.11649

Metrics for layer 0:
  pearson_correlation: 0.0079
  kl_divergence: -3899.0405
  ssim: 0.0346
  iou: 0.1458
Layer 0 metrics:
  pearson_correlation: 0.0079
  kl_divergence: -3899.0405
  ssim: 0.0346
  iou: 0.1458

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.42201, std: 0.11817

Metrics for layer 1:
  pearson_correlation: -0.0056
  kl_divergence: -3754.1333
  ssim: 0.0346
  iou: 0.1418
Layer 1 metrics:
  pearson_correlation: -0.0056
  kl_divergence: -3754.1333
  ssim: 0.0346
  iou: 0.1418

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.45952, std: 0.13260

Metrics for layer 2:
  pearson_correlation: -0.0230
  kl_divergence: -1362.1147
  ssim: 0.0458
  iou: 0.1346
Layer 2 metrics:
  pearson_correlation: -0.0230
  kl_divergence: -1362.1147
  ssim: 0.0458
  iou: 0.1346

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.39945, std: 0.10547

Metrics for layer 3:
  pearson_correlation: 0.0086
  kl_divergence: -1253.7180
  ssim: 0.0787
  iou: 0.1477
Layer 3 metrics:
  pearson_correlation: 0.0086
  kl_divergence: -1253.7180
  ssim: 0.0787
  iou: 0.1477

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.44770, std: 0.14224

Metrics for layer 4:
  pearson_correlation: 0.0385
  kl_divergence: -361.1701
  ssim: 0.0651
  iou: 0.1563
Layer 4 metrics:
  pearson_correlation: 0.0385
  kl_divergence: -361.1701
  ssim: 0.0651
  iou: 0.1563

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.44610, std: 0.14331

Metrics for layer 5:
  pearson_correlation: 0.0258
  kl_divergence: -363.2619
  ssim: 0.0550
  iou: 0.1371
Layer 5 metrics:
  pearson_correlation: 0.0258
  kl_divergence: -363.2619
  ssim: 0.0550
  iou: 0.1371

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.42244, std: 0.13753

Metrics for layer 6:
  pearson_correlation: 0.0116
  kl_divergence: -336.5865
  ssim: 0.0655
  iou: 0.1454
Layer 6 metrics:
  pearson_correlation: 0.0116
  kl_divergence: -336.5865
  ssim: 0.0655
  iou: 0.1454

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.46105, std: 0.16592

Metrics for layer 7:
  pearson_correlation: -0.0161
  kl_divergence: -80.7661
  ssim: 0.0282
  iou: 0.1462
Layer 7 metrics:
  pearson_correlation: -0.0161
  kl_divergence: -80.7661
  ssim: 0.0282
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.50679, std: 0.16761

Metrics for layer 8:
  pearson_correlation: -0.0642
  kl_divergence: -88.6122
  ssim: 0.0084
  iou: 0.1011
Layer 8 metrics:
  pearson_correlation: -0.0642
  kl_divergence: -88.6122
  ssim: 0.0084
  iou: 0.1011

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.49196, std: 0.16616

Metrics for layer 9:
  pearson_correlation: 0.0092
  kl_divergence: -87.8240
  ssim: 0.0390
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: 0.0092
  kl_divergence: -87.8240
  ssim: 0.0390
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.44969, std: 0.18572

Metrics for layer 10:
  pearson_correlation: 0.0057
  kl_divergence: -8.8609
  ssim: 0.0445
  iou: 0.1264
Layer 10 metrics:
  pearson_correlation: 0.0057
  kl_divergence: -8.8609
  ssim: 0.0445
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.54587, std: 0.16800

Metrics for layer 11:
  pearson_correlation: 0.0492
  kl_divergence: -24.9759
  ssim: 0.0707
  iou: 0.1667
Layer 11 metrics:
  pearson_correlation: 0.0492
  kl_divergence: -24.9759
  ssim: 0.0707
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.49118, std: 0.18605

Metrics for layer 12:
  pearson_correlation: 0.0307
  kl_divergence: -14.7997
  ssim: 0.1161
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: 0.0307
  kl_divergence: -14.7997
  ssim: 0.1161
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer11/batch_1_strength_0.0_results.npy

Processing attention strength 0.4
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.4 0. ]

Processing batch 1/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42241, std: 0.11751

Metrics for layer 0:
  pearson_correlation: -0.0043
  kl_divergence: -4548.5234
  ssim: 0.0511
  iou: 0.1413
Layer 0 metrics:
  pearson_correlation: -0.0043
  kl_divergence: -4548.5234
  ssim: 0.0511
  iou: 0.1413

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42960, std: 0.11802

Metrics for layer 1:
  pearson_correlation: 0.0054
  kl_divergence: -4613.2617
  ssim: 0.0490
  iou: 0.1453
Layer 1 metrics:
  pearson_correlation: 0.0054
  kl_divergence: -4613.2617
  ssim: 0.0490
  iou: 0.1453

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.49661, std: 0.13008

Metrics for layer 2:
  pearson_correlation: -0.0054
  kl_divergence: -1480.9441
  ssim: 0.0505
  iou: 0.1404
Layer 2 metrics:
  pearson_correlation: -0.0054
  kl_divergence: -1480.9441
  ssim: 0.0505
  iou: 0.1404

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.47996, std: 0.12799

Metrics for layer 3:
  pearson_correlation: 0.0041
  kl_divergence: -1445.2842
  ssim: 0.0529
  iou: 0.1445
Layer 3 metrics:
  pearson_correlation: 0.0041
  kl_divergence: -1445.2842
  ssim: 0.0529
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.48598, std: 0.14326

Metrics for layer 4:
  pearson_correlation: 0.0221
  kl_divergence: -382.2145
  ssim: 0.0641
  iou: 0.1470
Layer 4 metrics:
  pearson_correlation: 0.0221
  kl_divergence: -382.2145
  ssim: 0.0641
  iou: 0.1470

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47339, std: 0.14693

Metrics for layer 5:
  pearson_correlation: -0.0102
  kl_divergence: -367.1360
  ssim: 0.0592
  iou: 0.1454
Layer 5 metrics:
  pearson_correlation: -0.0102
  kl_divergence: -367.1360
  ssim: 0.0592
  iou: 0.1454

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47927, std: 0.15844

Metrics for layer 6:
  pearson_correlation: -0.0160
  kl_divergence: -369.2016
  ssim: 0.0524
  iou: 0.1371
Layer 6 metrics:
  pearson_correlation: -0.0160
  kl_divergence: -369.2016
  ssim: 0.0524
  iou: 0.1371

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.45798, std: 0.14968

Metrics for layer 7:
  pearson_correlation: -0.0407
  kl_divergence: -83.7796
  ssim: 0.0344
  iou: 0.1042
Layer 7 metrics:
  pearson_correlation: -0.0407
  kl_divergence: -83.7796
  ssim: 0.0344
  iou: 0.1042

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.47030, std: 0.17685

Metrics for layer 8:
  pearson_correlation: 0.0195
  kl_divergence: -86.7621
  ssim: 0.0435
  iou: 0.1395
Layer 8 metrics:
  pearson_correlation: 0.0195
  kl_divergence: -86.7621
  ssim: 0.0435
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.43691, std: 0.17540

Metrics for layer 9:
  pearson_correlation: -0.0301
  kl_divergence: -73.5004
  ssim: 0.0479
  iou: 0.1632
Layer 9 metrics:
  pearson_correlation: -0.0301
  kl_divergence: -73.5004
  ssim: 0.0479
  iou: 0.1632

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.43779, std: 0.19260

Metrics for layer 10:
  pearson_correlation: 0.0919
  kl_divergence: -17.8542
  ssim: 0.1551
  iou: 0.2099
Layer 10 metrics:
  pearson_correlation: 0.0919
  kl_divergence: -17.8542
  ssim: 0.1551
  iou: 0.2099

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.46480, std: 0.18484

Metrics for layer 11:
  pearson_correlation: 0.0446
  kl_divergence: -20.1416
  ssim: 0.1033
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: 0.0446
  kl_divergence: -20.1416
  ssim: 0.1033
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.42446, std: 0.20071

Metrics for layer 12:
  pearson_correlation: 0.0278
  kl_divergence: -15.7842
  ssim: 0.0294
  iou: 0.1264
Layer 12 metrics:
  pearson_correlation: 0.0278
  kl_divergence: -15.7842
  ssim: 0.0294
  iou: 0.1264
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer11/batch_0_strength_0.4_results.npy

Processing batch 2/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.40637, std: 0.11756

Metrics for layer 0:
  pearson_correlation: -0.0020
  kl_divergence: -3681.4727
  ssim: 0.0368
  iou: 0.1409
Layer 0 metrics:
  pearson_correlation: -0.0020
  kl_divergence: -3681.4727
  ssim: 0.0368
  iou: 0.1409

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.44629, std: 0.12857

Metrics for layer 1:
  pearson_correlation: -0.0088
  kl_divergence: -3852.5789
  ssim: 0.0290
  iou: 0.1431
Layer 1 metrics:
  pearson_correlation: -0.0088
  kl_divergence: -3852.5789
  ssim: 0.0290
  iou: 0.1431

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.48342, std: 0.12517

Metrics for layer 2:
  pearson_correlation: -0.0054
  kl_divergence: -1421.3080
  ssim: 0.0469
  iou: 0.1389
Layer 2 metrics:
  pearson_correlation: -0.0054
  kl_divergence: -1421.3080
  ssim: 0.0469
  iou: 0.1389

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.44333, std: 0.12728

Metrics for layer 3:
  pearson_correlation: -0.0007
  kl_divergence: -1335.8066
  ssim: 0.0523
  iou: 0.1443
Layer 3 metrics:
  pearson_correlation: -0.0007
  kl_divergence: -1335.8066
  ssim: 0.0523
  iou: 0.1443

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.44668, std: 0.14852

Metrics for layer 4:
  pearson_correlation: 0.0083
  kl_divergence: -354.1469
  ssim: 0.0580
  iou: 0.1371
Layer 4 metrics:
  pearson_correlation: 0.0083
  kl_divergence: -354.1469
  ssim: 0.0580
  iou: 0.1371

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.44145, std: 0.12559

Metrics for layer 5:
  pearson_correlation: -0.0135
  kl_divergence: -360.3211
  ssim: 0.0496
  iou: 0.1462
Layer 5 metrics:
  pearson_correlation: -0.0135
  kl_divergence: -360.3211
  ssim: 0.0496
  iou: 0.1462

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.50876, std: 0.13187

Metrics for layer 6:
  pearson_correlation: 0.0002
  kl_divergence: -411.6065
  ssim: 0.0535
  iou: 0.1387
Layer 6 metrics:
  pearson_correlation: 0.0002
  kl_divergence: -411.6065
  ssim: 0.0535
  iou: 0.1387

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.56029, std: 0.15135

Metrics for layer 7:
  pearson_correlation: -0.0259
  kl_divergence: -94.2101
  ssim: 0.0265
  iou: 0.1395
Layer 7 metrics:
  pearson_correlation: -0.0259
  kl_divergence: -94.2101
  ssim: 0.0265
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.55266, std: 0.16871

Metrics for layer 8:
  pearson_correlation: 0.0036
  kl_divergence: -93.7456
  ssim: 0.0275
  iou: 0.1264
Layer 8 metrics:
  pearson_correlation: 0.0036
  kl_divergence: -93.7456
  ssim: 0.0275
  iou: 0.1264

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.50206, std: 0.16280

Metrics for layer 9:
  pearson_correlation: -0.0246
  kl_divergence: -89.4816
  ssim: 0.0263
  iou: 0.1362
Layer 9 metrics:
  pearson_correlation: -0.0246
  kl_divergence: -89.4816
  ssim: 0.0263
  iou: 0.1362

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.42953, std: 0.16534

Metrics for layer 10:
  pearson_correlation: 0.0401
  kl_divergence: -12.5363
  ssim: 0.1012
  iou: 0.1951
Layer 10 metrics:
  pearson_correlation: 0.0401
  kl_divergence: -12.5363
  ssim: 0.1012
  iou: 0.1951

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.51831, std: 0.19917

Metrics for layer 11:
  pearson_correlation: 0.0725
  kl_divergence: -21.0382
  ssim: 0.0518
  iou: 0.2099
Layer 11 metrics:
  pearson_correlation: 0.0725
  kl_divergence: -21.0382
  ssim: 0.0518
  iou: 0.2099

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.42313, std: 0.19232

Metrics for layer 12:
  pearson_correlation: -0.0227
  kl_divergence: -10.9851
  ssim: -0.0310
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: -0.0227
  kl_divergence: -10.9851
  ssim: -0.0310
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer11/batch_1_strength_0.4_results.npy

Processing attention strength 0.8
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.8 0. ]

Processing batch 1/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42581, std: 0.12113

Metrics for layer 0:
  pearson_correlation: 0.0037
  kl_divergence: -4575.2983
  ssim: 0.0500
  iou: 0.1445
Layer 0 metrics:
  pearson_correlation: 0.0037
  kl_divergence: -4575.2983
  ssim: 0.0500
  iou: 0.1445

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42320, std: 0.12408

Metrics for layer 1:
  pearson_correlation: 0.0028
  kl_divergence: -4545.0645
  ssim: 0.0470
  iou: 0.1427
Layer 1 metrics:
  pearson_correlation: 0.0028
  kl_divergence: -4545.0645
  ssim: 0.0470
  iou: 0.1427

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.43873, std: 0.13101

Metrics for layer 2:
  pearson_correlation: -0.0243
  kl_divergence: -1337.9082
  ssim: 0.0513
  iou: 0.1408
Layer 2 metrics:
  pearson_correlation: -0.0243
  kl_divergence: -1337.9082
  ssim: 0.0513
  iou: 0.1408

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.43330, std: 0.13841

Metrics for layer 3:
  pearson_correlation: 0.0062
  kl_divergence: -1324.6272
  ssim: 0.0544
  iou: 0.1391
Layer 3 metrics:
  pearson_correlation: 0.0062
  kl_divergence: -1324.6272
  ssim: 0.0544
  iou: 0.1391

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.45953, std: 0.14866

Metrics for layer 4:
  pearson_correlation: 0.0262
  kl_divergence: -357.9483
  ssim: 0.0634
  iou: 0.1521
Layer 4 metrics:
  pearson_correlation: 0.0262
  kl_divergence: -357.9483
  ssim: 0.0634
  iou: 0.1521

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46994, std: 0.14673

Metrics for layer 5:
  pearson_correlation: -0.0265
  kl_divergence: -360.0011
  ssim: 0.0413
  iou: 0.1329
Layer 5 metrics:
  pearson_correlation: -0.0265
  kl_divergence: -360.0011
  ssim: 0.0413
  iou: 0.1329

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46015, std: 0.14444

Metrics for layer 6:
  pearson_correlation: 0.0118
  kl_divergence: -358.5350
  ssim: 0.0582
  iou: 0.1496
Layer 6 metrics:
  pearson_correlation: 0.0118
  kl_divergence: -358.5350
  ssim: 0.0582
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.46519, std: 0.18263

Metrics for layer 7:
  pearson_correlation: -0.0376
  kl_divergence: -72.5100
  ssim: 0.0044
  iou: 0.1297
Layer 7 metrics:
  pearson_correlation: -0.0376
  kl_divergence: -72.5100
  ssim: 0.0044
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.57469, std: 0.15108

Metrics for layer 8:
  pearson_correlation: -0.0582
  kl_divergence: -108.0797
  ssim: 0.0330
  iou: 0.1362
Layer 8 metrics:
  pearson_correlation: -0.0582
  kl_divergence: -108.0797
  ssim: 0.0330
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.47392, std: 0.15400

Metrics for layer 9:
  pearson_correlation: 0.0050
  kl_divergence: -82.1334
  ssim: 0.0416
  iou: 0.1598
Layer 9 metrics:
  pearson_correlation: 0.0050
  kl_divergence: -82.1334
  ssim: 0.0416
  iou: 0.1598

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49325, std: 0.22188

Metrics for layer 10:
  pearson_correlation: -0.0789
  kl_divergence: -19.7936
  ssim: -0.0055
  iou: 0.1011
Layer 10 metrics:
  pearson_correlation: -0.0789
  kl_divergence: -19.7936
  ssim: -0.0055
  iou: 0.1011

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.52479, std: 0.19386

Metrics for layer 11:
  pearson_correlation: -0.1140
  kl_divergence: -17.4261
  ssim: -0.0039
  iou: 0.0889
Layer 11 metrics:
  pearson_correlation: -0.1140
  kl_divergence: -17.4261
  ssim: -0.0039
  iou: 0.0889

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49608, std: 0.19783

Metrics for layer 12:
  pearson_correlation: 0.1526
  kl_divergence: -23.1806
  ssim: 0.1786
  iou: 0.1807
Layer 12 metrics:
  pearson_correlation: 0.1526
  kl_divergence: -23.1806
  ssim: 0.1786
  iou: 0.1807
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer11/batch_0_strength_0.8_results.npy

Processing batch 2/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.41988, std: 0.11407

Metrics for layer 0:
  pearson_correlation: 0.0022
  kl_divergence: -3756.6157
  ssim: 0.0372
  iou: 0.1432
Layer 0 metrics:
  pearson_correlation: 0.0022
  kl_divergence: -3756.6157
  ssim: 0.0372
  iou: 0.1432

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.41803, std: 0.11536

Metrics for layer 1:
  pearson_correlation: 0.0063
  kl_divergence: -3748.5471
  ssim: 0.0369
  iou: 0.1417
Layer 1 metrics:
  pearson_correlation: 0.0063
  kl_divergence: -3748.5471
  ssim: 0.0369
  iou: 0.1417

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.42993, std: 0.11341

Metrics for layer 2:
  pearson_correlation: 0.0167
  kl_divergence: -1317.9290
  ssim: 0.0635
  iou: 0.1424
Layer 2 metrics:
  pearson_correlation: 0.0167
  kl_divergence: -1317.9290
  ssim: 0.0635
  iou: 0.1424

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.47169, std: 0.12745

Metrics for layer 3:
  pearson_correlation: -0.0153
  kl_divergence: -1392.0796
  ssim: 0.0453
  iou: 0.1422
Layer 3 metrics:
  pearson_correlation: -0.0153
  kl_divergence: -1392.0796
  ssim: 0.0453
  iou: 0.1422

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.50696, std: 0.14591

Metrics for layer 4:
  pearson_correlation: 0.0298
  kl_divergence: -410.6175
  ssim: 0.0511
  iou: 0.1563
Layer 4 metrics:
  pearson_correlation: 0.0298
  kl_divergence: -410.6175
  ssim: 0.0511
  iou: 0.1563

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48204, std: 0.14160

Metrics for layer 5:
  pearson_correlation: 0.0256
  kl_divergence: -391.5033
  ssim: 0.0519
  iou: 0.1512
Layer 5 metrics:
  pearson_correlation: 0.0256
  kl_divergence: -391.5033
  ssim: 0.0519
  iou: 0.1512

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.45391, std: 0.15424

Metrics for layer 6:
  pearson_correlation: -0.0204
  kl_divergence: -359.0289
  ssim: 0.0527
  iou: 0.1429
Layer 6 metrics:
  pearson_correlation: -0.0204
  kl_divergence: -359.0289
  ssim: 0.0527
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.41329, std: 0.13230

Metrics for layer 7:
  pearson_correlation: -0.0529
  kl_divergence: -76.8206
  ssim: 0.0331
  iou: 0.1362
Layer 7 metrics:
  pearson_correlation: -0.0529
  kl_divergence: -76.8206
  ssim: 0.0331
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.48794, std: 0.15494

Metrics for layer 8:
  pearson_correlation: -0.0218
  kl_divergence: -87.0727
  ssim: 0.0261
  iou: 0.1429
Layer 8 metrics:
  pearson_correlation: -0.0218
  kl_divergence: -87.0727
  ssim: 0.0261
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.46873, std: 0.15889

Metrics for layer 9:
  pearson_correlation: -0.0284
  kl_divergence: -83.9173
  ssim: 0.0357
  iou: 0.1329
Layer 9 metrics:
  pearson_correlation: -0.0284
  kl_divergence: -83.9173
  ssim: 0.0357
  iou: 0.1329

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.53446, std: 0.18833

Metrics for layer 10:
  pearson_correlation: -0.0402
  kl_divergence: -14.3772
  ssim: 0.0341
  iou: 0.1667
Layer 10 metrics:
  pearson_correlation: -0.0402
  kl_divergence: -14.3772
  ssim: 0.0341
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.46368, std: 0.17656

Metrics for layer 11:
  pearson_correlation: 0.1097
  kl_divergence: -17.6582
  ssim: 0.0798
  iou: 0.1951
Layer 11 metrics:
  pearson_correlation: 0.1097
  kl_divergence: -17.6582
  ssim: 0.0798
  iou: 0.1951

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.48366, std: 0.17069

Metrics for layer 12:
  pearson_correlation: -0.0457
  kl_divergence: -16.0541
  ssim: -0.0158
  iou: 0.0889
Layer 12 metrics:
  pearson_correlation: -0.0457
  kl_divergence: -16.0541
  ssim: -0.0158
  iou: 0.0889
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer11/batch_1_strength_0.8_results.npy

Processing attention strength 1.2
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.2 0. ]

Processing batch 1/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.43723, std: 0.12626

Metrics for layer 0:
  pearson_correlation: -0.0046
  kl_divergence: -4640.4263
  ssim: 0.0435
  iou: 0.1447
Layer 0 metrics:
  pearson_correlation: -0.0046
  kl_divergence: -4640.4263
  ssim: 0.0435
  iou: 0.1447

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.44557, std: 0.12377

Metrics for layer 1:
  pearson_correlation: -0.0005
  kl_divergence: -4716.8828
  ssim: 0.0459
  iou: 0.1425
Layer 1 metrics:
  pearson_correlation: -0.0005
  kl_divergence: -4716.8828
  ssim: 0.0459
  iou: 0.1425

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.47925, std: 0.12905

Metrics for layer 2:
  pearson_correlation: -0.0146
  kl_divergence: -1438.8242
  ssim: 0.0477
  iou: 0.1381
Layer 2 metrics:
  pearson_correlation: -0.0146
  kl_divergence: -1438.8242
  ssim: 0.0477
  iou: 0.1381

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.41680, std: 0.13538

Metrics for layer 3:
  pearson_correlation: -0.0109
  kl_divergence: -1276.9163
  ssim: 0.0535
  iou: 0.1385
Layer 3 metrics:
  pearson_correlation: -0.0109
  kl_divergence: -1276.9163
  ssim: 0.0535
  iou: 0.1385

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.45684, std: 0.13678

Metrics for layer 4:
  pearson_correlation: 0.0253
  kl_divergence: -358.4784
  ssim: 0.0681
  iou: 0.1555
Layer 4 metrics:
  pearson_correlation: 0.0253
  kl_divergence: -358.4784
  ssim: 0.0681
  iou: 0.1555

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.45530, std: 0.15181

Metrics for layer 5:
  pearson_correlation: -0.0443
  kl_divergence: -345.6220
  ssim: 0.0439
  iou: 0.1313
Layer 5 metrics:
  pearson_correlation: -0.0443
  kl_divergence: -345.6220
  ssim: 0.0439
  iou: 0.1313

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.53954, std: 0.13071

Metrics for layer 6:
  pearson_correlation: 0.0194
  kl_divergence: -422.7677
  ssim: 0.0561
  iou: 0.1462
Layer 6 metrics:
  pearson_correlation: 0.0194
  kl_divergence: -422.7677
  ssim: 0.0561
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.44428, std: 0.13718

Metrics for layer 7:
  pearson_correlation: 0.0357
  kl_divergence: -84.8601
  ssim: 0.0743
  iou: 0.1362
Layer 7 metrics:
  pearson_correlation: 0.0357
  kl_divergence: -84.8601
  ssim: 0.0743
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.40938, std: 0.14871

Metrics for layer 8:
  pearson_correlation: 0.0294
  kl_divergence: -73.9341
  ssim: 0.0918
  iou: 0.1462
Layer 8 metrics:
  pearson_correlation: 0.0294
  kl_divergence: -73.9341
  ssim: 0.0918
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.47254, std: 0.16499

Metrics for layer 9:
  pearson_correlation: -0.0007
  kl_divergence: -85.4265
  ssim: 0.0610
  iou: 0.1598
Layer 9 metrics:
  pearson_correlation: -0.0007
  kl_divergence: -85.4265
  ssim: 0.0610
  iou: 0.1598

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.46204, std: 0.16649

Metrics for layer 10:
  pearson_correlation: 0.1226
  kl_divergence: -21.9215
  ssim: 0.1628
  iou: 0.1667
Layer 10 metrics:
  pearson_correlation: 0.1226
  kl_divergence: -21.9215
  ssim: 0.1628
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.35954, std: 0.16686

Metrics for layer 11:
  pearson_correlation: -0.0192
  kl_divergence: -0.2840
  ssim: 0.0855
  iou: 0.1667
Layer 11 metrics:
  pearson_correlation: -0.0192
  kl_divergence: -0.2840
  ssim: 0.0855
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.48010, std: 0.19637

Metrics for layer 12:
  pearson_correlation: 0.1283
  kl_divergence: -20.9221
  ssim: 0.0781
  iou: 0.1264
Layer 12 metrics:
  pearson_correlation: 0.1283
  kl_divergence: -20.9221
  ssim: 0.0781
  iou: 0.1264
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer11/batch_0_strength_1.2_results.npy

Processing batch 2/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.46524, std: 0.12082

Metrics for layer 0:
  pearson_correlation: -0.0005
  kl_divergence: -3953.0161
  ssim: 0.0305
  iou: 0.1425
Layer 0 metrics:
  pearson_correlation: -0.0005
  kl_divergence: -3953.0161
  ssim: 0.0305
  iou: 0.1425

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.40808, std: 0.11816

Metrics for layer 1:
  pearson_correlation: -0.0020
  kl_divergence: -3690.3599
  ssim: 0.0363
  iou: 0.1407
Layer 1 metrics:
  pearson_correlation: -0.0020
  kl_divergence: -3690.3599
  ssim: 0.0363
  iou: 0.1407

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.47051, std: 0.13535

Metrics for layer 2:
  pearson_correlation: 0.0013
  kl_divergence: -1391.4611
  ssim: 0.0457
  iou: 0.1485
Layer 2 metrics:
  pearson_correlation: 0.0013
  kl_divergence: -1391.4611
  ssim: 0.0457
  iou: 0.1485

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.45943, std: 0.13724

Metrics for layer 3:
  pearson_correlation: -0.0149
  kl_divergence: -1360.0811
  ssim: 0.0417
  iou: 0.1313
Layer 3 metrics:
  pearson_correlation: -0.0149
  kl_divergence: -1360.0811
  ssim: 0.0417
  iou: 0.1313

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.46809, std: 0.14499

Metrics for layer 4:
  pearson_correlation: -0.0558
  kl_divergence: -368.8853
  ssim: 0.0410
  iou: 0.1305
Layer 4 metrics:
  pearson_correlation: -0.0558
  kl_divergence: -368.8853
  ssim: 0.0410
  iou: 0.1305

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.50660, std: 0.14646

Metrics for layer 5:
  pearson_correlation: -0.0051
  kl_divergence: -404.9931
  ssim: 0.0487
  iou: 0.1487
Layer 5 metrics:
  pearson_correlation: -0.0051
  kl_divergence: -404.9931
  ssim: 0.0487
  iou: 0.1487

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.41893, std: 0.14356

Metrics for layer 6:
  pearson_correlation: 0.0113
  kl_divergence: -333.0086
  ssim: 0.0691
  iou: 0.1487
Layer 6 metrics:
  pearson_correlation: 0.0113
  kl_divergence: -333.0086
  ssim: 0.0691
  iou: 0.1487

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.46581, std: 0.18314

Metrics for layer 7:
  pearson_correlation: 0.0223
  kl_divergence: -83.3336
  ssim: 0.0329
  iou: 0.1329
Layer 7 metrics:
  pearson_correlation: 0.0223
  kl_divergence: -83.3336
  ssim: 0.0329
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.41857, std: 0.15691

Metrics for layer 8:
  pearson_correlation: 0.0281
  kl_divergence: -77.6527
  ssim: 0.0443
  iou: 0.1598
Layer 8 metrics:
  pearson_correlation: 0.0281
  kl_divergence: -77.6527
  ssim: 0.0443
  iou: 0.1598

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.43557, std: 0.15694

Metrics for layer 9:
  pearson_correlation: -0.0196
  kl_divergence: -78.7017
  ssim: 0.0342
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: -0.0196
  kl_divergence: -78.7017
  ssim: 0.0342
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.48922, std: 0.19249

Metrics for layer 10:
  pearson_correlation: -0.1119
  kl_divergence: -15.0636
  ssim: -0.0710
  iou: 0.1011
Layer 10 metrics:
  pearson_correlation: -0.1119
  kl_divergence: -15.0636
  ssim: -0.0710
  iou: 0.1011

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.52954, std: 0.18361

Metrics for layer 11:
  pearson_correlation: 0.0716
  kl_divergence: -8.3749
  ssim: 0.1327
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: 0.0716
  kl_divergence: -8.3749
  ssim: 0.1327
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.51004, std: 0.17421

Metrics for layer 12:
  pearson_correlation: -0.0465
  kl_divergence: -17.2229
  ssim: -0.0103
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: -0.0465
  kl_divergence: -17.2229
  ssim: -0.0103
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer11/batch_1_strength_1.2_results.npy

Analysis complete! Results saved to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer11
