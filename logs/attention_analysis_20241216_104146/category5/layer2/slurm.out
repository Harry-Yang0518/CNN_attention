Starting experiments for category 5
Running experiment for category 5, layer 0
===================================================
Starting experiment:
Category: 5
Layer: 0
Logs will be saved to: /scratch/hy2611/CNN_attention/logs/attention_analysis_20241216_104146/category5/layer0
===================================================
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-12-16 10:41:54.404802: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-16 10:41:54.423522: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2024-12-16 10:41:54.423951: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4078dc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-16 10:41:54.423970: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-16 10:41:54.426658: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-16 10:41:54.556194: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4070290 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-16 10:41:54.556213: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-12-16 10:41:54.556684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:2f:00.0
2024-12-16 10:41:54.557886: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:41:54.558944: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:41:54.559977: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:41:54.560992: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:41:54.562004: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:41:54.563034: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:41:54.564080: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:41:54.564092: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-12-16 10:41:54.564110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-16 10:41:54.564115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-16 10:41:54.564118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:61: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:87: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:15: sigmoid_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.sigmoid_cross_entropy instead. Note that the order of the predictions and labels arguments has been changed.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:322: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:82: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.


Verifying paths:
tc_path: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs exists
weight_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists
image_path: /scratch/hy2611/CNN_attention/Data/VGG16/images exists
save_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists

Initializing model...
('c11', [1, 224, 224, 64])
('c12', [1, 224, 224, 64])
('c21', [1, 112, 112, 128])
('c22', [1, 112, 112, 128])
('c31', [1, 56, 56, 256])
('c32', [1, 56, 56, 256])
('c33', [1, 56, 56, 256])
('c41', [1, 28, 28, 512])
('c42', [1, 28, 28, 512])
('c43', [1, 28, 28, 512])
('c51', [1, 14, 14, 512])
('c52', [1, 14, 14, 512])
('c53', [1, 14, 14, 512])
(0, 'conv1_1_W', (3, 3, 3, 64))
(1, 'conv1_1_b', (64,))
(2, 'conv1_2_W', (3, 3, 64, 64))
(3, 'conv1_2_b', (64,))
(4, 'conv2_1_W', (3, 3, 64, 128))
(5, 'conv2_1_b', (128,))
(6, 'conv2_2_W', (3, 3, 128, 128))
(7, 'conv2_2_b', (128,))
(8, 'conv3_1_W', (3, 3, 128, 256))
(9, 'conv3_1_b', (256,))
(10, 'conv3_2_W', (3, 3, 256, 256))
(11, 'conv3_2_b', (256,))
(12, 'conv3_3_W', (3, 3, 256, 256))
(13, 'conv3_3_b', (256,))
(14, 'conv4_1_W', (3, 3, 256, 512))
(15, 'conv4_1_b', (512,))
(16, 'conv4_2_W', (3, 3, 512, 512))
(17, 'conv4_2_b', (512,))
(18, 'conv4_3_W', (3, 3, 512, 512))
(19, 'conv4_3_b', (512,))
(20, 'conv5_1_W', (3, 3, 512, 512))
(21, 'conv5_1_b', (512,))
(22, 'conv5_2_W', (3, 3, 512, 512))
(23, 'conv5_2_b', (512,))
(24, 'conv5_3_W', (3, 3, 512, 512))
(25, 'conv5_3_b', (512,))
(26, 'fc6_W', (25088, 4096))
(27, 'fc6_b', (4096,))
(28, 'fc7_W', (4096, 4096))
(29, 'fc7_b', (4096,))
Checking checkpoint files:
Data file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.data-00000-of-00001 - Found
Index file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.index - Found
Loading checkpoint from: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt
Checkpoint loaded successfully

Initializing components...
Found tuning curves file: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs/featvecs20_train35_c.txt

Loading category 5 data...
Original positive images shape: (2, 224, 224, 3)

Processing data...

Processing attention strength 0.0
Attention vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

Processing batch 1/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.39658, std: 0.11233

Metrics for layer 0:
  pearson_correlation: 0.0023
  kl_divergence: -4356.3066
  ssim: 0.0578
  iou: 0.1431
Layer 0 metrics:
  pearson_correlation: 0.0023
  kl_divergence: -4356.3066
  ssim: 0.0578
  iou: 0.1431

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.41495, std: 0.11968

Metrics for layer 1:
  pearson_correlation: 0.0007
  kl_divergence: -4484.8804
  ssim: 0.0518
  iou: 0.1411
Layer 1 metrics:
  pearson_correlation: 0.0007
  kl_divergence: -4484.8804
  ssim: 0.0518
  iou: 0.1411

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.46754, std: 0.12959

Metrics for layer 2:
  pearson_correlation: -0.0012
  kl_divergence: -1415.9977
  ssim: 0.0518
  iou: 0.1449
Layer 2 metrics:
  pearson_correlation: -0.0012
  kl_divergence: -1415.9977
  ssim: 0.0518
  iou: 0.1449

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.46304, std: 0.14024

Metrics for layer 3:
  pearson_correlation: 0.0078
  kl_divergence: -1398.4260
  ssim: 0.0499
  iou: 0.1437
Layer 3 metrics:
  pearson_correlation: 0.0078
  kl_divergence: -1398.4260
  ssim: 0.0499
  iou: 0.1437

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46585, std: 0.13839

Metrics for layer 4:
  pearson_correlation: 0.0032
  kl_divergence: -365.8076
  ssim: 0.0640
  iou: 0.1521
Layer 4 metrics:
  pearson_correlation: 0.0032
  kl_divergence: -365.8076
  ssim: 0.0640
  iou: 0.1521

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46125, std: 0.15165

Metrics for layer 5:
  pearson_correlation: 0.0105
  kl_divergence: -356.9698
  ssim: 0.0534
  iou: 0.1581
Layer 5 metrics:
  pearson_correlation: 0.0105
  kl_divergence: -356.9698
  ssim: 0.0534
  iou: 0.1581

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.49115, std: 0.14487

Metrics for layer 6:
  pearson_correlation: -0.0343
  kl_divergence: -373.8137
  ssim: 0.0437
  iou: 0.1362
Layer 6 metrics:
  pearson_correlation: -0.0343
  kl_divergence: -373.8137
  ssim: 0.0437
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.50844, std: 0.17288

Metrics for layer 7:
  pearson_correlation: -0.0147
  kl_divergence: -95.3945
  ssim: 0.0366
  iou: 0.1329
Layer 7 metrics:
  pearson_correlation: -0.0147
  kl_divergence: -95.3945
  ssim: 0.0366
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.45104, std: 0.16098

Metrics for layer 8:
  pearson_correlation: -0.0523
  kl_divergence: -78.7661
  ssim: 0.0280
  iou: 0.1563
Layer 8 metrics:
  pearson_correlation: -0.0523
  kl_divergence: -78.7661
  ssim: 0.0280
  iou: 0.1563

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.50952, std: 0.15667

Metrics for layer 9:
  pearson_correlation: -0.0360
  kl_divergence: -95.7065
  ssim: 0.0463
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: -0.0360
  kl_divergence: -95.7065
  ssim: 0.0463
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.51631, std: 0.20867

Metrics for layer 10:
  pearson_correlation: 0.0139
  kl_divergence: -23.0499
  ssim: 0.0578
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: 0.0139
  kl_divergence: -23.0499
  ssim: 0.0578
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.45175, std: 0.19500

Metrics for layer 11:
  pearson_correlation: 0.0043
  kl_divergence: -13.3118
  ssim: -0.0286
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: 0.0043
  kl_divergence: -13.3118
  ssim: -0.0286
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.41806, std: 0.19040

Metrics for layer 12:
  pearson_correlation: 0.0969
  kl_divergence: -17.0518
  ssim: 0.0930
  iou: 0.1011
Layer 12 metrics:
  pearson_correlation: 0.0969
  kl_divergence: -17.0518
  ssim: 0.0930
  iou: 0.1011
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer0/batch_0_strength_0.0_results.npy

Processing batch 2/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.44779, std: 0.12647

Metrics for layer 0:
  pearson_correlation: 0.0055
  kl_divergence: -3871.4653
  ssim: 0.0305
  iou: 0.1446
Layer 0 metrics:
  pearson_correlation: 0.0055
  kl_divergence: -3871.4653
  ssim: 0.0305
  iou: 0.1446

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.42335, std: 0.12421

Metrics for layer 1:
  pearson_correlation: 0.0023
  kl_divergence: -3756.8896
  ssim: 0.0327
  iou: 0.1443
Layer 1 metrics:
  pearson_correlation: 0.0023
  kl_divergence: -3756.8896
  ssim: 0.0327
  iou: 0.1443

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.46721, std: 0.13962

Metrics for layer 2:
  pearson_correlation: 0.0071
  kl_divergence: -1382.3275
  ssim: 0.0437
  iou: 0.1468
Layer 2 metrics:
  pearson_correlation: 0.0071
  kl_divergence: -1382.3275
  ssim: 0.0437
  iou: 0.1468

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.47115, std: 0.12295

Metrics for layer 3:
  pearson_correlation: 0.0090
  kl_divergence: -1401.9724
  ssim: 0.0543
  iou: 0.1441
Layer 3 metrics:
  pearson_correlation: 0.0090
  kl_divergence: -1401.9724
  ssim: 0.0543
  iou: 0.1441

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.51348, std: 0.13395

Metrics for layer 4:
  pearson_correlation: -0.0207
  kl_divergence: -411.9026
  ssim: 0.0549
  iou: 0.1445
Layer 4 metrics:
  pearson_correlation: -0.0207
  kl_divergence: -411.9026
  ssim: 0.0549
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.49799, std: 0.14924

Metrics for layer 5:
  pearson_correlation: -0.0014
  kl_divergence: -401.2802
  ssim: 0.0482
  iou: 0.1445
Layer 5 metrics:
  pearson_correlation: -0.0014
  kl_divergence: -401.2802
  ssim: 0.0482
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48273, std: 0.13694

Metrics for layer 6:
  pearson_correlation: 0.0258
  kl_divergence: -393.6738
  ssim: 0.0667
  iou: 0.1649
Layer 6 metrics:
  pearson_correlation: 0.0258
  kl_divergence: -393.6738
  ssim: 0.0667
  iou: 0.1649

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.43246, std: 0.15643

Metrics for layer 7:
  pearson_correlation: -0.0060
  kl_divergence: -80.2594
  ssim: 0.0331
  iou: 0.1168
Layer 7 metrics:
  pearson_correlation: -0.0060
  kl_divergence: -80.2594
  ssim: 0.0331
  iou: 0.1168

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.49523, std: 0.14396

Metrics for layer 8:
  pearson_correlation: 0.0233
  kl_divergence: -90.0194
  ssim: 0.0442
  iou: 0.1496
Layer 8 metrics:
  pearson_correlation: 0.0233
  kl_divergence: -90.0194
  ssim: 0.0442
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.51018, std: 0.16787

Metrics for layer 9:
  pearson_correlation: 0.0098
  kl_divergence: -90.2207
  ssim: 0.0198
  iou: 0.1772
Layer 9 metrics:
  pearson_correlation: 0.0098
  kl_divergence: -90.2207
  ssim: 0.0198
  iou: 0.1772

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.53824, std: 0.17156

Metrics for layer 10:
  pearson_correlation: 0.0569
  kl_divergence: -21.3979
  ssim: 0.0590
  iou: 0.2250
Layer 10 metrics:
  pearson_correlation: 0.0569
  kl_divergence: -21.3979
  ssim: 0.0590
  iou: 0.2250

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.41958, std: 0.18601

Metrics for layer 11:
  pearson_correlation: -0.1320
  kl_divergence: -6.5692
  ssim: 0.0221
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: -0.1320
  kl_divergence: -6.5692
  ssim: 0.0221
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.53564, std: 0.20219

Metrics for layer 12:
  pearson_correlation: -0.0254
  kl_divergence: -22.1391
  ssim: 0.0089
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: -0.0254
  kl_divergence: -22.1391
  ssim: 0.0089
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer0/batch_1_strength_0.0_results.npy

Processing attention strength 0.4
Attention vector: [0.4 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.52395, std: 0.11905

Metrics for layer 0:
  pearson_correlation: -0.0053
  kl_divergence: -5249.3496
  ssim: 0.0405
  iou: 0.1405
Layer 0 metrics:
  pearson_correlation: -0.0053
  kl_divergence: -5249.3496
  ssim: 0.0405
  iou: 0.1405

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.43365, std: 0.12170

Metrics for layer 1:
  pearson_correlation: 0.0053
  kl_divergence: -4635.8804
  ssim: 0.0493
  iou: 0.1434
Layer 1 metrics:
  pearson_correlation: 0.0053
  kl_divergence: -4635.8804
  ssim: 0.0493
  iou: 0.1434

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.47221, std: 0.13079

Metrics for layer 2:
  pearson_correlation: 0.0036
  kl_divergence: -1426.1653
  ssim: 0.0496
  iou: 0.1468
Layer 2 metrics:
  pearson_correlation: 0.0036
  kl_divergence: -1426.1653
  ssim: 0.0496
  iou: 0.1468

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.49595, std: 0.12676

Metrics for layer 3:
  pearson_correlation: 0.0009
  kl_divergence: -1482.9893
  ssim: 0.0553
  iou: 0.1350
Layer 3 metrics:
  pearson_correlation: 0.0009
  kl_divergence: -1482.9893
  ssim: 0.0553
  iou: 0.1350

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.43378, std: 0.12769

Metrics for layer 4:
  pearson_correlation: 0.0192
  kl_divergence: -342.8031
  ssim: 0.0827
  iou: 0.1379
Layer 4 metrics:
  pearson_correlation: 0.0192
  kl_divergence: -342.8031
  ssim: 0.0827
  iou: 0.1379

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50611, std: 0.16602

Metrics for layer 5:
  pearson_correlation: 0.0008
  kl_divergence: -385.9115
  ssim: 0.0502
  iou: 0.1420
Layer 5 metrics:
  pearson_correlation: 0.0008
  kl_divergence: -385.9115
  ssim: 0.0502
  iou: 0.1420

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.49229, std: 0.14932

Metrics for layer 6:
  pearson_correlation: -0.0056
  kl_divergence: -381.6968
  ssim: 0.0570
  iou: 0.1420
Layer 6 metrics:
  pearson_correlation: -0.0056
  kl_divergence: -381.6968
  ssim: 0.0570
  iou: 0.1420

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.43330, std: 0.16793

Metrics for layer 7:
  pearson_correlation: -0.0061
  kl_divergence: -75.0692
  ssim: 0.0355
  iou: 0.1563
Layer 7 metrics:
  pearson_correlation: -0.0061
  kl_divergence: -75.0692
  ssim: 0.0355
  iou: 0.1563

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.51276, std: 0.15286

Metrics for layer 8:
  pearson_correlation: -0.0195
  kl_divergence: -95.9858
  ssim: 0.0307
  iou: 0.1395
Layer 8 metrics:
  pearson_correlation: -0.0195
  kl_divergence: -95.9858
  ssim: 0.0307
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.45224, std: 0.16466

Metrics for layer 9:
  pearson_correlation: -0.0626
  kl_divergence: -79.6538
  ssim: 0.0235
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: -0.0626
  kl_divergence: -79.6538
  ssim: 0.0235
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.45798, std: 0.18524

Metrics for layer 10:
  pearson_correlation: -0.0539
  kl_divergence: -6.6585
  ssim: -0.0330
  iou: 0.1264
Layer 10 metrics:
  pearson_correlation: -0.0539
  kl_divergence: -6.6585
  ssim: -0.0330
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.56191, std: 0.16773

Metrics for layer 11:
  pearson_correlation: 0.0328
  kl_divergence: -26.6955
  ssim: 0.0402
  iou: 0.2099
Layer 11 metrics:
  pearson_correlation: 0.0328
  kl_divergence: -26.6955
  ssim: 0.0402
  iou: 0.2099

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.47783, std: 0.17950

Metrics for layer 12:
  pearson_correlation: 0.1650
  kl_divergence: -22.0112
  ssim: 0.1835
  iou: 0.1136
Layer 12 metrics:
  pearson_correlation: 0.1650
  kl_divergence: -22.0112
  ssim: 0.1835
  iou: 0.1136
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer0/batch_0_strength_0.4_results.npy

Processing batch 2/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.49904, std: 0.11918

Metrics for layer 0:
  pearson_correlation: 0.0036
  kl_divergence: -4094.7229
  ssim: 0.0297
  iou: 0.1447
Layer 0 metrics:
  pearson_correlation: 0.0036
  kl_divergence: -4094.7229
  ssim: 0.0297
  iou: 0.1447

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.41189, std: 0.11296

Metrics for layer 1:
  pearson_correlation: 0.0023
  kl_divergence: -3720.6411
  ssim: 0.0383
  iou: 0.1423
Layer 1 metrics:
  pearson_correlation: 0.0023
  kl_divergence: -3720.6411
  ssim: 0.0383
  iou: 0.1423

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.45292, std: 0.13348

Metrics for layer 2:
  pearson_correlation: 0.0120
  kl_divergence: -1355.9376
  ssim: 0.0468
  iou: 0.1487
Layer 2 metrics:
  pearson_correlation: 0.0120
  kl_divergence: -1355.9376
  ssim: 0.0468
  iou: 0.1487

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.45864, std: 0.12761

Metrics for layer 3:
  pearson_correlation: -0.0040
  kl_divergence: -1369.3923
  ssim: 0.0497
  iou: 0.1452
Layer 3 metrics:
  pearson_correlation: -0.0040
  kl_divergence: -1369.3923
  ssim: 0.0497
  iou: 0.1452

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.50480, std: 0.15223

Metrics for layer 4:
  pearson_correlation: 0.0102
  kl_divergence: -403.4090
  ssim: 0.0494
  iou: 0.1546
Layer 4 metrics:
  pearson_correlation: 0.0102
  kl_divergence: -403.4090
  ssim: 0.0494
  iou: 0.1546

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.38642, std: 0.13443

Metrics for layer 5:
  pearson_correlation: -0.0611
  kl_divergence: -295.0052
  ssim: 0.0498
  iou: 0.1305
Layer 5 metrics:
  pearson_correlation: -0.0611
  kl_divergence: -295.0052
  ssim: 0.0498
  iou: 0.1305

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.45599, std: 0.14494

Metrics for layer 6:
  pearson_correlation: 0.0062
  kl_divergence: -364.7340
  ssim: 0.0544
  iou: 0.1412
Layer 6 metrics:
  pearson_correlation: 0.0062
  kl_divergence: -364.7340
  ssim: 0.0544
  iou: 0.1412

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.48854, std: 0.16365

Metrics for layer 7:
  pearson_correlation: -0.0077
  kl_divergence: -87.3911
  ssim: 0.0249
  iou: 0.1429
Layer 7 metrics:
  pearson_correlation: -0.0077
  kl_divergence: -87.3911
  ssim: 0.0249
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.53108, std: 0.16126

Metrics for layer 8:
  pearson_correlation: -0.0008
  kl_divergence: -93.6781
  ssim: 0.0420
  iou: 0.1429
Layer 8 metrics:
  pearson_correlation: -0.0008
  kl_divergence: -93.6781
  ssim: 0.0420
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.48628, std: 0.15065

Metrics for layer 9:
  pearson_correlation: -0.0342
  kl_divergence: -87.5290
  ssim: 0.0326
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: -0.0342
  kl_divergence: -87.5290
  ssim: 0.0326
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.48469, std: 0.18496

Metrics for layer 10:
  pearson_correlation: 0.0439
  kl_divergence: -15.8025
  ssim: 0.0281
  iou: 0.1667
Layer 10 metrics:
  pearson_correlation: 0.0439
  kl_divergence: -15.8025
  ssim: 0.0281
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.54807, std: 0.18128

Metrics for layer 11:
  pearson_correlation: -0.0489
  kl_divergence: -12.7790
  ssim: 0.0082
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: -0.0489
  kl_divergence: -12.7790
  ssim: 0.0082
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.43901, std: 0.15619

Metrics for layer 12:
  pearson_correlation: -0.0982
  kl_divergence: -12.8026
  ssim: -0.0409
  iou: 0.1011
Layer 12 metrics:
  pearson_correlation: -0.0982
  kl_divergence: -12.8026
  ssim: -0.0409
  iou: 0.1011
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer0/batch_1_strength_0.4_results.npy

Processing attention strength 0.8
Attention vector: [0.8 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.51735, std: 0.10988

Metrics for layer 0:
  pearson_correlation: 0.0049
  kl_divergence: -5231.2666
  ssim: 0.0473
  iou: 0.1455
Layer 0 metrics:
  pearson_correlation: 0.0049
  kl_divergence: -5231.2666
  ssim: 0.0473
  iou: 0.1455

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.45654, std: 0.11797

Metrics for layer 1:
  pearson_correlation: -0.0004
  kl_divergence: -4808.3853
  ssim: 0.0468
  iou: 0.1453
Layer 1 metrics:
  pearson_correlation: -0.0004
  kl_divergence: -4808.3853
  ssim: 0.0468
  iou: 0.1453

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.46319, std: 0.12723

Metrics for layer 2:
  pearson_correlation: -0.0087
  kl_divergence: -1404.7703
  ssim: 0.0542
  iou: 0.1366
Layer 2 metrics:
  pearson_correlation: -0.0087
  kl_divergence: -1404.7703
  ssim: 0.0542
  iou: 0.1366

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.47248, std: 0.13176

Metrics for layer 3:
  pearson_correlation: -0.0022
  kl_divergence: -1425.6234
  ssim: 0.0541
  iou: 0.1387
Layer 3 metrics:
  pearson_correlation: -0.0022
  kl_divergence: -1425.6234
  ssim: 0.0541
  iou: 0.1387

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.43237, std: 0.14951

Metrics for layer 4:
  pearson_correlation: -0.0158
  kl_divergence: -328.6906
  ssim: 0.0610
  iou: 0.1387
Layer 4 metrics:
  pearson_correlation: -0.0158
  kl_divergence: -328.6906
  ssim: 0.0610
  iou: 0.1387

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46019, std: 0.15209

Metrics for layer 5:
  pearson_correlation: -0.0006
  kl_divergence: -351.5083
  ssim: 0.0516
  iou: 0.1470
Layer 5 metrics:
  pearson_correlation: -0.0006
  kl_divergence: -351.5083
  ssim: 0.0516
  iou: 0.1470

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.51605, std: 0.15351

Metrics for layer 6:
  pearson_correlation: 0.0125
  kl_divergence: -399.3014
  ssim: 0.0461
  iou: 0.1470
Layer 6 metrics:
  pearson_correlation: 0.0125
  kl_divergence: -399.3014
  ssim: 0.0461
  iou: 0.1470

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.51375, std: 0.18242

Metrics for layer 7:
  pearson_correlation: 0.0195
  kl_divergence: -96.3281
  ssim: 0.0571
  iou: 0.1362
Layer 7 metrics:
  pearson_correlation: 0.0195
  kl_divergence: -96.3281
  ssim: 0.0571
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.51512, std: 0.16298

Metrics for layer 8:
  pearson_correlation: -0.0028
  kl_divergence: -98.5538
  ssim: 0.0503
  iou: 0.1329
Layer 8 metrics:
  pearson_correlation: -0.0028
  kl_divergence: -98.5538
  ssim: 0.0503
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.52114, std: 0.15995

Metrics for layer 9:
  pearson_correlation: 0.0008
  kl_divergence: -99.9690
  ssim: 0.0352
  iou: 0.1362
Layer 9 metrics:
  pearson_correlation: 0.0008
  kl_divergence: -99.9690
  ssim: 0.0352
  iou: 0.1362

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.54228, std: 0.16419

Metrics for layer 10:
  pearson_correlation: -0.1800
  kl_divergence: -11.9405
  ssim: -0.1338
  iou: 0.0652
Layer 10 metrics:
  pearson_correlation: -0.1800
  kl_divergence: -11.9405
  ssim: -0.1338
  iou: 0.0652

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49600, std: 0.18182

Metrics for layer 11:
  pearson_correlation: -0.0481
  kl_divergence: -21.4458
  ssim: 0.0232
  iou: 0.0769
Layer 11 metrics:
  pearson_correlation: -0.0481
  kl_divergence: -21.4458
  ssim: 0.0232
  iou: 0.0769

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.52573, std: 0.18298

Metrics for layer 12:
  pearson_correlation: -0.0702
  kl_divergence: -24.4642
  ssim: 0.0103
  iou: 0.0769
Layer 12 metrics:
  pearson_correlation: -0.0702
  kl_divergence: -24.4642
  ssim: 0.0103
  iou: 0.0769
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer0/batch_0_strength_0.8_results.npy

Processing batch 2/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.50529, std: 0.11513

Metrics for layer 0:
  pearson_correlation: 0.0102
  kl_divergence: -4125.5361
  ssim: 0.0309
  iou: 0.1457
Layer 0 metrics:
  pearson_correlation: 0.0102
  kl_divergence: -4125.5361
  ssim: 0.0309
  iou: 0.1457

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43751, std: 0.12912

Metrics for layer 1:
  pearson_correlation: -0.0098
  kl_divergence: -3808.9680
  ssim: 0.0292
  iou: 0.1401
Layer 1 metrics:
  pearson_correlation: -0.0098
  kl_divergence: -3808.9680
  ssim: 0.0292
  iou: 0.1401

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.42878, std: 0.12886

Metrics for layer 2:
  pearson_correlation: 0.0094
  kl_divergence: -1304.5083
  ssim: 0.0555
  iou: 0.1456
Layer 2 metrics:
  pearson_correlation: 0.0094
  kl_divergence: -1304.5083
  ssim: 0.0555
  iou: 0.1456

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.46321, std: 0.12929

Metrics for layer 3:
  pearson_correlation: 0.0029
  kl_divergence: -1380.5278
  ssim: 0.0482
  iou: 0.1408
Layer 3 metrics:
  pearson_correlation: 0.0029
  kl_divergence: -1380.5278
  ssim: 0.0482
  iou: 0.1408

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48656, std: 0.15107

Metrics for layer 4:
  pearson_correlation: -0.0011
  kl_divergence: -392.1363
  ssim: 0.0561
  iou: 0.1454
Layer 4 metrics:
  pearson_correlation: -0.0011
  kl_divergence: -392.1363
  ssim: 0.0561
  iou: 0.1454

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.46544, std: 0.14702

Metrics for layer 5:
  pearson_correlation: -0.0224
  kl_divergence: -372.4256
  ssim: 0.0387
  iou: 0.1354
Layer 5 metrics:
  pearson_correlation: -0.0224
  kl_divergence: -372.4256
  ssim: 0.0387
  iou: 0.1354

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.44868, std: 0.14956

Metrics for layer 6:
  pearson_correlation: -0.0258
  kl_divergence: -347.7662
  ssim: 0.0424
  iou: 0.1362
Layer 6 metrics:
  pearson_correlation: -0.0258
  kl_divergence: -347.7662
  ssim: 0.0424
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.44437, std: 0.16879

Metrics for layer 7:
  pearson_correlation: 0.0058
  kl_divergence: -80.4262
  ssim: 0.0315
  iou: 0.1429
Layer 7 metrics:
  pearson_correlation: 0.0058
  kl_divergence: -80.4262
  ssim: 0.0315
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.44910, std: 0.15109

Metrics for layer 8:
  pearson_correlation: -0.0670
  kl_divergence: -80.7997
  ssim: 0.0163
  iou: 0.1264
Layer 8 metrics:
  pearson_correlation: -0.0670
  kl_divergence: -80.7997
  ssim: 0.0163
  iou: 0.1264

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.52938, std: 0.15847

Metrics for layer 9:
  pearson_correlation: -0.0243
  kl_divergence: -90.5745
  ssim: 0.0299
  iou: 0.1329
Layer 9 metrics:
  pearson_correlation: -0.0243
  kl_divergence: -90.5745
  ssim: 0.0299
  iou: 0.1329

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.41861, std: 0.18076

Metrics for layer 10:
  pearson_correlation: 0.1041
  kl_divergence: -13.2832
  ssim: 0.1651
  iou: 0.1807
Layer 10 metrics:
  pearson_correlation: 0.1041
  kl_divergence: -13.2832
  ssim: 0.1651
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.55493, std: 0.19447

Metrics for layer 11:
  pearson_correlation: -0.0775
  kl_divergence: -22.3194
  ssim: 0.0345
  iou: 0.0889
Layer 11 metrics:
  pearson_correlation: -0.0775
  kl_divergence: -22.3194
  ssim: 0.0345
  iou: 0.0889

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.38850, std: 0.16026

Metrics for layer 12:
  pearson_correlation: 0.0824
  kl_divergence: -7.9717
  ssim: 0.1408
  iou: 0.2099
Layer 12 metrics:
  pearson_correlation: 0.0824
  kl_divergence: -7.9717
  ssim: 0.1408
  iou: 0.2099
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer0/batch_1_strength_0.8_results.npy

Processing attention strength 1.2
Attention vector: [1.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.48380, std: 0.12092

Metrics for layer 0:
  pearson_correlation: -0.0041
  kl_divergence: -4986.5767
  ssim: 0.0422
  iou: 0.1434
Layer 0 metrics:
  pearson_correlation: -0.0041
  kl_divergence: -4986.5767
  ssim: 0.0422
  iou: 0.1434

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.39835, std: 0.12371

Metrics for layer 1:
  pearson_correlation: 0.0049
  kl_divergence: -4341.8892
  ssim: 0.0518
  iou: 0.1436
Layer 1 metrics:
  pearson_correlation: 0.0049
  kl_divergence: -4341.8892
  ssim: 0.0518
  iou: 0.1436

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.48323, std: 0.12469

Metrics for layer 2:
  pearson_correlation: 0.0050
  kl_divergence: -1455.2832
  ssim: 0.0546
  iou: 0.1475
Layer 2 metrics:
  pearson_correlation: 0.0050
  kl_divergence: -1455.2832
  ssim: 0.0546
  iou: 0.1475

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.49027, std: 0.12473

Metrics for layer 3:
  pearson_correlation: -0.0016
  kl_divergence: -1471.3071
  ssim: 0.0580
  iou: 0.1366
Layer 3 metrics:
  pearson_correlation: -0.0016
  kl_divergence: -1471.3071
  ssim: 0.0580
  iou: 0.1366

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46110, std: 0.13999

Metrics for layer 4:
  pearson_correlation: -0.0043
  kl_divergence: -359.8649
  ssim: 0.0546
  iou: 0.1496
Layer 4 metrics:
  pearson_correlation: -0.0043
  kl_divergence: -359.8649
  ssim: 0.0546
  iou: 0.1496

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.45819, std: 0.14305

Metrics for layer 5:
  pearson_correlation: -0.0070
  kl_divergence: -357.6678
  ssim: 0.0498
  iou: 0.1346
Layer 5 metrics:
  pearson_correlation: -0.0070
  kl_divergence: -357.6678
  ssim: 0.0498
  iou: 0.1346

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.44858, std: 0.15022

Metrics for layer 6:
  pearson_correlation: 0.0499
  kl_divergence: -345.4122
  ssim: 0.0633
  iou: 0.1598
Layer 6 metrics:
  pearson_correlation: 0.0499
  kl_divergence: -345.4122
  ssim: 0.0633
  iou: 0.1598

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.50641, std: 0.17115

Metrics for layer 7:
  pearson_correlation: 0.0079
  kl_divergence: -88.1313
  ssim: 0.0605
  iou: 0.1737
Layer 7 metrics:
  pearson_correlation: 0.0079
  kl_divergence: -88.1313
  ssim: 0.0605
  iou: 0.1737

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.50465, std: 0.14955

Metrics for layer 8:
  pearson_correlation: 0.0377
  kl_divergence: -93.0857
  ssim: 0.0701
  iou: 0.1701
Layer 8 metrics:
  pearson_correlation: 0.0377
  kl_divergence: -93.0857
  ssim: 0.0701
  iou: 0.1701

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.52321, std: 0.15870

Metrics for layer 9:
  pearson_correlation: -0.0686
  kl_divergence: -98.1588
  ssim: 0.0126
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: -0.0686
  kl_divergence: -98.1588
  ssim: 0.0126
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.58498, std: 0.15810

Metrics for layer 10:
  pearson_correlation: 0.0396
  kl_divergence: -24.3368
  ssim: 0.0704
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: 0.0396
  kl_divergence: -24.3368
  ssim: 0.0704
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.35413, std: 0.16008

Metrics for layer 11:
  pearson_correlation: -0.0036
  kl_divergence: -5.2516
  ssim: 0.0471
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: -0.0036
  kl_divergence: -5.2516
  ssim: 0.0471
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.57583, std: 0.16373

Metrics for layer 12:
  pearson_correlation: 0.0190
  kl_divergence: -23.4003
  ssim: 0.0661
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: 0.0190
  kl_divergence: -23.4003
  ssim: 0.0661
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer0/batch_0_strength_1.2_results.npy

Processing batch 2/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.50348, std: 0.12089

Metrics for layer 0:
  pearson_correlation: 0.0085
  kl_divergence: -4111.2407
  ssim: 0.0292
  iou: 0.1445
Layer 0 metrics:
  pearson_correlation: 0.0085
  kl_divergence: -4111.2407
  ssim: 0.0292
  iou: 0.1445

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.41993, std: 0.11587

Metrics for layer 1:
  pearson_correlation: -0.0070
  kl_divergence: -3749.9216
  ssim: 0.0362
  iou: 0.1400
Layer 1 metrics:
  pearson_correlation: -0.0070
  kl_divergence: -3749.9216
  ssim: 0.0362
  iou: 0.1400

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.47372, std: 0.13258

Metrics for layer 2:
  pearson_correlation: -0.0084
  kl_divergence: -1393.4402
  ssim: 0.0428
  iou: 0.1441
Layer 2 metrics:
  pearson_correlation: -0.0084
  kl_divergence: -1393.4402
  ssim: 0.0428
  iou: 0.1441

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.42434, std: 0.13705

Metrics for layer 3:
  pearson_correlation: 0.0051
  kl_divergence: -1287.0330
  ssim: 0.0527
  iou: 0.1431
Layer 3 metrics:
  pearson_correlation: 0.0051
  kl_divergence: -1287.0330
  ssim: 0.0527
  iou: 0.1431

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.46756, std: 0.10955

Metrics for layer 4:
  pearson_correlation: -0.0206
  kl_divergence: -385.5840
  ssim: 0.0658
  iou: 0.1338
Layer 4 metrics:
  pearson_correlation: -0.0206
  kl_divergence: -385.5840
  ssim: 0.0658
  iou: 0.1338

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.45647, std: 0.12972

Metrics for layer 5:
  pearson_correlation: -0.0123
  kl_divergence: -371.5886
  ssim: 0.0685
  iou: 0.1379
Layer 5 metrics:
  pearson_correlation: -0.0123
  kl_divergence: -371.5886
  ssim: 0.0685
  iou: 0.1379

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48507, std: 0.13527

Metrics for layer 6:
  pearson_correlation: 0.0021
  kl_divergence: -391.5260
  ssim: 0.0612
  iou: 0.1379
Layer 6 metrics:
  pearson_correlation: 0.0021
  kl_divergence: -391.5260
  ssim: 0.0612
  iou: 0.1379

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.50095, std: 0.15663

Metrics for layer 7:
  pearson_correlation: 0.0253
  kl_divergence: -87.2313
  ssim: 0.0427
  iou: 0.1395
Layer 7 metrics:
  pearson_correlation: 0.0253
  kl_divergence: -87.2313
  ssim: 0.0427
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.44622, std: 0.17103

Metrics for layer 8:
  pearson_correlation: -0.0534
  kl_divergence: -77.8167
  ssim: 0.0208
  iou: 0.1105
Layer 8 metrics:
  pearson_correlation: -0.0534
  kl_divergence: -77.8167
  ssim: 0.0208
  iou: 0.1105

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.46855, std: 0.16723

Metrics for layer 9:
  pearson_correlation: 0.0250
  kl_divergence: -84.3542
  ssim: 0.0461
  iou: 0.1496
Layer 9 metrics:
  pearson_correlation: 0.0250
  kl_divergence: -84.3542
  ssim: 0.0461
  iou: 0.1496

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.52089, std: 0.19417

Metrics for layer 10:
  pearson_correlation: 0.0702
  kl_divergence: -19.7176
  ssim: 0.1106
  iou: 0.2099
Layer 10 metrics:
  pearson_correlation: 0.0702
  kl_divergence: -19.7176
  ssim: 0.1106
  iou: 0.2099

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.51532, std: 0.21214

Metrics for layer 11:
  pearson_correlation: 0.0397
  kl_divergence: -19.8900
  ssim: 0.1020
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: 0.0397
  kl_divergence: -19.8900
  ssim: 0.1020
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.47083, std: 0.19597

Metrics for layer 12:
  pearson_correlation: 0.1391
  kl_divergence: -19.8885
  ssim: 0.0955
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: 0.1391
  kl_divergence: -19.8885
  ssim: 0.0955
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer0/batch_1_strength_1.2_results.npy

Analysis complete! Results saved to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer0
Completed experiment for category 5, layer 0
----------------------------------------
Running experiment for category 5, layer 1
===================================================
Starting experiment:
Category: 5
Layer: 1
Logs will be saved to: /scratch/hy2611/CNN_attention/logs/attention_analysis_20241216_104146/category5/layer1
===================================================
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-12-16 10:44:35.690893: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-16 10:44:35.698362: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2024-12-16 10:44:35.698668: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x50ef710 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-16 10:44:35.698678: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-16 10:44:35.701349: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-16 10:44:35.840880: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x50e76e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-16 10:44:35.840898: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-12-16 10:44:35.841455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:2f:00.0
2024-12-16 10:44:35.842534: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:44:35.843496: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:44:35.844447: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:44:35.845513: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:44:35.846441: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:44:35.847351: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:44:35.848268: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:44:35.848279: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-12-16 10:44:35.848296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-16 10:44:35.848301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-16 10:44:35.848304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:61: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:87: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:15: sigmoid_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.sigmoid_cross_entropy instead. Note that the order of the predictions and labels arguments has been changed.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:322: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:82: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.


Verifying paths:
tc_path: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs exists
weight_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists
image_path: /scratch/hy2611/CNN_attention/Data/VGG16/images exists
save_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists

Initializing model...
('c11', [1, 224, 224, 64])
('c12', [1, 224, 224, 64])
('c21', [1, 112, 112, 128])
('c22', [1, 112, 112, 128])
('c31', [1, 56, 56, 256])
('c32', [1, 56, 56, 256])
('c33', [1, 56, 56, 256])
('c41', [1, 28, 28, 512])
('c42', [1, 28, 28, 512])
('c43', [1, 28, 28, 512])
('c51', [1, 14, 14, 512])
('c52', [1, 14, 14, 512])
('c53', [1, 14, 14, 512])
(0, 'conv1_1_W', (3, 3, 3, 64))
(1, 'conv1_1_b', (64,))
(2, 'conv1_2_W', (3, 3, 64, 64))
(3, 'conv1_2_b', (64,))
(4, 'conv2_1_W', (3, 3, 64, 128))
(5, 'conv2_1_b', (128,))
(6, 'conv2_2_W', (3, 3, 128, 128))
(7, 'conv2_2_b', (128,))
(8, 'conv3_1_W', (3, 3, 128, 256))
(9, 'conv3_1_b', (256,))
(10, 'conv3_2_W', (3, 3, 256, 256))
(11, 'conv3_2_b', (256,))
(12, 'conv3_3_W', (3, 3, 256, 256))
(13, 'conv3_3_b', (256,))
(14, 'conv4_1_W', (3, 3, 256, 512))
(15, 'conv4_1_b', (512,))
(16, 'conv4_2_W', (3, 3, 512, 512))
(17, 'conv4_2_b', (512,))
(18, 'conv4_3_W', (3, 3, 512, 512))
(19, 'conv4_3_b', (512,))
(20, 'conv5_1_W', (3, 3, 512, 512))
(21, 'conv5_1_b', (512,))
(22, 'conv5_2_W', (3, 3, 512, 512))
(23, 'conv5_2_b', (512,))
(24, 'conv5_3_W', (3, 3, 512, 512))
(25, 'conv5_3_b', (512,))
(26, 'fc6_W', (25088, 4096))
(27, 'fc6_b', (4096,))
(28, 'fc7_W', (4096, 4096))
(29, 'fc7_b', (4096,))
Checking checkpoint files:
Data file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.data-00000-of-00001 - Found
Index file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.index - Found
Loading checkpoint from: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt
Checkpoint loaded successfully

Initializing components...
Found tuning curves file: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs/featvecs20_train35_c.txt

Loading category 5 data...
Original positive images shape: (2, 224, 224, 3)

Processing data...

Processing attention strength 0.0
Attention vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

Processing batch 1/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.44372, std: 0.12503

Metrics for layer 0:
  pearson_correlation: 0.0009
  kl_divergence: -4698.9736
  ssim: 0.0454
  iou: 0.1415
Layer 0 metrics:
  pearson_correlation: 0.0009
  kl_divergence: -4698.9736
  ssim: 0.0454
  iou: 0.1415

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.40185, std: 0.12029

Metrics for layer 1:
  pearson_correlation: -0.0006
  kl_divergence: -4375.1567
  ssim: 0.0511
  iou: 0.1426
Layer 1 metrics:
  pearson_correlation: -0.0006
  kl_divergence: -4375.1567
  ssim: 0.0511
  iou: 0.1426

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.42090, std: 0.12677

Metrics for layer 2:
  pearson_correlation: -0.0125
  kl_divergence: -1297.1346
  ssim: 0.0561
  iou: 0.1393
Layer 2 metrics:
  pearson_correlation: -0.0125
  kl_divergence: -1297.1346
  ssim: 0.0561
  iou: 0.1393

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.44003, std: 0.13255

Metrics for layer 3:
  pearson_correlation: 0.0053
  kl_divergence: -1347.8384
  ssim: 0.0556
  iou: 0.1404
Layer 3 metrics:
  pearson_correlation: 0.0053
  kl_divergence: -1347.8384
  ssim: 0.0556
  iou: 0.1404

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46055, std: 0.13668

Metrics for layer 4:
  pearson_correlation: -0.0070
  kl_divergence: -362.3446
  ssim: 0.0595
  iou: 0.1264
Layer 4 metrics:
  pearson_correlation: -0.0070
  kl_divergence: -362.3446
  ssim: 0.0595
  iou: 0.1264

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50377, std: 0.14644

Metrics for layer 5:
  pearson_correlation: -0.0085
  kl_divergence: -390.5598
  ssim: 0.0446
  iou: 0.1420
Layer 5 metrics:
  pearson_correlation: -0.0085
  kl_divergence: -390.5598
  ssim: 0.0446
  iou: 0.1420

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50699, std: 0.15060

Metrics for layer 6:
  pearson_correlation: -0.0145
  kl_divergence: -391.5804
  ssim: 0.0530
  iou: 0.1437
Layer 6 metrics:
  pearson_correlation: -0.0145
  kl_divergence: -391.5804
  ssim: 0.0530
  iou: 0.1437

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.44368, std: 0.16577

Metrics for layer 7:
  pearson_correlation: 0.0696
  kl_divergence: -82.8287
  ssim: 0.0830
  iou: 0.1737
Layer 7 metrics:
  pearson_correlation: 0.0696
  kl_divergence: -82.8287
  ssim: 0.0830
  iou: 0.1737

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.48769, std: 0.15351

Metrics for layer 8:
  pearson_correlation: -0.0073
  kl_divergence: -92.3872
  ssim: 0.0462
  iou: 0.1429
Layer 8 metrics:
  pearson_correlation: -0.0073
  kl_divergence: -92.3872
  ssim: 0.0462
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.54397, std: 0.15906

Metrics for layer 9:
  pearson_correlation: -0.0843
  kl_divergence: -98.0822
  ssim: -0.0005
  iou: 0.1232
Layer 9 metrics:
  pearson_correlation: -0.0843
  kl_divergence: -98.0822
  ssim: -0.0005
  iou: 0.1232

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.43943, std: 0.17577

Metrics for layer 10:
  pearson_correlation: -0.0012
  kl_divergence: -17.5698
  ssim: 0.0346
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: -0.0012
  kl_divergence: -17.5698
  ssim: 0.0346
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.48424, std: 0.20428

Metrics for layer 11:
  pearson_correlation: -0.0097
  kl_divergence: -19.1959
  ssim: 0.0284
  iou: 0.1011
Layer 11 metrics:
  pearson_correlation: -0.0097
  kl_divergence: -19.1959
  ssim: 0.0284
  iou: 0.1011

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.41528, std: 0.17867

Metrics for layer 12:
  pearson_correlation: 0.0096
  kl_divergence: -14.1534
  ssim: 0.0491
  iou: 0.1264
Layer 12 metrics:
  pearson_correlation: 0.0096
  kl_divergence: -14.1534
  ssim: 0.0491
  iou: 0.1264
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer1/batch_0_strength_0.0_results.npy

Processing batch 2/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.42483, std: 0.12865

Metrics for layer 0:
  pearson_correlation: -0.0035
  kl_divergence: -3753.6528
  ssim: 0.0304
  iou: 0.1419
Layer 0 metrics:
  pearson_correlation: -0.0035
  kl_divergence: -3753.6528
  ssim: 0.0304
  iou: 0.1419

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43015, std: 0.11891

Metrics for layer 1:
  pearson_correlation: -0.0110
  kl_divergence: -3789.7854
  ssim: 0.0336
  iou: 0.1412
Layer 1 metrics:
  pearson_correlation: -0.0110
  kl_divergence: -3789.7854
  ssim: 0.0336
  iou: 0.1412

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.39616, std: 0.11476

Metrics for layer 2:
  pearson_correlation: 0.0005
  kl_divergence: -1234.7073
  ssim: 0.0684
  iou: 0.1449
Layer 2 metrics:
  pearson_correlation: 0.0005
  kl_divergence: -1234.7073
  ssim: 0.0684
  iou: 0.1449

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.47740, std: 0.12750

Metrics for layer 3:
  pearson_correlation: -0.0062
  kl_divergence: -1407.1215
  ssim: 0.0480
  iou: 0.1393
Layer 3 metrics:
  pearson_correlation: -0.0062
  kl_divergence: -1407.1215
  ssim: 0.0480
  iou: 0.1393

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.51182, std: 0.12782

Metrics for layer 4:
  pearson_correlation: -0.0105
  kl_divergence: -416.4832
  ssim: 0.0515
  iou: 0.1371
Layer 4 metrics:
  pearson_correlation: -0.0105
  kl_divergence: -416.4832
  ssim: 0.0515
  iou: 0.1371

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.41682, std: 0.13975

Metrics for layer 5:
  pearson_correlation: -0.0001
  kl_divergence: -326.9590
  ssim: 0.0627
  iou: 0.1454
Layer 5 metrics:
  pearson_correlation: -0.0001
  kl_divergence: -326.9590
  ssim: 0.0627
  iou: 0.1454

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.50623, std: 0.14436

Metrics for layer 6:
  pearson_correlation: 0.0326
  kl_divergence: -411.0579
  ssim: 0.0632
  iou: 0.1496
Layer 6 metrics:
  pearson_correlation: 0.0326
  kl_divergence: -411.0579
  ssim: 0.0632
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.40266, std: 0.14864

Metrics for layer 7:
  pearson_correlation: -0.0178
  kl_divergence: -72.0599
  ssim: 0.0358
  iou: 0.1496
Layer 7 metrics:
  pearson_correlation: -0.0178
  kl_divergence: -72.0599
  ssim: 0.0358
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.56029, std: 0.14856

Metrics for layer 8:
  pearson_correlation: 0.0066
  kl_divergence: -96.3391
  ssim: 0.0271
  iou: 0.1632
Layer 8 metrics:
  pearson_correlation: 0.0066
  kl_divergence: -96.3391
  ssim: 0.0271
  iou: 0.1632

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.47888, std: 0.14097

Metrics for layer 9:
  pearson_correlation: -0.0049
  kl_divergence: -87.4797
  ssim: 0.0500
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: -0.0049
  kl_divergence: -87.4797
  ssim: 0.0500
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.45788, std: 0.19410

Metrics for layer 10:
  pearson_correlation: 0.0067
  kl_divergence: -8.1384
  ssim: 0.0373
  iou: 0.1395
Layer 10 metrics:
  pearson_correlation: 0.0067
  kl_divergence: -8.1384
  ssim: 0.0373
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.53245, std: 0.19626

Metrics for layer 11:
  pearson_correlation: 0.0218
  kl_divergence: -17.6240
  ssim: 0.0479
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: 0.0218
  kl_divergence: -17.6240
  ssim: 0.0479
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.51917, std: 0.18491

Metrics for layer 12:
  pearson_correlation: 0.0329
  kl_divergence: -20.1833
  ssim: 0.0562
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: 0.0329
  kl_divergence: -20.1833
  ssim: 0.0562
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer1/batch_1_strength_0.0_results.npy

Processing attention strength 0.4
Attention vector: [0.  0.4 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.45440, std: 0.11404

Metrics for layer 0:
  pearson_correlation: 0.0037
  kl_divergence: -4805.3774
  ssim: 0.0510
  iou: 0.1430
Layer 0 metrics:
  pearson_correlation: 0.0037
  kl_divergence: -4805.3774
  ssim: 0.0510
  iou: 0.1430

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.48530, std: 0.11319

Metrics for layer 1:
  pearson_correlation: 0.0037
  kl_divergence: -5017.2178
  ssim: 0.0481
  iou: 0.1428
Layer 1 metrics:
  pearson_correlation: 0.0037
  kl_divergence: -5017.2178
  ssim: 0.0481
  iou: 0.1428

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.44966, std: 0.13956

Metrics for layer 2:
  pearson_correlation: -0.0128
  kl_divergence: -1360.0225
  ssim: 0.0488
  iou: 0.1329
Layer 2 metrics:
  pearson_correlation: -0.0128
  kl_divergence: -1360.0225
  ssim: 0.0488
  iou: 0.1329

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.53119, std: 0.12676

Metrics for layer 3:
  pearson_correlation: -0.0026
  kl_divergence: -1554.1204
  ssim: 0.0483
  iou: 0.1362
Layer 3 metrics:
  pearson_correlation: -0.0026
  kl_divergence: -1554.1204
  ssim: 0.0483
  iou: 0.1362

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.45894, std: 0.15507

Metrics for layer 4:
  pearson_correlation: 0.0260
  kl_divergence: -351.7322
  ssim: 0.0560
  iou: 0.1598
Layer 4 metrics:
  pearson_correlation: 0.0260
  kl_divergence: -351.7322
  ssim: 0.0560
  iou: 0.1598

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.48284, std: 0.15063

Metrics for layer 5:
  pearson_correlation: -0.0189
  kl_divergence: -368.5446
  ssim: 0.0505
  iou: 0.1429
Layer 5 metrics:
  pearson_correlation: -0.0189
  kl_divergence: -368.5446
  ssim: 0.0505
  iou: 0.1429

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47071, std: 0.14866

Metrics for layer 6:
  pearson_correlation: 0.0164
  kl_divergence: -368.1803
  ssim: 0.0623
  iou: 0.1504
Layer 6 metrics:
  pearson_correlation: 0.0164
  kl_divergence: -368.1803
  ssim: 0.0623
  iou: 0.1504

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.49722, std: 0.18094

Metrics for layer 7:
  pearson_correlation: 0.0035
  kl_divergence: -90.6250
  ssim: 0.0284
  iou: 0.1297
Layer 7 metrics:
  pearson_correlation: 0.0035
  kl_divergence: -90.6250
  ssim: 0.0284
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.49876, std: 0.15552

Metrics for layer 8:
  pearson_correlation: 0.0310
  kl_divergence: -91.7314
  ssim: 0.0620
  iou: 0.1598
Layer 8 metrics:
  pearson_correlation: 0.0310
  kl_divergence: -91.7314
  ssim: 0.0620
  iou: 0.1598

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.46949, std: 0.16550

Metrics for layer 9:
  pearson_correlation: 0.0004
  kl_divergence: -83.7949
  ssim: 0.0619
  iou: 0.1632
Layer 9 metrics:
  pearson_correlation: 0.0004
  kl_divergence: -83.7949
  ssim: 0.0619
  iou: 0.1632

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.47215, std: 0.18284

Metrics for layer 10:
  pearson_correlation: 0.0110
  kl_divergence: -21.3328
  ssim: 0.0830
  iou: 0.1667
Layer 10 metrics:
  pearson_correlation: 0.0110
  kl_divergence: -21.3328
  ssim: 0.0830
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.40930, std: 0.18115

Metrics for layer 11:
  pearson_correlation: -0.0440
  kl_divergence: -14.0807
  ssim: 0.0773
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: -0.0440
  kl_divergence: -14.0807
  ssim: 0.0773
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49618, std: 0.18778

Metrics for layer 12:
  pearson_correlation: 0.0531
  kl_divergence: -17.4987
  ssim: 0.1277
  iou: 0.1011
Layer 12 metrics:
  pearson_correlation: 0.0531
  kl_divergence: -17.4987
  ssim: 0.1277
  iou: 0.1011
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer1/batch_0_strength_0.4_results.npy

Processing batch 2/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.44105, std: 0.11896

Metrics for layer 0:
  pearson_correlation: -0.0015
  kl_divergence: -3846.7524
  ssim: 0.0333
  iou: 0.1407
Layer 0 metrics:
  pearson_correlation: -0.0015
  kl_divergence: -3846.7524
  ssim: 0.0333
  iou: 0.1407

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.50221, std: 0.11614

Metrics for layer 1:
  pearson_correlation: -0.0014
  kl_divergence: -4107.1572
  ssim: 0.0301
  iou: 0.1442
Layer 1 metrics:
  pearson_correlation: -0.0014
  kl_divergence: -4107.1572
  ssim: 0.0301
  iou: 0.1442

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.46619, std: 0.11466

Metrics for layer 2:
  pearson_correlation: -0.0045
  kl_divergence: -1392.0814
  ssim: 0.0585
  iou: 0.1402
Layer 2 metrics:
  pearson_correlation: -0.0045
  kl_divergence: -1392.0814
  ssim: 0.0585
  iou: 0.1402

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.46609, std: 0.13253

Metrics for layer 3:
  pearson_correlation: -0.0062
  kl_divergence: -1381.4126
  ssim: 0.0452
  iou: 0.1364
Layer 3 metrics:
  pearson_correlation: -0.0062
  kl_divergence: -1381.4126
  ssim: 0.0452
  iou: 0.1364

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.46090, std: 0.14520

Metrics for layer 4:
  pearson_correlation: -0.0019
  kl_divergence: -370.8408
  ssim: 0.0520
  iou: 0.1496
Layer 4 metrics:
  pearson_correlation: -0.0019
  kl_divergence: -370.8408
  ssim: 0.0520
  iou: 0.1496

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48357, std: 0.14077

Metrics for layer 5:
  pearson_correlation: 0.0035
  kl_divergence: -391.2833
  ssim: 0.0498
  iou: 0.1479
Layer 5 metrics:
  pearson_correlation: 0.0035
  kl_divergence: -391.2833
  ssim: 0.0498
  iou: 0.1479

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.46273, std: 0.14030

Metrics for layer 6:
  pearson_correlation: 0.0268
  kl_divergence: -374.1224
  ssim: 0.0679
  iou: 0.1404
Layer 6 metrics:
  pearson_correlation: 0.0268
  kl_divergence: -374.1224
  ssim: 0.0679
  iou: 0.1404

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.44931, std: 0.16036

Metrics for layer 7:
  pearson_correlation: 0.0178
  kl_divergence: -82.9204
  ssim: 0.0453
  iou: 0.1329
Layer 7 metrics:
  pearson_correlation: 0.0178
  kl_divergence: -82.9204
  ssim: 0.0453
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.49256, std: 0.14784

Metrics for layer 8:
  pearson_correlation: -0.0058
  kl_divergence: -88.9478
  ssim: 0.0319
  iou: 0.1496
Layer 8 metrics:
  pearson_correlation: -0.0058
  kl_divergence: -88.9478
  ssim: 0.0319
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.47718, std: 0.13954

Metrics for layer 9:
  pearson_correlation: -0.0556
  kl_divergence: -66.1928
  ssim: 0.0275
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: -0.0556
  kl_divergence: -66.1928
  ssim: 0.0275
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.49401, std: 0.16744

Metrics for layer 10:
  pearson_correlation: -0.0640
  kl_divergence: -10.7964
  ssim: -0.0438
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: -0.0640
  kl_divergence: -10.7964
  ssim: -0.0438
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.47335, std: 0.23057

Metrics for layer 11:
  pearson_correlation: -0.0375
  kl_divergence: -9.6267
  ssim: 0.0235
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: -0.0375
  kl_divergence: -9.6267
  ssim: 0.0235
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.46981, std: 0.20554

Metrics for layer 12:
  pearson_correlation: -0.1204
  kl_divergence: -12.2890
  ssim: -0.0590
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: -0.1204
  kl_divergence: -12.2890
  ssim: -0.0590
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer1/batch_1_strength_0.4_results.npy

Processing attention strength 0.8
Attention vector: [0.  0.8 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.41655, std: 0.12762

Metrics for layer 0:
  pearson_correlation: 0.0034
  kl_divergence: -4484.2568
  ssim: 0.0463
  iou: 0.1449
Layer 0 metrics:
  pearson_correlation: 0.0034
  kl_divergence: -4484.2568
  ssim: 0.0463
  iou: 0.1449

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.47719, std: 0.12389

Metrics for layer 1:
  pearson_correlation: 0.0085
  kl_divergence: -4947.8604
  ssim: 0.0443
  iou: 0.1464
Layer 1 metrics:
  pearson_correlation: 0.0085
  kl_divergence: -4947.8604
  ssim: 0.0443
  iou: 0.1464

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.46267, std: 0.12705

Metrics for layer 2:
  pearson_correlation: -0.0021
  kl_divergence: -1404.7505
  ssim: 0.0539
  iou: 0.1500
Layer 2 metrics:
  pearson_correlation: -0.0021
  kl_divergence: -1404.7505
  ssim: 0.0539
  iou: 0.1500

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.43485, std: 0.13972

Metrics for layer 3:
  pearson_correlation: -0.0184
  kl_divergence: -1318.7800
  ssim: 0.0484
  iou: 0.1383
Layer 3 metrics:
  pearson_correlation: -0.0184
  kl_divergence: -1318.7800
  ssim: 0.0484
  iou: 0.1383

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50629, std: 0.13218

Metrics for layer 4:
  pearson_correlation: 0.0134
  kl_divergence: -401.2447
  ssim: 0.0530
  iou: 0.1387
Layer 4 metrics:
  pearson_correlation: 0.0134
  kl_divergence: -401.2447
  ssim: 0.0530
  iou: 0.1387

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.45705, std: 0.15214

Metrics for layer 5:
  pearson_correlation: 0.0139
  kl_divergence: -352.8663
  ssim: 0.0496
  iou: 0.1496
Layer 5 metrics:
  pearson_correlation: 0.0139
  kl_divergence: -352.8663
  ssim: 0.0496
  iou: 0.1496

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50891, std: 0.14310

Metrics for layer 6:
  pearson_correlation: 0.0222
  kl_divergence: -401.3020
  ssim: 0.0588
  iou: 0.1538
Layer 6 metrics:
  pearson_correlation: 0.0222
  kl_divergence: -401.3020
  ssim: 0.0588
  iou: 0.1538

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.53503, std: 0.13086

Metrics for layer 7:
  pearson_correlation: -0.0228
  kl_divergence: -104.0750
  ssim: 0.0327
  iou: 0.1496
Layer 7 metrics:
  pearson_correlation: -0.0228
  kl_divergence: -104.0750
  ssim: 0.0327
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.46143, std: 0.16104

Metrics for layer 8:
  pearson_correlation: -0.0172
  kl_divergence: -87.2471
  ssim: 0.0412
  iou: 0.1362
Layer 8 metrics:
  pearson_correlation: -0.0172
  kl_divergence: -87.2471
  ssim: 0.0412
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.52143, std: 0.17497

Metrics for layer 9:
  pearson_correlation: 0.0144
  kl_divergence: -95.7508
  ssim: 0.0395
  iou: 0.1598
Layer 9 metrics:
  pearson_correlation: 0.0144
  kl_divergence: -95.7508
  ssim: 0.0395
  iou: 0.1598

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.52029, std: 0.20688

Metrics for layer 10:
  pearson_correlation: -0.0850
  kl_divergence: -20.1963
  ssim: -0.0031
  iou: 0.0769
Layer 10 metrics:
  pearson_correlation: -0.0850
  kl_divergence: -20.1963
  ssim: -0.0031
  iou: 0.0769

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.53498, std: 0.20082

Metrics for layer 11:
  pearson_correlation: 0.0534
  kl_divergence: -25.6111
  ssim: 0.0329
  iou: 0.0889
Layer 11 metrics:
  pearson_correlation: 0.0534
  kl_divergence: -25.6111
  ssim: 0.0329
  iou: 0.0889

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.59616, std: 0.18912

Metrics for layer 12:
  pearson_correlation: -0.0994
  kl_divergence: -18.3877
  ssim: 0.0177
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: -0.0994
  kl_divergence: -18.3877
  ssim: 0.0177
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer1/batch_0_strength_0.8_results.npy

Processing batch 2/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.38479, std: 0.10979

Metrics for layer 0:
  pearson_correlation: -0.0050
  kl_divergence: -3581.8906
  ssim: 0.0425
  iou: 0.1402
Layer 0 metrics:
  pearson_correlation: -0.0050
  kl_divergence: -3581.8906
  ssim: 0.0425
  iou: 0.1402

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.48694, std: 0.11758

Metrics for layer 1:
  pearson_correlation: -0.0018
  kl_divergence: -4043.7834
  ssim: 0.0308
  iou: 0.1405
Layer 1 metrics:
  pearson_correlation: -0.0018
  kl_divergence: -4043.7834
  ssim: 0.0308
  iou: 0.1405

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.46346, std: 0.13949

Metrics for layer 2:
  pearson_correlation: -0.0012
  kl_divergence: -1371.2882
  ssim: 0.0439
  iou: 0.1416
Layer 2 metrics:
  pearson_correlation: -0.0012
  kl_divergence: -1371.2882
  ssim: 0.0439
  iou: 0.1416

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.45468, std: 0.12190

Metrics for layer 3:
  pearson_correlation: 0.0028
  kl_divergence: -1366.9307
  ssim: 0.0549
  iou: 0.1449
Layer 3 metrics:
  pearson_correlation: 0.0028
  kl_divergence: -1366.9307
  ssim: 0.0549
  iou: 0.1449

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.49058, std: 0.15557

Metrics for layer 4:
  pearson_correlation: 0.0090
  kl_divergence: -393.5437
  ssim: 0.0411
  iou: 0.1598
Layer 4 metrics:
  pearson_correlation: 0.0090
  kl_divergence: -393.5437
  ssim: 0.0411
  iou: 0.1598

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.43512, std: 0.13869

Metrics for layer 5:
  pearson_correlation: -0.0112
  kl_divergence: -349.6536
  ssim: 0.0487
  iou: 0.1272
Layer 5 metrics:
  pearson_correlation: -0.0112
  kl_divergence: -349.6536
  ssim: 0.0487
  iou: 0.1272

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.44048, std: 0.14299

Metrics for layer 6:
  pearson_correlation: -0.0087
  kl_divergence: -351.3231
  ssim: 0.0539
  iou: 0.1346
Layer 6 metrics:
  pearson_correlation: -0.0087
  kl_divergence: -351.3231
  ssim: 0.0539
  iou: 0.1346

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.58510, std: 0.15381

Metrics for layer 7:
  pearson_correlation: 0.0078
  kl_divergence: -99.5978
  ssim: 0.0392
  iou: 0.1297
Layer 7 metrics:
  pearson_correlation: 0.0078
  kl_divergence: -99.5978
  ssim: 0.0392
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.50436, std: 0.14923

Metrics for layer 8:
  pearson_correlation: -0.0101
  kl_divergence: -90.9795
  ssim: 0.0361
  iou: 0.1462
Layer 8 metrics:
  pearson_correlation: -0.0101
  kl_divergence: -90.9795
  ssim: 0.0361
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.48353, std: 0.15800

Metrics for layer 9:
  pearson_correlation: 0.0510
  kl_divergence: -87.6366
  ssim: 0.0406
  iou: 0.1915
Layer 9 metrics:
  pearson_correlation: 0.0510
  kl_divergence: -87.6366
  ssim: 0.0406
  iou: 0.1915

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.48764, std: 0.16032

Metrics for layer 10:
  pearson_correlation: -0.0274
  kl_divergence: -18.7071
  ssim: -0.0534
  iou: 0.1667
Layer 10 metrics:
  pearson_correlation: -0.0274
  kl_divergence: -18.7071
  ssim: -0.0534
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.48114, std: 0.14626

Metrics for layer 11:
  pearson_correlation: -0.0489
  kl_divergence: -18.7789
  ssim: 0.0074
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: -0.0489
  kl_divergence: -18.7789
  ssim: 0.0074
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.55168, std: 0.15921

Metrics for layer 12:
  pearson_correlation: -0.0237
  kl_divergence: -23.4752
  ssim: -0.0286
  iou: 0.1136
Layer 12 metrics:
  pearson_correlation: -0.0237
  kl_divergence: -23.4752
  ssim: -0.0286
  iou: 0.1136
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer1/batch_1_strength_0.8_results.npy

Processing attention strength 1.2
Attention vector: [0.  1.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.46262, std: 0.11541

Metrics for layer 0:
  pearson_correlation: 0.0042
  kl_divergence: -4862.3364
  ssim: 0.0486
  iou: 0.1416
Layer 0 metrics:
  pearson_correlation: 0.0042
  kl_divergence: -4862.3364
  ssim: 0.0486
  iou: 0.1416

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.51957, std: 0.10764

Metrics for layer 1:
  pearson_correlation: 0.0047
  kl_divergence: -5246.7949
  ssim: 0.0484
  iou: 0.1432
Layer 1 metrics:
  pearson_correlation: 0.0047
  kl_divergence: -5246.7949
  ssim: 0.0484
  iou: 0.1432

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.44730, std: 0.13090

Metrics for layer 2:
  pearson_correlation: -0.0135
  kl_divergence: -1363.1714
  ssim: 0.0520
  iou: 0.1433
Layer 2 metrics:
  pearson_correlation: -0.0135
  kl_divergence: -1363.1714
  ssim: 0.0520
  iou: 0.1433

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.44030, std: 0.12199

Metrics for layer 3:
  pearson_correlation: 0.0011
  kl_divergence: -1356.2675
  ssim: 0.0618
  iou: 0.1410
Layer 3 metrics:
  pearson_correlation: 0.0011
  kl_divergence: -1356.2675
  ssim: 0.0618
  iou: 0.1410

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47911, std: 0.13435

Metrics for layer 4:
  pearson_correlation: -0.0361
  kl_divergence: -374.0480
  ssim: 0.0529
  iou: 0.1240
Layer 4 metrics:
  pearson_correlation: -0.0361
  kl_divergence: -374.0480
  ssim: 0.0529
  iou: 0.1240

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47207, std: 0.13752

Metrics for layer 5:
  pearson_correlation: 0.0001
  kl_divergence: -365.0025
  ssim: 0.0604
  iou: 0.1487
Layer 5 metrics:
  pearson_correlation: 0.0001
  kl_divergence: -365.0025
  ssim: 0.0604
  iou: 0.1487

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50961, std: 0.14109

Metrics for layer 6:
  pearson_correlation: 0.0273
  kl_divergence: -398.4733
  ssim: 0.0605
  iou: 0.1563
Layer 6 metrics:
  pearson_correlation: 0.0273
  kl_divergence: -398.4733
  ssim: 0.0605
  iou: 0.1563

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.49918, std: 0.15189

Metrics for layer 7:
  pearson_correlation: -0.0086
  kl_divergence: -95.8311
  ssim: 0.0408
  iou: 0.1329
Layer 7 metrics:
  pearson_correlation: -0.0086
  kl_divergence: -95.8311
  ssim: 0.0408
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.44343, std: 0.14926

Metrics for layer 8:
  pearson_correlation: -0.0009
  kl_divergence: -82.8260
  ssim: 0.0491
  iou: 0.1297
Layer 8 metrics:
  pearson_correlation: -0.0009
  kl_divergence: -82.8260
  ssim: 0.0491
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.44927, std: 0.18618

Metrics for layer 9:
  pearson_correlation: 0.0400
  kl_divergence: -81.3837
  ssim: 0.0561
  iou: 0.1772
Layer 9 metrics:
  pearson_correlation: 0.0400
  kl_divergence: -81.3837
  ssim: 0.0561
  iou: 0.1772

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.55249, std: 0.15006

Metrics for layer 10:
  pearson_correlation: -0.1047
  kl_divergence: -23.8013
  ssim: 0.0007
  iou: 0.1136
Layer 10 metrics:
  pearson_correlation: -0.1047
  kl_divergence: -23.8013
  ssim: 0.0007
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.41112, std: 0.15793

Metrics for layer 11:
  pearson_correlation: 0.0225
  kl_divergence: -13.0076
  ssim: 0.0542
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: 0.0225
  kl_divergence: -13.0076
  ssim: 0.0542
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.54915, std: 0.18929

Metrics for layer 12:
  pearson_correlation: 0.1502
  kl_divergence: -24.1426
  ssim: 0.1357
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: 0.1502
  kl_divergence: -24.1426
  ssim: 0.1357
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer1/batch_0_strength_1.2_results.npy

Processing batch 2/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.40348, std: 0.11429

Metrics for layer 0:
  pearson_correlation: -0.0006
  kl_divergence: -3673.9814
  ssim: 0.0385
  iou: 0.1442
Layer 0 metrics:
  pearson_correlation: -0.0006
  kl_divergence: -3673.9814
  ssim: 0.0385
  iou: 0.1442

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.52526, std: 0.11711

Metrics for layer 1:
  pearson_correlation: -0.0066
  kl_divergence: -4193.1572
  ssim: 0.0282
  iou: 0.1409
Layer 1 metrics:
  pearson_correlation: -0.0066
  kl_divergence: -4193.1572
  ssim: 0.0282
  iou: 0.1409

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.46944, std: 0.12749

Metrics for layer 2:
  pearson_correlation: -0.0198
  kl_divergence: -1389.5391
  ssim: 0.0473
  iou: 0.1329
Layer 2 metrics:
  pearson_correlation: -0.0198
  kl_divergence: -1389.5391
  ssim: 0.0473
  iou: 0.1329

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.46864, std: 0.13725

Metrics for layer 3:
  pearson_correlation: -0.0113
  kl_divergence: -1381.2782
  ssim: 0.0407
  iou: 0.1426
Layer 3 metrics:
  pearson_correlation: -0.0113
  kl_divergence: -1381.2782
  ssim: 0.0407
  iou: 0.1426

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47020, std: 0.14161

Metrics for layer 4:
  pearson_correlation: -0.0168
  kl_divergence: -378.0021
  ssim: 0.0549
  iou: 0.1362
Layer 4 metrics:
  pearson_correlation: -0.0168
  kl_divergence: -378.0021
  ssim: 0.0549
  iou: 0.1362

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48452, std: 0.14072

Metrics for layer 5:
  pearson_correlation: 0.0074
  kl_divergence: -391.8931
  ssim: 0.0617
  iou: 0.1546
Layer 5 metrics:
  pearson_correlation: 0.0074
  kl_divergence: -391.8931
  ssim: 0.0617
  iou: 0.1546

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.46975, std: 0.13815

Metrics for layer 6:
  pearson_correlation: 0.0011
  kl_divergence: -379.6352
  ssim: 0.0626
  iou: 0.1512
Layer 6 metrics:
  pearson_correlation: 0.0011
  kl_divergence: -379.6352
  ssim: 0.0626
  iou: 0.1512

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.49698, std: 0.15303

Metrics for layer 7:
  pearson_correlation: -0.0245
  kl_divergence: -87.7195
  ssim: 0.0271
  iou: 0.1264
Layer 7 metrics:
  pearson_correlation: -0.0245
  kl_divergence: -87.7195
  ssim: 0.0271
  iou: 0.1264

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.46652, std: 0.17475

Metrics for layer 8:
  pearson_correlation: -0.0064
  kl_divergence: -81.9351
  ssim: 0.0257
  iou: 0.1598
Layer 8 metrics:
  pearson_correlation: -0.0064
  kl_divergence: -81.9351
  ssim: 0.0257
  iou: 0.1598

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.48627, std: 0.17652

Metrics for layer 9:
  pearson_correlation: -0.0614
  kl_divergence: -84.9459
  ssim: 0.0185
  iou: 0.1200
Layer 9 metrics:
  pearson_correlation: -0.0614
  kl_divergence: -84.9459
  ssim: 0.0185
  iou: 0.1200

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.47602, std: 0.17502

Metrics for layer 10:
  pearson_correlation: -0.1374
  kl_divergence: -12.3859
  ssim: -0.0570
  iou: 0.1136
Layer 10 metrics:
  pearson_correlation: -0.1374
  kl_divergence: -12.3859
  ssim: -0.0570
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.56313, std: 0.16444

Metrics for layer 11:
  pearson_correlation: 0.0663
  kl_divergence: -25.3282
  ssim: 0.0178
  iou: 0.1807
Layer 11 metrics:
  pearson_correlation: 0.0663
  kl_divergence: -25.3282
  ssim: 0.0178
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.54379, std: 0.16839

Metrics for layer 12:
  pearson_correlation: 0.0029
  kl_divergence: -23.3123
  ssim: 0.0418
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: 0.0029
  kl_divergence: -23.3123
  ssim: 0.0418
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer1/batch_1_strength_1.2_results.npy

Analysis complete! Results saved to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer1
Completed experiment for category 5, layer 1
----------------------------------------
Running experiment for category 5, layer 2
===================================================
Starting experiment:
Category: 5
Layer: 2
Logs will be saved to: /scratch/hy2611/CNN_attention/logs/attention_analysis_20241216_104146/category5/layer2
===================================================
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-12-16 10:47:22.003616: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-16 10:47:22.022513: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2024-12-16 10:47:22.022955: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3dfb7b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-16 10:47:22.022972: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-16 10:47:22.025829: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-16 10:47:22.170847: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3dd5f70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-16 10:47:22.170866: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-12-16 10:47:22.171411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:2f:00.0
2024-12-16 10:47:22.172641: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:47:22.173717: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:47:22.174753: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:47:22.175920: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:47:22.176985: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:47:22.177982: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:47:22.178991: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:47:22.179003: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-12-16 10:47:22.179022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-16 10:47:22.179027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-16 10:47:22.179030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:61: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:87: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:15: sigmoid_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.sigmoid_cross_entropy instead. Note that the order of the predictions and labels arguments has been changed.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:322: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:82: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.


Verifying paths:
tc_path: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs exists
weight_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists
image_path: /scratch/hy2611/CNN_attention/Data/VGG16/images exists
save_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists

Initializing model...
('c11', [1, 224, 224, 64])
('c12', [1, 224, 224, 64])
('c21', [1, 112, 112, 128])
('c22', [1, 112, 112, 128])
('c31', [1, 56, 56, 256])
('c32', [1, 56, 56, 256])
('c33', [1, 56, 56, 256])
('c41', [1, 28, 28, 512])
('c42', [1, 28, 28, 512])
('c43', [1, 28, 28, 512])
('c51', [1, 14, 14, 512])
('c52', [1, 14, 14, 512])
('c53', [1, 14, 14, 512])
(0, 'conv1_1_W', (3, 3, 3, 64))
(1, 'conv1_1_b', (64,))
(2, 'conv1_2_W', (3, 3, 64, 64))
(3, 'conv1_2_b', (64,))
(4, 'conv2_1_W', (3, 3, 64, 128))
(5, 'conv2_1_b', (128,))
(6, 'conv2_2_W', (3, 3, 128, 128))
(7, 'conv2_2_b', (128,))
(8, 'conv3_1_W', (3, 3, 128, 256))
(9, 'conv3_1_b', (256,))
(10, 'conv3_2_W', (3, 3, 256, 256))
(11, 'conv3_2_b', (256,))
(12, 'conv3_3_W', (3, 3, 256, 256))
(13, 'conv3_3_b', (256,))
(14, 'conv4_1_W', (3, 3, 256, 512))
(15, 'conv4_1_b', (512,))
(16, 'conv4_2_W', (3, 3, 512, 512))
(17, 'conv4_2_b', (512,))
(18, 'conv4_3_W', (3, 3, 512, 512))
(19, 'conv4_3_b', (512,))
(20, 'conv5_1_W', (3, 3, 512, 512))
(21, 'conv5_1_b', (512,))
(22, 'conv5_2_W', (3, 3, 512, 512))
(23, 'conv5_2_b', (512,))
(24, 'conv5_3_W', (3, 3, 512, 512))
(25, 'conv5_3_b', (512,))
(26, 'fc6_W', (25088, 4096))
(27, 'fc6_b', (4096,))
(28, 'fc7_W', (4096, 4096))
(29, 'fc7_b', (4096,))
Checking checkpoint files:
Data file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.data-00000-of-00001 - Found
Index file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.index - Found
Loading checkpoint from: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt
Checkpoint loaded successfully

Initializing components...
Found tuning curves file: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs/featvecs20_train35_c.txt

Loading category 5 data...
Original positive images shape: (2, 224, 224, 3)

Processing data...

Processing attention strength 0.0
Attention vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

Processing batch 1/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.40431, std: 0.11780

Metrics for layer 0:
  pearson_correlation: 0.0018
  kl_divergence: -4404.2583
  ssim: 0.0532
  iou: 0.1465
Layer 0 metrics:
  pearson_correlation: 0.0018
  kl_divergence: -4404.2583
  ssim: 0.0532
  iou: 0.1465

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.38371, std: 0.10999

Metrics for layer 1:
  pearson_correlation: -0.0008
  kl_divergence: -4250.0933
  ssim: 0.0614
  iou: 0.1438
Layer 1 metrics:
  pearson_correlation: -0.0008
  kl_divergence: -4250.0933
  ssim: 0.0614
  iou: 0.1438

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.38380, std: 0.12187

Metrics for layer 2:
  pearson_correlation: 0.0238
  kl_divergence: -1209.4312
  ssim: 0.0747
  iou: 0.1468
Layer 2 metrics:
  pearson_correlation: 0.0238
  kl_divergence: -1209.4312
  ssim: 0.0747
  iou: 0.1468

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.43247, std: 0.12863

Metrics for layer 3:
  pearson_correlation: -0.0147
  kl_divergence: -1325.9395
  ssim: 0.0566
  iou: 0.1340
Layer 3 metrics:
  pearson_correlation: -0.0147
  kl_divergence: -1325.9395
  ssim: 0.0566
  iou: 0.1340

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.41193, std: 0.12697

Metrics for layer 4:
  pearson_correlation: -0.0332
  kl_divergence: -318.3831
  ssim: 0.0672
  iou: 0.1329
Layer 4 metrics:
  pearson_correlation: -0.0332
  kl_divergence: -318.3831
  ssim: 0.0672
  iou: 0.1329

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.45066, std: 0.12900

Metrics for layer 5:
  pearson_correlation: 0.0142
  kl_divergence: -356.2542
  ssim: 0.0841
  iou: 0.1563
Layer 5 metrics:
  pearson_correlation: 0.0142
  kl_divergence: -356.2542
  ssim: 0.0841
  iou: 0.1563

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.45350, std: 0.14525

Metrics for layer 6:
  pearson_correlation: -0.0330
  kl_divergence: -350.2531
  ssim: 0.0443
  iou: 0.1379
Layer 6 metrics:
  pearson_correlation: -0.0330
  kl_divergence: -350.2531
  ssim: 0.0443
  iou: 0.1379

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.45020, std: 0.16279

Metrics for layer 7:
  pearson_correlation: -0.0132
  kl_divergence: -79.3327
  ssim: 0.0284
  iou: 0.1529
Layer 7 metrics:
  pearson_correlation: -0.0132
  kl_divergence: -79.3327
  ssim: 0.0284
  iou: 0.1529

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.48409, std: 0.16969

Metrics for layer 8:
  pearson_correlation: -0.0045
  kl_divergence: -88.5294
  ssim: 0.0700
  iou: 0.1462
Layer 8 metrics:
  pearson_correlation: -0.0045
  kl_divergence: -88.5294
  ssim: 0.0700
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.45375, std: 0.14177

Metrics for layer 9:
  pearson_correlation: 0.0075
  kl_divergence: -84.7872
  ssim: 0.0518
  iou: 0.1200
Layer 9 metrics:
  pearson_correlation: 0.0075
  kl_divergence: -84.7872
  ssim: 0.0518
  iou: 0.1200

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.48154, std: 0.19841

Metrics for layer 10:
  pearson_correlation: 0.0423
  kl_divergence: -20.3739
  ssim: 0.0449
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: 0.0423
  kl_divergence: -20.3739
  ssim: 0.0449
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.45121, std: 0.19133

Metrics for layer 11:
  pearson_correlation: -0.0207
  kl_divergence: -10.8705
  ssim: 0.0568
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: -0.0207
  kl_divergence: -10.8705
  ssim: 0.0568
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.48889, std: 0.20613

Metrics for layer 12:
  pearson_correlation: 0.0687
  kl_divergence: -16.0148
  ssim: 0.0985
  iou: 0.2099
Layer 12 metrics:
  pearson_correlation: 0.0687
  kl_divergence: -16.0148
  ssim: 0.0985
  iou: 0.2099
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer2/batch_0_strength_0.0_results.npy

Processing batch 2/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43857, std: 0.12392

Metrics for layer 0:
  pearson_correlation: -0.0026
  kl_divergence: -3828.7766
  ssim: 0.0315
  iou: 0.1435
Layer 0 metrics:
  pearson_correlation: -0.0026
  kl_divergence: -3828.7766
  ssim: 0.0315
  iou: 0.1435

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.44774, std: 0.11817

Metrics for layer 1:
  pearson_correlation: -0.0004
  kl_divergence: -3880.3760
  ssim: 0.0336
  iou: 0.1411
Layer 1 metrics:
  pearson_correlation: -0.0004
  kl_divergence: -3880.3760
  ssim: 0.0336
  iou: 0.1411

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.44512, std: 0.12693

Metrics for layer 2:
  pearson_correlation: 0.0008
  kl_divergence: -1339.9357
  ssim: 0.0524
  iou: 0.1441
Layer 2 metrics:
  pearson_correlation: 0.0008
  kl_divergence: -1339.9357
  ssim: 0.0524
  iou: 0.1441

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.43305, std: 0.12607

Metrics for layer 3:
  pearson_correlation: -0.0149
  kl_divergence: -1312.2218
  ssim: 0.0538
  iou: 0.1327
Layer 3 metrics:
  pearson_correlation: -0.0149
  kl_divergence: -1312.2218
  ssim: 0.0538
  iou: 0.1327

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.45404, std: 0.15711

Metrics for layer 4:
  pearson_correlation: 0.0218
  kl_divergence: -361.2858
  ssim: 0.0597
  iou: 0.1445
Layer 4 metrics:
  pearson_correlation: 0.0218
  kl_divergence: -361.2858
  ssim: 0.0597
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.54032, std: 0.13115

Metrics for layer 5:
  pearson_correlation: -0.0167
  kl_divergence: -436.5047
  ssim: 0.0451
  iou: 0.1404
Layer 5 metrics:
  pearson_correlation: -0.0167
  kl_divergence: -436.5047
  ssim: 0.0451
  iou: 0.1404

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47014, std: 0.14825

Metrics for layer 6:
  pearson_correlation: -0.0080
  kl_divergence: -377.6370
  ssim: 0.0412
  iou: 0.1454
Layer 6 metrics:
  pearson_correlation: -0.0080
  kl_divergence: -377.6370
  ssim: 0.0412
  iou: 0.1454

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.47900, std: 0.16897

Metrics for layer 7:
  pearson_correlation: -0.0177
  kl_divergence: -85.7907
  ssim: 0.0129
  iou: 0.1297
Layer 7 metrics:
  pearson_correlation: -0.0177
  kl_divergence: -85.7907
  ssim: 0.0129
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.48007, std: 0.17749

Metrics for layer 8:
  pearson_correlation: -0.0424
  kl_divergence: -83.8589
  ssim: 0.0209
  iou: 0.1264
Layer 8 metrics:
  pearson_correlation: -0.0424
  kl_divergence: -83.8589
  ssim: 0.0209
  iou: 0.1264

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.44543, std: 0.15708

Metrics for layer 9:
  pearson_correlation: -0.0108
  kl_divergence: -81.5606
  ssim: 0.0438
  iou: 0.1462
Layer 9 metrics:
  pearson_correlation: -0.0108
  kl_divergence: -81.5606
  ssim: 0.0438
  iou: 0.1462

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.47769, std: 0.17611

Metrics for layer 10:
  pearson_correlation: 0.0357
  kl_divergence: -18.1556
  ssim: 0.0635
  iou: 0.1951
Layer 10 metrics:
  pearson_correlation: 0.0357
  kl_divergence: -18.1556
  ssim: 0.0635
  iou: 0.1951

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.48527, std: 0.18647

Metrics for layer 11:
  pearson_correlation: -0.0055
  kl_divergence: -3.6109
  ssim: 0.0479
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: -0.0055
  kl_divergence: -3.6109
  ssim: 0.0479
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.51877, std: 0.19304

Metrics for layer 12:
  pearson_correlation: 0.1249
  kl_divergence: -14.5980
  ssim: 0.2292
  iou: 0.1951
Layer 12 metrics:
  pearson_correlation: 0.1249
  kl_divergence: -14.5980
  ssim: 0.2292
  iou: 0.1951
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer2/batch_1_strength_0.0_results.npy

Processing attention strength 0.4
Attention vector: [0.  0.  0.4 0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.45473, std: 0.12610

Metrics for layer 0:
  pearson_correlation: -0.0044
  kl_divergence: -4775.2979
  ssim: 0.0431
  iou: 0.1435
Layer 0 metrics:
  pearson_correlation: -0.0044
  kl_divergence: -4775.2979
  ssim: 0.0431
  iou: 0.1435

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.45377, std: 0.11953

Metrics for layer 1:
  pearson_correlation: -0.0050
  kl_divergence: -4782.5103
  ssim: 0.0461
  iou: 0.1421
Layer 1 metrics:
  pearson_correlation: -0.0050
  kl_divergence: -4782.5103
  ssim: 0.0461
  iou: 0.1421

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.47425, std: 0.12761

Metrics for layer 2:
  pearson_correlation: -0.0015
  kl_divergence: -1431.3462
  ssim: 0.0546
  iou: 0.1487
Layer 2 metrics:
  pearson_correlation: -0.0015
  kl_divergence: -1431.3462
  ssim: 0.0546
  iou: 0.1487

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.46089, std: 0.11026

Metrics for layer 3:
  pearson_correlation: -0.0225
  kl_divergence: -1409.2209
  ssim: 0.0628
  iou: 0.1334
Layer 3 metrics:
  pearson_correlation: -0.0225
  kl_divergence: -1409.2209
  ssim: 0.0628
  iou: 0.1334

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.44792, std: 0.13616

Metrics for layer 4:
  pearson_correlation: 0.0038
  kl_divergence: -348.9477
  ssim: 0.0662
  iou: 0.1395
Layer 4 metrics:
  pearson_correlation: 0.0038
  kl_divergence: -348.9477
  ssim: 0.0662
  iou: 0.1395

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46238, std: 0.14265

Metrics for layer 5:
  pearson_correlation: 0.0006
  kl_divergence: -359.7770
  ssim: 0.0619
  iou: 0.1387
Layer 5 metrics:
  pearson_correlation: 0.0006
  kl_divergence: -359.7770
  ssim: 0.0619
  iou: 0.1387

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.51288, std: 0.12940

Metrics for layer 6:
  pearson_correlation: 0.0097
  kl_divergence: -405.1793
  ssim: 0.0666
  iou: 0.1572
Layer 6 metrics:
  pearson_correlation: 0.0097
  kl_divergence: -405.1793
  ssim: 0.0666
  iou: 0.1572

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.54142, std: 0.14842

Metrics for layer 7:
  pearson_correlation: -0.0366
  kl_divergence: -104.1392
  ssim: 0.0364
  iou: 0.1168
Layer 7 metrics:
  pearson_correlation: -0.0366
  kl_divergence: -104.1392
  ssim: 0.0364
  iou: 0.1168

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.51477, std: 0.14420

Metrics for layer 8:
  pearson_correlation: 0.0158
  kl_divergence: -95.1350
  ssim: 0.0561
  iou: 0.1329
Layer 8 metrics:
  pearson_correlation: 0.0158
  kl_divergence: -95.1350
  ssim: 0.0561
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.41032, std: 0.14952

Metrics for layer 9:
  pearson_correlation: -0.0246
  kl_divergence: -72.4459
  ssim: 0.0711
  iou: 0.1136
Layer 9 metrics:
  pearson_correlation: -0.0246
  kl_divergence: -72.4459
  ssim: 0.0711
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.48575, std: 0.20743

Metrics for layer 10:
  pearson_correlation: 0.1005
  kl_divergence: -22.5108
  ssim: 0.0386
  iou: 0.1264
Layer 10 metrics:
  pearson_correlation: 0.1005
  kl_divergence: -22.5108
  ssim: 0.0386
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.47304, std: 0.23867

Metrics for layer 11:
  pearson_correlation: 0.0490
  kl_divergence: -17.5432
  ssim: 0.0924
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: 0.0490
  kl_divergence: -17.5432
  ssim: 0.0924
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.54743, std: 0.19299

Metrics for layer 12:
  pearson_correlation: -0.0430
  kl_divergence: -24.9286
  ssim: 0.0955
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: -0.0430
  kl_divergence: -24.9286
  ssim: 0.0955
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer2/batch_0_strength_0.4_results.npy

Processing batch 2/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43967, std: 0.12671

Metrics for layer 0:
  pearson_correlation: 0.0001
  kl_divergence: -3828.8416
  ssim: 0.0303
  iou: 0.1415
Layer 0 metrics:
  pearson_correlation: 0.0001
  kl_divergence: -3828.8416
  ssim: 0.0303
  iou: 0.1415

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.46034, std: 0.12786

Metrics for layer 1:
  pearson_correlation: 0.0051
  kl_divergence: -3925.4802
  ssim: 0.0285
  iou: 0.1439
Layer 1 metrics:
  pearson_correlation: 0.0051
  kl_divergence: -3925.4802
  ssim: 0.0285
  iou: 0.1439

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.49450, std: 0.12473

Metrics for layer 2:
  pearson_correlation: -0.0150
  kl_divergence: -1440.5804
  ssim: 0.0468
  iou: 0.1406
Layer 2 metrics:
  pearson_correlation: -0.0150
  kl_divergence: -1440.5804
  ssim: 0.0468
  iou: 0.1406

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.42631, std: 0.11904

Metrics for layer 3:
  pearson_correlation: 0.0000
  kl_divergence: -1305.7454
  ssim: 0.0591
  iou: 0.1364
Layer 3 metrics:
  pearson_correlation: 0.0000
  kl_divergence: -1305.7454
  ssim: 0.0591
  iou: 0.1364

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.39882, std: 0.13207

Metrics for layer 4:
  pearson_correlation: 0.0035
  kl_divergence: -312.5421
  ssim: 0.0693
  iou: 0.1546
Layer 4 metrics:
  pearson_correlation: 0.0035
  kl_divergence: -312.5421
  ssim: 0.0693
  iou: 0.1546

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.46356, std: 0.14875

Metrics for layer 5:
  pearson_correlation: -0.0196
  kl_divergence: -368.4181
  ssim: 0.0427
  iou: 0.1563
Layer 5 metrics:
  pearson_correlation: -0.0196
  kl_divergence: -368.4181
  ssim: 0.0427
  iou: 0.1563

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47323, std: 0.14718

Metrics for layer 6:
  pearson_correlation: 0.0223
  kl_divergence: -383.2991
  ssim: 0.0582
  iou: 0.1479
Layer 6 metrics:
  pearson_correlation: 0.0223
  kl_divergence: -383.2991
  ssim: 0.0582
  iou: 0.1479

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.41388, std: 0.15292

Metrics for layer 7:
  pearson_correlation: 0.0553
  kl_divergence: -77.6475
  ssim: 0.0610
  iou: 0.1598
Layer 7 metrics:
  pearson_correlation: 0.0553
  kl_divergence: -77.6475
  ssim: 0.0610
  iou: 0.1598

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.50502, std: 0.14211

Metrics for layer 8:
  pearson_correlation: -0.0286
  kl_divergence: -90.8462
  ssim: 0.0306
  iou: 0.1462
Layer 8 metrics:
  pearson_correlation: -0.0286
  kl_divergence: -90.8462
  ssim: 0.0306
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.51996, std: 0.16068

Metrics for layer 9:
  pearson_correlation: 0.0185
  kl_divergence: -87.1879
  ssim: 0.0458
  iou: 0.1362
Layer 9 metrics:
  pearson_correlation: 0.0185
  kl_divergence: -87.1879
  ssim: 0.0458
  iou: 0.1362

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.52962, std: 0.20460

Metrics for layer 10:
  pearson_correlation: -0.0163
  kl_divergence: -11.8444
  ssim: 0.0116
  iou: 0.1395
Layer 10 metrics:
  pearson_correlation: -0.0163
  kl_divergence: -11.8444
  ssim: 0.0116
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.43995, std: 0.15800

Metrics for layer 11:
  pearson_correlation: 0.1223
  kl_divergence: -15.1506
  ssim: 0.0501
  iou: 0.2895
Layer 11 metrics:
  pearson_correlation: 0.1223
  kl_divergence: -15.1506
  ssim: 0.0501
  iou: 0.2895

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.48336, std: 0.20598

Metrics for layer 12:
  pearson_correlation: -0.1141
  kl_divergence: -10.3803
  ssim: -0.1025
  iou: 0.1136
Layer 12 metrics:
  pearson_correlation: -0.1141
  kl_divergence: -10.3803
  ssim: -0.1025
  iou: 0.1136
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer2/batch_1_strength_0.4_results.npy

Processing attention strength 0.8
Attention vector: [0.  0.  0.8 0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.43341, std: 0.11417

Metrics for layer 0:
  pearson_correlation: -0.0132
  kl_divergence: -4635.7397
  ssim: 0.0501
  iou: 0.1417
Layer 0 metrics:
  pearson_correlation: -0.0132
  kl_divergence: -4635.7397
  ssim: 0.0501
  iou: 0.1417

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42037, std: 0.11305

Metrics for layer 1:
  pearson_correlation: -0.0003
  kl_divergence: -4541.7090
  ssim: 0.0534
  iou: 0.1449
Layer 1 metrics:
  pearson_correlation: -0.0003
  kl_divergence: -4541.7090
  ssim: 0.0534
  iou: 0.1449

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.49759, std: 0.12985

Metrics for layer 2:
  pearson_correlation: 0.0087
  kl_divergence: -1485.5208
  ssim: 0.0557
  iou: 0.1437
Layer 2 metrics:
  pearson_correlation: 0.0087
  kl_divergence: -1485.5208
  ssim: 0.0557
  iou: 0.1437

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.49361, std: 0.12530

Metrics for layer 3:
  pearson_correlation: 0.0079
  kl_divergence: -1479.2108
  ssim: 0.0524
  iou: 0.1468
Layer 3 metrics:
  pearson_correlation: 0.0079
  kl_divergence: -1479.2108
  ssim: 0.0524
  iou: 0.1468

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50834, std: 0.14531

Metrics for layer 4:
  pearson_correlation: -0.0016
  kl_divergence: -398.5020
  ssim: 0.0513
  iou: 0.1289
Layer 4 metrics:
  pearson_correlation: -0.0016
  kl_divergence: -398.5020
  ssim: 0.0513
  iou: 0.1289

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46627, std: 0.14449

Metrics for layer 5:
  pearson_correlation: -0.0119
  kl_divergence: -361.7308
  ssim: 0.0539
  iou: 0.1354
Layer 5 metrics:
  pearson_correlation: -0.0119
  kl_divergence: -361.7308
  ssim: 0.0539
  iou: 0.1354

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47282, std: 0.14823

Metrics for layer 6:
  pearson_correlation: 0.0359
  kl_divergence: -371.8611
  ssim: 0.0655
  iou: 0.1454
Layer 6 metrics:
  pearson_correlation: 0.0359
  kl_divergence: -371.8611
  ssim: 0.0655
  iou: 0.1454

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.43662, std: 0.14886

Metrics for layer 7:
  pearson_correlation: -0.0763
  kl_divergence: -79.2880
  ssim: 0.0292
  iou: 0.1232
Layer 7 metrics:
  pearson_correlation: -0.0763
  kl_divergence: -79.2880
  ssim: 0.0292
  iou: 0.1232

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.50968, std: 0.15908

Metrics for layer 8:
  pearson_correlation: 0.0020
  kl_divergence: -96.4228
  ssim: 0.0513
  iou: 0.1105
Layer 8 metrics:
  pearson_correlation: 0.0020
  kl_divergence: -96.4228
  ssim: 0.0513
  iou: 0.1105

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.43208, std: 0.16037

Metrics for layer 9:
  pearson_correlation: -0.0142
  kl_divergence: -76.3307
  ssim: 0.0764
  iou: 0.1264
Layer 9 metrics:
  pearson_correlation: -0.0142
  kl_divergence: -76.3307
  ssim: 0.0764
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.48965, std: 0.17782

Metrics for layer 10:
  pearson_correlation: -0.0417
  kl_divergence: -21.5485
  ssim: 0.0603
  iou: 0.1264
Layer 10 metrics:
  pearson_correlation: -0.0417
  kl_divergence: -21.5485
  ssim: 0.0603
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.40311, std: 0.17338

Metrics for layer 11:
  pearson_correlation: 0.0083
  kl_divergence: -14.8744
  ssim: 0.0724
  iou: 0.2099
Layer 11 metrics:
  pearson_correlation: 0.0083
  kl_divergence: -14.8744
  ssim: 0.0724
  iou: 0.2099

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.47391, std: 0.15470

Metrics for layer 12:
  pearson_correlation: 0.0553
  kl_divergence: -18.1442
  ssim: 0.0976
  iou: 0.1807
Layer 12 metrics:
  pearson_correlation: 0.0553
  kl_divergence: -18.1442
  ssim: 0.0976
  iou: 0.1807
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer2/batch_0_strength_0.8_results.npy

Processing batch 2/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.44039, std: 0.11510

Metrics for layer 0:
  pearson_correlation: 0.0071
  kl_divergence: -3854.1523
  ssim: 0.0354
  iou: 0.1415
Layer 0 metrics:
  pearson_correlation: 0.0071
  kl_divergence: -3854.1523
  ssim: 0.0354
  iou: 0.1415

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43091, std: 0.11854

Metrics for layer 1:
  pearson_correlation: -0.0001
  kl_divergence: -3801.7690
  ssim: 0.0335
  iou: 0.1445
Layer 1 metrics:
  pearson_correlation: -0.0001
  kl_divergence: -3801.7690
  ssim: 0.0335
  iou: 0.1445

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.46213, std: 0.12152

Metrics for layer 2:
  pearson_correlation: 0.0104
  kl_divergence: -1381.9536
  ssim: 0.0545
  iou: 0.1435
Layer 2 metrics:
  pearson_correlation: 0.0104
  kl_divergence: -1381.9536
  ssim: 0.0545
  iou: 0.1435

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.44633, std: 0.12852

Metrics for layer 3:
  pearson_correlation: -0.0089
  kl_divergence: -1340.4858
  ssim: 0.0500
  iou: 0.1412
Layer 3 metrics:
  pearson_correlation: -0.0089
  kl_divergence: -1340.4858
  ssim: 0.0500
  iou: 0.1412

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48308, std: 0.14721

Metrics for layer 4:
  pearson_correlation: 0.0013
  kl_divergence: -388.8607
  ssim: 0.0611
  iou: 0.1321
Layer 4 metrics:
  pearson_correlation: 0.0013
  kl_divergence: -388.8607
  ssim: 0.0611
  iou: 0.1321

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.53096, std: 0.15087

Metrics for layer 5:
  pearson_correlation: -0.0078
  kl_divergence: -422.1102
  ssim: 0.0406
  iou: 0.1354
Layer 5 metrics:
  pearson_correlation: -0.0078
  kl_divergence: -422.1102
  ssim: 0.0406
  iou: 0.1354

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.45521, std: 0.14274

Metrics for layer 6:
  pearson_correlation: 0.0180
  kl_divergence: -368.9247
  ssim: 0.0574
  iou: 0.1521
Layer 6 metrics:
  pearson_correlation: 0.0180
  kl_divergence: -368.9247
  ssim: 0.0574
  iou: 0.1521

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.44486, std: 0.17186

Metrics for layer 7:
  pearson_correlation: 0.0011
  kl_divergence: -79.5573
  ssim: 0.0368
  iou: 0.1529
Layer 7 metrics:
  pearson_correlation: 0.0011
  kl_divergence: -79.5573
  ssim: 0.0368
  iou: 0.1529

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.41897, std: 0.14809

Metrics for layer 8:
  pearson_correlation: -0.0669
  kl_divergence: -75.9076
  ssim: 0.0158
  iou: 0.1362
Layer 8 metrics:
  pearson_correlation: -0.0669
  kl_divergence: -75.9076
  ssim: 0.0158
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.39460, std: 0.15075

Metrics for layer 9:
  pearson_correlation: 0.0412
  kl_divergence: -74.9949
  ssim: 0.0606
  iou: 0.1667
Layer 9 metrics:
  pearson_correlation: 0.0412
  kl_divergence: -74.9949
  ssim: 0.0606
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.51035, std: 0.18125

Metrics for layer 10:
  pearson_correlation: -0.1020
  kl_divergence: 0.4096
  ssim: -0.1203
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: -0.1020
  kl_divergence: 0.4096
  ssim: -0.1203
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.48723, std: 0.19018

Metrics for layer 11:
  pearson_correlation: -0.0215
  kl_divergence: -16.4062
  ssim: 0.0435
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: -0.0215
  kl_divergence: -16.4062
  ssim: 0.0435
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.42092, std: 0.19077

Metrics for layer 12:
  pearson_correlation: 0.0799
  kl_divergence: -8.3290
  ssim: 0.1347
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: 0.0799
  kl_divergence: -8.3290
  ssim: 0.1347
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer2/batch_1_strength_0.8_results.npy

Processing attention strength 1.2
Attention vector: [0.  0.  1.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.45903, std: 0.12213

Metrics for layer 0:
  pearson_correlation: -0.0026
  kl_divergence: -4814.1685
  ssim: 0.0443
  iou: 0.1436
Layer 0 metrics:
  pearson_correlation: -0.0026
  kl_divergence: -4814.1685
  ssim: 0.0443
  iou: 0.1436

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.45264, std: 0.12543

Metrics for layer 1:
  pearson_correlation: 0.0083
  kl_divergence: -4773.4507
  ssim: 0.0453
  iou: 0.1450
Layer 1 metrics:
  pearson_correlation: 0.0083
  kl_divergence: -4773.4507
  ssim: 0.0453
  iou: 0.1450

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.49450, std: 0.13821

Metrics for layer 2:
  pearson_correlation: -0.0001
  kl_divergence: -1466.1978
  ssim: 0.0471
  iou: 0.1491
Layer 2 metrics:
  pearson_correlation: -0.0001
  kl_divergence: -1466.1978
  ssim: 0.0471
  iou: 0.1491

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.48092, std: 0.12658

Metrics for layer 3:
  pearson_correlation: -0.0083
  kl_divergence: -1445.9897
  ssim: 0.0508
  iou: 0.1439
Layer 3 metrics:
  pearson_correlation: -0.0083
  kl_divergence: -1445.9897
  ssim: 0.0508
  iou: 0.1439

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.49342, std: 0.13953

Metrics for layer 4:
  pearson_correlation: 0.0102
  kl_divergence: -387.6749
  ssim: 0.0603
  iou: 0.1429
Layer 4 metrics:
  pearson_correlation: 0.0102
  kl_divergence: -387.6749
  ssim: 0.0603
  iou: 0.1429

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.43623, std: 0.13378

Metrics for layer 5:
  pearson_correlation: -0.0179
  kl_divergence: -335.1386
  ssim: 0.0617
  iou: 0.1329
Layer 5 metrics:
  pearson_correlation: -0.0179
  kl_divergence: -335.1386
  ssim: 0.0617
  iou: 0.1329

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.48019, std: 0.14592

Metrics for layer 6:
  pearson_correlation: -0.0254
  kl_divergence: -372.5916
  ssim: 0.0525
  iou: 0.1354
Layer 6 metrics:
  pearson_correlation: -0.0254
  kl_divergence: -372.5916
  ssim: 0.0525
  iou: 0.1354

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.53355, std: 0.16621

Metrics for layer 7:
  pearson_correlation: -0.0071
  kl_divergence: -101.1587
  ssim: 0.0408
  iou: 0.1462
Layer 7 metrics:
  pearson_correlation: -0.0071
  kl_divergence: -101.1587
  ssim: 0.0408
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.47242, std: 0.17148

Metrics for layer 8:
  pearson_correlation: -0.0299
  kl_divergence: -87.3756
  ssim: 0.0258
  iou: 0.1200
Layer 8 metrics:
  pearson_correlation: -0.0299
  kl_divergence: -87.3756
  ssim: 0.0258
  iou: 0.1200

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.51047, std: 0.16922

Metrics for layer 9:
  pearson_correlation: -0.0560
  kl_divergence: -92.8833
  ssim: 0.0127
  iou: 0.1136
Layer 9 metrics:
  pearson_correlation: -0.0560
  kl_divergence: -92.8833
  ssim: 0.0127
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.48179, std: 0.17168

Metrics for layer 10:
  pearson_correlation: -0.0035
  kl_divergence: -8.8389
  ssim: -0.0229
  iou: 0.0889
Layer 10 metrics:
  pearson_correlation: -0.0035
  kl_divergence: -8.8389
  ssim: -0.0229
  iou: 0.0889

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.50727, std: 0.21539

Metrics for layer 11:
  pearson_correlation: -0.0727
  kl_divergence: -14.5812
  ssim: -0.0392
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: -0.0727
  kl_divergence: -14.5812
  ssim: -0.0392
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.41325, std: 0.18100

Metrics for layer 12:
  pearson_correlation: -0.0012
  kl_divergence: -11.1693
  ssim: 0.0456
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: -0.0012
  kl_divergence: -11.1693
  ssim: 0.0456
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer2/batch_0_strength_1.2_results.npy

Processing batch 2/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.39857, std: 0.11666

Metrics for layer 0:
  pearson_correlation: 0.0035
  kl_divergence: -3644.1555
  ssim: 0.0377
  iou: 0.1468
Layer 0 metrics:
  pearson_correlation: 0.0035
  kl_divergence: -3644.1555
  ssim: 0.0377
  iou: 0.1468

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.40815, std: 0.12067

Metrics for layer 1:
  pearson_correlation: -0.0030
  kl_divergence: -3683.8801
  ssim: 0.0348
  iou: 0.1465
Layer 1 metrics:
  pearson_correlation: -0.0030
  kl_divergence: -3683.8801
  ssim: 0.0348
  iou: 0.1465

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.51319, std: 0.13642

Metrics for layer 2:
  pearson_correlation: 0.0032
  kl_divergence: -1472.2012
  ssim: 0.0431
  iou: 0.1443
Layer 2 metrics:
  pearson_correlation: 0.0032
  kl_divergence: -1472.2012
  ssim: 0.0431
  iou: 0.1443

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.45625, std: 0.13190

Metrics for layer 3:
  pearson_correlation: 0.0005
  kl_divergence: -1362.0591
  ssim: 0.0476
  iou: 0.1523
Layer 3 metrics:
  pearson_correlation: 0.0005
  kl_divergence: -1362.0591
  ssim: 0.0476
  iou: 0.1523

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.44070, std: 0.13091

Metrics for layer 4:
  pearson_correlation: 0.0141
  kl_divergence: -360.1880
  ssim: 0.0660
  iou: 0.1521
Layer 4 metrics:
  pearson_correlation: 0.0141
  kl_divergence: -360.1880
  ssim: 0.0660
  iou: 0.1521

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.41901, std: 0.14945

Metrics for layer 5:
  pearson_correlation: 0.0225
  kl_divergence: -331.9963
  ssim: 0.0562
  iou: 0.1589
Layer 5 metrics:
  pearson_correlation: 0.0225
  kl_divergence: -331.9963
  ssim: 0.0562
  iou: 0.1589

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47362, std: 0.15281

Metrics for layer 6:
  pearson_correlation: 0.0016
  kl_divergence: -377.5775
  ssim: 0.0522
  iou: 0.1479
Layer 6 metrics:
  pearson_correlation: 0.0016
  kl_divergence: -377.5775
  ssim: 0.0522
  iou: 0.1479

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.52483, std: 0.14985

Metrics for layer 7:
  pearson_correlation: 0.0062
  kl_divergence: -92.1962
  ssim: 0.0311
  iou: 0.1632
Layer 7 metrics:
  pearson_correlation: 0.0062
  kl_divergence: -92.1962
  ssim: 0.0311
  iou: 0.1632

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.44584, std: 0.16954

Metrics for layer 8:
  pearson_correlation: 0.0119
  kl_divergence: -81.5453
  ssim: 0.0383
  iou: 0.1395
Layer 8 metrics:
  pearson_correlation: 0.0119
  kl_divergence: -81.5453
  ssim: 0.0383
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.51018, std: 0.15592

Metrics for layer 9:
  pearson_correlation: -0.0109
  kl_divergence: -90.5003
  ssim: 0.0356
  iou: 0.1462
Layer 9 metrics:
  pearson_correlation: -0.0109
  kl_divergence: -90.5003
  ssim: 0.0356
  iou: 0.1462

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.47968, std: 0.19817

Metrics for layer 10:
  pearson_correlation: 0.2221
  kl_divergence: -17.5056
  ssim: 0.2364
  iou: 0.2099
Layer 10 metrics:
  pearson_correlation: 0.2221
  kl_divergence: -17.5056
  ssim: 0.2364
  iou: 0.2099

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.45942, std: 0.18324

Metrics for layer 11:
  pearson_correlation: 0.0532
  kl_divergence: -16.7986
  ssim: 0.1471
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: 0.0532
  kl_divergence: -16.7986
  ssim: 0.1471
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.46566, std: 0.18661

Metrics for layer 12:
  pearson_correlation: -0.0511
  kl_divergence: -15.7937
  ssim: 0.0308
  iou: 0.1264
Layer 12 metrics:
  pearson_correlation: -0.0511
  kl_divergence: -15.7937
  ssim: 0.0308
  iou: 0.1264
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer2/batch_1_strength_1.2_results.npy

Analysis complete! Results saved to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer2
