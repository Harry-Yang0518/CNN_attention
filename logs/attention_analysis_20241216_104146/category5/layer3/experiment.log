WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-12-16 10:50:09.547247: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-16 10:50:09.609518: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2024-12-16 10:50:09.609923: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4bf59c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-16 10:50:09.609937: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-16 10:50:09.612824: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-16 10:50:09.751872: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4be4350 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-16 10:50:09.751890: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-12-16 10:50:09.752419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:2f:00.0
2024-12-16 10:50:09.753631: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:50:09.754732: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:50:09.755819: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:50:09.756911: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:50:09.757988: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:50:09.759042: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:50:09.760095: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:50:09.760106: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-12-16 10:50:09.760126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-16 10:50:09.760131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-16 10:50:09.760134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:61: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:87: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:15: sigmoid_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.sigmoid_cross_entropy instead. Note that the order of the predictions and labels arguments has been changed.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:322: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:82: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.


Verifying paths:
tc_path: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs exists
weight_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists
image_path: /scratch/hy2611/CNN_attention/Data/VGG16/images exists
save_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists

Initializing model...
('c11', [1, 224, 224, 64])
('c12', [1, 224, 224, 64])
('c21', [1, 112, 112, 128])
('c22', [1, 112, 112, 128])
('c31', [1, 56, 56, 256])
('c32', [1, 56, 56, 256])
('c33', [1, 56, 56, 256])
('c41', [1, 28, 28, 512])
('c42', [1, 28, 28, 512])
('c43', [1, 28, 28, 512])
('c51', [1, 14, 14, 512])
('c52', [1, 14, 14, 512])
('c53', [1, 14, 14, 512])
(0, 'conv1_1_W', (3, 3, 3, 64))
(1, 'conv1_1_b', (64,))
(2, 'conv1_2_W', (3, 3, 64, 64))
(3, 'conv1_2_b', (64,))
(4, 'conv2_1_W', (3, 3, 64, 128))
(5, 'conv2_1_b', (128,))
(6, 'conv2_2_W', (3, 3, 128, 128))
(7, 'conv2_2_b', (128,))
(8, 'conv3_1_W', (3, 3, 128, 256))
(9, 'conv3_1_b', (256,))
(10, 'conv3_2_W', (3, 3, 256, 256))
(11, 'conv3_2_b', (256,))
(12, 'conv3_3_W', (3, 3, 256, 256))
(13, 'conv3_3_b', (256,))
(14, 'conv4_1_W', (3, 3, 256, 512))
(15, 'conv4_1_b', (512,))
(16, 'conv4_2_W', (3, 3, 512, 512))
(17, 'conv4_2_b', (512,))
(18, 'conv4_3_W', (3, 3, 512, 512))
(19, 'conv4_3_b', (512,))
(20, 'conv5_1_W', (3, 3, 512, 512))
(21, 'conv5_1_b', (512,))
(22, 'conv5_2_W', (3, 3, 512, 512))
(23, 'conv5_2_b', (512,))
(24, 'conv5_3_W', (3, 3, 512, 512))
(25, 'conv5_3_b', (512,))
(26, 'fc6_W', (25088, 4096))
(27, 'fc6_b', (4096,))
(28, 'fc7_W', (4096, 4096))
(29, 'fc7_b', (4096,))
Checking checkpoint files:
Data file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.data-00000-of-00001 - Found
Index file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.index - Found
Loading checkpoint from: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt
Checkpoint loaded successfully

Initializing components...
Found tuning curves file: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs/featvecs20_train35_c.txt

Loading category 5 data...
Original positive images shape: (2, 224, 224, 3)

Processing data...

Processing attention strength 0.0
Attention vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

Processing batch 1/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.45233, std: 0.12559

Metrics for layer 0:
  pearson_correlation: -0.0043
  kl_divergence: -4760.2856
  ssim: 0.0428
  iou: 0.1404
Layer 0 metrics:
  pearson_correlation: -0.0043
  kl_divergence: -4760.2856
  ssim: 0.0428
  iou: 0.1404

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42460, std: 0.11675

Metrics for layer 1:
  pearson_correlation: 0.0015
  kl_divergence: -4571.3003
  ssim: 0.0532
  iou: 0.1420
Layer 1 metrics:
  pearson_correlation: 0.0015
  kl_divergence: -4571.3003
  ssim: 0.0532
  iou: 0.1420

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.49289, std: 0.12772

Metrics for layer 2:
  pearson_correlation: -0.0147
  kl_divergence: -1468.9125
  ssim: 0.0495
  iou: 0.1381
Layer 2 metrics:
  pearson_correlation: -0.0147
  kl_divergence: -1468.9125
  ssim: 0.0495
  iou: 0.1381

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.46971, std: 0.13519

Metrics for layer 3:
  pearson_correlation: -0.0040
  kl_divergence: -1416.3782
  ssim: 0.0498
  iou: 0.1433
Layer 3 metrics:
  pearson_correlation: -0.0040
  kl_divergence: -1416.3782
  ssim: 0.0498
  iou: 0.1433

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.45120, std: 0.14124

Metrics for layer 4:
  pearson_correlation: -0.0060
  kl_divergence: -347.4987
  ssim: 0.0532
  iou: 0.1404
Layer 4 metrics:
  pearson_correlation: -0.0060
  kl_divergence: -347.4987
  ssim: 0.0532
  iou: 0.1404

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50335, std: 0.14063

Metrics for layer 5:
  pearson_correlation: -0.0194
  kl_divergence: -388.3788
  ssim: 0.0526
  iou: 0.1248
Layer 5 metrics:
  pearson_correlation: -0.0194
  kl_divergence: -388.3788
  ssim: 0.0526
  iou: 0.1248

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47538, std: 0.14214

Metrics for layer 6:
  pearson_correlation: 0.0121
  kl_divergence: -374.4337
  ssim: 0.0700
  iou: 0.1598
Layer 6 metrics:
  pearson_correlation: 0.0121
  kl_divergence: -374.4337
  ssim: 0.0700
  iou: 0.1598

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.43002, std: 0.14676

Metrics for layer 7:
  pearson_correlation: 0.0077
  kl_divergence: -77.5297
  ssim: 0.0579
  iou: 0.1429
Layer 7 metrics:
  pearson_correlation: 0.0077
  kl_divergence: -77.5297
  ssim: 0.0579
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.46523, std: 0.16141

Metrics for layer 8:
  pearson_correlation: -0.0280
  kl_divergence: -83.1362
  ssim: 0.0581
  iou: 0.1297
Layer 8 metrics:
  pearson_correlation: -0.0280
  kl_divergence: -83.1362
  ssim: 0.0581
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.51094, std: 0.16177

Metrics for layer 9:
  pearson_correlation: -0.0278
  kl_divergence: -94.9022
  ssim: 0.0294
  iou: 0.1297
Layer 9 metrics:
  pearson_correlation: -0.0278
  kl_divergence: -94.9022
  ssim: 0.0294
  iou: 0.1297

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49066, std: 0.19062

Metrics for layer 10:
  pearson_correlation: 0.1717
  kl_divergence: -23.6652
  ssim: 0.1802
  iou: 0.1951
Layer 10 metrics:
  pearson_correlation: 0.1717
  kl_divergence: -23.6652
  ssim: 0.1802
  iou: 0.1951

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.51128, std: 0.19496

Metrics for layer 11:
  pearson_correlation: 0.0254
  kl_divergence: -23.0206
  ssim: -0.0041
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: 0.0254
  kl_divergence: -23.0206
  ssim: -0.0041
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.47793, std: 0.17153

Metrics for layer 12:
  pearson_correlation: 0.1426
  kl_divergence: -18.9583
  ssim: 0.1412
  iou: 0.1807
Layer 12 metrics:
  pearson_correlation: 0.1426
  kl_divergence: -18.9583
  ssim: 0.1412
  iou: 0.1807
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer3/batch_0_strength_0.0_results.npy

Processing batch 2/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.39924, std: 0.11495

Metrics for layer 0:
  pearson_correlation: 0.0034
  kl_divergence: -3652.7385
  ssim: 0.0393
  iou: 0.1477
Layer 0 metrics:
  pearson_correlation: 0.0034
  kl_divergence: -3652.7385
  ssim: 0.0393
  iou: 0.1477

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43133, std: 0.11647

Metrics for layer 1:
  pearson_correlation: -0.0003
  kl_divergence: -3805.5896
  ssim: 0.0357
  iou: 0.1409
Layer 1 metrics:
  pearson_correlation: -0.0003
  kl_divergence: -3805.5896
  ssim: 0.0357
  iou: 0.1409

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.42935, std: 0.12639

Metrics for layer 2:
  pearson_correlation: 0.0003
  kl_divergence: -1306.0195
  ssim: 0.0523
  iou: 0.1383
Layer 2 metrics:
  pearson_correlation: 0.0003
  kl_divergence: -1306.0195
  ssim: 0.0523
  iou: 0.1383

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.44801, std: 0.13909

Metrics for layer 3:
  pearson_correlation: -0.0066
  kl_divergence: -1335.1715
  ssim: 0.0434
  iou: 0.1389
Layer 3 metrics:
  pearson_correlation: -0.0066
  kl_divergence: -1335.1715
  ssim: 0.0434
  iou: 0.1389

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.45067, std: 0.13333

Metrics for layer 4:
  pearson_correlation: -0.0366
  kl_divergence: -360.3385
  ssim: 0.0538
  iou: 0.1313
Layer 4 metrics:
  pearson_correlation: -0.0366
  kl_divergence: -360.3385
  ssim: 0.0538
  iou: 0.1313

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47212, std: 0.14189

Metrics for layer 5:
  pearson_correlation: -0.0245
  kl_divergence: -379.0588
  ssim: 0.0555
  iou: 0.1297
Layer 5 metrics:
  pearson_correlation: -0.0245
  kl_divergence: -379.0588
  ssim: 0.0555
  iou: 0.1297

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47260, std: 0.15610

Metrics for layer 6:
  pearson_correlation: 0.0138
  kl_divergence: -378.3198
  ssim: 0.0475
  iou: 0.1623
Layer 6 metrics:
  pearson_correlation: 0.0138
  kl_divergence: -378.3198
  ssim: 0.0475
  iou: 0.1623

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.50273, std: 0.17489

Metrics for layer 7:
  pearson_correlation: -0.0309
  kl_divergence: -87.0755
  ssim: 0.0120
  iou: 0.1529
Layer 7 metrics:
  pearson_correlation: -0.0309
  kl_divergence: -87.0755
  ssim: 0.0120
  iou: 0.1529

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.42272, std: 0.15797

Metrics for layer 8:
  pearson_correlation: -0.0009
  kl_divergence: -78.1588
  ssim: 0.0406
  iou: 0.1462
Layer 8 metrics:
  pearson_correlation: -0.0009
  kl_divergence: -78.1588
  ssim: 0.0406
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.49109, std: 0.15884

Metrics for layer 9:
  pearson_correlation: -0.0228
  kl_divergence: -87.4740
  ssim: 0.0384
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: -0.0228
  kl_divergence: -87.4740
  ssim: 0.0384
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.49811, std: 0.16288

Metrics for layer 10:
  pearson_correlation: -0.1142
  kl_divergence: -15.9935
  ssim: -0.0921
  iou: 0.1667
Layer 10 metrics:
  pearson_correlation: -0.1142
  kl_divergence: -15.9935
  ssim: -0.0921
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.45953, std: 0.20225

Metrics for layer 11:
  pearson_correlation: -0.0728
  kl_divergence: -7.9688
  ssim: -0.0228
  iou: 0.1011
Layer 11 metrics:
  pearson_correlation: -0.0728
  kl_divergence: -7.9688
  ssim: -0.0228
  iou: 0.1011

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.55312, std: 0.18276

Metrics for layer 12:
  pearson_correlation: -0.0220
  kl_divergence: -24.0781
  ssim: 0.0470
  iou: 0.1136
Layer 12 metrics:
  pearson_correlation: -0.0220
  kl_divergence: -24.0781
  ssim: 0.0470
  iou: 0.1136
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer3/batch_1_strength_0.0_results.npy

Processing attention strength 0.4
Attention vector: [0.  0.  0.  0.4 0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.43665, std: 0.12709

Metrics for layer 0:
  pearson_correlation: -0.0019
  kl_divergence: -4639.0117
  ssim: 0.0440
  iou: 0.1437
Layer 0 metrics:
  pearson_correlation: -0.0019
  kl_divergence: -4639.0117
  ssim: 0.0440
  iou: 0.1437

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42419, std: 0.12178

Metrics for layer 1:
  pearson_correlation: -0.0044
  kl_divergence: -4548.9487
  ssim: 0.0475
  iou: 0.1425
Layer 1 metrics:
  pearson_correlation: -0.0044
  kl_divergence: -4548.9487
  ssim: 0.0475
  iou: 0.1425

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.46231, std: 0.13588

Metrics for layer 2:
  pearson_correlation: 0.0090
  kl_divergence: -1397.2031
  ssim: 0.0522
  iou: 0.1508
Layer 2 metrics:
  pearson_correlation: 0.0090
  kl_divergence: -1397.2031
  ssim: 0.0522
  iou: 0.1508

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.55296, std: 0.12327

Metrics for layer 3:
  pearson_correlation: 0.0003
  kl_divergence: -1598.9456
  ssim: 0.0515
  iou: 0.1393
Layer 3 metrics:
  pearson_correlation: 0.0003
  kl_divergence: -1598.9456
  ssim: 0.0515
  iou: 0.1393

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.42738, std: 0.13747

Metrics for layer 4:
  pearson_correlation: 0.0055
  kl_divergence: -329.0248
  ssim: 0.0624
  iou: 0.1429
Layer 4 metrics:
  pearson_correlation: 0.0055
  kl_divergence: -329.0248
  ssim: 0.0624
  iou: 0.1429

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.45842, std: 0.14089

Metrics for layer 5:
  pearson_correlation: -0.0030
  kl_divergence: -358.8674
  ssim: 0.0516
  iou: 0.1313
Layer 5 metrics:
  pearson_correlation: -0.0030
  kl_divergence: -358.8674
  ssim: 0.0516
  iou: 0.1313

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.43133, std: 0.15075

Metrics for layer 6:
  pearson_correlation: -0.0110
  kl_divergence: -331.5529
  ssim: 0.0547
  iou: 0.1281
Layer 6 metrics:
  pearson_correlation: -0.0110
  kl_divergence: -331.5529
  ssim: 0.0547
  iou: 0.1281

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.52073, std: 0.13663

Metrics for layer 7:
  pearson_correlation: -0.0178
  kl_divergence: -89.5013
  ssim: 0.0471
  iou: 0.1264
Layer 7 metrics:
  pearson_correlation: -0.0178
  kl_divergence: -89.5013
  ssim: 0.0471
  iou: 0.1264

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.46175, std: 0.16150

Metrics for layer 8:
  pearson_correlation: -0.0463
  kl_divergence: -79.3773
  ssim: 0.0532
  iou: 0.1329
Layer 8 metrics:
  pearson_correlation: -0.0463
  kl_divergence: -79.3773
  ssim: 0.0532
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.49692, std: 0.17366

Metrics for layer 9:
  pearson_correlation: -0.0151
  kl_divergence: -92.6061
  ssim: 0.0402
  iou: 0.1496
Layer 9 metrics:
  pearson_correlation: -0.0151
  kl_divergence: -92.6061
  ssim: 0.0402
  iou: 0.1496

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.47405, std: 0.18036

Metrics for layer 10:
  pearson_correlation: -0.0299
  kl_divergence: -17.6165
  ssim: -0.0110
  iou: 0.1264
Layer 10 metrics:
  pearson_correlation: -0.0299
  kl_divergence: -17.6165
  ssim: -0.0110
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49432, std: 0.19126

Metrics for layer 11:
  pearson_correlation: -0.0462
  kl_divergence: -19.1354
  ssim: 0.0045
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: -0.0462
  kl_divergence: -19.1354
  ssim: 0.0045
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.56477, std: 0.18982

Metrics for layer 12:
  pearson_correlation: -0.0781
  kl_divergence: -26.6891
  ssim: -0.0539
  iou: 0.1011
Layer 12 metrics:
  pearson_correlation: -0.0781
  kl_divergence: -26.6891
  ssim: -0.0539
  iou: 0.1011
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer3/batch_0_strength_0.4_results.npy

Processing batch 2/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43257, std: 0.11048

Metrics for layer 0:
  pearson_correlation: -0.0012
  kl_divergence: -3819.2207
  ssim: 0.0377
  iou: 0.1394
Layer 0 metrics:
  pearson_correlation: -0.0012
  kl_divergence: -3819.2207
  ssim: 0.0377
  iou: 0.1394

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.39015, std: 0.12069

Metrics for layer 1:
  pearson_correlation: -0.0083
  kl_divergence: -3587.9321
  ssim: 0.0358
  iou: 0.1375
Layer 1 metrics:
  pearson_correlation: -0.0083
  kl_divergence: -3587.9321
  ssim: 0.0358
  iou: 0.1375

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.44504, std: 0.13010

Metrics for layer 2:
  pearson_correlation: 0.0023
  kl_divergence: -1336.4153
  ssim: 0.0496
  iou: 0.1406
Layer 2 metrics:
  pearson_correlation: 0.0023
  kl_divergence: -1336.4153
  ssim: 0.0496
  iou: 0.1406

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.52914, std: 0.12125

Metrics for layer 3:
  pearson_correlation: -0.0037
  kl_divergence: -1509.6108
  ssim: 0.0468
  iou: 0.1371
Layer 3 metrics:
  pearson_correlation: -0.0037
  kl_divergence: -1509.6108
  ssim: 0.0468
  iou: 0.1371

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.44707, std: 0.15464

Metrics for layer 4:
  pearson_correlation: -0.0377
  kl_divergence: -351.2390
  ssim: 0.0423
  iou: 0.1412
Layer 4 metrics:
  pearson_correlation: -0.0377
  kl_divergence: -351.2390
  ssim: 0.0423
  iou: 0.1412

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47453, std: 0.13038

Metrics for layer 5:
  pearson_correlation: -0.0181
  kl_divergence: -385.7532
  ssim: 0.0593
  iou: 0.1248
Layer 5 metrics:
  pearson_correlation: -0.0181
  kl_divergence: -385.7532
  ssim: 0.0593
  iou: 0.1248

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.43863, std: 0.14986

Metrics for layer 6:
  pearson_correlation: 0.0027
  kl_divergence: -348.4506
  ssim: 0.0544
  iou: 0.1379
Layer 6 metrics:
  pearson_correlation: 0.0027
  kl_divergence: -348.4506
  ssim: 0.0544
  iou: 0.1379

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.53941, std: 0.16450

Metrics for layer 7:
  pearson_correlation: -0.0582
  kl_divergence: -92.4569
  ssim: 0.0168
  iou: 0.1329
Layer 7 metrics:
  pearson_correlation: -0.0582
  kl_divergence: -92.4569
  ssim: 0.0168
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.47764, std: 0.17517

Metrics for layer 8:
  pearson_correlation: 0.0225
  kl_divergence: -86.3752
  ssim: 0.0330
  iou: 0.1297
Layer 8 metrics:
  pearson_correlation: 0.0225
  kl_divergence: -86.3752
  ssim: 0.0330
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.45137, std: 0.17612

Metrics for layer 9:
  pearson_correlation: 0.0171
  kl_divergence: -78.8805
  ssim: 0.0452
  iou: 0.1667
Layer 9 metrics:
  pearson_correlation: 0.0171
  kl_divergence: -78.8805
  ssim: 0.0452
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.44369, std: 0.17782

Metrics for layer 10:
  pearson_correlation: -0.0168
  kl_divergence: -13.8433
  ssim: -0.0421
  iou: 0.1807
Layer 10 metrics:
  pearson_correlation: -0.0168
  kl_divergence: -13.8433
  ssim: -0.0421
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.48998, std: 0.17919

Metrics for layer 11:
  pearson_correlation: 0.0862
  kl_divergence: -20.0548
  ssim: 0.1907
  iou: 0.1807
Layer 11 metrics:
  pearson_correlation: 0.0862
  kl_divergence: -20.0548
  ssim: 0.1907
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.37469, std: 0.18717

Metrics for layer 12:
  pearson_correlation: -0.0881
  kl_divergence: 5.9081
  ssim: -0.0196
  iou: 0.1011
Layer 12 metrics:
  pearson_correlation: -0.0881
  kl_divergence: 5.9081
  ssim: -0.0196
  iou: 0.1011
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer3/batch_1_strength_0.4_results.npy

Processing attention strength 0.8
Attention vector: [0.  0.  0.  0.8 0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.44800, std: 0.12009

Metrics for layer 0:
  pearson_correlation: 0.0026
  kl_divergence: -4743.4116
  ssim: 0.0475
  iou: 0.1454
Layer 0 metrics:
  pearson_correlation: 0.0026
  kl_divergence: -4743.4116
  ssim: 0.0475
  iou: 0.1454

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.40664, std: 0.12064

Metrics for layer 1:
  pearson_correlation: -0.0027
  kl_divergence: -4413.5469
  ssim: 0.0503
  iou: 0.1415
Layer 1 metrics:
  pearson_correlation: -0.0027
  kl_divergence: -4413.5469
  ssim: 0.0503
  iou: 0.1415

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.45837, std: 0.13152

Metrics for layer 2:
  pearson_correlation: 0.0097
  kl_divergence: -1393.7780
  ssim: 0.0551
  iou: 0.1452
Layer 2 metrics:
  pearson_correlation: 0.0097
  kl_divergence: -1393.7780
  ssim: 0.0551
  iou: 0.1452

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.48018, std: 0.12526

Metrics for layer 3:
  pearson_correlation: 0.0050
  kl_divergence: -1443.7183
  ssim: 0.0577
  iou: 0.1431
Layer 3 metrics:
  pearson_correlation: 0.0050
  kl_divergence: -1443.7183
  ssim: 0.0577
  iou: 0.1431

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46189, std: 0.15181

Metrics for layer 4:
  pearson_correlation: 0.0248
  kl_divergence: -359.6756
  ssim: 0.0616
  iou: 0.1420
Layer 4 metrics:
  pearson_correlation: 0.0248
  kl_divergence: -359.6756
  ssim: 0.0616
  iou: 0.1420

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.49449, std: 0.14123

Metrics for layer 5:
  pearson_correlation: 0.0214
  kl_divergence: -386.4470
  ssim: 0.0643
  iou: 0.1521
Layer 5 metrics:
  pearson_correlation: 0.0214
  kl_divergence: -386.4470
  ssim: 0.0643
  iou: 0.1521

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50795, std: 0.13793

Metrics for layer 6:
  pearson_correlation: -0.0150
  kl_divergence: -396.1701
  ssim: 0.0644
  iou: 0.1346
Layer 6 metrics:
  pearson_correlation: -0.0150
  kl_divergence: -396.1701
  ssim: 0.0644
  iou: 0.1346

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.50343, std: 0.15456

Metrics for layer 7:
  pearson_correlation: 0.0035
  kl_divergence: -95.9517
  ssim: 0.0557
  iou: 0.1807
Layer 7 metrics:
  pearson_correlation: 0.0035
  kl_divergence: -95.9517
  ssim: 0.0557
  iou: 0.1807

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.45557, std: 0.16054

Metrics for layer 8:
  pearson_correlation: -0.0013
  kl_divergence: -81.4597
  ssim: 0.0454
  iou: 0.1329
Layer 8 metrics:
  pearson_correlation: -0.0013
  kl_divergence: -81.4597
  ssim: 0.0454
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.45374, std: 0.15846

Metrics for layer 9:
  pearson_correlation: 0.0912
  kl_divergence: -87.7654
  ssim: 0.0949
  iou: 0.1462
Layer 9 metrics:
  pearson_correlation: 0.0912
  kl_divergence: -87.7654
  ssim: 0.0949
  iou: 0.1462

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.47014, std: 0.17422

Metrics for layer 10:
  pearson_correlation: -0.0386
  kl_divergence: -5.8672
  ssim: -0.0523
  iou: 0.1136
Layer 10 metrics:
  pearson_correlation: -0.0386
  kl_divergence: -5.8672
  ssim: -0.0523
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.47740, std: 0.20232

Metrics for layer 11:
  pearson_correlation: 0.1078
  kl_divergence: -18.5630
  ssim: 0.2143
  iou: 0.1951
Layer 11 metrics:
  pearson_correlation: 0.1078
  kl_divergence: -18.5630
  ssim: 0.2143
  iou: 0.1951

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49859, std: 0.19664

Metrics for layer 12:
  pearson_correlation: -0.0953
  kl_divergence: -20.7992
  ssim: 0.0439
  iou: 0.1136
Layer 12 metrics:
  pearson_correlation: -0.0953
  kl_divergence: -20.7992
  ssim: 0.0439
  iou: 0.1136
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer3/batch_0_strength_0.8_results.npy

Processing batch 2/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.42871, std: 0.12604

Metrics for layer 0:
  pearson_correlation: 0.0008
  kl_divergence: -3779.0247
  ssim: 0.0316
  iou: 0.1419
Layer 0 metrics:
  pearson_correlation: 0.0008
  kl_divergence: -3779.0247
  ssim: 0.0316
  iou: 0.1419

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.41212, std: 0.11751

Metrics for layer 1:
  pearson_correlation: -0.0066
  kl_divergence: -3708.3252
  ssim: 0.0363
  iou: 0.1422
Layer 1 metrics:
  pearson_correlation: -0.0066
  kl_divergence: -3708.3252
  ssim: 0.0363
  iou: 0.1422

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.44640, std: 0.13664

Metrics for layer 2:
  pearson_correlation: -0.0025
  kl_divergence: -1335.5662
  ssim: 0.0446
  iou: 0.1402
Layer 2 metrics:
  pearson_correlation: -0.0025
  kl_divergence: -1335.5662
  ssim: 0.0446
  iou: 0.1402

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.49659, std: 0.13010

Metrics for layer 3:
  pearson_correlation: -0.0070
  kl_divergence: -1443.3911
  ssim: 0.0438
  iou: 0.1363
Layer 3 metrics:
  pearson_correlation: -0.0070
  kl_divergence: -1443.3911
  ssim: 0.0438
  iou: 0.1363

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.44779, std: 0.13190

Metrics for layer 4:
  pearson_correlation: -0.0054
  kl_divergence: -359.9367
  ssim: 0.0591
  iou: 0.1563
Layer 4 metrics:
  pearson_correlation: -0.0054
  kl_divergence: -359.9367
  ssim: 0.0591
  iou: 0.1563

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.43285, std: 0.13888

Metrics for layer 5:
  pearson_correlation: -0.0063
  kl_divergence: -345.9095
  ssim: 0.0601
  iou: 0.1297
Layer 5 metrics:
  pearson_correlation: -0.0063
  kl_divergence: -345.9095
  ssim: 0.0601
  iou: 0.1297

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48755, std: 0.14402

Metrics for layer 6:
  pearson_correlation: 0.0146
  kl_divergence: -394.4412
  ssim: 0.0534
  iou: 0.1496
Layer 6 metrics:
  pearson_correlation: 0.0146
  kl_divergence: -394.4412
  ssim: 0.0534
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.46818, std: 0.16257

Metrics for layer 7:
  pearson_correlation: 0.0061
  kl_divergence: -85.4384
  ssim: 0.0375
  iou: 0.1462
Layer 7 metrics:
  pearson_correlation: 0.0061
  kl_divergence: -85.4384
  ssim: 0.0375
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.48448, std: 0.18496

Metrics for layer 8:
  pearson_correlation: 0.0214
  kl_divergence: -85.0341
  ssim: 0.0317
  iou: 0.1701
Layer 8 metrics:
  pearson_correlation: 0.0214
  kl_divergence: -85.0341
  ssim: 0.0317
  iou: 0.1701

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.53553, std: 0.15879

Metrics for layer 9:
  pearson_correlation: 0.0162
  kl_divergence: -95.2290
  ssim: 0.0401
  iou: 0.1264
Layer 9 metrics:
  pearson_correlation: 0.0162
  kl_divergence: -95.2290
  ssim: 0.0401
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.50438, std: 0.16226

Metrics for layer 10:
  pearson_correlation: 0.0931
  kl_divergence: -21.7395
  ssim: 0.1597
  iou: 0.1667
Layer 10 metrics:
  pearson_correlation: 0.0931
  kl_divergence: -21.7395
  ssim: 0.1597
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.44298, std: 0.19538

Metrics for layer 11:
  pearson_correlation: -0.0686
  kl_divergence: -10.8874
  ssim: 0.0507
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: -0.0686
  kl_divergence: -10.8874
  ssim: 0.0507
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.40203, std: 0.17311

Metrics for layer 12:
  pearson_correlation: -0.0372
  kl_divergence: -11.5066
  ssim: 0.0326
  iou: 0.0889
Layer 12 metrics:
  pearson_correlation: -0.0372
  kl_divergence: -11.5066
  ssim: 0.0326
  iou: 0.0889
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer3/batch_1_strength_0.8_results.npy

Processing attention strength 1.2
Attention vector: [0.  0.  0.  1.2 0.  0.  0.  0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.43109, std: 0.11570

Metrics for layer 0:
  pearson_correlation: -0.0022
  kl_divergence: -4621.9717
  ssim: 0.0504
  iou: 0.1444
Layer 0 metrics:
  pearson_correlation: -0.0022
  kl_divergence: -4621.9717
  ssim: 0.0504
  iou: 0.1444

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.39335, std: 0.11271

Metrics for layer 1:
  pearson_correlation: 0.0039
  kl_divergence: -4329.1763
  ssim: 0.0587
  iou: 0.1438
Layer 1 metrics:
  pearson_correlation: 0.0039
  kl_divergence: -4329.1763
  ssim: 0.0587
  iou: 0.1438

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.52200, std: 0.12699

Metrics for layer 2:
  pearson_correlation: -0.0014
  kl_divergence: -1536.6339
  ssim: 0.0491
  iou: 0.1410
Layer 2 metrics:
  pearson_correlation: -0.0014
  kl_divergence: -1536.6339
  ssim: 0.0491
  iou: 0.1410

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.49987, std: 0.13150

Metrics for layer 3:
  pearson_correlation: 0.0043
  kl_divergence: -1487.5059
  ssim: 0.0480
  iou: 0.1406
Layer 3 metrics:
  pearson_correlation: 0.0043
  kl_divergence: -1487.5059
  ssim: 0.0480
  iou: 0.1406

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46122, std: 0.14836

Metrics for layer 4:
  pearson_correlation: 0.0204
  kl_divergence: -357.6137
  ssim: 0.0508
  iou: 0.1504
Layer 4 metrics:
  pearson_correlation: 0.0204
  kl_divergence: -357.6137
  ssim: 0.0508
  iou: 0.1504

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50272, std: 0.13343

Metrics for layer 5:
  pearson_correlation: 0.0174
  kl_divergence: -396.0163
  ssim: 0.0571
  iou: 0.1512
Layer 5 metrics:
  pearson_correlation: 0.0174
  kl_divergence: -396.0163
  ssim: 0.0571
  iou: 0.1512

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.53132, std: 0.15010

Metrics for layer 6:
  pearson_correlation: -0.0164
  kl_divergence: -407.9266
  ssim: 0.0399
  iou: 0.1362
Layer 6 metrics:
  pearson_correlation: -0.0164
  kl_divergence: -407.9266
  ssim: 0.0399
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.47119, std: 0.16625

Metrics for layer 7:
  pearson_correlation: -0.0463
  kl_divergence: -86.3060
  ssim: 0.0407
  iou: 0.1105
Layer 7 metrics:
  pearson_correlation: -0.0463
  kl_divergence: -86.3060
  ssim: 0.0407
  iou: 0.1105

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.46884, std: 0.15270

Metrics for layer 8:
  pearson_correlation: -0.0606
  kl_divergence: -87.0719
  ssim: 0.0439
  iou: 0.1136
Layer 8 metrics:
  pearson_correlation: -0.0606
  kl_divergence: -87.0719
  ssim: 0.0439
  iou: 0.1136

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.46631, std: 0.15351

Metrics for layer 9:
  pearson_correlation: -0.0217
  kl_divergence: -87.0504
  ssim: 0.0281
  iou: 0.1362
Layer 9 metrics:
  pearson_correlation: -0.0217
  kl_divergence: -87.0504
  ssim: 0.0281
  iou: 0.1362

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.48586, std: 0.20374

Metrics for layer 10:
  pearson_correlation: 0.0623
  kl_divergence: -20.6976
  ssim: 0.1231
  iou: 0.1136
Layer 10 metrics:
  pearson_correlation: 0.0623
  kl_divergence: -20.6976
  ssim: 0.1231
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49916, std: 0.17671

Metrics for layer 11:
  pearson_correlation: 0.0377
  kl_divergence: -20.7903
  ssim: 0.0660
  iou: 0.1807
Layer 11 metrics:
  pearson_correlation: 0.0377
  kl_divergence: -20.7903
  ssim: 0.0660
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49182, std: 0.16855

Metrics for layer 12:
  pearson_correlation: -0.0540
  kl_divergence: -21.5735
  ssim: -0.0011
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: -0.0540
  kl_divergence: -21.5735
  ssim: -0.0011
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer3/batch_0_strength_1.2_results.npy

Processing batch 2/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.40379, std: 0.11256

Metrics for layer 0:
  pearson_correlation: 0.0042
  kl_divergence: -3681.1619
  ssim: 0.0398
  iou: 0.1401
Layer 0 metrics:
  pearson_correlation: 0.0042
  kl_divergence: -3681.1619
  ssim: 0.0398
  iou: 0.1401

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.44358, std: 0.11964

Metrics for layer 1:
  pearson_correlation: 0.0027
  kl_divergence: -3859.9280
  ssim: 0.0334
  iou: 0.1413
Layer 1 metrics:
  pearson_correlation: 0.0027
  kl_divergence: -3859.9280
  ssim: 0.0334
  iou: 0.1413

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.46222, std: 0.12412

Metrics for layer 2:
  pearson_correlation: -0.0047
  kl_divergence: -1380.7277
  ssim: 0.0497
  iou: 0.1385
Layer 2 metrics:
  pearson_correlation: -0.0047
  kl_divergence: -1380.7277
  ssim: 0.0497
  iou: 0.1385

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.49074, std: 0.12637

Metrics for layer 3:
  pearson_correlation: 0.0126
  kl_divergence: -1431.0948
  ssim: 0.0511
  iou: 0.1387
Layer 3 metrics:
  pearson_correlation: 0.0126
  kl_divergence: -1431.0948
  ssim: 0.0511
  iou: 0.1387

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.49157, std: 0.14815

Metrics for layer 4:
  pearson_correlation: -0.0034
  kl_divergence: -390.4441
  ssim: 0.0536
  iou: 0.1598
Layer 4 metrics:
  pearson_correlation: -0.0034
  kl_divergence: -390.4441
  ssim: 0.0536
  iou: 0.1598

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.45456, std: 0.14705

Metrics for layer 5:
  pearson_correlation: -0.0074
  kl_divergence: -363.1031
  ssim: 0.0526
  iou: 0.1546
Layer 5 metrics:
  pearson_correlation: -0.0074
  kl_divergence: -363.1031
  ssim: 0.0526
  iou: 0.1546

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48236, std: 0.14655

Metrics for layer 6:
  pearson_correlation: -0.0133
  kl_divergence: -387.6982
  ssim: 0.0436
  iou: 0.1387
Layer 6 metrics:
  pearson_correlation: -0.0133
  kl_divergence: -387.6982
  ssim: 0.0436
  iou: 0.1387

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.40295, std: 0.16093

Metrics for layer 7:
  pearson_correlation: 0.0269
  kl_divergence: -74.2430
  ssim: 0.0526
  iou: 0.1701
Layer 7 metrics:
  pearson_correlation: 0.0269
  kl_divergence: -74.2430
  ssim: 0.0526
  iou: 0.1701

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.46636, std: 0.18326

Metrics for layer 8:
  pearson_correlation: -0.0119
  kl_divergence: -83.1762
  ssim: 0.0224
  iou: 0.1329
Layer 8 metrics:
  pearson_correlation: -0.0119
  kl_divergence: -83.1762
  ssim: 0.0224
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.41781, std: 0.15253

Metrics for layer 9:
  pearson_correlation: -0.0324
  kl_divergence: -75.3669
  ssim: 0.0321
  iou: 0.1329
Layer 9 metrics:
  pearson_correlation: -0.0324
  kl_divergence: -75.3669
  ssim: 0.0321
  iou: 0.1329

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.48352, std: 0.16176

Metrics for layer 10:
  pearson_correlation: 0.1914
  kl_divergence: -21.2943
  ssim: 0.1470
  iou: 0.1951
Layer 10 metrics:
  pearson_correlation: 0.1914
  kl_divergence: -21.2943
  ssim: 0.1470
  iou: 0.1951

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.43510, std: 0.16703

Metrics for layer 11:
  pearson_correlation: -0.0179
  kl_divergence: -14.2847
  ssim: -0.0329
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: -0.0179
  kl_divergence: -14.2847
  ssim: -0.0329
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.55615, std: 0.16787

Metrics for layer 12:
  pearson_correlation: 0.1586
  kl_divergence: -25.9823
  ssim: 0.0970
  iou: 0.1807
Layer 12 metrics:
  pearson_correlation: 0.1586
  kl_divergence: -25.9823
  ssim: 0.0970
  iou: 0.1807
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer3/batch_1_strength_1.2_results.npy

Analysis complete! Results saved to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer3
