WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-12-16 11:15:38.270842: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-16 11:15:38.289637: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2024-12-16 11:15:38.290281: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4217a20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:15:38.290297: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-16 11:15:38.293025: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-16 11:15:38.421980: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x42004d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-16 11:15:38.421998: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-12-16 11:15:38.422560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:2f:00.0
2024-12-16 11:15:38.423853: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:15:38.425003: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:15:38.426105: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:15:38.427185: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:15:38.428279: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:15:38.429363: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:15:38.430437: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 11:15:38.430448: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-12-16 11:15:38.430466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-16 11:15:38.430471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-16 11:15:38.430475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:61: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:87: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:15: sigmoid_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.sigmoid_cross_entropy instead. Note that the order of the predictions and labels arguments has been changed.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:322: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:82: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.


Verifying paths:
tc_path: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs exists
weight_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists
image_path: /scratch/hy2611/CNN_attention/Data/VGG16/images exists
save_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists

Initializing model...
('c11', [1, 224, 224, 64])
('c12', [1, 224, 224, 64])
('c21', [1, 112, 112, 128])
('c22', [1, 112, 112, 128])
('c31', [1, 56, 56, 256])
('c32', [1, 56, 56, 256])
('c33', [1, 56, 56, 256])
('c41', [1, 28, 28, 512])
('c42', [1, 28, 28, 512])
('c43', [1, 28, 28, 512])
('c51', [1, 14, 14, 512])
('c52', [1, 14, 14, 512])
('c53', [1, 14, 14, 512])
(0, 'conv1_1_W', (3, 3, 3, 64))
(1, 'conv1_1_b', (64,))
(2, 'conv1_2_W', (3, 3, 64, 64))
(3, 'conv1_2_b', (64,))
(4, 'conv2_1_W', (3, 3, 64, 128))
(5, 'conv2_1_b', (128,))
(6, 'conv2_2_W', (3, 3, 128, 128))
(7, 'conv2_2_b', (128,))
(8, 'conv3_1_W', (3, 3, 128, 256))
(9, 'conv3_1_b', (256,))
(10, 'conv3_2_W', (3, 3, 256, 256))
(11, 'conv3_2_b', (256,))
(12, 'conv3_3_W', (3, 3, 256, 256))
(13, 'conv3_3_b', (256,))
(14, 'conv4_1_W', (3, 3, 256, 512))
(15, 'conv4_1_b', (512,))
(16, 'conv4_2_W', (3, 3, 512, 512))
(17, 'conv4_2_b', (512,))
(18, 'conv4_3_W', (3, 3, 512, 512))
(19, 'conv4_3_b', (512,))
(20, 'conv5_1_W', (3, 3, 512, 512))
(21, 'conv5_1_b', (512,))
(22, 'conv5_2_W', (3, 3, 512, 512))
(23, 'conv5_2_b', (512,))
(24, 'conv5_3_W', (3, 3, 512, 512))
(25, 'conv5_3_b', (512,))
(26, 'fc6_W', (25088, 4096))
(27, 'fc6_b', (4096,))
(28, 'fc7_W', (4096, 4096))
(29, 'fc7_b', (4096,))
Checking checkpoint files:
Data file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.data-00000-of-00001 - Found
Index file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.index - Found
Loading checkpoint from: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt
Checkpoint loaded successfully

Initializing components...
Found tuning curves file: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs/featvecs20_train35_c.txt

Loading category 5 data...
Original positive images shape: (2, 224, 224, 3)

Processing data...

Processing attention strength 0.0
Attention vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

Processing batch 1/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.40561, std: 0.12137

Metrics for layer 0:
  pearson_correlation: -0.0016
  kl_divergence: -4406.5522
  ssim: 0.0518
  iou: 0.1413
Layer 0 metrics:
  pearson_correlation: -0.0016
  kl_divergence: -4406.5522
  ssim: 0.0518
  iou: 0.1413

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.40976, std: 0.11858

Metrics for layer 1:
  pearson_correlation: -0.0023
  kl_divergence: -4445.1045
  ssim: 0.0513
  iou: 0.1413
Layer 1 metrics:
  pearson_correlation: -0.0023
  kl_divergence: -4445.1045
  ssim: 0.0513
  iou: 0.1413

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.44564, std: 0.12008

Metrics for layer 2:
  pearson_correlation: 0.0017
  kl_divergence: -1370.3236
  ssim: 0.0632
  iou: 0.1456
Layer 2 metrics:
  pearson_correlation: 0.0017
  kl_divergence: -1370.3236
  ssim: 0.0632
  iou: 0.1456

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.45191, std: 0.13084

Metrics for layer 3:
  pearson_correlation: 0.0173
  kl_divergence: -1378.1528
  ssim: 0.0582
  iou: 0.1515
Layer 3 metrics:
  pearson_correlation: 0.0173
  kl_divergence: -1378.1528
  ssim: 0.0582
  iou: 0.1515

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.51756, std: 0.14132

Metrics for layer 4:
  pearson_correlation: 0.0190
  kl_divergence: -405.7701
  ssim: 0.0618
  iou: 0.1412
Layer 4 metrics:
  pearson_correlation: 0.0190
  kl_divergence: -405.7701
  ssim: 0.0618
  iou: 0.1412

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47397, std: 0.14171

Metrics for layer 5:
  pearson_correlation: -0.0109
  kl_divergence: -366.8965
  ssim: 0.0544
  iou: 0.1512
Layer 5 metrics:
  pearson_correlation: -0.0109
  kl_divergence: -366.8965
  ssim: 0.0544
  iou: 0.1512

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47970, std: 0.15637

Metrics for layer 6:
  pearson_correlation: -0.0126
  kl_divergence: -369.4372
  ssim: 0.0491
  iou: 0.1313
Layer 6 metrics:
  pearson_correlation: -0.0126
  kl_divergence: -369.4372
  ssim: 0.0491
  iou: 0.1313

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.51533, std: 0.14662

Metrics for layer 7:
  pearson_correlation: 0.0228
  kl_divergence: -98.9514
  ssim: 0.0617
  iou: 0.1496
Layer 7 metrics:
  pearson_correlation: 0.0228
  kl_divergence: -98.9514
  ssim: 0.0617
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.52685, std: 0.16415

Metrics for layer 8:
  pearson_correlation: 0.0008
  kl_divergence: -97.0147
  ssim: 0.0376
  iou: 0.1264
Layer 8 metrics:
  pearson_correlation: 0.0008
  kl_divergence: -97.0147
  ssim: 0.0376
  iou: 0.1264

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.50179, std: 0.16084

Metrics for layer 9:
  pearson_correlation: 0.0031
  kl_divergence: -93.6199
  ssim: 0.0517
  iou: 0.1264
Layer 9 metrics:
  pearson_correlation: 0.0031
  kl_divergence: -93.6199
  ssim: 0.0517
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.52009, std: 0.19787

Metrics for layer 10:
  pearson_correlation: 0.0633
  kl_divergence: -24.1636
  ssim: 0.1594
  iou: 0.1807
Layer 10 metrics:
  pearson_correlation: 0.0633
  kl_divergence: -24.1636
  ssim: 0.1594
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49870, std: 0.17878

Metrics for layer 11:
  pearson_correlation: -0.0380
  kl_divergence: -22.3406
  ssim: 0.0428
  iou: 0.1395
Layer 11 metrics:
  pearson_correlation: -0.0380
  kl_divergence: -22.3406
  ssim: 0.0428
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.50835, std: 0.17480

Metrics for layer 12:
  pearson_correlation: -0.0376
  kl_divergence: -22.3013
  ssim: 0.1450
  iou: 0.1264
Layer 12 metrics:
  pearson_correlation: -0.0376
  kl_divergence: -22.3013
  ssim: 0.1450
  iou: 0.1264
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer12/batch_0_strength_0.0_results.npy

Processing batch 2/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.40062, std: 0.11003

Metrics for layer 0:
  pearson_correlation: 0.0057
  kl_divergence: -3667.9189
  ssim: 0.0418
  iou: 0.1447
Layer 0 metrics:
  pearson_correlation: 0.0057
  kl_divergence: -3667.9189
  ssim: 0.0418
  iou: 0.1447

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.44174, std: 0.12252

Metrics for layer 1:
  pearson_correlation: 0.0007
  kl_divergence: -3845.1450
  ssim: 0.0326
  iou: 0.1418
Layer 1 metrics:
  pearson_correlation: 0.0007
  kl_divergence: -3845.1450
  ssim: 0.0326
  iou: 0.1418

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.47909, std: 0.12918

Metrics for layer 2:
  pearson_correlation: 0.0171
  kl_divergence: -1416.7609
  ssim: 0.0489
  iou: 0.1458
Layer 2 metrics:
  pearson_correlation: 0.0171
  kl_divergence: -1416.7609
  ssim: 0.0489
  iou: 0.1458

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.42004, std: 0.14185

Metrics for layer 3:
  pearson_correlation: 0.0016
  kl_divergence: -1268.4258
  ssim: 0.0444
  iou: 0.1475
Layer 3 metrics:
  pearson_correlation: 0.0016
  kl_divergence: -1268.4258
  ssim: 0.0444
  iou: 0.1475

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.43912, std: 0.13747

Metrics for layer 4:
  pearson_correlation: 0.0115
  kl_divergence: -355.8444
  ssim: 0.0639
  iou: 0.1437
Layer 4 metrics:
  pearson_correlation: 0.0115
  kl_divergence: -355.8444
  ssim: 0.0639
  iou: 0.1437

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.50865, std: 0.12676

Metrics for layer 5:
  pearson_correlation: 0.0161
  kl_divergence: -414.1596
  ssim: 0.0652
  iou: 0.1563
Layer 5 metrics:
  pearson_correlation: 0.0161
  kl_divergence: -414.1596
  ssim: 0.0652
  iou: 0.1563

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48331, std: 0.14641

Metrics for layer 6:
  pearson_correlation: 0.0004
  kl_divergence: -389.7745
  ssim: 0.0496
  iou: 0.1512
Layer 6 metrics:
  pearson_correlation: 0.0004
  kl_divergence: -389.7745
  ssim: 0.0496
  iou: 0.1512

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.44625, std: 0.15756

Metrics for layer 7:
  pearson_correlation: -0.0277
  kl_divergence: -81.1728
  ssim: 0.0319
  iou: 0.1496
Layer 7 metrics:
  pearson_correlation: -0.0277
  kl_divergence: -81.1728
  ssim: 0.0319
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.48858, std: 0.15678

Metrics for layer 8:
  pearson_correlation: 0.0016
  kl_divergence: -88.7242
  ssim: 0.0309
  iou: 0.1362
Layer 8 metrics:
  pearson_correlation: 0.0016
  kl_divergence: -88.7242
  ssim: 0.0309
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.51731, std: 0.13886

Metrics for layer 9:
  pearson_correlation: -0.0343
  kl_divergence: -87.8887
  ssim: 0.0365
  iou: 0.1200
Layer 9 metrics:
  pearson_correlation: -0.0343
  kl_divergence: -87.8887
  ssim: 0.0365
  iou: 0.1200

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.31954, std: 0.15201

Metrics for layer 10:
  pearson_correlation: 0.0079
  kl_divergence: 2.6800
  ssim: 0.0197
  iou: 0.1807
Layer 10 metrics:
  pearson_correlation: 0.0079
  kl_divergence: 2.6800
  ssim: 0.0197
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.49760, std: 0.17474

Metrics for layer 11:
  pearson_correlation: -0.0774
  kl_divergence: -17.8327
  ssim: -0.0698
  iou: 0.1667
Layer 11 metrics:
  pearson_correlation: -0.0774
  kl_divergence: -17.8327
  ssim: -0.0698
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.57122, std: 0.19060

Metrics for layer 12:
  pearson_correlation: 0.0632
  kl_divergence: -25.2495
  ssim: 0.0938
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: 0.0632
  kl_divergence: -25.2495
  ssim: 0.0938
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer12/batch_1_strength_0.0_results.npy

Processing attention strength 0.4
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.4]

Processing batch 1/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42657, std: 0.12229

Metrics for layer 0:
  pearson_correlation: 0.0015
  kl_divergence: -4574.6191
  ssim: 0.0483
  iou: 0.1440
Layer 0 metrics:
  pearson_correlation: 0.0015
  kl_divergence: -4574.6191
  ssim: 0.0483
  iou: 0.1440

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.45036, std: 0.13091

Metrics for layer 1:
  pearson_correlation: -0.0028
  kl_divergence: -4729.6577
  ssim: 0.0414
  iou: 0.1426
Layer 1 metrics:
  pearson_correlation: -0.0028
  kl_divergence: -4729.6577
  ssim: 0.0414
  iou: 0.1426

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.46340, std: 0.14184

Metrics for layer 2:
  pearson_correlation: 0.0007
  kl_divergence: -1396.7537
  ssim: 0.0512
  iou: 0.1420
Layer 2 metrics:
  pearson_correlation: 0.0007
  kl_divergence: -1396.7537
  ssim: 0.0512
  iou: 0.1420

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.47280, std: 0.13982

Metrics for layer 3:
  pearson_correlation: 0.0107
  kl_divergence: -1422.0192
  ssim: 0.0517
  iou: 0.1424
Layer 3 metrics:
  pearson_correlation: 0.0107
  kl_divergence: -1422.0192
  ssim: 0.0517
  iou: 0.1424

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46489, std: 0.14165

Metrics for layer 4:
  pearson_correlation: 0.0145
  kl_divergence: -365.7336
  ssim: 0.0673
  iou: 0.1487
Layer 4 metrics:
  pearson_correlation: 0.0145
  kl_divergence: -365.7336
  ssim: 0.0673
  iou: 0.1487

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50876, std: 0.14582

Metrics for layer 5:
  pearson_correlation: -0.0167
  kl_divergence: -392.1266
  ssim: 0.0401
  iou: 0.1412
Layer 5 metrics:
  pearson_correlation: -0.0167
  kl_divergence: -392.1266
  ssim: 0.0401
  iou: 0.1412

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.52911, std: 0.13522

Metrics for layer 6:
  pearson_correlation: -0.0110
  kl_divergence: -413.3851
  ssim: 0.0514
  iou: 0.1470
Layer 6 metrics:
  pearson_correlation: -0.0110
  kl_divergence: -413.3851
  ssim: 0.0514
  iou: 0.1470

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.47713, std: 0.15177

Metrics for layer 7:
  pearson_correlation: 0.0848
  kl_divergence: -86.4271
  ssim: 0.0882
  iou: 0.1951
Layer 7 metrics:
  pearson_correlation: 0.0848
  kl_divergence: -86.4271
  ssim: 0.0882
  iou: 0.1951

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.42930, std: 0.16385

Metrics for layer 8:
  pearson_correlation: -0.0004
  kl_divergence: -78.3959
  ssim: 0.0530
  iou: 0.1232
Layer 8 metrics:
  pearson_correlation: -0.0004
  kl_divergence: -78.3959
  ssim: 0.0530
  iou: 0.1232

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.47618, std: 0.17236

Metrics for layer 9:
  pearson_correlation: 0.0636
  kl_divergence: -92.0344
  ssim: 0.0612
  iou: 0.1529
Layer 9 metrics:
  pearson_correlation: 0.0636
  kl_divergence: -92.0344
  ssim: 0.0612
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.40081, std: 0.18531

Metrics for layer 10:
  pearson_correlation: -0.0039
  kl_divergence: -12.9752
  ssim: 0.0368
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: -0.0039
  kl_divergence: -12.9752
  ssim: 0.0368
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.52834, std: 0.20236

Metrics for layer 11:
  pearson_correlation: 0.0878
  kl_divergence: -23.0774
  ssim: 0.1253
  iou: 0.2099
Layer 11 metrics:
  pearson_correlation: 0.0878
  kl_divergence: -23.0774
  ssim: 0.1253
  iou: 0.2099

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.40840, std: 0.16557

Metrics for layer 12:
  pearson_correlation: 0.0128
  kl_divergence: -16.4096
  ssim: -0.0320
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: 0.0128
  kl_divergence: -16.4096
  ssim: -0.0320
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer12/batch_0_strength_0.4_results.npy

Processing batch 2/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43480, std: 0.12402

Metrics for layer 0:
  pearson_correlation: 0.0138
  kl_divergence: -3814.2683
  ssim: 0.0321
  iou: 0.1463
Layer 0 metrics:
  pearson_correlation: 0.0138
  kl_divergence: -3814.2683
  ssim: 0.0321
  iou: 0.1463

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.37075, std: 0.10744

Metrics for layer 1:
  pearson_correlation: -0.0047
  kl_divergence: -3510.0405
  ssim: 0.0461
  iou: 0.1417
Layer 1 metrics:
  pearson_correlation: -0.0047
  kl_divergence: -3510.0405
  ssim: 0.0461
  iou: 0.1417

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.47255, std: 0.12504

Metrics for layer 2:
  pearson_correlation: -0.0040
  kl_divergence: -1399.3251
  ssim: 0.0481
  iou: 0.1416
Layer 2 metrics:
  pearson_correlation: -0.0040
  kl_divergence: -1399.3251
  ssim: 0.0481
  iou: 0.1416

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.40399, std: 0.12597

Metrics for layer 3:
  pearson_correlation: 0.0036
  kl_divergence: -1246.2795
  ssim: 0.0569
  iou: 0.1416
Layer 3 metrics:
  pearson_correlation: 0.0036
  kl_divergence: -1246.2795
  ssim: 0.0569
  iou: 0.1416

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.45138, std: 0.14320

Metrics for layer 4:
  pearson_correlation: -0.0214
  kl_divergence: -360.6965
  ssim: 0.0527
  iou: 0.1362
Layer 4 metrics:
  pearson_correlation: -0.0214
  kl_divergence: -360.6965
  ssim: 0.0527
  iou: 0.1362

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.45256, std: 0.14284

Metrics for layer 5:
  pearson_correlation: -0.0012
  kl_divergence: -361.7422
  ssim: 0.0603
  iou: 0.1563
Layer 5 metrics:
  pearson_correlation: -0.0012
  kl_divergence: -361.7422
  ssim: 0.0603
  iou: 0.1563

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.46535, std: 0.13656

Metrics for layer 6:
  pearson_correlation: -0.0273
  kl_divergence: -375.0994
  ssim: 0.0508
  iou: 0.1281
Layer 6 metrics:
  pearson_correlation: -0.0273
  kl_divergence: -375.0994
  ssim: 0.0508
  iou: 0.1281

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.51028, std: 0.15418

Metrics for layer 7:
  pearson_correlation: -0.0690
  kl_divergence: -88.5448
  ssim: 0.0158
  iou: 0.1232
Layer 7 metrics:
  pearson_correlation: -0.0690
  kl_divergence: -88.5448
  ssim: 0.0158
  iou: 0.1232

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.51704, std: 0.15398

Metrics for layer 8:
  pearson_correlation: -0.0713
  kl_divergence: -88.2283
  ssim: 0.0198
  iou: 0.1329
Layer 8 metrics:
  pearson_correlation: -0.0713
  kl_divergence: -88.2283
  ssim: 0.0198
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.53933, std: 0.16121

Metrics for layer 9:
  pearson_correlation: -0.0105
  kl_divergence: -92.1972
  ssim: 0.0247
  iou: 0.1462
Layer 9 metrics:
  pearson_correlation: -0.0105
  kl_divergence: -92.1972
  ssim: 0.0247
  iou: 0.1462

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.44539, std: 0.17765

Metrics for layer 10:
  pearson_correlation: 0.1071
  kl_divergence: -13.9942
  ssim: 0.1340
  iou: 0.1807
Layer 10 metrics:
  pearson_correlation: 0.1071
  kl_divergence: -13.9942
  ssim: 0.1340
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.45321, std: 0.20452

Metrics for layer 11:
  pearson_correlation: 0.1206
  kl_divergence: -5.0999
  ssim: 0.1542
  iou: 0.1951
Layer 11 metrics:
  pearson_correlation: 0.1206
  kl_divergence: -5.0999
  ssim: 0.1542
  iou: 0.1951

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.48218, std: 0.15673

Metrics for layer 12:
  pearson_correlation: 0.0330
  kl_divergence: -19.3146
  ssim: 0.0274
  iou: 0.2099
Layer 12 metrics:
  pearson_correlation: 0.0330
  kl_divergence: -19.3146
  ssim: 0.0274
  iou: 0.2099
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer12/batch_1_strength_0.4_results.npy

Processing attention strength 0.8
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.8]

Processing batch 1/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.40785, std: 0.11965

Metrics for layer 0:
  pearson_correlation: 0.0035
  kl_divergence: -4434.7437
  ssim: 0.0516
  iou: 0.1451
Layer 0 metrics:
  pearson_correlation: 0.0035
  kl_divergence: -4434.7437
  ssim: 0.0516
  iou: 0.1451

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.41302, std: 0.11821

Metrics for layer 1:
  pearson_correlation: -0.0011
  kl_divergence: -4473.4463
  ssim: 0.0519
  iou: 0.1422
Layer 1 metrics:
  pearson_correlation: -0.0011
  kl_divergence: -4473.4463
  ssim: 0.0519
  iou: 0.1422

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.43889, std: 0.13408

Metrics for layer 2:
  pearson_correlation: 0.0081
  kl_divergence: -1343.3478
  ssim: 0.0544
  iou: 0.1437
Layer 2 metrics:
  pearson_correlation: 0.0081
  kl_divergence: -1343.3478
  ssim: 0.0544
  iou: 0.1437

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.46135, std: 0.13300

Metrics for layer 3:
  pearson_correlation: -0.0002
  kl_divergence: -1397.2589
  ssim: 0.0527
  iou: 0.1412
Layer 3 metrics:
  pearson_correlation: -0.0002
  kl_divergence: -1397.2589
  ssim: 0.0527
  iou: 0.1412

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.48932, std: 0.16155

Metrics for layer 4:
  pearson_correlation: 0.0045
  kl_divergence: -377.7235
  ssim: 0.0491
  iou: 0.1445
Layer 4 metrics:
  pearson_correlation: 0.0045
  kl_divergence: -377.7235
  ssim: 0.0491
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.41196, std: 0.13544

Metrics for layer 5:
  pearson_correlation: 0.0065
  kl_divergence: -318.7222
  ssim: 0.0725
  iou: 0.1581
Layer 5 metrics:
  pearson_correlation: 0.0065
  kl_divergence: -318.7222
  ssim: 0.0725
  iou: 0.1581

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46456, std: 0.14432

Metrics for layer 6:
  pearson_correlation: -0.0300
  kl_divergence: -359.1121
  ssim: 0.0385
  iou: 0.1395
Layer 6 metrics:
  pearson_correlation: -0.0300
  kl_divergence: -359.1121
  ssim: 0.0385
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.53794, std: 0.17344

Metrics for layer 7:
  pearson_correlation: -0.0353
  kl_divergence: -100.9108
  ssim: 0.0496
  iou: 0.1297
Layer 7 metrics:
  pearson_correlation: -0.0353
  kl_divergence: -100.9108
  ssim: 0.0496
  iou: 0.1297

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.48121, std: 0.13251

Metrics for layer 8:
  pearson_correlation: -0.0121
  kl_divergence: -90.2680
  ssim: 0.0628
  iou: 0.1462
Layer 8 metrics:
  pearson_correlation: -0.0121
  kl_divergence: -90.2680
  ssim: 0.0628
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.45436, std: 0.15973

Metrics for layer 9:
  pearson_correlation: 0.0038
  kl_divergence: -85.6252
  ssim: 0.0492
  iou: 0.1496
Layer 9 metrics:
  pearson_correlation: 0.0038
  kl_divergence: -85.6252
  ssim: 0.0492
  iou: 0.1496

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.50862, std: 0.21625

Metrics for layer 10:
  pearson_correlation: -0.0217
  kl_divergence: -21.3025
  ssim: -0.0578
  iou: 0.1136
Layer 10 metrics:
  pearson_correlation: -0.0217
  kl_divergence: -21.3025
  ssim: -0.0578
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.55089, std: 0.18911

Metrics for layer 11:
  pearson_correlation: -0.0571
  kl_divergence: -23.0647
  ssim: 0.1161
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: -0.0571
  kl_divergence: -23.0647
  ssim: 0.1161
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.44790, std: 0.19322

Metrics for layer 12:
  pearson_correlation: -0.0029
  kl_divergence: -13.1192
  ssim: 0.0320
  iou: 0.1529
Layer 12 metrics:
  pearson_correlation: -0.0029
  kl_divergence: -13.1192
  ssim: 0.0320
  iou: 0.1529
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer12/batch_0_strength_0.8_results.npy

Processing batch 2/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.42955, std: 0.12046

Metrics for layer 0:
  pearson_correlation: 0.0011
  kl_divergence: -3792.3613
  ssim: 0.0340
  iou: 0.1438
Layer 0 metrics:
  pearson_correlation: 0.0011
  kl_divergence: -3792.3613
  ssim: 0.0340
  iou: 0.1438

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43098, std: 0.12858

Metrics for layer 1:
  pearson_correlation: 0.0071
  kl_divergence: -3790.1746
  ssim: 0.0311
  iou: 0.1450
Layer 1 metrics:
  pearson_correlation: 0.0071
  kl_divergence: -3790.1746
  ssim: 0.0311
  iou: 0.1450

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.39984, std: 0.10895

Metrics for layer 2:
  pearson_correlation: -0.0044
  kl_divergence: -1248.9587
  ssim: 0.0708
  iou: 0.1391
Layer 2 metrics:
  pearson_correlation: -0.0044
  kl_divergence: -1248.9587
  ssim: 0.0708
  iou: 0.1391

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.43912, std: 0.11891

Metrics for layer 3:
  pearson_correlation: 0.0168
  kl_divergence: -1336.4124
  ssim: 0.0613
  iou: 0.1475
Layer 3 metrics:
  pearson_correlation: 0.0168
  kl_divergence: -1336.4124
  ssim: 0.0613
  iou: 0.1475

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48411, std: 0.13798

Metrics for layer 4:
  pearson_correlation: -0.0154
  kl_divergence: -392.3972
  ssim: 0.0551
  iou: 0.1445
Layer 4 metrics:
  pearson_correlation: -0.0154
  kl_divergence: -392.3972
  ssim: 0.0551
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.51936, std: 0.14129

Metrics for layer 5:
  pearson_correlation: 0.0318
  kl_divergence: -422.5919
  ssim: 0.0518
  iou: 0.1479
Layer 5 metrics:
  pearson_correlation: 0.0318
  kl_divergence: -422.5919
  ssim: 0.0518
  iou: 0.1479

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.45170, std: 0.12996

Metrics for layer 6:
  pearson_correlation: -0.0165
  kl_divergence: -366.9095
  ssim: 0.0587
  iou: 0.1379
Layer 6 metrics:
  pearson_correlation: -0.0165
  kl_divergence: -366.9095
  ssim: 0.0587
  iou: 0.1379

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.46311, std: 0.15636

Metrics for layer 7:
  pearson_correlation: -0.0513
  kl_divergence: -82.6893
  ssim: 0.0126
  iou: 0.1395
Layer 7 metrics:
  pearson_correlation: -0.0513
  kl_divergence: -82.6893
  ssim: 0.0126
  iou: 0.1395

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.45642, std: 0.12313

Metrics for layer 8:
  pearson_correlation: 0.0206
  kl_divergence: -82.6104
  ssim: 0.0646
  iou: 0.1737
Layer 8 metrics:
  pearson_correlation: 0.0206
  kl_divergence: -82.6104
  ssim: 0.0646
  iou: 0.1737

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.50362, std: 0.15448

Metrics for layer 9:
  pearson_correlation: -0.0413
  kl_divergence: -86.6385
  ssim: 0.0340
  iou: 0.1429
Layer 9 metrics:
  pearson_correlation: -0.0413
  kl_divergence: -86.6385
  ssim: 0.0340
  iou: 0.1429

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.59280, std: 0.17751

Metrics for layer 10:
  pearson_correlation: 0.0622
  kl_divergence: -24.1011
  ssim: 0.0808
  iou: 0.1667
Layer 10 metrics:
  pearson_correlation: 0.0622
  kl_divergence: -24.1011
  ssim: 0.0808
  iou: 0.1667

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.52534, std: 0.17153

Metrics for layer 11:
  pearson_correlation: 0.0943
  kl_divergence: -23.0567
  ssim: 0.0837
  iou: 0.1529
Layer 11 metrics:
  pearson_correlation: 0.0943
  kl_divergence: -23.0567
  ssim: 0.0837
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.46304, std: 0.18818

Metrics for layer 12:
  pearson_correlation: 0.0932
  kl_divergence: -14.0950
  ssim: 0.1178
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: 0.0932
  kl_divergence: -14.0950
  ssim: 0.1178
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer12/batch_1_strength_0.8_results.npy

Processing attention strength 1.2
Attention vector: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.2]

Processing batch 1/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.44731, std: 0.11961

Metrics for layer 0:
  pearson_correlation: -0.0013
  kl_divergence: -4738.4448
  ssim: 0.0468
  iou: 0.1420
Layer 0 metrics:
  pearson_correlation: -0.0013
  kl_divergence: -4738.4448
  ssim: 0.0468
  iou: 0.1420

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42656, std: 0.11613

Metrics for layer 1:
  pearson_correlation: -0.0013
  kl_divergence: -4589.4194
  ssim: 0.0524
  iou: 0.1415
Layer 1 metrics:
  pearson_correlation: -0.0013
  kl_divergence: -4589.4194
  ssim: 0.0524
  iou: 0.1415

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.43101, std: 0.12183

Metrics for layer 2:
  pearson_correlation: -0.0011
  kl_divergence: -1328.9626
  ssim: 0.0644
  iou: 0.1460
Layer 2 metrics:
  pearson_correlation: -0.0011
  kl_divergence: -1328.9626
  ssim: 0.0644
  iou: 0.1460

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.42217, std: 0.12654

Metrics for layer 3:
  pearson_correlation: 0.0052
  kl_divergence: -1308.0168
  ssim: 0.0635
  iou: 0.1416
Layer 3 metrics:
  pearson_correlation: 0.0052
  kl_divergence: -1308.0168
  ssim: 0.0635
  iou: 0.1416

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47359, std: 0.11967

Metrics for layer 4:
  pearson_correlation: -0.0044
  kl_divergence: -373.9181
  ssim: 0.0738
  iou: 0.1445
Layer 4 metrics:
  pearson_correlation: -0.0044
  kl_divergence: -373.9181
  ssim: 0.0738
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47282, std: 0.14130

Metrics for layer 5:
  pearson_correlation: -0.0089
  kl_divergence: -369.9108
  ssim: 0.0512
  iou: 0.1379
Layer 5 metrics:
  pearson_correlation: -0.0089
  kl_divergence: -369.9108
  ssim: 0.0512
  iou: 0.1379

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.45663, std: 0.15128

Metrics for layer 6:
  pearson_correlation: -0.0173
  kl_divergence: -348.7358
  ssim: 0.0478
  iou: 0.1281
Layer 6 metrics:
  pearson_correlation: -0.0173
  kl_divergence: -348.7358
  ssim: 0.0478
  iou: 0.1281

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.53468, std: 0.16915

Metrics for layer 7:
  pearson_correlation: 0.0362
  kl_divergence: -102.2369
  ssim: 0.0803
  iou: 0.1772
Layer 7 metrics:
  pearson_correlation: 0.0362
  kl_divergence: -102.2369
  ssim: 0.0803
  iou: 0.1772

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.48635, std: 0.15050

Metrics for layer 8:
  pearson_correlation: 0.0288
  kl_divergence: -93.0952
  ssim: 0.0569
  iou: 0.1362
Layer 8 metrics:
  pearson_correlation: 0.0288
  kl_divergence: -93.0952
  ssim: 0.0569
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.49448, std: 0.16418

Metrics for layer 9:
  pearson_correlation: -0.0034
  kl_divergence: -92.8782
  ssim: 0.0561
  iou: 0.1362
Layer 9 metrics:
  pearson_correlation: -0.0034
  kl_divergence: -92.8782
  ssim: 0.0561
  iou: 0.1362

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.50007, std: 0.21279

Metrics for layer 10:
  pearson_correlation: -0.0115
  kl_divergence: -21.4430
  ssim: 0.0227
  iou: 0.1264
Layer 10 metrics:
  pearson_correlation: -0.0115
  kl_divergence: -21.4430
  ssim: 0.0227
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.41826, std: 0.19347

Metrics for layer 11:
  pearson_correlation: -0.0583
  kl_divergence: -15.0728
  ssim: 0.0273
  iou: 0.1011
Layer 11 metrics:
  pearson_correlation: -0.0583
  kl_divergence: -15.0728
  ssim: 0.0273
  iou: 0.1011

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.48019, std: 0.20263

Metrics for layer 12:
  pearson_correlation: 0.0475
  kl_divergence: -20.2807
  ssim: -0.0052
  iou: 0.2099
Layer 12 metrics:
  pearson_correlation: 0.0475
  kl_divergence: -20.2807
  ssim: -0.0052
  iou: 0.2099
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer12/batch_0_strength_1.2_results.npy

Processing batch 2/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.45763, std: 0.12025

Metrics for layer 0:
  pearson_correlation: 0.0059
  kl_divergence: -3923.4536
  ssim: 0.0319
  iou: 0.1455
Layer 0 metrics:
  pearson_correlation: 0.0059
  kl_divergence: -3923.4536
  ssim: 0.0319
  iou: 0.1455

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.38282, std: 0.11181

Metrics for layer 1:
  pearson_correlation: 0.0005
  kl_divergence: -3571.1895
  ssim: 0.0416
  iou: 0.1411
Layer 1 metrics:
  pearson_correlation: 0.0005
  kl_divergence: -3571.1895
  ssim: 0.0416
  iou: 0.1411

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.43652, std: 0.13527

Metrics for layer 2:
  pearson_correlation: 0.0082
  kl_divergence: -1315.8462
  ssim: 0.0510
  iou: 0.1475
Layer 2 metrics:
  pearson_correlation: 0.0082
  kl_divergence: -1315.8462
  ssim: 0.0510
  iou: 0.1475

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.48351, std: 0.11153

Metrics for layer 3:
  pearson_correlation: -0.0074
  kl_divergence: -1427.5142
  ssim: 0.0571
  iou: 0.1412
Layer 3 metrics:
  pearson_correlation: -0.0074
  kl_divergence: -1427.5142
  ssim: 0.0571
  iou: 0.1412

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47130, std: 0.15457

Metrics for layer 4:
  pearson_correlation: -0.0010
  kl_divergence: -377.2362
  ssim: 0.0500
  iou: 0.1462
Layer 4 metrics:
  pearson_correlation: -0.0010
  kl_divergence: -377.2362
  ssim: 0.0500
  iou: 0.1462

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.46166, std: 0.14198

Metrics for layer 5:
  pearson_correlation: -0.0034
  kl_divergence: -372.0511
  ssim: 0.0553
  iou: 0.1437
Layer 5 metrics:
  pearson_correlation: -0.0034
  kl_divergence: -372.0511
  ssim: 0.0553
  iou: 0.1437

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.52028, std: 0.15378

Metrics for layer 6:
  pearson_correlation: 0.0149
  kl_divergence: -419.6925
  ssim: 0.0445
  iou: 0.1546
Layer 6 metrics:
  pearson_correlation: 0.0149
  kl_divergence: -419.6925
  ssim: 0.0445
  iou: 0.1546

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.52148, std: 0.15514

Metrics for layer 7:
  pearson_correlation: -0.0057
  kl_divergence: -91.3262
  ssim: 0.0284
  iou: 0.1362
Layer 7 metrics:
  pearson_correlation: -0.0057
  kl_divergence: -91.3262
  ssim: 0.0284
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.47110, std: 0.16535

Metrics for layer 8:
  pearson_correlation: 0.0040
  kl_divergence: -85.1545
  ssim: 0.0444
  iou: 0.1168
Layer 8 metrics:
  pearson_correlation: 0.0040
  kl_divergence: -85.1545
  ssim: 0.0444
  iou: 0.1168

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.56573, std: 0.12913

Metrics for layer 9:
  pearson_correlation: 0.0118
  kl_divergence: -93.1269
  ssim: 0.0443
  iou: 0.1496
Layer 9 metrics:
  pearson_correlation: 0.0118
  kl_divergence: -93.1269
  ssim: 0.0443
  iou: 0.1496

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.47579, std: 0.17754

Metrics for layer 10:
  pearson_correlation: 0.0396
  kl_divergence: -7.8857
  ssim: 0.0815
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: 0.0396
  kl_divergence: -7.8857
  ssim: 0.0815
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.54260, std: 0.18960

Metrics for layer 11:
  pearson_correlation: -0.0462
  kl_divergence: -20.6192
  ssim: -0.0149
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: -0.0462
  kl_divergence: -20.6192
  ssim: -0.0149
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.51588, std: 0.22296

Metrics for layer 12:
  pearson_correlation: 0.1273
  kl_divergence: -20.8948
  ssim: 0.1568
  iou: 0.1264
Layer 12 metrics:
  pearson_correlation: 0.1273
  kl_divergence: -20.8948
  ssim: 0.1568
  iou: 0.1264
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer12/batch_1_strength_1.2_results.npy

Analysis complete! Results saved to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer12
