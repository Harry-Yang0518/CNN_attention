WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:63: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2024-12-16 10:58:15.218369: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2024-12-16 10:58:15.237509: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2024-12-16 10:58:15.237947: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4b724e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2024-12-16 10:58:15.237962: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2024-12-16 10:58:15.240668: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2024-12-16 10:58:15.387830: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4b6b570 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-12-16 10:58:15.387853: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2024-12-16 10:58:15.388458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:2f:00.0
2024-12-16 10:58:15.389638: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:58:15.390693: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:58:15.391708: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:58:15.392733: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:58:15.393730: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:58:15.394727: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:58:15.395731: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
2024-12-16 10:58:15.395742: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2024-12-16 10:58:15.395759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-12-16 10:58:15.395764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2024-12-16 10:58:15.395767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:61: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:87: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:15: sigmoid_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.sigmoid_cross_entropy instead. Note that the order of the predictions and labels arguments has been changed.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:322: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /ext3/envs/vgg16_env/lib/python2.7/site-packages/tensorflow_core/contrib/losses/python/losses/loss_ops.py:121: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/vgg_16.py:25: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /scratch/hy2611/CNN_attention/main/new/main.py:82: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.


Verifying paths:
tc_path: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs exists
weight_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists
image_path: /scratch/hy2611/CNN_attention/Data/VGG16/images exists
save_path: /scratch/hy2611/CNN_attention/Data/VGG16 exists

Initializing model...
('c11', [1, 224, 224, 64])
('c12', [1, 224, 224, 64])
('c21', [1, 112, 112, 128])
('c22', [1, 112, 112, 128])
('c31', [1, 56, 56, 256])
('c32', [1, 56, 56, 256])
('c33', [1, 56, 56, 256])
('c41', [1, 28, 28, 512])
('c42', [1, 28, 28, 512])
('c43', [1, 28, 28, 512])
('c51', [1, 14, 14, 512])
('c52', [1, 14, 14, 512])
('c53', [1, 14, 14, 512])
(0, 'conv1_1_W', (3, 3, 3, 64))
(1, 'conv1_1_b', (64,))
(2, 'conv1_2_W', (3, 3, 64, 64))
(3, 'conv1_2_b', (64,))
(4, 'conv2_1_W', (3, 3, 64, 128))
(5, 'conv2_1_b', (128,))
(6, 'conv2_2_W', (3, 3, 128, 128))
(7, 'conv2_2_b', (128,))
(8, 'conv3_1_W', (3, 3, 128, 256))
(9, 'conv3_1_b', (256,))
(10, 'conv3_2_W', (3, 3, 256, 256))
(11, 'conv3_2_b', (256,))
(12, 'conv3_3_W', (3, 3, 256, 256))
(13, 'conv3_3_b', (256,))
(14, 'conv4_1_W', (3, 3, 256, 512))
(15, 'conv4_1_b', (512,))
(16, 'conv4_2_W', (3, 3, 512, 512))
(17, 'conv4_2_b', (512,))
(18, 'conv4_3_W', (3, 3, 512, 512))
(19, 'conv4_3_b', (512,))
(20, 'conv5_1_W', (3, 3, 512, 512))
(21, 'conv5_1_b', (512,))
(22, 'conv5_2_W', (3, 3, 512, 512))
(23, 'conv5_2_b', (512,))
(24, 'conv5_3_W', (3, 3, 512, 512))
(25, 'conv5_3_b', (512,))
(26, 'fc6_W', (25088, 4096))
(27, 'fc6_b', (4096,))
(28, 'fc7_W', (4096, 4096))
(29, 'fc7_b', (4096,))
Checking checkpoint files:
Data file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.data-00000-of-00001 - Found
Index file: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt.index - Found
Loading checkpoint from: /scratch/hy2611/CNN_attention/Data/VGG16/catbins/catbin_5.ckpt
Checkpoint loaded successfully

Initializing components...
Found tuning curves file: /scratch/hy2611/CNN_attention/Data/VGG16/object_GradsTCs/featvecs20_train35_c.txt

Loading category 5 data...
Original positive images shape: (2, 224, 224, 3)

Processing data...

Processing attention strength 0.0
Attention vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

Processing batch 1/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.44316, std: 0.12315

Metrics for layer 0:
  pearson_correlation: -0.0065
  kl_divergence: -4692.1377
  ssim: 0.0463
  iou: 0.1395
Layer 0 metrics:
  pearson_correlation: -0.0065
  kl_divergence: -4692.1377
  ssim: 0.0463
  iou: 0.1395

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.45749, std: 0.13039

Metrics for layer 1:
  pearson_correlation: -0.0052
  kl_divergence: -4784.1753
  ssim: 0.0405
  iou: 0.1407
Layer 1 metrics:
  pearson_correlation: -0.0052
  kl_divergence: -4784.1753
  ssim: 0.0405
  iou: 0.1407

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.49734, std: 0.12649

Metrics for layer 2:
  pearson_correlation: 0.0195
  kl_divergence: -1486.7765
  ssim: 0.0571
  iou: 0.1487
Layer 2 metrics:
  pearson_correlation: 0.0195
  kl_divergence: -1486.7765
  ssim: 0.0571
  iou: 0.1487

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.48187, std: 0.12900

Metrics for layer 3:
  pearson_correlation: 0.0068
  kl_divergence: -1450.7798
  ssim: 0.0535
  iou: 0.1429
Layer 3 metrics:
  pearson_correlation: 0.0068
  kl_divergence: -1450.7798
  ssim: 0.0535
  iou: 0.1429

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.48219, std: 0.14874

Metrics for layer 4:
  pearson_correlation: -0.0225
  kl_divergence: -375.3386
  ssim: 0.0438
  iou: 0.1354
Layer 4 metrics:
  pearson_correlation: -0.0225
  kl_divergence: -375.3386
  ssim: 0.0438
  iou: 0.1354

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.46971, std: 0.13681

Metrics for layer 5:
  pearson_correlation: -0.0096
  kl_divergence: -369.3701
  ssim: 0.0526
  iou: 0.1454
Layer 5 metrics:
  pearson_correlation: -0.0096
  kl_divergence: -369.3701
  ssim: 0.0526
  iou: 0.1454

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.38669, std: 0.13019

Metrics for layer 6:
  pearson_correlation: -0.0096
  kl_divergence: -291.4173
  ssim: 0.0776
  iou: 0.1412
Layer 6 metrics:
  pearson_correlation: -0.0096
  kl_divergence: -291.4173
  ssim: 0.0776
  iou: 0.1412

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.47146, std: 0.18631

Metrics for layer 7:
  pearson_correlation: 0.0501
  kl_divergence: -85.7714
  ssim: 0.0677
  iou: 0.1362
Layer 7 metrics:
  pearson_correlation: 0.0501
  kl_divergence: -85.7714
  ssim: 0.0677
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.51697, std: 0.18657

Metrics for layer 8:
  pearson_correlation: 0.0319
  kl_divergence: -95.9271
  ssim: 0.0401
  iou: 0.1529
Layer 8 metrics:
  pearson_correlation: 0.0319
  kl_divergence: -95.9271
  ssim: 0.0401
  iou: 0.1529

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.54322, std: 0.15857

Metrics for layer 9:
  pearson_correlation: 0.0164
  kl_divergence: -103.4568
  ssim: 0.0566
  iou: 0.1462
Layer 9 metrics:
  pearson_correlation: 0.0164
  kl_divergence: -103.4568
  ssim: 0.0566
  iou: 0.1462

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.50909, std: 0.16114

Metrics for layer 10:
  pearson_correlation: -0.0291
  kl_divergence: -18.3439
  ssim: 0.0428
  iou: 0.1807
Layer 10 metrics:
  pearson_correlation: -0.0291
  kl_divergence: -18.3439
  ssim: 0.0428
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49781, std: 0.17075

Metrics for layer 11:
  pearson_correlation: -0.0621
  kl_divergence: -19.7050
  ssim: -0.0249
  iou: 0.1807
Layer 11 metrics:
  pearson_correlation: -0.0621
  kl_divergence: -19.7050
  ssim: -0.0249
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.46133, std: 0.20918

Metrics for layer 12:
  pearson_correlation: 0.1208
  kl_divergence: -19.5554
  ssim: 0.2183
  iou: 0.2099
Layer 12 metrics:
  pearson_correlation: 0.1208
  kl_divergence: -19.5554
  ssim: 0.2183
  iou: 0.2099
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer6/batch_0_strength_0.0_results.npy

Processing batch 2/2
Attention strength: 0.0
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.44170, std: 0.12809

Metrics for layer 0:
  pearson_correlation: -0.0016
  kl_divergence: -3835.9739
  ssim: 0.0299
  iou: 0.1384
Layer 0 metrics:
  pearson_correlation: -0.0016
  kl_divergence: -3835.9739
  ssim: 0.0299
  iou: 0.1384

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.41608, std: 0.12329

Metrics for layer 1:
  pearson_correlation: 0.0066
  kl_divergence: -3725.1292
  ssim: 0.0340
  iou: 0.1459
Layer 1 metrics:
  pearson_correlation: 0.0066
  kl_divergence: -3725.1292
  ssim: 0.0340
  iou: 0.1459

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.44215, std: 0.13301

Metrics for layer 2:
  pearson_correlation: 0.0107
  kl_divergence: -1332.1147
  ssim: 0.0519
  iou: 0.1466
Layer 2 metrics:
  pearson_correlation: 0.0107
  kl_divergence: -1332.1147
  ssim: 0.0519
  iou: 0.1466

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.41815, std: 0.12711

Metrics for layer 3:
  pearson_correlation: 0.0051
  kl_divergence: -1278.8624
  ssim: 0.0545
  iou: 0.1464
Layer 3 metrics:
  pearson_correlation: 0.0051
  kl_divergence: -1278.8624
  ssim: 0.0545
  iou: 0.1464

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.43264, std: 0.14322

Metrics for layer 4:
  pearson_correlation: 0.0109
  kl_divergence: -347.2995
  ssim: 0.0645
  iou: 0.1362
Layer 4 metrics:
  pearson_correlation: 0.0109
  kl_divergence: -347.2995
  ssim: 0.0645
  iou: 0.1362

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.42382, std: 0.13526

Metrics for layer 5:
  pearson_correlation: 0.0212
  kl_divergence: -338.7662
  ssim: 0.0763
  iou: 0.1581
Layer 5 metrics:
  pearson_correlation: 0.0212
  kl_divergence: -338.7662
  ssim: 0.0763
  iou: 0.1581

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.44289, std: 0.13072

Metrics for layer 6:
  pearson_correlation: 0.0373
  kl_divergence: -362.3783
  ssim: 0.0726
  iou: 0.1496
Layer 6 metrics:
  pearson_correlation: 0.0373
  kl_divergence: -362.3783
  ssim: 0.0726
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.48077, std: 0.17405

Metrics for layer 7:
  pearson_correlation: 0.0257
  kl_divergence: -84.0513
  ssim: 0.0318
  iou: 0.1667
Layer 7 metrics:
  pearson_correlation: 0.0257
  kl_divergence: -84.0513
  ssim: 0.0318
  iou: 0.1667

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.49062, std: 0.18423

Metrics for layer 8:
  pearson_correlation: 0.0064
  kl_divergence: -85.4751
  ssim: 0.0307
  iou: 0.1200
Layer 8 metrics:
  pearson_correlation: 0.0064
  kl_divergence: -85.4751
  ssim: 0.0307
  iou: 0.1200

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.49384, std: 0.15876

Metrics for layer 9:
  pearson_correlation: 0.0267
  kl_divergence: -87.3804
  ssim: 0.0488
  iou: 0.1362
Layer 9 metrics:
  pearson_correlation: 0.0267
  kl_divergence: -87.3804
  ssim: 0.0488
  iou: 0.1362

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.53303, std: 0.19942

Metrics for layer 10:
  pearson_correlation: -0.0252
  kl_divergence: -11.3991
  ssim: 0.0089
  iou: 0.1395
Layer 10 metrics:
  pearson_correlation: -0.0252
  kl_divergence: -11.3991
  ssim: 0.0089
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.49027, std: 0.19871

Metrics for layer 11:
  pearson_correlation: 0.0196
  kl_divergence: -17.8651
  ssim: 0.0896
  iou: 0.1011
Layer 11 metrics:
  pearson_correlation: 0.0196
  kl_divergence: -17.8651
  ssim: 0.0896
  iou: 0.1011

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.47928, std: 0.18225

Metrics for layer 12:
  pearson_correlation: 0.1429
  kl_divergence: -18.3204
  ssim: 0.1349
  iou: 0.1951
Layer 12 metrics:
  pearson_correlation: 0.1429
  kl_divergence: -18.3204
  ssim: 0.1349
  iou: 0.1951
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer6/batch_1_strength_0.0_results.npy

Processing attention strength 0.4
Attention vector: [0.  0.  0.  0.  0.  0.  0.4 0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.47438, std: 0.12223

Metrics for layer 0:
  pearson_correlation: 0.0016
  kl_divergence: -4927.8384
  ssim: 0.0436
  iou: 0.1428
Layer 0 metrics:
  pearson_correlation: 0.0016
  kl_divergence: -4927.8384
  ssim: 0.0436
  iou: 0.1428

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.40840, std: 0.11371

Metrics for layer 1:
  pearson_correlation: -0.0033
  kl_divergence: -4447.2246
  ssim: 0.0535
  iou: 0.1403
Layer 1 metrics:
  pearson_correlation: -0.0033
  kl_divergence: -4447.2246
  ssim: 0.0535
  iou: 0.1403

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.41533, std: 0.12210

Metrics for layer 2:
  pearson_correlation: 0.0217
  kl_divergence: -1296.4419
  ssim: 0.0702
  iou: 0.1443
Layer 2 metrics:
  pearson_correlation: 0.0217
  kl_divergence: -1296.4419
  ssim: 0.0702
  iou: 0.1443

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.48281, std: 0.13698

Metrics for layer 3:
  pearson_correlation: 0.0042
  kl_divergence: -1447.5959
  ssim: 0.0474
  iou: 0.1452
Layer 3 metrics:
  pearson_correlation: 0.0042
  kl_divergence: -1447.5959
  ssim: 0.0474
  iou: 0.1452

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.42270, std: 0.13995

Metrics for layer 4:
  pearson_correlation: 0.0108
  kl_divergence: -328.4099
  ssim: 0.0711
  iou: 0.1429
Layer 4 metrics:
  pearson_correlation: 0.0108
  kl_divergence: -328.4099
  ssim: 0.0711
  iou: 0.1429

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50560, std: 0.14206

Metrics for layer 5:
  pearson_correlation: 0.0148
  kl_divergence: -393.8235
  ssim: 0.0688
  iou: 0.1504
Layer 5 metrics:
  pearson_correlation: 0.0148
  kl_divergence: -393.8235
  ssim: 0.0688
  iou: 0.1504

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.52579, std: 0.13777

Metrics for layer 6:
  pearson_correlation: -0.0135
  kl_divergence: -410.5425
  ssim: 0.0515
  iou: 0.1387
Layer 6 metrics:
  pearson_correlation: -0.0135
  kl_divergence: -410.5425
  ssim: 0.0515
  iou: 0.1387

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.53212, std: 0.15933

Metrics for layer 7:
  pearson_correlation: 0.0003
  kl_divergence: -101.5437
  ssim: 0.0649
  iou: 0.1362
Layer 7 metrics:
  pearson_correlation: 0.0003
  kl_divergence: -101.5437
  ssim: 0.0649
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.50752, std: 0.13889

Metrics for layer 8:
  pearson_correlation: -0.0005
  kl_divergence: -97.9487
  ssim: 0.0547
  iou: 0.1362
Layer 8 metrics:
  pearson_correlation: -0.0005
  kl_divergence: -97.9487
  ssim: 0.0547
  iou: 0.1362

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.45407, std: 0.15997

Metrics for layer 9:
  pearson_correlation: 0.0054
  kl_divergence: -84.4232
  ssim: 0.0388
  iou: 0.1496
Layer 9 metrics:
  pearson_correlation: 0.0054
  kl_divergence: -84.4232
  ssim: 0.0388
  iou: 0.1496

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.48258, std: 0.19063

Metrics for layer 10:
  pearson_correlation: 0.0084
  kl_divergence: -15.7059
  ssim: 0.0384
  iou: 0.1807
Layer 10 metrics:
  pearson_correlation: 0.0084
  kl_divergence: -15.7059
  ssim: 0.0384
  iou: 0.1807

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.42729, std: 0.17661

Metrics for layer 11:
  pearson_correlation: 0.0180
  kl_divergence: -10.8450
  ssim: 0.1022
  iou: 0.2099
Layer 11 metrics:
  pearson_correlation: 0.0180
  kl_divergence: -10.8450
  ssim: 0.1022
  iou: 0.2099

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.62556, std: 0.17510

Metrics for layer 12:
  pearson_correlation: -0.0125
  kl_divergence: -29.0884
  ssim: 0.0634
  iou: 0.1951
Layer 12 metrics:
  pearson_correlation: -0.0125
  kl_divergence: -29.0884
  ssim: 0.0634
  iou: 0.1951
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer6/batch_0_strength_0.4_results.npy

Processing batch 2/2
Attention strength: 0.4
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.41857, std: 0.11995

Metrics for layer 0:
  pearson_correlation: 0.0019
  kl_divergence: -3741.0181
  ssim: 0.0346
  iou: 0.1448
Layer 0 metrics:
  pearson_correlation: 0.0019
  kl_divergence: -3741.0181
  ssim: 0.0346
  iou: 0.1448

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.43234, std: 0.12384

Metrics for layer 1:
  pearson_correlation: 0.0015
  kl_divergence: -3800.7322
  ssim: 0.0325
  iou: 0.1419
Layer 1 metrics:
  pearson_correlation: 0.0015
  kl_divergence: -3800.7322
  ssim: 0.0325
  iou: 0.1419

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.42473, std: 0.12616

Metrics for layer 2:
  pearson_correlation: -0.0026
  kl_divergence: -1294.7024
  ssim: 0.0546
  iou: 0.1412
Layer 2 metrics:
  pearson_correlation: -0.0026
  kl_divergence: -1294.7024
  ssim: 0.0546
  iou: 0.1412

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.46803, std: 0.13154

Metrics for layer 3:
  pearson_correlation: 0.0136
  kl_divergence: -1389.8513
  ssim: 0.0493
  iou: 0.1506
Layer 3 metrics:
  pearson_correlation: 0.0136
  kl_divergence: -1389.8513
  ssim: 0.0493
  iou: 0.1506

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.46025, std: 0.13700

Metrics for layer 4:
  pearson_correlation: -0.0231
  kl_divergence: -370.2286
  ssim: 0.0535
  iou: 0.1248
Layer 4 metrics:
  pearson_correlation: -0.0231
  kl_divergence: -370.2286
  ssim: 0.0535
  iou: 0.1248

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.48853, std: 0.14199

Metrics for layer 5:
  pearson_correlation: 0.0090
  kl_divergence: -395.6640
  ssim: 0.0485
  iou: 0.1623
Layer 5 metrics:
  pearson_correlation: 0.0090
  kl_divergence: -395.6640
  ssim: 0.0485
  iou: 0.1623

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.55347, std: 0.13495

Metrics for layer 6:
  pearson_correlation: 0.0111
  kl_divergence: -444.5768
  ssim: 0.0576
  iou: 0.1572
Layer 6 metrics:
  pearson_correlation: 0.0111
  kl_divergence: -444.5768
  ssim: 0.0576
  iou: 0.1572

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.46496, std: 0.15478

Metrics for layer 7:
  pearson_correlation: -0.0076
  kl_divergence: -84.7838
  ssim: 0.0362
  iou: 0.1136
Layer 7 metrics:
  pearson_correlation: -0.0076
  kl_divergence: -84.7838
  ssim: 0.0362
  iou: 0.1136

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.47318, std: 0.14354

Metrics for layer 8:
  pearson_correlation: -0.0006
  kl_divergence: -86.5085
  ssim: 0.0379
  iou: 0.1496
Layer 8 metrics:
  pearson_correlation: -0.0006
  kl_divergence: -86.5085
  ssim: 0.0379
  iou: 0.1496

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.48096, std: 0.16247

Metrics for layer 9:
  pearson_correlation: -0.0006
  kl_divergence: -86.0635
  ssim: 0.0347
  iou: 0.1073
Layer 9 metrics:
  pearson_correlation: -0.0006
  kl_divergence: -86.0635
  ssim: 0.0347
  iou: 0.1073

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.47108, std: 0.19446

Metrics for layer 10:
  pearson_correlation: -0.0639
  kl_divergence: -12.4166
  ssim: 0.0258
  iou: 0.1011
Layer 10 metrics:
  pearson_correlation: -0.0639
  kl_divergence: -12.4166
  ssim: 0.0258
  iou: 0.1011

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.49627, std: 0.17615

Metrics for layer 11:
  pearson_correlation: -0.0393
  kl_divergence: -19.3373
  ssim: 0.0347
  iou: 0.0889
Layer 11 metrics:
  pearson_correlation: -0.0393
  kl_divergence: -19.3373
  ssim: 0.0347
  iou: 0.0889

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.45591, std: 0.15687

Metrics for layer 12:
  pearson_correlation: 0.0564
  kl_divergence: -15.9145
  ssim: 0.0703
  iou: 0.1807
Layer 12 metrics:
  pearson_correlation: 0.0564
  kl_divergence: -15.9145
  ssim: 0.0703
  iou: 0.1807
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer6/batch_1_strength_0.4_results.npy

Processing attention strength 0.8
Attention vector: [0.  0.  0.  0.  0.  0.  0.8 0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.39707, std: 0.11318

Metrics for layer 0:
  pearson_correlation: 0.0001
  kl_divergence: -4358.2852
  ssim: 0.0581
  iou: 0.1403
Layer 0 metrics:
  pearson_correlation: 0.0001
  kl_divergence: -4358.2852
  ssim: 0.0581
  iou: 0.1403

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.36675, std: 0.09958

Metrics for layer 1:
  pearson_correlation: -0.0033
  kl_divergence: -4126.3311
  ssim: 0.0709
  iou: 0.1413
Layer 1 metrics:
  pearson_correlation: -0.0033
  kl_divergence: -4126.3311
  ssim: 0.0709
  iou: 0.1413

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.43990, std: 0.13219

Metrics for layer 2:
  pearson_correlation: -0.0028
  kl_divergence: -1345.1726
  ssim: 0.0540
  iou: 0.1431
Layer 2 metrics:
  pearson_correlation: -0.0028
  kl_divergence: -1345.1726
  ssim: 0.0540
  iou: 0.1431

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.44499, std: 0.13047

Metrics for layer 3:
  pearson_correlation: 0.0144
  kl_divergence: -1366.2034
  ssim: 0.0556
  iou: 0.1449
Layer 3 metrics:
  pearson_correlation: 0.0144
  kl_divergence: -1366.2034
  ssim: 0.0556
  iou: 0.1449

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.52630, std: 0.13825

Metrics for layer 4:
  pearson_correlation: -0.0298
  kl_divergence: -409.0574
  ssim: 0.0524
  iou: 0.1264
Layer 4 metrics:
  pearson_correlation: -0.0298
  kl_divergence: -409.0574
  ssim: 0.0524
  iou: 0.1264

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47306, std: 0.14695

Metrics for layer 5:
  pearson_correlation: 0.0243
  kl_divergence: -370.5228
  ssim: 0.0674
  iou: 0.1512
Layer 5 metrics:
  pearson_correlation: 0.0243
  kl_divergence: -370.5228
  ssim: 0.0674
  iou: 0.1512

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.53038, std: 0.14249

Metrics for layer 6:
  pearson_correlation: 0.0130
  kl_divergence: -411.5355
  ssim: 0.0550
  iou: 0.1371
Layer 6 metrics:
  pearson_correlation: 0.0130
  kl_divergence: -411.5355
  ssim: 0.0550
  iou: 0.1371

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.52545, std: 0.14251

Metrics for layer 7:
  pearson_correlation: 0.0469
  kl_divergence: -102.7028
  ssim: 0.0759
  iou: 0.1772
Layer 7 metrics:
  pearson_correlation: 0.0469
  kl_divergence: -102.7028
  ssim: 0.0759
  iou: 0.1772

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.50208, std: 0.17338

Metrics for layer 8:
  pearson_correlation: 0.0326
  kl_divergence: -95.0143
  ssim: 0.0528
  iou: 0.1598
Layer 8 metrics:
  pearson_correlation: 0.0326
  kl_divergence: -95.0143
  ssim: 0.0528
  iou: 0.1598

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.50750, std: 0.16214

Metrics for layer 9:
  pearson_correlation: 0.0928
  kl_divergence: -99.3863
  ssim: 0.0687
  iou: 0.1632
Layer 9 metrics:
  pearson_correlation: 0.0928
  kl_divergence: -99.3863
  ssim: 0.0687
  iou: 0.1632

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.44974, std: 0.16816

Metrics for layer 10:
  pearson_correlation: -0.0268
  kl_divergence: -9.5685
  ssim: 0.0162
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: -0.0268
  kl_divergence: -9.5685
  ssim: 0.0162
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.49556, std: 0.17145

Metrics for layer 11:
  pearson_correlation: -0.1017
  kl_divergence: -16.6269
  ssim: -0.0360
  iou: 0.1136
Layer 11 metrics:
  pearson_correlation: -0.1017
  kl_divergence: -16.6269
  ssim: -0.0360
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.44312, std: 0.18206

Metrics for layer 12:
  pearson_correlation: -0.0099
  kl_divergence: -18.0676
  ssim: -0.0059
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: -0.0099
  kl_divergence: -18.0676
  ssim: -0.0059
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer6/batch_0_strength_0.8_results.npy

Processing batch 2/2
Attention strength: 0.8
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.44315, std: 0.11670

Metrics for layer 0:
  pearson_correlation: 0.0021
  kl_divergence: -3862.5420
  ssim: 0.0343
  iou: 0.1429
Layer 0 metrics:
  pearson_correlation: 0.0021
  kl_divergence: -3862.5420
  ssim: 0.0343
  iou: 0.1429

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.39218, std: 0.11578

Metrics for layer 1:
  pearson_correlation: -0.0045
  kl_divergence: -3611.1943
  ssim: 0.0384
  iou: 0.1414
Layer 1 metrics:
  pearson_correlation: -0.0045
  kl_divergence: -3611.1943
  ssim: 0.0384
  iou: 0.1414

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.43849, std: 0.12845

Metrics for layer 2:
  pearson_correlation: -0.0037
  kl_divergence: -1322.5798
  ssim: 0.0530
  iou: 0.1441
Layer 2 metrics:
  pearson_correlation: -0.0037
  kl_divergence: -1322.5798
  ssim: 0.0530
  iou: 0.1441

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.47691, std: 0.13753

Metrics for layer 3:
  pearson_correlation: 0.0042
  kl_divergence: -1403.4351
  ssim: 0.0410
  iou: 0.1404
Layer 3 metrics:
  pearson_correlation: 0.0042
  kl_divergence: -1403.4351
  ssim: 0.0410
  iou: 0.1404

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.46191, std: 0.15153

Metrics for layer 4:
  pearson_correlation: -0.0065
  kl_divergence: -368.9003
  ssim: 0.0488
  iou: 0.1512
Layer 4 metrics:
  pearson_correlation: -0.0065
  kl_divergence: -368.9003
  ssim: 0.0488
  iou: 0.1512

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.50344, std: 0.13806

Metrics for layer 5:
  pearson_correlation: -0.0092
  kl_divergence: -406.4167
  ssim: 0.0535
  iou: 0.1362
Layer 5 metrics:
  pearson_correlation: -0.0092
  kl_divergence: -406.4167
  ssim: 0.0535
  iou: 0.1362

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.51343, std: 0.13449

Metrics for layer 6:
  pearson_correlation: 0.0004
  kl_divergence: -414.6082
  ssim: 0.0519
  iou: 0.1420
Layer 6 metrics:
  pearson_correlation: 0.0004
  kl_divergence: -414.6082
  ssim: 0.0519
  iou: 0.1420

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.51200, std: 0.15739

Metrics for layer 7:
  pearson_correlation: -0.0565
  kl_divergence: -91.0510
  ssim: 0.0287
  iou: 0.1200
Layer 7 metrics:
  pearson_correlation: -0.0565
  kl_divergence: -91.0510
  ssim: 0.0287
  iou: 0.1200

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.43250, std: 0.16178

Metrics for layer 8:
  pearson_correlation: 0.0251
  kl_divergence: -79.7869
  ssim: 0.0459
  iou: 0.1632
Layer 8 metrics:
  pearson_correlation: 0.0251
  kl_divergence: -79.7869
  ssim: 0.0459
  iou: 0.1632

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.52887, std: 0.14625

Metrics for layer 9:
  pearson_correlation: -0.0173
  kl_divergence: -92.8076
  ssim: 0.0367
  iou: 0.1395
Layer 9 metrics:
  pearson_correlation: -0.0173
  kl_divergence: -92.8076
  ssim: 0.0367
  iou: 0.1395

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.47584, std: 0.18066

Metrics for layer 10:
  pearson_correlation: -0.1491
  kl_divergence: -14.7586
  ssim: -0.1090
  iou: 0.1136
Layer 10 metrics:
  pearson_correlation: -0.1491
  kl_divergence: -14.7586
  ssim: -0.1090
  iou: 0.1136

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.42420, std: 0.19158

Metrics for layer 11:
  pearson_correlation: -0.0475
  kl_divergence: -11.8995
  ssim: -0.0041
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: -0.0475
  kl_divergence: -11.8995
  ssim: -0.0041
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.47454, std: 0.17477

Metrics for layer 12:
  pearson_correlation: -0.0510
  kl_divergence: -16.8141
  ssim: -0.0106
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: -0.0510
  kl_divergence: -16.8141
  ssim: -0.0106
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer6/batch_1_strength_0.8_results.npy

Processing attention strength 1.2
Attention vector: [0.  0.  0.  0.  0.  0.  1.2 0.  0.  0.  0.  0.  0. ]

Processing batch 1/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.45221, std: 0.12679

Metrics for layer 0:
  pearson_correlation: -0.0048
  kl_divergence: -4755.1392
  ssim: 0.0416
  iou: 0.1425
Layer 0 metrics:
  pearson_correlation: -0.0048
  kl_divergence: -4755.1392
  ssim: 0.0416
  iou: 0.1425

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.06079, std: 0.06400
Attention - min: 0.00000, max: 1.00000, mean: 0.42086, std: 0.12131

Metrics for layer 1:
  pearson_correlation: 0.0018
  kl_divergence: -4529.6157
  ssim: 0.0501
  iou: 0.1440
Layer 1 metrics:
  pearson_correlation: 0.0018
  kl_divergence: -4529.6157
  ssim: 0.0501
  iou: 0.1440

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.44039, std: 0.12951

Metrics for layer 2:
  pearson_correlation: 0.0015
  kl_divergence: -1350.0283
  ssim: 0.0602
  iou: 0.1327
Layer 2 metrics:
  pearson_correlation: 0.0015
  kl_divergence: -1350.0283
  ssim: 0.0602
  iou: 0.1327

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07963, std: 0.07093
Attention - min: 0.00000, max: 1.00000, mean: 0.44993, std: 0.12075

Metrics for layer 3:
  pearson_correlation: 0.0107
  kl_divergence: -1383.2537
  ssim: 0.0645
  iou: 0.1462
Layer 3 metrics:
  pearson_correlation: 0.0107
  kl_divergence: -1383.2537
  ssim: 0.0645
  iou: 0.1462

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.50617, std: 0.15298

Metrics for layer 4:
  pearson_correlation: -0.0184
  kl_divergence: -390.4158
  ssim: 0.0537
  iou: 0.1289
Layer 4 metrics:
  pearson_correlation: -0.0184
  kl_divergence: -390.4158
  ssim: 0.0537
  iou: 0.1289

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.47008, std: 0.14176

Metrics for layer 5:
  pearson_correlation: -0.0056
  kl_divergence: -364.9849
  ssim: 0.0569
  iou: 0.1479
Layer 5 metrics:
  pearson_correlation: -0.0056
  kl_divergence: -364.9849
  ssim: 0.0569
  iou: 0.1479

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11024, std: 0.10024
Attention - min: 0.00000, max: 1.00000, mean: 0.48958, std: 0.12581

Metrics for layer 6:
  pearson_correlation: 0.0020
  kl_divergence: -387.9091
  ssim: 0.0606
  iou: 0.1371
Layer 6 metrics:
  pearson_correlation: 0.0020
  kl_divergence: -387.9091
  ssim: 0.0606
  iou: 0.1371

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.45902, std: 0.15082

Metrics for layer 7:
  pearson_correlation: -0.0842
  kl_divergence: -82.9460
  ssim: 0.0426
  iou: 0.0980
Layer 7 metrics:
  pearson_correlation: -0.0842
  kl_divergence: -82.9460
  ssim: 0.0426
  iou: 0.0980

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.47794, std: 0.13775

Metrics for layer 8:
  pearson_correlation: 0.0298
  kl_divergence: -91.4433
  ssim: 0.0797
  iou: 0.1462
Layer 8 metrics:
  pearson_correlation: 0.0298
  kl_divergence: -91.4433
  ssim: 0.0797
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.12111, std: 0.11528
Attention - min: 0.00000, max: 1.00000, mean: 0.48781, std: 0.15682

Metrics for layer 9:
  pearson_correlation: 0.0052
  kl_divergence: -93.3995
  ssim: 0.0425
  iou: 0.1200
Layer 9 metrics:
  pearson_correlation: 0.0052
  kl_divergence: -93.3995
  ssim: 0.0425
  iou: 0.1200

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.50586, std: 0.18843

Metrics for layer 10:
  pearson_correlation: 0.0682
  kl_divergence: -18.5318
  ssim: 0.0951
  iou: 0.1951
Layer 10 metrics:
  pearson_correlation: 0.0682
  kl_divergence: -18.5318
  ssim: 0.0951
  iou: 0.1951

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.48397, std: 0.20609

Metrics for layer 11:
  pearson_correlation: -0.0205
  kl_divergence: -13.5895
  ssim: 0.0450
  iou: 0.1264
Layer 11 metrics:
  pearson_correlation: -0.0205
  kl_divergence: -13.5895
  ssim: 0.0450
  iou: 0.1264

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.16107, std: 0.13879
Attention - min: 0.00000, max: 1.00000, mean: 0.46510, std: 0.22080

Metrics for layer 12:
  pearson_correlation: -0.0551
  kl_divergence: -18.0897
  ssim: -0.0565
  iou: 0.1395
Layer 12 metrics:
  pearson_correlation: -0.0551
  kl_divergence: -18.0897
  ssim: -0.0565
  iou: 0.1395
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.06079, std=0.06400
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer6/batch_0_strength_1.2_results.npy

Processing batch 2/2
Attention strength: 1.2
Generating tuning curve attention maps...
Successfully generated 13 attention maps
Computing saliency maps...
Saliency statistics: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0
Saliency map shape: (1, 224, 224)
Non-zero elements: 50175
Value range: 0.0 - 1.0

=== Debug Shapes After saliency computation ===
Saliency map shape: (1, 224, 224)
Attention map 0 shape: (1, 224, 224, 64)
Attention map 1 shape: (1, 224, 224, 64)
Attention map 2 shape: (1, 112, 112, 128)
Attention map 3 shape: (1, 112, 112, 128)
Attention map 4 shape: (1, 56, 56, 256)
Attention map 5 shape: (1, 56, 56, 256)
Attention map 6 shape: (1, 56, 56, 256)
Attention map 7 shape: (1, 28, 28, 512)
Attention map 8 shape: (1, 28, 28, 512)
Attention map 9 shape: (1, 28, 28, 512)
Attention map 10 shape: (1, 14, 14, 512)
Attention map 11 shape: (1, 14, 14, 512)
Attention map 12 shape: (1, 14, 14, 512)
Successfully generated saliency maps
Comparing saliency and attention maps...

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.42740, std: 0.11549

Metrics for layer 0:
  pearson_correlation: 0.0025
  kl_divergence: -3789.8740
  ssim: 0.0361
  iou: 0.1450
Layer 0 metrics:
  pearson_correlation: 0.0025
  kl_divergence: -3789.8740
  ssim: 0.0361
  iou: 0.1450

After resizing:
Target shape: (224, 224)
Saliency map shape: (224, 224)
Attention map shape: (224, 224)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.03700, std: 0.03738
Attention - min: 0.00000, max: 1.00000, mean: 0.41185, std: 0.11880

Metrics for layer 1:
  pearson_correlation: 0.0030
  kl_divergence: -3708.9744
  ssim: 0.0354
  iou: 0.1482
Layer 1 metrics:
  pearson_correlation: 0.0030
  kl_divergence: -3708.9744
  ssim: 0.0354
  iou: 0.1482

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.41685, std: 0.13149

Metrics for layer 2:
  pearson_correlation: 0.0104
  kl_divergence: -1274.5818
  ssim: 0.0539
  iou: 0.1408
Layer 2 metrics:
  pearson_correlation: 0.0104
  kl_divergence: -1274.5818
  ssim: 0.0539
  iou: 0.1408

After resizing:
Target shape: (112, 112)
Saliency map shape: (112, 112)
Attention map shape: (112, 112)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07117, std: 0.06162
Attention - min: 0.00000, max: 1.00000, mean: 0.45439, std: 0.13305

Metrics for layer 3:
  pearson_correlation: -0.0104
  kl_divergence: -1353.9106
  ssim: 0.0464
  iou: 0.1410
Layer 3 metrics:
  pearson_correlation: -0.0104
  kl_divergence: -1353.9106
  ssim: 0.0464
  iou: 0.1410

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47387, std: 0.12237

Metrics for layer 4:
  pearson_correlation: -0.0171
  kl_divergence: -387.7816
  ssim: 0.0637
  iou: 0.1445
Layer 4 metrics:
  pearson_correlation: -0.0171
  kl_divergence: -387.7816
  ssim: 0.0637
  iou: 0.1445

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.47752, std: 0.14460

Metrics for layer 5:
  pearson_correlation: 0.0190
  kl_divergence: -387.9899
  ssim: 0.0611
  iou: 0.1387
Layer 5 metrics:
  pearson_correlation: 0.0190
  kl_divergence: -387.9899
  ssim: 0.0611
  iou: 0.1387

After resizing:
Target shape: (56, 56)
Saliency map shape: (56, 56)
Attention map shape: (56, 56)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.11423, std: 0.10009
Attention - min: 0.00000, max: 1.00000, mean: 0.46734, std: 0.13320

Metrics for layer 6:
  pearson_correlation: 0.0038
  kl_divergence: -379.5356
  ssim: 0.0570
  iou: 0.1429
Layer 6 metrics:
  pearson_correlation: 0.0038
  kl_divergence: -379.5356
  ssim: 0.0570
  iou: 0.1429

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.51222, std: 0.15271

Metrics for layer 7:
  pearson_correlation: -0.0118
  kl_divergence: -89.3107
  ssim: 0.0407
  iou: 0.1462
Layer 7 metrics:
  pearson_correlation: -0.0118
  kl_divergence: -89.3107
  ssim: 0.0407
  iou: 0.1462

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.49294, std: 0.16897

Metrics for layer 8:
  pearson_correlation: -0.0944
  kl_divergence: -86.6432
  ssim: 0.0120
  iou: 0.1329
Layer 8 metrics:
  pearson_correlation: -0.0944
  kl_divergence: -86.6432
  ssim: 0.0120
  iou: 0.1329

After resizing:
Target shape: (28, 28)
Saliency map shape: (28, 28)
Attention map shape: (28, 28)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.07594, std: 0.07019
Attention - min: 0.00000, max: 1.00000, mean: 0.51776, std: 0.15974

Metrics for layer 9:
  pearson_correlation: 0.0492
  kl_divergence: -91.7729
  ssim: 0.0356
  iou: 0.1737
Layer 9 metrics:
  pearson_correlation: 0.0492
  kl_divergence: -91.7729
  ssim: 0.0356
  iou: 0.1737

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.44097, std: 0.17827

Metrics for layer 10:
  pearson_correlation: 0.1466
  kl_divergence: -15.7385
  ssim: 0.1788
  iou: 0.1529
Layer 10 metrics:
  pearson_correlation: 0.1466
  kl_divergence: -15.7385
  ssim: 0.1788
  iou: 0.1529

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.49590, std: 0.17501

Metrics for layer 11:
  pearson_correlation: -0.0653
  kl_divergence: -16.1891
  ssim: -0.0319
  iou: 0.1951
Layer 11 metrics:
  pearson_correlation: -0.0653
  kl_divergence: -16.1891
  ssim: -0.0319
  iou: 0.1951

After resizing:
Target shape: (14, 14)
Saliency map shape: (14, 14)
Attention map shape: (14, 14)

Normalized maps statistics:
Saliency - min: 0.00000, max: 1.00000, mean: 0.18658, std: 0.16890
Attention - min: 0.00000, max: 1.00000, mean: 0.43681, std: 0.18710

Metrics for layer 12:
  pearson_correlation: 0.0447
  kl_divergence: -14.0967
  ssim: -0.0107
  iou: 0.1667
Layer 12 metrics:
  pearson_correlation: 0.0447
  kl_divergence: -14.0967
  ssim: -0.0107
  iou: 0.1667
Analyzing attention effects...
Computing baseline responses...
Computing responses with attention...

Creating feed dict:

Creating feed dict:
Successfully analyzed attention effects
Generating visualizations...
Saliency (final) stats at visualization: min=0.00000, max=1.00000, mean=0.03700, std=0.03738
Saved visualization for image 0
Saved batch results to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer6/batch_1_strength_1.2_results.npy

Analysis complete! Results saved to /scratch/hy2611/CNN_attention/Data/VGG16/attention_results_cat5_layer6
